[["Map",1,2,9,10,1635,1636,1654,1655,1670,1671],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.5","content-config-digest","44bd13e67cfcf995","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://sanyuesha.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null],\"rehypePlugins\":[null],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","posts",["Map",11,12,27,28,43,44,55,56,71,72,83,84,95,96,108,109,119,120,134,135,144,145,154,155,167,168,178,179,189,190,202,203,216,217,229,230,241,242,253,254,265,266,277,278,290,291,302,303,315,316,327,328,341,342,352,353,363,364,375,376,386,387,400,401,412,413,424,425,434,435,446,447,457,458,468,469,479,480,490,491,500,501,511,512,521,522,532,533,542,543,552,553,565,566,577,578,589,590,601,602,613,614,625,626,637,638,649,650,662,663,674,675,686,687,698,699,711,712,723,724,735,736,746,747,757,758,768,769,780,781,792,793,804,805,817,818,830,831,841,842,852,853,864,865,876,877,889,890,900,901,911,912,922,923,934,935,946,947,957,958,971,972,982,983,993,994,1005,1006,1017,1018,1030,1031,1042,1043,1053,1054,1065,1066,1076,1077,1088,1089,1099,1100,1109,1110,1121,1122,1133,1134,1145,1146,1156,1157,1168,1169,1180,1181,1193,1194,1204,1205,1216,1217,1228,1229,1239,1240,1251,1252,1263,1264,1276,1277,1287,1288,1299,1300,1311,1312,1322,1323,1334,1335,1345,1346,1356,1357,1367,1368,1378,1379,1390,1391,1402,1403,1414,1415,1425,1426,1436,1437,1447,1448,1460,1461,1471,1472,1483,1484,1495,1496,1506,1507,1518,1519,1532,1533,1545,1546,1555,1556,1566,1567,1578,1579,1588,1589,1599,1600,1612,1613,1624,1625],"deep-dive-react-rendering",{"id":11,"data":13,"body":23,"filePath":24,"digest":25,"legacyId":26,"deferredRender":22},{"title":14,"summary":15,"date":16,"tags":17,"group":21,"featured":22},"深入理解 React 的渲染","React 如何将组件翻译成 DOM tree，涉及 reconcile、commit 与常见性能优化思路。",["Date","2024-09-03T00:00:00.000Z"],[18,19,20],"react","rendering","performance","技术分享",true,"React 是一个 UI Library，用来把组件翻译成 DOM。流程可抽象为两个阶段：\n\n1. **Render/Reconcile**：对比虚拟树，计算需要变更的节点与属性。\n2. **Commit**：把变更应用到 DOM（或宿主），同步副作用。\n\n常见优化方向：\n\n- 合理拆分组件、用 `memo` 避免不必要渲染\n- 使用 `useTransition`、`Suspense` 改善交互流畅性\n- 列表类组件关注 key 与分页/虚拟化\n\n接下来会在站点里持续记录实践案例。","src/content/posts/deep-dive-react-rendering.mdx","7978c6ad685a3260","deep-dive-react-rendering.mdx","frontend-sre-notes",{"id":27,"data":29,"body":39,"filePath":40,"digest":41,"legacyId":42,"deferredRender":22},{"title":30,"summary":31,"date":32,"tags":33,"group":37,"featured":38},"前端 SRE 思考：可观测性与发布节奏","如何给前端加入可观测性、发布闸口与回滚策略，降低线上风险。",["Date","2024-08-12T00:00:00.000Z"],[34,35,36],"sre","frontend","release","思考",false,"前端的 SRE 思路与后端类似，但更关注体验与灰度：\n\n- 指标：FCP、LCP、CLS、错误率、请求成功率、缓存命中率\n- 阶段：预发布监控、灰度分流、快速回滚、事后复盘\n- 工具：前端埋点、RUM、CI 自动化 smoke、`canary` 策略\n\n我的基本原则是「**先可观测，再快迭代**」。","src/content/posts/frontend-sre-notes.mdx","a8bd29702041adc8","frontend-sre-notes.mdx","10-things-you-dont-know-about-go",{"id":43,"data":45,"body":51,"filePath":52,"digest":53,"legacyId":54,"deferredRender":22},{"title":46,"summary":47,"date":48,"tags":49,"group":50,"featured":38},"关于 Golang 你可能不知道的几件事","> 本文翻译自 https://talks.golang.org/2012/10things.slide",["Date","2019-08-01T00:00:00.000Z"],[50],"golang","> 本文翻译自 https://talks.golang.org/2012/10things.slide\n\n\n## 1. 匿名 struct\n\n\n**聚集全局变量 Grouped globals**\n\n```golang\nvar config struct {\n    APIKey      string\n    OAuthConfig oauth.Config\n}\n\nconfig.APIKey = \"BADC0C0A\"\n```\n\n**模板数据 Template data**\n\n```golang\ndata := struct {\n    Title string\n    Users []*User\n}{\n    title,\n    users,\n}\nerr := tmpl.Execute(w, data)\n\n```\n\n\n**组织测试数据 Test tables**\n\n```golang\nvar indexRuneTests = []struct {\n    s    string\n    rune rune\n    out  int\n}{\n    {\"a A x\", 'A', 2},\n    {\"some_text=some_value\", '=', 9},\n    {\"☺a\", 'a', 3},\n    {\"a☻☺b\", '☺', 4},\n}\n\n```\n\n**嵌入式 lock Embeded lock**\n\n```golang\nvar hits struct {\n    sync.Mutex\n    n int\n}\n\nhits.Lock()\nhits.n++\nhits.Unlock()\n\n```\n\n\n## 2. 嵌套 struct\n\n嵌套 JSON 解析 Decoding deeply nested JSON data \n\n\n```golang\n{\"data\": {\"children\": [\n  {\"data\": {\n    \"title\": \"The Go homepage\",\n    \"url\": \"http://golang.org/\"\n  }},\n  ...\n]}}\n\ntype Item struct {\n    Title string\n    URL   string\n}\n\ntype Response struct {\n    Data struct {\n        Children []struct {\n            Data Item\n        }\n    }\n}\n```\n\n\n## 3. 命令行 doc \n\n\n```bash\n// Mutex 文档\n% godoc sync Mutex\n\n// 显示私有变量\n% godoc -src sync Mutex\n\n```\n\n\n## 4. mock 文件系统\n\n```golang\n\nvar fs fileSystem = osFS{}\n\ntype fileSystem interface {\n    Open(name string) (file, error)\n    Stat(name string) (os.FileInfo, error)\n}\n\ntype file interface {\n    io.Closer\n    io.Reader\n    io.ReaderAt\n    io.Seeker\n    Stat() (os.FileInfo, error)\n}\n\n// osFS implements fileSystem using the local disk.\ntype osFS struct{}\n\nfunc (osFS) Open(name string) (file, error)        { return os.Open(name) }\nfunc (osFS) Stat(name string) (os.FileInfo, error) { return os.Stat(name) }\n\n```\n\n\n## 5. 方法表达式\n\n```golang\ntype T struct {}\nfunc (T) Foo(s string) { println(s) }\n\nvar fn func(T, string) = T.Foo\n```\n\n\n```golang\nfunc (c *Cmd) stdin() (f *os.File, err error)\nfunc (c *Cmd) stdout() (f *os.File, err error)\nfunc (c *Cmd) stderr() (f *os.File, err error)\ntype F func(*Cmd) (*os.File, error)\nfor _, setupFd := range []F{(*Cmd).stdin, (*Cmd).stdout, (*Cmd).stderr} {\n    fd, err := setupFd(c)\n    if err != nil {\n        c.closeDescriptors(c.closeAfterStart)\n        c.closeDescriptors(c.closeAfterWait)\n        return err\n    }\n    c.childFiles = append(c.childFiles, fd)\n}\n```\n\n\n## 6. 同一个 channel 发送和接受\n\n\n```golang\n\npackage main\n\nimport \"fmt\"\n\nvar battle = make(chan string)\n\nfunc warrior(name string, done chan struct{}) {\n    select {\n    case opponent := \u003C-battle:\n        fmt.Printf(\"%s beat %s\\n\", name, opponent)\n    case battle \u003C- name:\n        // I lost :-(\n    }\n    done \u003C- struct{}{}\n}\n\nfunc main() {\n    done := make(chan struct{})\n    langs := []string{\"Go\", \"C\", \"C++\", \"Java\", \"Perl\", \"Python\"}\n    for _, l := range langs { go warrior(l, done) }\n    for _ = range langs { \u003C-done }\n}\n\n```\n\n## 7. 使用 close channel 完成广播\n\n\n```golang\nfunc waiter(i int, block, done chan struct{}) {\n    time.Sleep(time.Duration(rand.Intn(3000)) * time.Millisecond)\n    fmt.Println(i, \"waiting...\")\n    \u003C-block\n    fmt.Println(i, \"done!\")\n    done \u003C- struct{}{}\n}\n\nfunc main() {\n    block, done := make(chan struct{}), make(chan struct{})\n    for i := 0; i \u003C 4; i++ {\n        go waiter(i, block, done)\n    }\n    time.Sleep(5 * time.Second)\n    close(block)\n    for i := 0; i \u003C 4; i++ {\n        \u003C-done\n    }\n}\n\n```\n\n\n```golang\n\nfunc worker(i int, ch chan Work, quit chan struct{}) {\n    var quitting bool\n    for {\n        select {\n        case w := \u003C-ch:\n            if quitting {\n                w.Refuse(); fmt.Println(\"worker\", i, \"refused\", w)\n                break\n            }\n            w.Do(); fmt.Println(\"worker\", i, \"processed\", w)\n        case \u003C-quit:\n            fmt.Println(\"worker\", i, \"quitting\")\n            quitting = true\n        }\n    }\n}\n\nfunc main() {\n    ch, quit := make(chan Work), make(chan struct{})\n    go makeWork(ch)\n    for i := 0; i \u003C 4; i++ { go worker(i, ch, quit) }\n    time.Sleep(5 * time.Second)\n    close(quit)\n    time.Sleep(2 * time.Second)\n}\n```\n\n\n## 8. select 中的 nil\n\n```golang\n\nfunc worker(i int, ch chan Work, quit chan struct{}) {\n    for {\n        select {\n        case w := \u003C-ch:\n            if quit == nil {\n                w.Refuse(); fmt.Println(\"worker\", i, \"refused\", w)\n                break\n            }\n            w.Do(); fmt.Println(\"worker\", i, \"processed\", w)\n        case \u003C-quit:\n            fmt.Println(\"worker\", i, \"quitting\")\n            quit = nil\n        }\n    }\n}\n\nfunc main() {\n    ch, quit := make(chan Work), make(chan struct{})\n    go makeWork(ch)\n    for i := 0; i \u003C 4; i++ { go worker(i, ch, quit) }\n    time.Sleep(5 * time.Second)\n    close(quit)\n    time.Sleep(2 * time.Second)\n}\n\n```","src/content/posts/10-things-you-dont-know-about-Go.mdx","5083a8519209a70f","10-things-you-dont-know-about-Go.mdx","2017-css-framework",{"id":55,"data":57,"body":67,"filePath":68,"digest":69,"legacyId":70,"deferredRender":22},{"title":58,"summary":59,"date":60,"tags":61,"group":66,"featured":38},"开发中常用的 CSS framework（2015年至今）","自 bootstrap CSS framework 已经成了开发者必不可少的技术选型了，随着移动端的不断发展和日趋复杂化的 UI 交互模式的需要，适应各种场景的 CSS framework 也层出不穷，在此盘点一下个人日常开发时选择的几种 CSS framework，排名不分先后...",["Date","2017-05-25T00:00:00.000Z"],[62,63,64,65],"bulma","purecss","semantic-ui","tachyons","css","自 bootstrap CSS framework 已经成了开发者必不可少的技术选型了，随着移动端的不断发展和日趋复杂化的 UI 交互模式的需要，适应各种场景的 CSS framework 也层出不穷，在此盘点一下个人日常开发时选择的几种 CSS framework，排名不分先后。\n\n## [purecss](https://purecss.io/)\n\n### 优点\n\n简单实用响应式，提供了 grid 布局、form、menu、 button、table 几种常用组件，无 JavaScript。\n\n### 适用场景\n\n页面所需组件比较少，适用于只需要比较简单的 form 以及很基础的交互，中大型项目不适合，缺 JavaScript，需要借助第三方 JavaScript 或者自己实现，开发效率差。\n\n- https://git-star.com/\n\n## [bulma](https://github.com/jgthms/bulma/)\n\n龙珠布尔玛的英文名字？好像是。\n\n### 优点\n\nmobile first、语义化、模块化、html 结构简洁明确，提供了大量基础性组件，甚至是一般做官方网站使用的 banner、hexo 都有，可以快速构建官网等非常常用的网站样式。\n\n提供了一些非常基础的工具化 class，比如 [modifiers](http://bulma.io/documentation/modifiers/syntax/) 可以直接修改内边距、外边距、边框都常需要改动的地方，非常实用。\n\n开发者友好。\n\n{/* more */}\n\n### 适用场景\n\n官网、活动性页面、大中型项目，缺乏 JavaScript，动态的部分需要自己实现，现在大多数项目都会用第三方 JavaScript framework，bulma 非常容易借助 react、angular、vuejs、emberjs 实现自己的 UI components，这得意于 bulma 本身的组件化和模块化，以及便捷地覆写和修改机制。\n\n- https://github.com/vue-bulma/vue-admin vue bulma\n- https://github.com/bokuweb/re-bulma react bulma\n\n## [tachyons](http://tachyons.io/)\n\n### 优点\n\n无意中发现这货，class 名称非常难看，语义化也差，但是组件能组合出各式各样的 UI 以及布局，非常神奇，有大量现成的已经组合好的 component 供使用。\n\n无 JavaScript。\n\n### 适用场景\n\n能够够最快速的做成常见网站的样式，class 名称语义化差，开发者不友好。\n\n## [semantic-ui](https://semantic-ui.com/)\n\n### 优点\n\n正如其名，semantic 语义化很好，提供了大量常用的组件，能够实现各种组合形成更丰富的组件，而且官方提供了 ember、react 的版本。\n\n基于 jQuery。\n\n### 适用场景\n\n大中型类 CMS 项目非常适合，提供了大量常用组件，包含 JavaScript，但是其覆盖没有 bulma 容易，学习成本高，一旦理解其常用组件结构，使用非常方便。\n\nsemantic-ui 性能稍差，在性能要求高的场景慎用。\n\nsemantic-ui 引用了 Google fonts，在国内网络环境中最好去掉。\n\n- https://github.com/wecatch/ember-semantic-ui\n- https://github.com/Semantic-Org/Semantic-UI-React\n- https://github.com/Semantic-Org/Semantic-UI-Ember","src/content/posts/2017-css-framework.mdx","41f4d742e1e1b770","2017-css-framework.mdx","about-api",{"id":71,"data":73,"body":79,"filePath":80,"digest":81,"legacyId":82,"deferredRender":22},{"title":74,"summary":75,"date":76,"tags":77,"group":78,"featured":38},"说说 API 这个事","移动互联网盛行之前， RESTful API 就已经存在很久了，只不过恰巧移动桌面的的兴起让 RESTful API 变成了几乎任何需要联网设备的标配，它的普及也正好证明了它的重要性程度是和它的普及程度是一样的。虽然没有专门的厂商来定义 RESTful API 的标准，但是得意于...",["Date","2017-11-19T00:00:00.000Z"],[],"技术","移动互联网盛行之前， RESTful API 就已经存在很久了，只不过恰巧移动桌面的的兴起让 RESTful API 变成了几乎任何需要联网设备的标配，它的普及也正好证明了它的重要性程度是和它的普及程度是一样的。虽然没有专门的厂商来定义 RESTful API 的标准，但是得意于大平台的垄断和其 API 使用范围的广泛性，大平台出品的开放式 API 几乎就可以成为一种标准，所以想要把你的 API 设计的更标准一点，参考一下主流开放平台的 API 即可，那些可参考的平台包括但不限于：twitter、Facebook、github、Yahoo、Google 等。\n\n不论提供什么内容或服务的 API 从其诞生起一般要经历：定义设计、测试、上线、升级、维护等几个阶段，而 API 作为一种消费品不得不需要进行非常清晰的定义和描述才能真正投入实际生产使用，这就需要 API的定义 层级清晰，分组合理，文档美观，测试方便，升级容易。而 RESTFul 经过移动互联网的洗礼已经衍生出了很多解决方案来达到上述目的，甚至有的公司基于此已经成功做成了一桩大生意悄悄地发财，比如卖身 Oracle 的 [apiary.io](https://apiary.io/)。\n\n\n# 标准\n\n虽然大厂的 API 可以参考成为一种标准，但是每次设计 API 都去翻翻大厂的文档显得真有点太逊了点，[OpenAPI](https://github.com/OAI) 和 [swagger-ui](https://swagger.io/) 提供了关于 API 定义的标准，前者是 API 设计的一些规约，后者是基于此规约实现的自动化 API 文档和测试工具。有了这两者，你再也不会为了把 API 定义的更标准更通用而去和消费 API 的 开发者讨价还价了。\n\n除了 swagger 其他一些 API 工具厂商也会提供一些轮子做 API 设计和文档的工具，比如 apiary 有 https://github.com/apiaryio/api-blueprint ，api-blueprint 定义了一种描述 API 的语言，这种语言更高阶，更合适开发者抒写和定义，这种语言也称之为领域驱动语言，是用来专门描述特定领域内容的高阶语言。api-blueprint 会把描述的 API 自动转换更有利于开发者的形式，类似 swagger-ui 那样。\n\n- https://github.com/OAI\n- https://swagger.io/\n- https://github.com/apiaryio/api-blueprint\n\n\n# 文档\n\nswagger-ui 在遵循 OAI 的同时其自身就是非常美观的 API 文档工具，swagger 支持的是 **YML**格式的描述，而 api-blueprint 是 **markdown** 格式，相比 swagger 更容易抒写。\n\n![swagger](https://static.git-star.com/15122829585a239b4e911d4.png)\n![swagger](https://static.git-star.com/15122828935a239b0d0b99e.png)\n\napi-blueprint 只提供了对 API 的描述，要根据它的描述输出好看的文档还需要借助支持这种语言的工具，在 api-blueprint 的官方提供了一些工具可以很好的完成文档的解析和渲染。\n\n- https://github.com/danielgtaylor/aglio\n- https://github.com/bukalapak/snowboard\n\n![snowboard](https://static.git-star.com/WX20171202-134256@2x.png)\n\n![aglio](https://static.git-star.com/WX20171203-142635@2x.png)\n\n更多选择可以看 https://apiblueprint.org/tools.html# \n\n# 测试\n\nAPI 的测试是和 API 的定义密不可分的，拥有好的 API 定义是可以让 API 测试事半功倍的，一般的 API 设计工具都都会提供简单的 API 测试，也有专门的服务只提供相应的 API 测试服务比如 https://runscope.com/ ，API 测试也有不少开源的解决方案，比如网易的 https://github.com/NEYouFan/nei-toolkit ，这儿工具就集 API 定义、mock、测试与一体，wecatch 也自己实现过一个 API 测试工具 https://github.com/wecatch/turbo-api-test ，使用 yml 描述，利用 Python 的 unittest 自动生成测试套件并且汇报测试结果，我们已经在生产环境使用了，很轻便。\n\n- [runscope](https://runscope.com/)\n- [nei-toolkit](https://github.com/NEYouFan/nei-toolkit)\n- [turbo-api-test](https://github.com/wecatch/turbo-api-test)\n\n# 监控\n\n监控可以理解为对生产环境 API 持续不断的测试并汇报健康状态，所以监控又是和测试密不可分的，不过不同于测试，对生成环境测试就需要注意不同 HTTP method 对产生的副作用，尤其是 POST 这种非幂等方法要非常谨慎使用，而当初 wecatch 造 [turbo-api-test](https://github.com/wecatch/turbo-api-test) 一方面是为了测试，另一方面也是为了可以配合 [zabbix](https://www.zabbix.com/) 对生产环境的 API 健康状态进行监控和报警。\n\n# 选择合适的一套工具\n\n任何时候当你开始新的服务准备好开始新的 API 之前一定要根据自己的需要选择一整套完整的方案，从定义、文档、测试、监控都要面面俱到，并让团队所有人都遵循这一套规范，如此才能在 API 的整个生命周期之内无论团队成员如何变化，或者业务如何变化都能游刃有余解决 API 的一切问题。\n\n\n# 资源\n\n- [Swagger从入门到精通](https://www.gitbook.com/book/huangwenchao/swagger/details)","src/content/posts/about-api.mdx","26d147699565e57e","about-api.mdx","airflow",{"id":83,"data":85,"body":91,"filePath":92,"digest":93,"legacyId":94,"deferredRender":22},{"title":86,"summary":87,"date":88,"tags":89,"group":90,"featured":38},"使用 airflow 替代你的 crontab","# Airflow 是什么",["Date","2017-11-13T00:00:00.000Z"],[83],"大数据","# Airflow 是什么\n\nAirflow 是 Airbnb 开发的用于工作流管理的开源项目，自带 UI，现在 Apache 下做孵化，地址是https://github.com/apache/incubator-airflow\n\n![airflow](http://airflow.incubator.apache.org/_images/airflow.gif)\n\n# Airflow 解决什么问题\n\nAirflow 主要解决的问题可以参考 Airbnb 官方的博客: [airflow-a-workflow-management-platform](https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8)，简单来说就是管理和调度各种离线定时 Job ，可以替代 crontab。\n\n当 cron job 规模达到数百上千时，其对人的要求将会非常高的，如果你的团队经历过这样的事情，应该能体会其中痛苦，所以使用类似 airflow 这样的工具代替 cron 来做定时任务将会极大提高工作效率。\n\n{/* more */}\n\n# 开始使用 airflow 之前需要知道和准备的\n\nAirflow 在 pip 上已经更名为 `apache-airflow`，下载最新版请使用后者 `pip install apache-airflow`。\n\nAirflow 1.8 版本依赖的是 MySQL 5.6 以上，5.7 以下报 `1071, u'Specified key was too long; max key length is 767 bytes`，如果你使用 MySQL 作为你的 airflow backend 请升级你的 MySQL 到最新版。\n\nMySQL 5.6 升级到 5.7 在使用 airflow 时会报 `1146, u\"Table 'performance_schema.session_variables' doesn't exist\"`，执行 `mysql_upgrade -u root -p --force` 解决。\n\nAirflow 的 mysql driver 使用的是 mysqlclient `mysql://root:@127.0.0.1/sqlalchemy_lab?charset=utf8`，如果使用其他 driver 将报 syntax error。\n\n\n# 基础概念\n\nAirflow 中最基本的两个概念是：DAG 和 task。DAG 的全称是 Directed Acyclic Graph 是所有你想执行的任务的集合，在这个集合中你定义了他们的依赖关系，一个 DAG 是指一个 DAG object，一个 DAG object 可以在 Python 脚本中配置完成。\n\n比如一个简单的的 DAG 包含三个 task：A、B、C，A 执行成功之后 B 才能执行，C 不依赖 A 和 B 即可执行。在这个简单的 DAG 中 A B C 可以是任何你想要执行的任务。\n\nDAG 的定义使用 Python 完成的，其实就是一个 Python 文件，存放在 DAG 目录，Airflow 会动态的从这个目录构建 DAG object，每个 DAG object 代表了一个 workflow，每个 workflow 都可以包含任意个 task。\n\n# 安装和使用\n\nAirflow 是基于 Python 构建的，可以很容易用 pip 安装使用，`pip install apache-airflow`，默认情况下 airflow 会在 `~/airflow` 目录存放相关配置。\n\nAirflow 提供了一些列命令来完成 airflow 的初始化工作来和它的正确使用。\n\n```shell\n# 在 airflow 目录初始化数据库和 airflow 配置\nairflow initdb\n# 启动 airflow web\nairflow webserver\n# 开始调度\nairflow scheduler\n```\n更详细的信息请参考文档 http://airflow.incubator.apache.org/\n\n# 第一个 DAG\n\nDAG 的配置用 Python 完成像这样：\n\n```python\n\"\"\"\nCode that goes along with the Airflow tutorial located at:\nhttps://github.com/airbnb/airflow/blob/master/airflow/example_dags/tutorial.py\n\"\"\"\nfrom airflow import DAG\nfrom airflow.operators.bash_operator import BashOperator\nfrom datetime import datetime, timedelta\n\n\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'start_date': datetime(2015, 6, 1),\n    'email': ['airflow@airflow.com'],\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n    # 'queue': 'bash_queue',\n    # 'pool': 'backfill',\n    # 'priority_weight': 10,\n    # 'end_date': datetime(2016, 1, 1),\n}\n\ndag = DAG('tutorial', default_args=default_args, schedule_interval=timedelta(1))\n\n# t1, t2 and t3 are examples of tasks created by instantiating operators\nt1 = BashOperator(\n    task_id='print_date',\n    bash_command='date',\n    dag=dag)\n\nt2 = BashOperator(\n    task_id='sleep',\n    bash_command='sleep 5',\n    retries=3,\n    dag=dag)\n\ntemplated_command = \"\"\"\n    {% for i in range(5) %}\n        echo \"{{ ds }}\"\n        echo \"{{ macros.ds_add(ds, 7)}}\"\n        echo \"{{ params.my_param }}\"\n    {% endfor %}\n\"\"\"\n\nt3 = BashOperator(\n    task_id='templated',\n    bash_command=templated_command,\n    params={'my_param': 'Parameter I passed in'},\n    dag=dag)\n\nt2.set_upstream(t1) # t2 依赖 t1\nt3.set_upstream(t1)\n```\n\nDAG 脚本的目的只是定义 DAG 的配置，并不包含任何的数据处理，在这里 operator 就是 task。\n\n# DAG 的实例化\n\n一个 DAG 脚本是由 DAG object 的实例化和对应的 operator 组成的，除此之外我们还可以定义默认的参数提供给每个任务。\n\nDAG 对象实例化可以根据我们的需要提供对应的初始化参数，实例化 DAG 对象需要提供唯一的 dag_id：\n\n```python\ndag = DAG(\n    'tutorial', default_args=default_args, schedule_interval=timedelta(1))\n```\n\n# Task 的实例化\n\n```python\nt1 = BashOperator(\n    task_id='print_date',\n    bash_command='date',\n    dag=dag)\n\nt2 = BashOperator(\n    task_id='sleep',\n    bash_command='sleep 5',\n    retries=3,\n    dag=dag)\n```\n\ntask 对象的定义的就是 operator 的实例化，operator 有 task_id，用来区分任务，可以按照需要定制 bash_command，也可以传递参数等。\n\n# Task 的依赖\n\nTask 之间是能相互建立依赖的，形如：\n\n```python\nt2.set_upstream(t1)\n\n# This means that t2 will depend on t1\n# running successfully to run\n# It is equivalent to\n# t1.set_downstream(t2)\n\nt3.set_upstream(t1)\n\n# all of this is equivalent to\n# dag.set_dependency('print_date', 'sleep')\n# dag.set_dependency('print_date', 'templated')\n```\n\nAirflow 会自动检测环形依赖以防止 task 无法工作的情况出现，更复杂的情况请参考文档。\n\n# 执行和测试\n\n和 airflow.cfg 同级目录下建立 dag 目录，用来存放第一个 DAG 脚本，然后执行 `python tutorial.py ` ，如果没有报错说明 tutorial 建立成功了。\n\n# Airflow 的命令行\n\nAirflow 提供了一些列的命令行用来查看 DAG 和 task\n\n```shell\n# print the list of active DAGs\nairflow list_dags\n\n# prints the list of tasks the \"tutorial\" dag_id\nairflow list_tasks tutorial\n\n# prints the hierarchy of tasks in the tutorial DAG\nairflow list_tasks tutorial --tree\n```\n\n# 测试任务的执行\n\n执行任务很简单，指定 DAG 并去指定 task 和执行的日期\n\n```shell\n# command layout: command subcommand dag_id task_id date\n\n# testing print_date\nairflow test tutorial print_date 2015-06-01\n\n# testing sleep\nairflow test tutorial sleep 2015-06-01\n```\n\ntest 命令会执行任务并且输出到控制台，不会把任务的执行状态进行持久化\n\n# 执行任务和并记录状态\n\n执行任务在 Airflow 中称之为 backfill，以 backfill 执行会真正开始追踪任务的执行状态和依赖，并且会记录日志\n\n```shell\n# optional, start a web server in debug mode in the background\n# airflow webserver --debug &\n\n# start your backfill on a date range\nairflow backfill tutorial -s 2015-06-01 -e 2015-06-07\n```\n\n# 更多关于 DAG 和 operator\n\n## DAG 的 scope\n\nAirflow 会默认加载任意它能导入到饿 DAG object，这就意味着只要是全局的 DAG object 都可以被导入，但是有时候为了让 DAG 不被导入，比如 SubDagOperator 就可以使用 local 的作用域。\n\n```python\ndag_1 = DAG('this_dag_will_be_discovered')\n\ndef my_function()\n    dag_2 = DAG('but_this_dag_will_not')\n\nmy_function()\n```\n\n## DAG 可以指定默认的参数\n\nDAG 的默认参数会应用到所有的 operator 中。\n\n```python\ndefault_args=dict(\n    start_date=datetime(2016, 1, 1),\n    owner='Airflow')\n\ndag = DAG('my_dag', default_args=default_args)\nop = DummyOperator(task_id='dummy', dag=dag)\nprint(op.owner) # Airflow\n```\n\n## 扩展性极强的 operator\n\nAirflow operator 很容易扩展，这也是 airflow 几乎支持任何形式 task 重要原因。虽然 Airflow 支持不同的 task 可以传输数据，但是如果你的两个 task 之间确实需要共享数据，最好的办法是把他们写在一起。\n\n# 常见问题\n\n1. 配置 Airflow 发送邮件\n\nDAG 执行失败时会可以发送邮件，需要配置好 smtp，在 airflow 配置中默认会开启 starttls，但是最新版下面会报错，如果不在乎 ssl，改成 false 即可\n\n2. Airflow 支持配置 url 前缀\n\n最新版已经支持配置 url 前缀，但是还有一些问题没有解决，比如很多页面的 url 都是硬编码的，如果启用配置 url 前缀，导致一些页面的 url 还是使用原来的相对路径会报 404 错误，这个可以修改页面调用的 url 路径即可\n\n\n# 参考资料\n\n- http://airflow.incubator.apache.org/\n- https://github.com/apache/incubator-airflow\n- https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8\n- Airflow 测试 demo https://github.com/zhyq0826/airflow","src/content/posts/airflow.mdx","4105f4d9e81cbefc","airflow.mdx","algorithm-tree-1",{"id":95,"data":97,"body":104,"filePath":105,"digest":106,"legacyId":107,"deferredRender":22},{"title":98,"summary":99,"date":100,"tags":101,"group":103,"featured":38},"算法—树","树结构是一种典型的非线性结构，非线性就意味着数据结构中至少拥有两个直接前驱或后继元素",["Date","2017-10-17T00:00:00.000Z"],[102],"tree","算法","树结构是一种典型的非线性结构，非线性就意味着数据结构中至少拥有两个直接前驱或后继元素\n\n# 概念\n\n## 树\n\n树是由 n（n>=0）个节点组成的有穷集合 D 与 D 上的关系集合 R 构成的集合，通常用 T 来表示，再此定义上，树满足以下三个条件\n- n=0 时，该节点集合为空，该树被称之为空树\n- 在任意非空树中，有且只有一个根节点 root\n- 当 n>1 时，除根节点外其余节点可以分为 m 个不相交的自己，每一个这样的子集本身又是一棵树，称为根节点的子树\n\n树的定义是一个递归定义。\n\n## 树的表示\n\n树可以用树的形状或文氏图表示\n\n## 节点的度\n\n节点拥有的子树的数目称之为节点度，直观来说就是每个节点的直接子节点个数\n\n## 树的度\n\n树中各节点度的最大的值称之为树的度\n\n## 分支节点\n\n度不为 0 的节点称之为分支节点或普通节点，有的称之为非终端节点\n\n## 节点的层次\n\n从树的根节点开始，根节点为第1层，根节点的子节点是第2层，依次类推\n\n## 树的深度\n\n树中节点的最大层次称之书的高度或深度\n\n## 森林\n\nn(n>=0) 个不相交的树称之为森林\n\n## 叶子节点\n\n度为 0 的节点称之为叶子节点\n\n# 特性\n\n- 非空树的节点总数等于树中所有节点的度之和再加 1 (1其实是根节点)\n- 深度为 k 的非空树第 i 层最多有 k^i-1 个节点 (证明？)\n- 深度为 h 的 k 叉树最多有\n- 具有 n 个节点的 k 叉树的最小深度\n\n# 树的实践和应用\n\n## 问题【1】\n\n> 树和森林的转换","src/content/posts/algorithm-tree-1.mdx","a6a0f7281be10dd4","algorithm-tree-1.mdx","algorithm-link-list-1",{"id":108,"data":110,"body":115,"filePath":116,"digest":117,"legacyId":118,"deferredRender":22},{"title":111,"summary":112,"date":113,"tags":114,"group":103,"featured":38},"算法-顺序表","# 概念",["Date","2017-11-20T00:00:00.000Z"],[],"# 概念\n\n## 线性表\n\n在数据结构中最基本的数据结构是线性表，其定义是：n 个数据元素的有限序列，其中 n 是线性表的长度，n >= 0。\n\n## 顺序表\n\n顺序表是线性表的一种，在计算机内部表示为一块连续的地址空间，其特性有：\n- 用一串连续的地址空间存储\n- 元素可以根据相对位置随机存取\n\n## 数组\n\n数组就是满足顺序表的一种数据结构\n\n![数组](https://static.git-star.com/c-array.png)\n\n# 基本操作\n\n顺序表的基本操作主要包含：\n- 插入元素 O(1)\n- 删除元素 O(1)\n- 查找元素 O(n)\n- 获取元素 O(1)\n- 修改元素 O(1)\n\n在数组中完成这些操作比较简单，也可以非常容易获得各个操作的大 O 表示，但由于顺序表是连续的地址空间，且大小一般固定，如果数据是动态增减，这样的数据结构用顺序表就不是非常容易表示，这就需要用到另一种线性表：链表。","src/content/posts/algorithm-link-list-1.mdx","c0578c28a5b19001","algorithm-link-list-1.mdx","about-interview",{"id":119,"data":121,"body":130,"filePath":131,"digest":132,"legacyId":133,"deferredRender":22},{"title":122,"summary":123,"date":124,"tags":125,"group":129,"featured":38},"聊聊面试和程序员找工作这件事","最近把工作换了，工作内容也从原来的单纯得后端开发转到了云，基本上换了个方向。由于公司的距离我比较在意，最低要求是最远不要超过北五环或者公司就在望京，再加上对公司规模和工作内容的要求，能选择的公司基本不多。",["Date","2019-06-27T00:00:00.000Z"],[126,127,128],"面试","程序员","工作","程序人生","最近把工作换了，工作内容也从原来的单纯得后端开发转到了云，基本上换了个方向。由于公司的距离我比较在意，最低要求是最远不要超过北五环或者公司就在望京，再加上对公司规模和工作内容的要求，能选择的公司基本不多。\n\n先说说今年的市场行情。都说今年行情不好，整体找工作的经历来看，确实各家都比较谨慎，通过类似拉勾网这种渠道投简历大多数没有任何回应，所以如果有认识的人，优先考虑内推。\n\n再说说程序员找工作必须经历的笔试面试。\n\nIT 这个行业比其他行业特殊点的是，面试一般有笔试，而且会在白板上手写代码，甚至有的公司会出智力题，巨头们如微软、Google 等的面试是出了名的难。虽然工作了这么多年，面过很多人，也被不少人面过，基本还没遇到过出智力题的情况，大家都是按照传统套路出牌，不偏不倚。很多公司面试最少有四面，三面技术面，一面 hr 面，有的公司会多点，有五轮技术面，一轮 hr 面，但套路都大同小异，总结下对程序员考察点基本划分为：\n\n- 计算机基础科学知识\n- 项目经验和工程能力\n- 常用开源软件的理解、使用和应用\n- 语言细节\n- 思维能力和学习能力\n- 其他如领导力、团队合作、职业规划等软实力\n\n接下来我会把每个考察点一一展开来谈谈我的经历和看法，只针对具有普遍意义的程序员面试。\n\n### 计算机基础科学知识\n\n科班出身的程序员在基础计算机科学知识上是占优势的，即使很长时间没有碰这些理论性知识，花点时间重新复习一下也不会是什么大问题。基本的基础知识包括：\n\n- 算法\n- 数据库理论\n- 操作系统和计算机体系结构\n- 计算机网络和协议\n- 分布式基础理论\n- 计算机语言以及编译原理\n\n#### 算法\n\n算法是一个老生常谈的话题，作为程序员不可能绕得开，正面面对是唯一的办法，如果仅仅是抱着攻破各大公司面试题的这种想法去学算法，心会很累，而且会失去对算法的兴趣。相反如果留点心，根本不难发现现代各大开源软件到处都是经典算法的影子，MySQL 索引中的 B+ 算法，Redis 中集合中的 skiplist、hash 等数据结构，Java HashMap 中红黑树等等、字符串搜索提示的 Tire 树、大数据过滤的布隆算法等等不一而足，也就是说学习算法最好的途径是**从解决实际生产问题入手逐个击破掌握**。\n\n由于所有的算法都是建立在特定的数据结构之上的，而这些数据结构又是各种经典数据结构的组合和创新，比如红黑树是为了解决二叉查找树插入、删除不高效而演变出的结构，B+ 树又是多叉树的经典应用场景，skiplist 是链表和二分查找的经典组合，所以想要掌握算法又必须要能做到把所有**常用的数据结构烂熟于心，对他们的优缺点有着原理性的理解，能够熟练写出最基本的表达和实现**，这些基本结构包括：\n\n- 数组\n- 队列\n- 栈\n- 链表\n- 树\n- hashmap\n- 图\n\n有了结构，就能按图索骥，不断把触角延伸，一步步探索这些结构的演变；有了问题，就有了场景，就能把算法应用起来，做到理论联系实际，而最后需要注意就是**分类、归纳、对比，总结和不断地练习**。\n\n算法分类，按功能划分有：排序、查找、压缩、过滤等等，按结构划分有：数组、链表、队列、栈、树、图、位图、hashmap 等等，按照思想划分有：暴力、分治、回溯、递归、贪心、动态规划等等，按照领域解决问题场景划分有：存储算法、分布式算法、调度算法、机器学习算法、限流算法、字符串匹配算法等等。\n\n有了上面这些方法论和学习地图，配合 LeetCode 的习题不断练习，算法终能掌握，不过可以预见的是，这个过程对于我们大部分并非天赋异禀，没有得到如来神掌真传的程序员来说是都是一场漫长而艰辛的寂寞之旅。\n\n#### 数据库理论\n\n不管什么时候数据都是 IT 行业赖以存在的基石，因而存储不管在什么时候都应该在程序员应该掌握的领域知识中排第一位，按照目前后端开发经常遇到的存储类型可以简单划分为：\n\n- 传统关系型数据库\n- NoSQL 数据库\n- 内存数据库\n- 图数据库\n- 大规模分布式存储系统\n\n互联网企业中，传统关系数据库基本都是 MySQL 或者 PostgreSQL 为代表的，其他收费的数据库一般来说基本可以不用考虑，因而一般来说只要掌握了 MySQL 或者 PostgreSQL 就能胜任绝大部分和存储相关的开发工作。\n\n关系数据库本身有一套非常复杂的理论，比如事务、外键、数据库范式等等，但是由于真实生产环境的复杂性，很多数据库理论都不会严格被实现，因而学习数据库知识最好以大规模使用的开源软件为准即可。\n\n**MySQL**\n\nMySQL 是关系数据库的最强代表，没有之一，因而掌握了 MySQL 基本可以通吃，可以从以下几方面入手：\n\n- MySQL 数据库基本安装和使用以及组件结构\n- MySQL 支持的数据类型以及各自使用场景优缺点\n- MySQL 各种存储引擎以及适用场景\n- MySQL 实现的基本原理 (推荐 《MySQL 技术内幕 —InnoDB 存储引擎》)\n- MySQL 索引实现以及优化 (推荐 MySQL 官方文档索引相关章节)\n- MySQL 优化 (推荐 《高性能 MySQL》)\n\nMySQL 涉及到的知识点非常庞大，没有哪本书会把 MySQL 的方方面面都涉及到，如果你确实比较懒，买点付费课程也是一种学习途径。\n\n**MongoDB、HBase、Elasticsearch、Cassandra、各种 KV 数据库**\n\nNoSQL 数据库是个很大的概念，基本上把 MongoDB、HBase、Redis 等等都包括了，拿 MongoDB来说， 本身是个文档数据库，支持以类似 JSON 的格式存储，支持大规模的读写，自带分布式部署和 shard，虽然 MongoDB 的争议不少，但是不可否认 MongoDB 的使用还算比较广泛。\n\n其实这些数据库产品不论哪种，如果平时工作中有应用，就多花点时间研究一下，能做到深入了解最好，这对面试都是加分项，至少能够说明个人的技术视野比较开阔，不局限，如果没有时间深入了解，最起码能做到，**知道其应用场景以及局限，能够和 MySQL 这种传统数据库比较起来使用**。\n\n**Redis**\n\nRedis 是一种典型的内存数据库，但是由于其应用真的是太广泛了，已经成为各大公司使用频度仅次于 MySQL 的开源软件，所以对 Redis 的了解要非常深入才能具备足够的竞争力：\n\n- Redis 的基本安装和使用\n- Redis 的各种数据结构以及使用场景\n- Redis 的各种命令以及常用配置的含义\n- Redis 的基本原理以及各种典型的使用场景\n\n推荐看看 《Redis 的设计与实现》、《Redis 开发与运维》以及 Redis 在各大厂的典型实践案例，网上有很多文章，掌握了这些，面试基本没有任何问题。\n\n**图数据库**\n\n如果不是针对特定公司或者特定场景的，可以略过。\n\n**大规模分布式存储系统**\n\n这个要稍微提一下，有的公司会问 **HDFS 以及 Ceph 这样的大规模分布式存储系统的基本原理**，这方面如果没有实践经验可以了解一下基本原理和理论即可，可以不必深究，除非是面试的岗位就是做类似系统的，那就需要特别了解了。\n\n#### 操作系统和计算机体系结构\n\n操作系统和计算机底层的一些知识一般绕不开，常见的包括：\n\n- 进程、线程、协程等的原理和差异\n- 进程间通信\n- 进程的在操作系统中的实现以及调度\n- 内存模型\n- CPU 模型\n- Linux 系统\n\n这部分内容确实能区分出程序员的基本功力，推荐 《深入理解计算机系统》和 《计算机程序的构造和解释》，啃完这两本，几乎没有过不去的操作系统相关的面试。\n\n#### 计算机网络和协议\n\n网络协议可以说是面试必考，包括 TCP\\IP、UDP、HTTP、HTTPS、HTTP2，操作系统常见的网络模型，对于 TCP 应该至少掌握：\n\n- 三次握手和四次挥手的原理以及状态变迁\n- TCP 的可靠性是如何保证的\n- TCP 限流、慢启动、拥塞控制、长连接保证等等\n- TCP 的拆包过程、重组过程等\n- TCP 和 UDP 的基本区别，适用场景\n- DNS 解析的过程、各部分使用的协议以及缘由\n\n推荐《TCP-IP详解卷一》中有关 TCP 和、UDP以及 IP 的章节，而且 TCP 的状态变迁本身并不是特别复杂，虽然状态不少，如果理解着记忆，并且结合着 tcpdump 多看一下各个场景下 TCP 的连接状态基本都能搞明白，很多公司喜欢问为什么不是二次握手，以及为什么不是三次挥手，并且会问原因，如果对 TCP 各个状态变迁没有做深入了解，这些问题会被绕晕。\n\nHTTP 协议是 web 开发必须要掌握的，不只是后端程序员，前端程序员也有同样的要求，对于 **HTTP 协议可以看 《HTTP 协议权威指南》 这本书**足够了，不需要买任何课程，费钱。\n\nHTTPS 要理解其原理和过程。\n\nHTTP2 要理解其原理，以及和 HTTP 1.1 相比做了如何的改进。\n\n和网络相关的还有一大块内容是 Linux 的网络模型，也就是现代高性能 Server 底层实现 epoll 等网络模型，包括但不限于 Redis、Nginx、Gunicorn、libuv 等底层都依赖于此，因此必须要掌握，推荐《unix 高级网络编程》这两本书。\n\n如果比较懒，可以参考我写的书 https://sanyuesha.com/python-server-tutorial/  。\n\n#### 分布式基础理论\n\n知道分布式解决的问题是什么，以及分布式带来的挑战是什么，知道基本的 CAP 理论，理解常见的分布式一致性算法，理解常见的分布式架构原理以及适用场景。\n\n推荐  https://github.com/mixu/distsysbook 和 https://github.com/heathermiller/dist-prog-book 两本书，推荐 https://raft.github.io/ 对 raft 一致性算法的介绍。\n\n### 项目经验和工程能力\n\n一般来说，大多数程序员的项目经验来自于工作时做的各种项目，因而**对做过的项目在实现之后要能不断的总结提炼其中的精华部分**，很多面试官喜欢让面试者 show 出自己所做项目的难点以及有深度的地方，这就是不断总结提炼的原因。如果平时能养成经常总结概括，回答这种问题基本可以做到即问即答。\n\n工程能力是程序员的一大基础能力，工程能力的强弱决定了程序员能够胜任不同规模和不同复杂性项目的能力，工程能力是一种过程性得动态能力，其主要来自于**对项目的不断实践和反复重构优化的过程中**。\n\n因而作为一名程序员，要对自己所做项目的**完整生命周期负责**，从项目构建、单元测试、部署、日志收集、容量规划、监控报警、性能优化、扩容等软件生存过程要全程参与，如果没有办法做到全程参与，至少也要能理解整个服务链路的生命周期。\n\n### 常用开源软件的理解、使用和应用\n\n面试经常会被问到各种开源软件的使用和原理，这些问题非常具体，而且答案比较标准，对于此要对自己常用的软件原理最好都能掌握，并且对其使用场景要非常熟悉，拿后端程序员来说，包括但不限于：\n\n- NGINX\n- MySQL\n- Redis\n- MongoDB\n- ES\n- HBASE\n- HDFS\n- Kafka\n- MQ\n- ZK\n\n最好能做到精通一个到两个，其他做到基本掌握和使用即可，**没有面试官会要求一个面试者能掌握所有，但是很多面试官都期待面试者能至少对其中一个有非常深入的研究**，如果面试者能做到这一点，将会是很大的加分项。\n\n### 语言细节\n\n有的公司对语言有强烈要求，比如 Java 生态的，有的公司对语言没有强烈要求，比如 Python 或者 Go 生态的公司，但都会提问面试者熟悉的语言一些非常微小的细节，比如 Python 中的迭代器内部结构，以及迭代器和生成器的区别，比如 Go 中的 slice 的内部机制以及如何扩容缩容等。因而面试者要对自己熟悉的语言要有比较深入的理解才行，如果是 Java 系的就要对 Java 的各种常用标准库的内部实现以及各种并发编程模型、锁等熟悉，如果是 Python 系的，就要对 Python 常用数据结构的用法，差异，垃圾回收机制，GIL，内部原理都能掌握，同样 Go 也是如此，其实不管是哪种语言，只要留点心，再不济 **Google 一下各种语言常见的面试问题**，这一关总体来说问题都不会太大。\n\n### 思维能力和学习能力\n\n很多公司对思维能力的考察一般是通过做算法题或解决一个特定场景的问题，算法上文已经讲过了，**对于系统设计这种场景性的问题，解决之道也是在日常工作中能对自己遇到的各种问题不断优化总结以及做项目时多问几个问题逐步积累出来的**：\n\n- 如果在现有项目的规模放大十倍百倍这个项目应该如何设计和架构\n- 对于一个问题有没有更好的设计方案，如果有那该如何取舍权衡，如果没有，为什么\n\n**思维能力本质上反映出来的其实也是工程能力，也就是解决问题时能不能面面俱到的照顾到各个方面，并且权衡取舍到最优方案**。\n\n面对这类问题，面试者一定要通过**不断向面试官提问来缩小问题的范围和分析清楚问题的各种边界条件，争取考虑周全**。\n\n学习能力考察一般会转换成让面试者讲述一门自己工作之外学习到的新技术或新技能，并且要阐述清楚其学习的目的以及这项新技术的原理和内部机制。所以任何时候都不要停止学习，因为我们都是程序员。\n\n### 软实力\n\n软实力是程序员能够在职场不断晋升，放大自身价值的必备技能，而这些能力确实需要每个程序员能根据自身条件来培养，完全因人而异。所以面试者要能非常了解自己的**性格特质、能力边界、兴趣爱好以及对未来的规划期待**等等。\n\n推荐阅读 《黑客与画家》、《软实力：代码之外的生存指南》、《程序员的思维训练》。\n\n### 选择\n\n找工作和择偶很像，选择对方或者被对方选择，而这个选择在大程度上决定了未来一到两年自己职业的发展，甚至更远将来的选择，因而如何选择非常重要：\n\n1. 如果是应届毕业，优选大企业，对于刚毕业的程序员，公司比做什么更重要，大公司提供了更多的可能性，有更多选择的机会锻炼和历练自己\n2. 毕业两年到三年，已经经历了很多，大概知道自己的兴趣点和志向，此时根据市场热点选择一个自己感兴趣的方向，以及在这个方向上再选择一个上升型的企业，趁年轻可以获得公司成长的红利，也会得到更大的锻炼\n3. 毕业五年以上，这个阶段的程序员面临一个很大的职业选型的问题，走技术路线，成为专家，走带管理的路线，成为专家型领导，每个人的性格特质不一样，这个时候就需要特别了解自己，包括自己的性格特点，能力范围，兴趣志向，还要了解行业趋势，未来市场的行情等等，最终综合选择一个自己能够深扎的行业以及技术方向做下去。\n4. 时机来临选择创业或转行\n\n### 危机中的幸运\n\n很多人都说程序员是青春饭的职业，确实行业发展趋势中不可避免很多公司倾向选择更年轻的程序员，如果程序员想在行业长久立足只能是：不断提高自己的竞争力。写出更好的软件并不是拼体力，而是各种综合能力的体现，程序员想要持续享受 IT 行业发展带来的红利，唯有永远学习，不断提高个人能力。","src/content/posts/about-interview.mdx","9e4d0c8e5087f3ea","about-interview.mdx","algorithm-two-tree-1",{"id":134,"data":136,"body":140,"filePath":141,"digest":142,"legacyId":143,"deferredRender":22},{"title":137,"summary":112,"date":138,"tags":139,"group":103,"featured":38},"算法-二叉树",["Date","2017-11-28T00:00:00.000Z"],[],"# 概念\n\n## 二叉树\n\n二叉树是树的度为 2 的树，而且二叉树的每个节点子树是有顺序的，分别是左子树和右子树，二叉树是有序树\n\n# 二叉树的实现\n\n二叉树的实现分为：顺序存储结构和链式存储结构。\n\n## 顺序存储结构\n\n利用二叉树自身的一些性质来推断出其左右子树在顺序存储结构中的位置，由于顺序存储结构是以二叉树最大作为空间估算前提条件，对空间的利用不合理。\n\n\n## 链式存储结构\n\n在二叉树的链式存储结构中，每个节点都包含数据域、左右子孩子的链接。\n```python\nclass Node(object):\n    def __init__(self):\n        self.data = None\n        self.left = None\n        self.right = None\n```\n\n\n# 二叉树的基本操作\n\n## 遍历二叉树\n\n二叉树的遍历是对二叉树中每个节点进行访问，完整遍历一棵树就是要遍历二叉树的根节点、左右子树。\n\n### 前序遍历\n\n根节点->左子树->右子树\n```python\ndef traverse(node):\n    if node is None:\n        return\n    print(node.data)\n    traverse(node.left)\n    traverse(node.right)\n\n```\n\n\n### 中序遍历\n\n左子树->根节点->右子树\n```python\ndef traverse(node):\n    if node is None:\n        return\n    traverse(node.left)\n    print(node.data)\n    traverse(node.right)\n\n```\n\n### 后序遍历\n\n左子树->右子树->根节点\n```python\ndef traverse(node):\n    if node is None:\n        return\n    traverse(node.left)\n    traverse(node.right)\n    print(node.data)\n\n```\n\n\n### 层序遍历\n\n层序遍历又称广度优先搜索，按照从上到下、从左到右的顺序对节点按照节点所在的层进行遍历，借助队列实现。\n\n```python\n\ndef layerorder(node):\n    queue = list()\n    path = list()\n    queue.append(node)\n    while len(queue):\n        current = queue.pop(0)\n        path.append(current.val)\n        if current.left:\n            queue.append(current.left)\n        if current.right:\n            queue.append(current.right)\n```\n\n# 二叉树的实际应用和操作\n\n## 问题【1】求一个节点的父节点\n\n二叉树是单向的层次结构，无法直接由子节点获取父节点，但是我们可以根据层序遍历的思想获得父节点\n\n```python\n\ndef find_parent(root, node):\n    queue = []\n    queue.append(root)\n    while len(queue):\n        current_node = queue.pop(0)\n        if current_node.left:\n            queue.append(current_node.left)\n            if current_node.left == node:\n                return current_node\n        if current_node.right:\n            queue.append(current_node.right)\n            if current_node.right == node:\n                return current_node\n\n```\n\n\n## 问题【2】求一个节点的兄弟节点\n\n由于二叉树的单向的层次结构，获取兄弟节点可以借助先获取父节点然后再通过父节点获取兄弟节点\n\n```python\n\nfind_parent(root, node).left\nfind_parent(root, node).right\n\n```\n\n## 问题【3】求一个二叉树的高度\n\n### 方法 1\n\n递归的去遍历所有节点求树高度，最后就演化成只要求根节点子树的高度对比就行，非常容易实现\n\n```python\n\ndef get_tree_depth1(node, depth=0):\n    \"\"\"\n    递归的写法\n    \"\"\"\n    if node is None:\n        return depth\n    depth += 1\n    left_depth = get_tree_depth1(node.left, depth)\n    right_depth = get_tree_depth1(node.right, depth)\n\n    return max(left_depth, right_depth)\n\n```\n\n\n### 方法 2\n\n如果树的高度非常高，会导致递归的层次非常深，可以改成循环\n\n\n二叉树的高度也就是二叉树的深度，等于二叉树的叶子节点的最大深度，这里我们需要对二叉树进行深度遍历来获得二叉树的节点深度和最大深度，鉴于此我们在遍历过程中需要进行回退，因为事先我们是不知道哪一条遍历的路径是最长的，所以需要借助栈这种可以回退的结构。","src/content/posts/algorithm-two-tree-1.mdx","a9c1d07e2a70d055","algorithm-two-tree-1.mdx","algorithm-link-list-2",{"id":144,"data":146,"body":150,"filePath":151,"digest":152,"legacyId":153,"deferredRender":22},{"title":147,"summary":112,"date":148,"tags":149,"group":103,"featured":38},"算法-链表",["Date","2017-11-21T00:00:00.000Z"],[],"# 概念\n\n## 链表\n\n链表是线性表的一种，但是链表不同于顺序表，其在内存中的表示不一定是连续的地址空间，可以是任意的地址空间，基于此链表可以动态的添加任意大小的数据而不需要事先分配空间。\n\n## 链表的分类\n\n链表分为：单链表、双链表、循环链表，其元素存放的地址不连续，可以随意添加任意节点。\n\n# 单链表\n\n## 特性\n\n- 节点的物理位置不一定连续，但是逻辑上通过指针实现连续\n- 有一个头节点和一个尾节点，只有尾部节点没有后继节点\n- 知道头部节点就可以遍历整个链表\n\n单链表的表示（之后如果不特别说明默认都将使用 Python 来演示）:\n```python\n\nclass Node(object):\n    def __init__(self):\n        self.data = None\n        self.next = None\n```\n\n单链表的每个节点中都包含**一个数据域和指向下一个节点的指针域**，单链表通常有一个表头用来表示链表的开始，尾部节点的指针域为 null。\n\n![单链表](https://static.git-star.com/ll2.gif)\n\n\n## 插入操作\n\n插入新的节点 p\n\n### 尾部插入\n\n尾部插入节点，可以直接将尾部节点的指针域指向新节点 `tail.next = p`，如果尾部节点不知道需要遍历链表然后插入尾部节点\n\n```python\ncur = head\nwhile cur.next:\n    cur = cur.next\ncur.next = p\n    \n```\n\n### 在第 i 个位置之后插入\n\n首先找到单链表的第 i 个节点位置，获取地址为 q，然后 `p.next = q.next, q.next=p`\n\n## 删除操作\n\n删除节点 p\n\n删除单链表的节点非常简单，首先遍历找到节点，然后让节点的前驱节点指向节点的 next\n\n```python\n# 删除节点是头部节点\nif head == p:\n    head = head.next\n    head.next = None\nelse:\n    cur = head\n    while cur.next != p:\n        cur = cur.next\n    cur.next = p.next\n    p.next = None\n```\n\n## 查找指定节点\n\n查找单链表很简单，遍历循环单链表即可\n\n# 双链表\n\n## 特性\n\n每个节点包含两个指针域前驱 prev 和后继 next 以及一个数据域，但是头部节点没有前驱节点，尾部节点没有后继节点，单链表的表示：\n```python\nclass Node(object):\n    def __init__(self):\n        self.data = None\n        self.next = None\n        self.prev = None\n```\n\n![double-link-list](https://static.git-star.com/doubly_linked_list.jpg)\n\n\n双链表的插入、查找、删除操作和单链表类似，只需要注意正确处理节点的前驱节点即可\n\n\n# 循环链表\n\n循环列表是尾部节点的指针域指向了头部节点形成了一个环，也就是说遍历循环列表时会回到头部节点，\n\n![circle-link-list](https://static.git-star.com/6140048350_a89768edc5.jpg)\n\n\n# 链表的实际应用和操作\n\n## 问题【1】\n\n> 求一个单链表倒数第 m 个节点，要求不得求出链表长度，不得对链表进行逆转，找到则返回，没有则返回 null。\n\n\n### 方法 1\n\n\n![](https://static.git-star.com/WX20171123-192334.png)\n\n从图不难看出，可以设置两个变量a 和 b ，先让 b 开始从头遍历走 m 个节点，这样 a 和 b 的距离就相差 m 个节点，然后让 a 和 b 同时进行遍历，而倒数 m 个节点其实就是当 b 到达链表末尾的时候，a 指向的节点。\n\n```python\na,b = head,head\np = 1\nwhile b.next and p \u003C m:\n    b = b.next\n    p += 1\n\nwhile b.next:\n    a = a.next\n    b = b.next\n\n```\n\n## 问题【2】\n\n> 判断一个单链表是否有环\n\n![](https://static.git-star.com/de785741-d2de-431f-a9c6-ad964c3606b2_01.png)\n\n\n单链表有环，也就是链表没有尾部节点，环一定存在于尾部\n\n\n### 方法 1\n\n链表有环说明链表从某个节点开始如果一直遍历，最终会回到那个节点，但是由于是单链表我们无法准确找到那个节点，因为只能单向遍历，除非把所有的结点都记录下来，也就是每遍历一个节点都需要记录和检查有没有被访问过，如果被访问过说明节点有环。\n\n记录节点是否遍历过需要额外的空间，随着链表长度的变大而变大。\n\n### 方法 2\n\n如果有环，当在环上放置多个指针进行遍历，但是遍历的速度不同时，最终他们会相遇，由于不知道链表有多长，方法一在链表可能还没有遍历完就可能预定的存储空间不够用了，而用两个指针进行遍历相互追赶最终相遇却不需要额外的空间，注意最终二者相遇的时候肯定都不为 null\n\n此文讲解了 https://lanphier.co.uk/algorithms/detecting-a-loop-in-a-linked-list/ 检测环的一些有趣探讨\n\n```python\na, b = head, head\nwhile a and a.next and b.next:\n    a = a.next.next\n    b = b.next\n    if a == b:\n        return a\n\nreturn None\n\n```\n\n## 问题【3】\n\n> 如果一个单链表有环，如何找出环的起始位置\n\n## 问题【4】\n\n> 如何判断两个单链表相交\n\n![](https://static.git-star.com/ll-intersection.jpg)\n\n两个单链表相交意味着两个链表的尾部节点是相同的\n\n### 方法 1\n\n各自遍历两个链表，比对尾部节点是否相同，此方法时 O(max(n,m))，以两个链表在最长的为准\n\n\n## 问题【5】\n\n> 逆转单链表\n\n## 方法 1\n\n单链表逆转其实就是把节点的 next 指针指向节点的前驱节点，现在假设链表需要反转，那么反转的过程其实会把链表截断，对于单链表来说，最重要的其实是表头，链表截断成两个之后，需要时刻记住两个链表分别的表头，语言反应了思维，所以变量的命名统一可以反应思维\n\n\n\n```python\nleft_head = head\nright_head = head.next\nleft_head.next = None\nwhile left_head and right_head:\n    tmp_right_head = right_head.next\n    right_head.next = left_head\n    left_head = right_head\n    right_head = tmp_right_head\n\nhead = left_head\n```\n\n反转之后最后一步记住更改原来的表头\n\n![step-1](https://static.git-star.com/WX20171127-152340.png)\n\n![step-2](https://static.git-star.com/WX20171127-152421.png)\n\n![step-3](https://static.git-star.com/WX20171127-152508.png)\n\n\n## 方法 2\n\n另一种思路是提出一个假节点，称之为 dumb 节点\n\n```python\ndef reverse():\n    prev = None     # 假想的 prev 节点\n    while head:\n        temp = head.next\n        # 反转，指向前驱\n        head.next = prev\n        # 移动 prev 和 head\n        prev = head\n        head = temp\n\n    # 最后一个前驱节点也就是原来链表的尾部节点是新的头部节点\n    head = prev\n```","src/content/posts/algorithm-link-list-2.mdx","1698c691e0754fa3","algorithm-link-list-2.mdx","architecture-event-pattern",{"id":154,"data":156,"body":163,"filePath":164,"digest":165,"legacyId":166,"deferredRender":22},{"title":157,"summary":158,"date":159,"tags":160,"group":78,"featured":38},"架构的设计模式：事件驱动","### 概念",["Date","2020-06-29T00:00:00.000Z"],[161,162],"架构","设计模式","### 概念\n\n事件驱动架构是一种分布式的异步架构模式，是解耦复杂系统组件的一种处理手段。这种架构模式主要包含两种实施方式，一种是集中式的，一种是非集中式的。\n\n### 集中式架构\n\n\u003Cimg src=\"https://static.git-star.com/0_aqkwbPRXOJHQTdFL.png\" style=\"zoom:50%;\" />\n\n其包含了 event mediator、event channel、event queue、event processor 这些组件，理解 event mediator 是理解这种架构的关键。Event mediator 直译为事件中间处理器，也就是说这个组件是一个事件中枢处理单元，既然是中枢作用也就是这个组件知道事件的处理流程，但是他不执行具体的事件业务处理逻辑，举例来说 event mediator 在接受到 initial event 之后（在集中式模式中，有两种事件类型，一种是 initial event，一种是 processing event，initial event 是 event mediator 接受的原始事件，processing event 是由 event mediator 分发并且由 event processor 处理的事件），会根据事件的特征对事件进行拆分，形成不同的更小单元的 processing event ，这些事件之间没有明显的顺序依赖，各自独立，然后经过不同的 event channel 发送到不同的 event processor。\n\nEvent processor 是一组各自独立的组件，他们彼此之间没有依赖，也就是**他们处理 processing event 的逻辑是自包含的，不依赖于其他 processor 的处理结果**，这是他们的显著特征。\n\n集中式的工作模式可以以一个处理保险流程的例子来说明如图：\n\n\u003Cimg src=\"https://static.git-star.com/sapr_0202.png\" style=\"zoom:50%;\" />\n\nEvent mediator 在接受到一个 relocation event 原始事件之后，拆分成 change address、recalc quote、update cliams 等 processing event，这些 event 彼此独立，经由各自的 event channel 发送到 不同的 event processor 处理。\n\n### 非集中式架构\n\n\n\n\u003Cimg src=\"https://static.git-star.com/0_iGkuegluZ0UhcRGC.png\" style=\"zoom:50%;\" />\n\n这种模式主要由 event processor 和 event channel 构成，较为简单，但是不同于集中式，这种模式的**事件可能彼此是相互关联的**，比如一个 event processor 的处理结果是另一个 event processor 的需要消费的事件，整个事件处理过程像一条彼此相扣的链条。\n\n同样以处理保险的为例来说明这种模式的工作流程：\n\n\u003Cimg src=\"https://static.git-star.com/sapr_0204.png\" style=\"zoom:50%;\" />\n\n图中明显可以观察到，当 change address 完成后产生的 event 会被 quote process 和 claims process 接收并处理，同样他们的处理结果又分别被 notification process 和 adjustment process 接受，整个过程就像是接力赛跑，每个 processor 必须要完成自己的工作其他 processor 才能开始执行，整个处理过程像链条一样，只有整个流程结束才能形成一个完整的业务逻辑。\n\n### 权衡\n\n事件驱动架构模式是较为复杂的，他涉及了多个分布式系统之间的交互，系统之间的稳定调用、业务的延迟敏感性等都是要必须考量的因素，尤其是在业务逻辑拆分成多个分布式执行单元之后，他们不再是一组完整的原子执行单元，而变成了分布式事务，这也加剧了这种架构模式的设计难度。因而在设计这种架构时，event 是否能够独立完成，是否要依赖于其他事件，是否是一组无法分割的事务单元都在影响着事件的拆分粒度。\n\n### 事件架构的度量\n\n**agility**\n\n各个组件彼此独立，耦合性低，彼此变更而不相互影响，敏捷性强\n\n**deployment**\n\n非集中式架构部署相对容易，组件的依赖程度较低，集中式架构相对较难，各个 processor 都依赖 event mediator\n\n**testability**    \n\n复杂分布式系统难以测量\n\n**performance**\n\n虽然各个组件之间的消息传递的成本需要考虑，但是由于业务逻辑分拆成多个小单元异步执行，整体性能提升较为明显\n\n**scalability**\n\n组件独立，scale out 容易，尤其是 processor \n\n**development**\n\n分布式系统，天然特征，开发难，测试难","src/content/posts/architecture-event-pattern.mdx","f5ebf8bcf67de1fd","architecture-event-pattern.mdx","architecture-evolution-process",{"id":167,"data":169,"body":174,"filePath":175,"digest":176,"legacyId":177,"deferredRender":22},{"title":170,"summary":171,"date":172,"tags":173,"group":78,"featured":38},"互联网后端架构的演化","任何复杂技术的架构几乎都是随着需求的变化以及业务的增长逐渐演化出来的，并不是一开始就是复杂的庞然大物，互联网后端的技术架构几乎莫不是如此。",["Date","2019-01-12T00:00:00.000Z"],[161],"任何复杂技术的架构几乎都是随着需求的变化以及业务的增长逐渐演化出来的，并不是一开始就是复杂的庞然大物，互联网后端的技术架构几乎莫不是如此。\n\n## 数据库篇\n\n> 以 MySQL 为例说明支持事务的持久化数据库的架构演变。\n\n![](https://static.git-star.com/a47dcc86d1c35dc111df2f4c8b1f7d64.png)\n\n\n\n### 单实例 single-instance\n\n在数据量很小，业务规模也很小的时候一般使用一台数据库实例即可，比如业务还处于探索阶段，用户量很少的情况。\n\n**优势**\n\n简单，开发调试方便，维护成本低廉\n\n**缺点**\n\n缺乏可靠性，单机实例一旦故障，既不可写，又不可读。\n\n### 主从结构 master-slave\n\n伴随着业务的增长，单机性能会遇到瓶颈，比如单机连接数、单机处理并发的能力都是有限的，这就需要数据库可以做到横向扩展，主从结构 master-slave 就是满足这一需求的架构，有的地方又称之为 **master-replication** 架构。\n\n**优势**\n\n可靠性得到提升，主节点故障，从节点会自动提升为主节点，突破了单机性能瓶颈，可以做到横向扩展。\n\n**缺点**\n\n主从节点同步有延迟，主从节点数据一致性需要一定的时间，对数据实时性要求较高的场景需要开发者自己处理同步延迟的问题，比如读写都在 master 节点上执行。\n\n### 双主多从\n\n为了保证主库的高可用，可以设置多个主库，多个主库之间进行双向同步，使用 keepalive 监测双主的可用性随时进行切换。\n\n**优势**\n\n解决写单点的问题。\n\n**缺点**\n\n主库之间同步一致性复杂。\n\n### 分片 sharding\n\n随着数据量的不断增大，单机存储所有数据会导致数据库实例的性能开始下降，于是会考虑根据业务需求，把数据拆分成几部分存储，称之为**切片分库**，每一数据库实例存储整体数据中的一部分，这样单机存储的容量会降低，能够继续充分发挥单机的性能。\n\n**优势**\n\n数据分散存储，能够通过横向扩展，满足业务发展需求。\n\n**缺点**\n\n复杂度高，横向扩展虽然能够降低单机数据的存储量，但是实时复杂，比如对于一般采用的 hash 方法实时的分库，新增节点，意味着原有的数据需要重新 hash。\n\n### 分片加主从\n\n数据分片解决的是数据量过大的问题，但是单节点的可靠性并没有得到保证，因而可以在分片的同时，对每一个分片继续实施主从架构以保证单个片的数据可靠性。\n\n**优势**\n\n数据分散存储，数据可靠性有保证，支持横向扩展，满足业务需求。\n\n### 自动分片和自动扩容\n\n这是数据库架构最理想的状态，相当于支持无限扩展，只要新增节点，在保证数据可靠性的同时(多副本存储)，集群会自动对数据进行动态平衡（重新 hash）。\n\n## 缓存篇\n\n> 缓存是互联网架构中必不可少的一个组件，以 redis 为例说明缓存架构的演变。\n\n![](https://static.git-star.com/f5a9fb089a8d32bce76f34e619a32f9f.png)\n\n### 单点 single-instance\n\n缓存的重要作用就是缓解持久化 DB 的压力，业务发展的初期用户量少，单点足以应付\n\n**优势**\n\n配合单点 APP 使用，和 APP 部署在同一主机，部署方便，维护方便，开发方便\n\n### 主从结构 master-slave\n\n随着用户量增大，请求规模的增长，单点无法满足请求压力，可以使用主从结构来分摊请求压力，缓存的场景以写少读多最常见，主从结构能够有效缓解单点的带来的问题。\n\n**优势**\n\n解决单点性能瓶颈\n\n### 一致性 hash 切片 sharding\n\n随着单点的写压力以及数据量逐步增大，可以使用一致性 hash 的方式将数据进行切片分散存储，解决单点容量的问题，一致性 hash 的方式能够有效缓解，增减节点带来的缓存失效问题。\n\n**优势**\n\n解决单点容量不足的问题和压力过大的问题\n\n**劣势**\n\n运维复杂\n\n### 一致性 hash 高可用\n\n切片之后的数据存在单点的问题，也就是数据只在一个节点读和写，如果节点挂掉，缓存就失效了。如果业务需要保证缓存也要高可用，每个节点可以使用主从结构，多副本的方式存储，配合以 sentinel 进行主从切换。\n\n**优势**\n\n解决切片之后数据单点的问题\n\n### 一致性 hash 自动伸缩\n\n采用一致性 hash 最大的问题是缩容和扩容带来的数据一致性难题，每增加和删除节点都需要重新对数据进行动态调整，要做到能够自动伸缩一般会配以 monitor 组件对每个节点的容量进行监控，在达到阈值之后，新增节点进行扩容，然后通知 router 等组件，一致性 hash 的 slot 发生了变化，对受影响的 key 进行特殊处理，保证数据的可用性，迁移完成之后，通知 router 开始正常处理请求。\n\n## APP 篇\n\n> 同数据库和缓存，后端应用服务的架构也是随业务的发展逐步调整，不断演化\n\n**单点**\n\n![](https://static.git-star.com/c53dd40a6f9c3119a337abf21217ecc6.png)\n\n压力很小的验证业务时候采用的架构模式，cache、session、nginx、DB 可能都是同一主机，配合以 crontab 完成异步任务。\n\n**集群**\n\n![](https://static.git-star.com/15d136d8a752eb93e8b19799a3c1fc47.png)\n\n采用集群一方面是为了解决单点压力的问题，一方面是为了解决单点可靠性的问题，当 crontab 的任务数量成规模之后，需要采用异步任务队列来代替实现，维护成本更低，开发更高效。\n\n**更大规模的单体应用**\n\n![](https://static.git-star.com/14dd29dda365f3da8a451b8082f06681.png)\n\n随着业务的复杂度的提升，在未采用微服务之前，APP 会按照功能和服务不断进行拆分，各个 APP 之间通过 MQ 进行通信，异步任务队列也可以采用 MQ 来取代，缓存使用分布式缓存，可以按照自己的需要采用 master-slave 或者一致性 hash，数据库按照业务需要可以是 master-slave，也可以是切片分库，外网通过 DNS 轮询的方式进行负载均衡，静态文件采用 CDN 进行分发。\n\n### 微服务\n\n![](https://static.git-star.com/cf80a1d007dcbbe62e512f7b1f437670.png)\n\n随着单体规模的不断变大，单体应用的业务边界会越来越模糊，会有很多重复的功能出现在单体应用中，这些重复功能会导致每个单体应用都会消耗一定的基础设置资源，比如缓存、DB 资源等等，为了减少重复功能的开发和维护，合理利用基础设置资源，单体应用逐步演化成微服务架构。\n\n在微服务架构中，每个服务维护着自己的数据库，也就是说数据库的连接资源等都是每个服务自己持有，各个服务之间通过 MQ 进行数据通信，随着架构的复杂度提升，配套的需要有配置中心、服务注册与发现、日志、监控、调用链接追踪等基础设施来支持整个微服务的运行。","src/content/posts/architecture-evolution-process.mdx","8493afdbe300c13b","architecture-evolution-process.mdx","architecture-pattern",{"id":178,"data":180,"body":185,"filePath":186,"digest":187,"legacyId":188,"deferredRender":22},{"title":181,"summary":182,"date":183,"tags":184,"group":78,"featured":38},"架构的设计模式：层次架构","> 本文节选自 Software Architecture Patterns",["Date","2020-06-27T00:00:00.000Z"],[161,162],"> 本文节选自 Software Architecture Patterns\n\n### 概念\n\n最常用的架构设计模式就是**分层架构**，也叫**层次架构**，在分层架构中，具有相似功能的组件被组织在同一层，不同的层次负责不同的角色。虽然在这种架构模式中没有明确规定有多少层，一般来说分层架构都包含：presentation、business、persistence、database。在有些场景，persistence 和 database 有时候会合并成一层。\n\n在分层架构中，每个层次在负责扮演自己的角色的同时，还需要提供一层抽象来满足来自其他层的请求，比如 presentation 在负责展示数据的同时，不需要知道数据取自于哪里，数据的提取、聚合工作是有他的下一层 business 抽象提供的。显然易见，这种分层的一个优势就是，**功能分明，职责清晰**。\n\n\u003Cimg src=\"https://static.git-star.com/sapr_0101.png\" style=\"zoom:50%;\" />\n\n### 分层架构中的数据流动\n\n\u003Cimg src=\"https://static.git-star.com/sapr_0102.png\" style=\"zoom:50%;\" />\n\n在分层架构中，数据的流向是有严格规定的，默认的情况下，数据必须经过指定的层才能到达另一个层，也就是不能跨层流动，图中 **closed** 标志就是在表达这样的含义。为什么数据不能跨层流动，即使某些场景下数据跨层流动显然有更好的性能，很重要的一个原因就是为了保持**层的隔离性**。层隔离可以让每层的变动都只影响和他直接交互的层次，而其他层则不需要做出变更，以此达到**高内聚，低耦合**的架构目的。\n\n#### 例外情况\n\n生活总是有例外的情况，同样架构也是如此，虽然层的隔离性能够限制层次变化影响的范围，但是有些时候又需要取消这种隔离。\n\n\u003Cimg src=\"https://static.git-star.com/sapr_0103.png\" style=\"zoom:50%;\" />\n\n比如图中需要为 business 层提供具有通用功能的 service layer 来提供类似数据转换，日志等不带业务逻辑的工具功能，这个层次在架构中位于 business 层之下，也就是他是为 business 层服务的，presentation 不能直接访问他，但是按照上文 closed 的原则，意味着所有来自于 business 的请求必须要先经过 service 层才能到达 persistence，但是作为一个提供通用工具功能的层次，如果强制让所有来自 business 的请求都经过他显得多次一举，没有意义，因为并不是所有的数据都必须要进行转换或者需要日志功能，因而在这个场景之下，service 变成 **open**，即可以让来自 business 的请求跨过 service 访问 persistence。\n\n层次的 open and close 是为定义层次之间的关系服务的，也决定了层次之间的数据流向，因而如果使用层次架构，架构师的职责之一就是权衡每个层次的开放性。\n\n### 警惕\n\n分层架构如此简单通用，以至于在没有找到合适的架构的时候总是可以考虑分层架构。但是这里需要值得警惕的是**无意义的分层**。无意义的分层就是说层次非常单薄，层次中的业务逻辑非常少或者几乎没有，导致数据的流动仅仅是为了层次的划分而必须要经过这些无意义的层。如何决定一个层是必须的？**二八原则**，也就是 80% 的 request 决定了这个层次存在的必要性和开闭原则，如果 80% 的request 都是简单的经过，这个层次可以考虑开放或者取消。\n\n### 分层架构的度量\n\n**agility**\n\n敏捷性意味着能轻松应对变化，但是分层架构显然在这方面做的做的不够 ，如果你只是在一个层次中做出改变，可能还稍微好点，但是如果变化发生在多个层次，所耗费的精力和时间都非常多，因为分层架构一般都是单体应用，单体应用的一个显著问题就是应对变化显得耦合过重。\n\n**deployment**\n\n对一个层次中的组件进行变更通常都意味着整个层次或者整个应用必须要重新部署。  \n\n**testability**    \n\n每个层次的依赖都是可预测的，也就是数据流进的层次和数据流出的层次，这也意味着可以很容易实现各个层次的 mock。\n\n**performance**\n\n如果是单体应用中的分层架构，整体性能不会太低，考虑到每个数据请求都要经过多个层次，极端情况下对于那些不需要经过多个层次的数据可能会显得性能低下\n\n**scalability**\n\n由于层次的限制，如果单纯的伸缩整个应用，可能会导致某些层次有性能问题，比如单体应用横向扩展可能会导致 database 的 connection 暴涨，从而引起 db 的性能问题，此时可以考虑把 database 层单独伸缩，但是层次之间的数据交互又成了问题。\n\n**development**\n\n由于分层架构简单易实施，开发入门容易","src/content/posts/architecture-pattern.mdx","49398376d5fc0f38","architecture-pattern.mdx","chat-app-with-go-python-node",{"id":189,"data":191,"body":198,"filePath":199,"digest":200,"legacyId":201,"deferredRender":22},{"title":192,"summary":193,"date":194,"tags":195,"group":78,"featured":38},"用一个简易的 web chat 说说 Python、Golang、Nodejs 的异步","在 web 编程中，经常有业务需要在处理请求时做异步操作，比如耗时太长的 IO 操作，等异步执行完成之后再结束请求返回 response 到 client，在这个过程中 client 和 server 一直保持着连接不释放，也就是当前请求在从 client 的角度看一直处于阻塞状...",["Date","2017-06-24T00:00:00.000Z"],[196,50,197],"python","node","在 web 编程中，经常有业务需要在处理请求时做异步操作，比如耗时太长的 IO 操作，等异步执行完成之后再结束请求返回 response 到 client，在这个过程中 client 和 server 一直保持着连接不释放，也就是当前请求在从 client 的角度看一直处于阻塞状态，直到请求结束。\n\n之所以称之为异步，最重要的特征就是 server 可以继续处理其他 request 而**不被阻塞**。\n\n不同语言在处理这种异步场景的方式是截然不同的，常见的处理策略有：消息共享（异步任务队列）、多线程多进程、event（linux signals，nodejs event loop）、协程 coroutine（返回 Future、Promise 代表程序执行的未来状态），其中 coroutine 是应用最广泛的，这也是今天此篇的主题。\n\n{/* more */}\n\n什么是 coroutine？简单来说就是一段可以在特定时刻自由被 suspend、execute、kill 的 program。程序对 coroutine 的控制就像操作系统对 process 的控制，但是代价要低廉的多。这也是很多语言都支持用 coroutine 的方式进行异步操作的一个重要原因，其中就包括 Golang、Python、JavaScript(ES6)、Erlang 等。\n\n**Talk is cheap, show me your code.** 在此我们用一个非常简单的 web chat demo app 来一起表一表 Golang、Python、Nodejs 中的异步。\n\n\n## Chat demo app 的简单描述\n\nDemo 只是为了说明 coroutine 在不同语言是如何应用的，因而场景非常简单：一个内容输入框，任意 client 发送的消息都能在其他 client 显示。 \n\n![](/images/chat-gif.gif)\n\n**项目地址**\n\nhttps://github.com/zhyq0826/chat-app-tutorial\n\n## Chat demo app 的工作原理\n\n两个主要的 API：\n\n1. `/a/message/new` 用于消息发送，在此称之为 message-new\n2. `/a/message/updates` 用于消息接受，在此称之为 message-update\n\nClient 通过 message-update 从 server 端获取最新的消息，如果没有新消息，当次 request 就被挂起，等待新消息的发送，当有新消息来临，获取最新消息之后，断开 connection，一定间隔之后重新请求 server 继续获取新的消息，并重复之前的过程。\n\n由于 message-update 从 server 获取消息的时候有可能需要较长时间的等待，server 会一直持有 client 的连接不释放，因而要求来自 message-update client 的请求不能阻塞 server 处理其他请求，并且 message-update 在没有消息到达时需要一直挂起。\n\n**Server 处理 message-update 的过程就是一个异步的过程**。\n\n## Python 的实现\n\nPython 中用 yield 来实现 coroutine，但是想要在 web 中实现 coroutine 是需要特别处理，在此我们用了 tornado 这个支持 asynchronous network 的 web framework 来实现 message-update 的处理。\n\nTornado 中一个 Future 代表的是未来的一个结果，在一次异步请求过程中，yield 会解析 Future，如果 Future 未完成，请求就会继续等待。\n\n```python\n@gen.coroutine   #1\ndef post(self):\n    cursor = self.get_argument(\"cursor\", None)\n    # Save the future returned by wait_for_messages so we can cancel\n    # it in wait_for_messages\n    self.future = GLOBAL_MESSAGE_BUFFER.wait_for_messages(cursor=cursor)\n    messages = yield self.future #2\n    if self.request.connection.stream.closed():\n        return\n    self.write(dict(messages=messages))\n```\n\n`#1` 出通过 tornado 特有的 gen.coroutine 让当前请求支持 coroutine，`#2` 是当前请求等待的未来的执行结果，每个 message-update client 都通过 GLOBAL_MESSAGE_BUFFER.wait_for_messages 的调用生成一个 future，然后加入消息等待的列表，只要 future 未解析完成，请求会一直挂起，tornado 就是通过 yield 和 future 的配合来完成一次异步请求的。\n\n理解 yield 是如何等待 future 完成的过程其实就是理解 Python generator 如何解析的过程，细节我们有机会再表。\n\n## Golang 的实现\n\nGolang 天生就在语言层面支持了 coroutine `go func()` 就可以开启 coroutine 的执行，是不是很简单，是不是很刺激，比起 tornado 必须特别处理要赏心悦目的多，而且 go 自带的 `net/http` 包实现的 http 请求又天生支持 coroutine，完全不需要类似 tornado 这种第三方 library 来支持了（此处为 Python 2 ）。Golang 比 Python 更牛逼的地方在于支持 coroutine 之间使用 channel 进行通信，是不是更刺激。\n\n```go\nfunc MessageUpdatesHandler(w http.ResponseWriter, r *http.Request) {\n\tclient := Client{id: uuid.NewV4().String(), c: make(chan []byte)} #1\n\tmessageBuffer.NewWaiter(&client) #2\n\tmsg := \u003C-client.c //挂起请求等待消息来临 #3\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\tw.Write(msg)\n}\n```\n\n`#1` 为每个 client 生成 一个唯一的身份和 channel，然后 client 加入消息 `#2` 等待列表等候消息的来临，`#3` 就是挂起请求的关键点：等待 channel 的消息。Channel 的通信默认就是阻塞的，即当前 message-update 这个 coroutine 会被 `#3` 的等待而挂起不会执行，也就达到了 client 连接不能断的要求。\n\n## Nodejs 的实现\n\nNodejs 天生异步，通过 callback 来完成异步通知的接收和执行。为了演示方便我们用了 express ，在 express 中如果一个请求不主动调用 `res.end` 或 `res.send`、`res.json` 请求就不会结束。在 nodejs 中请求如何才能知道消息到达了，需要 response？Python 我们用了 **Future**，Golang 用了 **channel**，Nodejs 实现也绝不仅仅只有一种，在此我们用了**事件**和 **Promise**。\n\nPromise 类似 Future，代表的是一次未来的执行，并且在执行完成之后通过 resolve 和 reject 来完成执行结果的通知，then 或 catch 中获取执行结果。通过 Promise 能有效解决 nodejs 中回调嵌套以及异步执行错误无法外抛的问题。\n\nPromise 作为一种规范，nodejs 中有多种第三方库都做了实现，在此我们用了 bluebird 这个 library。\n\n事件是 nodejs 中常用的编程模型，熟悉 JavaScript 的同学应该很了解了，不细表。\n\n```JavaScript\napp.post('/a/message/updates', function(req, res){\n    var p = new Promise(function(resolve, reject){\n        messageBuffer.messageEmitter.on(\"newMessage\", function(data){  #1\n            resolve(data); #2\n        });\n    });\n    var client = makeClient(uuidv4(), p);\n    messageBuffer.newWaiter(client);\n    p.then(function(data){  #3\n        res.set('Content-Type', 'application/json');\n        res.json({'messages': data});\n    });\n});\n```\n\n每个 message-update client  都会生成一个 Promise，并且 Promise 在消息来临事件 newMessage `#1` 触发以后执行 Promise 的 resolve `#2` 来告知当前 client 消息来临。\n\n## 小结\n\n三种语言实现异步的策略是不尽相同的，其中 Golang 的最容易理解也最容易实现，这完全得意于 go 天生对 coroutine 的支持以及强大的 channel 通信。文中 Python 的实现是基于 Python 2，在 Python 3 中 coroutine 的使用有了很大的改善，但是相比 Golang 还是美中不足。Nodejs 作为天生的异步后端 JavaScript，想要完全使用 Promise 来发挥其优势还是需要很多技巧来让整个调用栈都完美支持，不过 ES6 中的 yield，ES7 中的 await/async 对异步的操作都有了很大改善，他们的处理方式神似 Python（据说 ES6 草案的实现就是一群 Python 程序员）。\n\n\n> Python 的例子改自 tornado https://github.com/tornadoweb/tornado/tree/master/demos/chat\n>\n> chat-app 地址 https://github.com/zhyq0826/chat-app-tutorial\n>\n> Promise Bluebird http://bluebirdjs.com/docs/getting-started.html\n>\n> tornado https://tornado.readthedocs.io/en/stable/guide/intro.html\n>\n> Golang channel https://tour.golang.org/concurrency/2","src/content/posts/chat-app-with-go-python-node.mdx","1e3c00aa1e91de41","chat-app-with-go-python-node.mdx","config-local-dev-https-with-spring",{"id":202,"data":204,"body":212,"filePath":213,"digest":214,"legacyId":215,"deferredRender":22},{"title":205,"summary":206,"date":207,"tags":208,"group":211,"featured":38},"配置浏览器信任的 Spring boot https 开发环境","日常大多数前端使用的都是 Chrome 浏览器，由于安全策略的限制，Chrome 不允许在 https 环境之下访问非 https 的资源，包括静态资源和非静态 http 请求，会报 错误，因此为了让前端同学可以在日常的环境中和后端同学联合调试就需要一套可信任的 https 环境...",["Date","2021-12-04T00:00:00.000Z"],[209,210],"java","https","Java","日常大多数前端使用的都是 Chrome 浏览器，由于安全策略的限制，Chrome 不允许在 https 环境之下访问非 https 的资源，包括静态资源和非静态 http 请求，会报 `Mixed Content blocked` 错误，因此为了让前端同学可以在日常的环境中和后端同学联合调试就需要一套可信任的 https 环境，最终状态是通过自定义域名访问 http 服务事浏览器会显示证书安全的标志，如下访问 freecodecamp.org 一样\n\n![](https://static.git-star.com/WX20211204-140412@2x.png)\n\n本文详细记录了配合 Spring boot 在 Mac 下搭建一套浏览器信任的 https 环境的全部工作，我们假设本地要使用的域名是 `dev.com`\n\n## 生成自签名证书\n\n生成一个 RSA-2048 的 key ，用来生成 Root SSL certificate，生成过程中根据提示输入密码，这个密码在后续使用过程中会用到，所谓根证书就是权威机构颁发的证书，详细含义见 [What is a Root SSL Certificate?](https://support.dnsimple.com/articles/what-is-ssl-root-certificate/)\n\n```bash\nopenssl genrsa -des3 -out rootCA.key 2048\n```\n\n然后用这个 key 生成根证书，这个证书的有效期是 1024 天，可以根据自己的需要变更。\n\n```bash\nopenssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.pem\n```\n\n## 让 Mac 信任证书\n\n打开 Mac 的钥匙串 App，导入生成的 `rootCA.pem` \n\n\u003Cimg src=\"https://static.git-star.com/WX20211204-143101@2x.png\" style=\"zoom:50%;\" />\n\n\n\n然后双击导入的证书进行编辑，改写信任->当使用证书一览:始终信任\n\n\u003Cimg src=\"https://static.git-star.com/WX20211204-143405@2x.png\" style=\"zoom:50%;\" />\n\n\n\n## 为域名 dev.com 签发证书\n\n创建 server.csr.cnf 文件，输入以下内容\n\n```bash\n[req]\ndefault_bits = 2048\nprompt = no\ndefault_md = sha256\ndistinguished_name = dn\n\n[dn]\nC=US\nST=RandomState\nL=RandomCity\nO=RandomOrganization\nOU=RandomOrganizationUnit\nemailAddress=hello@dev.com\nCN = dev.com\n```\n\n创建一个 v3.ext 文件，输入以下内容\n\n```bash\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1 = dev.com\n```\n\n使用 `server.csf.cnf` 文件为 dev.com 创建一个certificate  key 保存为 `server.key` 文件\n\n```bash\nopenssl req -new -sha256 -nodes -out server.csr -newkey rsa:2048 -keyout server.key -config \u003C( cat server.csr.cnf )\n```\n\n接着生成 certificate signing request 文件 `server.crt` \n\n```bash\nopenssl x509 -req -in server.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out server.crt -days 500 -sha256 -extfile v3.ext\n```\n\n## 配置 spring boot 的 https \n\nJava 提供了 [keytool](https://docs.oracle.com/javase/8/docs/technotes/tools/unix/keytool.html) 工具为 Java 程序生成对应的 https 证书，其格式是 JKS 或 PKCS12，在这里我们在 Spring boot 中 使用 PKCS12 格式，在上面的我们已经为 dev.com 生成了对应的证书，再此我们可以使用 keytool 工具进行转换为 PKCS12 \n\n```bash\nopenssl pkcs12 -export -out springboot.p12 -inkey server.key -in server.crt\n```\n\n把 `springboot.p12`拷贝到 Spring 项目的 resource 下，配置 Spring 的 `application.yaml` 或 `application.properties`\n\n```yaml\nserver:\n  ssl:\n    key-store: classpath:springboot.p12\n    key-store-password: password\n    key-store-type: pkcs12\n    key-password: password\n  port: 443\n```\n\n\n\n启动 Spring 程序，配置 dev.com 指定到本地 127.0.0.1 即可完成访问\n\n\n\n## 参考\n\n- https://www.thomasvitale.com/https-spring-boot-ssl-certificate/\n- https://www.freecodecamp.org/news/how-to-get-https-working-on-your-local-development-environment-in-5-minutes-7af615770eec/","src/content/posts/config-local-dev-https-with-spring.mdx","126611cb70defa07","config-local-dev-https-with-spring.mdx","consul-health-check",{"id":216,"data":218,"body":225,"filePath":226,"digest":227,"legacyId":228,"deferredRender":22},{"title":219,"summary":220,"date":221,"tags":222,"group":224,"featured":38},"Consul 健康检查","之前的文章已经让我们知道搭建 consul 的集群比较简单，今天我们来继续我们的系列，使用 consul 进行 health check。",["Date","2018-05-16T00:00:00.000Z"],[223,224],"health check","consul","之前的文章已经让我们知道搭建 consul 的集群比较简单，今天我们来继续我们的系列，使用 consul 进行 health check。\n\n开始之前，你需要准备我们在前面文章中已经搭建好的 cluster。\n\n## 定义 checks\n\n同定义 service 一样，定义 checks 可以通过配置或者调用 HTTP API 来实现，在此我们之前一样使用配置文件来实现，这是最通用的做法。\n\n在 consul 0.9 之后，agent 必须配置 `enable_script_checks` 为 true 来允许 script checks。\n\n在第二个节点上创建两个定义文件：\n```shell\nvagrant@n2:~$ echo '{\"check\": {\"name\": \"ping\",\n  \"args\": [\"ping\", \"-c1\", \"google.com\"], \"interval\": \"30s\"}}' \\\n  >/etc/consul.d/ping.json\n\nvagrant@n2:~$ echo '{\"service\": {\"name\": \"web\", \"tags\": [\"rails\"], \"port\": 80,\n  \"check\": {\"args\": [\"curl\", \"localhost\"], \"interval\": \"10s\"}}}' \\\n  >/etc/consul.d/web.json\n\n```\n这里我们定义了一个 ping 的 host check，这个 check 每 30s 执行一次 `ping -c1 google.com`命令。基于 script 的 health check 执行命令时的 user 和 开启 consul 进程是同一个。如果检测程序退出时的 code >= 2，这次检测会被标记为 failing，这个服务也被认为是不健康的 unhealthy。**这个规则适用任何 script-base 的 health check**。\n\n第二个命令定义了一个服务 web，并且每 10s 进行一次 curl 检查来确保服务仍然可用。\n\n重新启动 consul 来加载刚才的定义：\n```shell\n2018/05/16 11:32:16 [INFO] agent: Synced check \"ping\"\n2018/05/16 11:32:22 [WARN] agent: Check \"service:web\" is now critical\n2018/05/16 11:32:32 [WARN] agent: Check \"service:web\" is now critical\n2018/05/16 11:32:35 [WARN] agent: Check \"ping\" is now warning\n2018/05/16 11:32:35 [INFO] agent: Synced check \"ping\"\n```\n从输出结果我们不难看出，ping 现在是警告状态，service:web 报严重错误，由于 google 被墙所以 ping 会超时，端口在 80 的 web 服务我们本地根本没有开启。\n\n## 获取 checking 状态\n\n可以通过 API 来获取有关 health check 的运行状态：\n```shell\nvagrant@n1:~$ curl http://localhost:8500/v1/health/state/critical\n[{\n    \"Node\": \"agent-two\",\n    \"CheckID\": \"service:web\",\n    \"Name\": \"Service 'web' check\",\n    \"Status\": \"critical\",\n    \"Notes\": \"\",\n    \"Output\": \"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\\n                                 Dload  Upload   Total   Spent    Left  Speed\\n\\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused\\n\",\n    \"ServiceID\": \"web\",\n    \"ServiceName\": \"web\",\n    \"ServiceTags\": [\"rails\"],\n    \"Definition\": {},\n    \"CreateIndex\": 557,\n    \"ModifyIndex\": 594\n}]\n```\n为了证实我们获取的结果，可以使用 DNS 查询查看 web 服务的：\n```shell\nvagrant@n1:~$ dig @127.0.0.1 -p 8600 web.service.consul\n; \u003C\u003C>> DiG 9.9.5-9+deb8u14-Debian \u003C\u003C>> @127.0.0.1 -p 8600 web.service.consul\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER\u003C\u003C- opcode: QUERY, status: NXDOMAIN, id: 63358\n;; flags: qr aa rd; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;web.service.consul.        IN  A\n\n;; AUTHORITY SECTION:\nconsul.         0   IN  SOA ns.consul. hostmaster.consul. 1526471396 3600 600 86400 0\n\n;; Query time: 0 msec\n;; SERVER: 127.0.0.1#8600(127.0.0.1)\n;; WHEN: Wed May 16 11:49:55 GMT 2018\n;; MSG SIZE  rcvd: 97\n```\n\n可以看到没有返回正确的状态，因为服务已经不可用了。\n\n## 参考资料\n\n- https://www.consul.io/intro/getting-started/checks.html","src/content/posts/consul-health-check.mdx","811aeeb2d9648556","consul-health-check.mdx","consul-cluster",{"id":229,"data":231,"body":237,"filePath":238,"digest":239,"legacyId":240,"deferredRender":22},{"title":232,"summary":233,"date":234,"tags":235,"group":224,"featured":38},"Consul 集群","单个节点的 consul agent 在测试时非常容易使用，但是如果想要在生产环境中搭建一个稳定的可靠的 consul 服务还需要对 consul cluster 有深入了解。",["Date","2018-04-28T00:00:00.000Z"],[236,224],"集群","单个节点的 consul agent 在测试时非常容易使用，但是如果想要在生产环境中搭建一个稳定的可靠的 consul 服务还需要对 consul cluster 有深入了解。\n\n当一个 consul agent 启动时，它本身对其它 consul 节点是一无所知的，这一个节点组成了一个独立的集群。如果想要知道其它的集群成员，这个 agent 必须在启动时加入一个已经存在集群。为了加入一个集群，这个 agent 必须知道至少一个独立存在的 agent member，待加入之后，这个 agent 会和这个节点进行通讯获取其它节点信息。\n\n一个 consul 的 agent 可以加入任何一个 agent，不仅包括 server mode 的 agent。\n\n## 启动多个 agent\n\n为了模拟一个真实的集群，我们将启动通过 vagrant 启动两个节点，vagrantfile 见 [demo section of the Consul repo](https://github.com/hashicorp/consul/tree/master/demo/vagrant-cluster) 。\n\n> vagrant 的下载配置非常简单，进入 https://www.vagrantup.com/downloads.html 选择所需要的版本，安装即可，注意翻墙。\n\n首先启动两个节点：\n```\nvagrant up\n```\n待系统可用之后，就可以进入机器进行集群相关的配置：\n```\nvagrant ssh n1\n```\n\n在前文中我们为了测试方便使用的 **-dev flag** 来启动一个 development server，但是在生产环境中我们将去掉这个参数。\n\n每个在 cluster 中的 node 必须要有唯一的名字，默认情况下 consul 使用 hostname，但是我们也可以使用 [-node](https://www.consul.io/docs/agent/options.html#_node) command-line option 进行覆盖。\n\n启动我们也可以指定 consul listen on 的地址，这个地址必须能被 cluster 中其它节点连接和使用。虽然 bind address 不是严格要求，但是最佳实践中总是推荐必须指定一个，consul 默认会监听所有 ipv4 的 interface，如果发现了多个 私有 ip，则停止 bind。\n\n第一个节点在我们整个 cluster 中将是一个单独的 server ，详见 [server](https://www.consul.io/docs/agent/options.html#_server) switch。\n\n[-bootstrap-expect flag](https://www.consul.io/docs/agent/options.html#_bootstrap_expect) 揭示了整个 cluster 中其它 server node 的数量，这个 flag 的目的是为了延迟 replicated log 复制，直到指定数量的 server 全部加入 cluster，详见 [bootstrapping guide](https://www.consul.io/docs/guides/bootstrapping.html) 。\n\n在这个 cluster 例子中，我们启用了 [-enable-script-checks](https://www.consul.io/docs/agent/options.html#_enable_script_checks) flag 来执行内部的脚本进行 health check。在生产环境中个，你可以配置 [ACLs](https://www.consul.io/docs/guides/acl.html)来配合这个 flag 来注册任意的脚本。\n\n```shell\nvagrant@n1:~$ consul agent -server -bootstrap-expect=1 \\\n    -data-dir=/tmp/consul -node=agent-one -bind=172.20.20.10 \\\n    -enable-script-checks=true -config-dir=/etc/consul.d\n...\n```\n\n然后我们再进入第二个 node：\n```shell\nvagrant ssh n2\n```\n\n第二个agent 启动时我们指定了 vargrantfile 中指定的 ip 和 node name，由于这个 node 不是 server，所以我们不必提供 [server](https://www.consul.io/docs/agent/options.html#_server) switch。\n\n```shell\nvagrant@n2:~$ consul agent -data-dir=/tmp/consul -node=agent-two \\\n    -bind=172.20.20.11 -enable-script-checks=true -config-dir=/etc/consul.d\n...\n```\n\n至此，我们有两个 consul agent 启动，一个是 server，一个是 client，两个 agent 彼此之间互相不知道，各自形成一个独立的 单节点 cluster，可以使用 [`consul members`](https://www.consul.io/docs/commands/members.html) 命令来验证这一点。\n\n## 加入 cluster\n\n现在，我们来告诉第一个 agent 加入第二个 agent：\n\n```shell\n$ vagrant ssh n1\n...\nvagrant@n1:~$ consul join 172.20.20.11\nSuccessfully joined cluster by contacting 1 nodes.\n```\n\n我们可以在两个 agent logs 看到它们彼此加入的信息：\n```shell\n2018/05/16 10:02:33 [INFO] agent: (LAN) joining: [172.20.20.11]\n2018/05/16 10:02:33 [INFO] serf: EventMemberJoin: agent-two 172.20.20.11\n2018/05/16 10:02:33 [INFO] agent: (LAN) joined: 1 Err: \u003Cnil>\n2018/05/16 10:02:33 [INFO] consul: member 'agent-two' joined, marking health alive\n\n```\n\n再次执行 consul members 可以进行验证，两个节点已经相互知道彼此了：\n```shell\nvagrant@n1:~$ consul members\nNode       Address            Status  Type    Build  Protocol  DC   Segment\nagent-one  172.20.20.10:8301  alive   server  1.1.0  2         dc1  \u003Call>\nagent-two  172.20.20.11:8301  alive   client  1.1.0  2         dc1  \u003Cdefault>\n```\n\n记住，为了加入一个集群，consul agent 仅仅只需要知道一个已经存在的 member 即可。\n\n## 在 agent 启动时自动加入 cluster\n\n理想的情况下，一个 agent 启动时应该自动加入 cluster 而不需要人工进行干预，consul 可以在各个云平台通过给定的 tag 进行自动发现。我们也可以在 agent 启动时手动指定节点信息 [-join](https://www.consul.io/docs/agent/options.html#_join) flag。\n\n## 查询节点\n\n和查询 service 类似，consul 也提供了类似的 API 通过 DNS 和 HTTP 的方式来查询节点信息，对 DNS API 来说，结构是 `NAME.node.consul` or`NAME.node.DATACENTER.consul`，如果 datacenter 被移除，consul 只会在本地 datacenter 查询：\n\n```shell\nvagrant@n1:~$ dig @127.0.0.1 -p 8600 agent-two.node.consul\n; \u003C\u003C>> DiG 9.9.5-9+deb8u14-Debian \u003C\u003C>> @127.0.0.1 -p 8600 agent-two.node.consul\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER\u003C\u003C- opcode: QUERY, status: NOERROR, id: 46375\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;agent-two.node.consul.     IN  A\n\n;; ANSWER SECTION:\nagent-two.node.consul.  0   IN  A   172.20.20.11\n\n;; Query time: 0 msec\n;; SERVER: 127.0.0.1#8600(127.0.0.1)\n;; WHEN: Wed May 16 10:06:26 GMT 2018\n;; MSG SIZE  rcvd: 66\n```\n\n查询节点信息对系统管理员特别有用，可以快速获得节点地址。\n\n## 离开 cluster\n\n如果想让 agent 离开节点，可以使用 ctrl-c 或者强制 agent 退出，gracefully 退出能够让节点过渡到 left 的状态，其它强制手段执行退出，其它节点会自动检测并标记节点为 failed。\n\n\n## 参考资料\n\n- https://www.consul.io/intro/getting-started/join.html","src/content/posts/consul-cluster.mdx","0ea170eefa719757","consul-cluster.mdx","consul-ui",{"id":241,"data":243,"body":249,"filePath":250,"digest":251,"legacyId":252,"deferredRender":22},{"title":244,"summary":245,"date":246,"tags":247,"group":224,"featured":38},"Consul UI","Consul 还提供了一个 web dashboard 用来查看 service、nodes、health checks，还可以用进行 kv 的 put 和 read，web ui 可独立部署 -ui parameter：",["Date","2018-05-17T00:00:00.000Z"],[248,224],"ui","Consul 还提供了一个 web dashboard 用来查看 service、nodes、health checks，还可以用进行 kv 的 put 和 read，web ui 可独立部署 [-ui parameter](https://www.consul.io/docs/agent/options.html#_ui)：\n\n```shell\nconsul agent -ui\n```\n\nUI 的默认地址是 http://localhost:8500/ui，在线 [demo](http://demo.consul.io/)\n\nConsul 1.1.0 中重新设计了新的 UI，可以设置环境变量 CONSUL_UI_BETA=true 开启。\n\n## 参考资料\n\n- https://www.consul.io/intro/getting-started/ui.html","src/content/posts/consul-ui.mdx","f5191ae2fac3da32","consul-ui.mdx","consul-kv",{"id":253,"data":255,"body":261,"filePath":262,"digest":263,"legacyId":264,"deferredRender":22},{"title":256,"summary":257,"date":258,"tags":259,"group":224,"featured":38},"Consul KV 存储","Consul 除了支持服务配置和发现，集成 Heath check 之外，还支持简单的 KV 存储且易于使用。KV 存储为 consul 赋予了更为丰富的使用场景，比如可以使用 KV store 做配置中心、服务协调、leader 选举等等。",["Date","2018-05-17T00:00:00.000Z"],[260,224],"kv","Consul 除了支持服务配置和发现，集成 Heath check 之外，还支持简单的 KV 存储且易于使用。KV 存储为 consul 赋予了更为丰富的使用场景，比如可以使用 KV store 做配置中心、服务协调、leader 选举等等。\n\n## 简单的使用\n\n使用 consul KV store 非常简单，在此我们使用几个简单的 key 来做个演示。Consul 提供了两种方法来存储 KV，一种是 http API，一种是 consul kv cli，为了演示简单我们在此使用 consul cli，更复杂的功能可以参考 [Consul KV HTTP API](https://www.consul.io/api/kv.html)。\n\n现在开始使用 consul 的 kv store，在此我们请求 consul 返回我们要求的 key 的数据：\n\n```shell\nvagrant@n1:~$ consul kv get redis/config/minconns\nError! No key exists at: redis/config/minconns\n```\n\n正如结果显示，没有此 key 相关的数据，因为我们还没有存储任何东西。现在我们使用 put 创建一个新的 key：\n```shell\n$ consul kv put redis/config/minconns 1\nSuccess! Data written to: redis/config/minconns\n\n$ consul kv put redis/config/maxconns 25\nSuccess! Data written to: redis/config/maxconns\n\n$ consul kv put -flags=42 redis/config/users/admin abcd1234\nSuccess! Data written to: redis/config/users/admin\n\n```\n再次执行 get 命令，会正确返回我们设置的值。\n\n使用 -detailed flag 可以让 consul 更详细的信息：\n```shell\nvagrant@n1:~$ consul kv get -detailed redis/config/minconns\nCreateIndex      6209\nFlags            0\nKey              redis/config/minconns\nLockIndex        0\nModifyIndex      6209\nSession          -\nValue            1\n```\n\n我们为 Key \"redis/config/users/admin\" 设置了一个 flag value 是 42，所有的 key 都支持 64-bit int flag value。所有的 client 都可以根据自己需要为 flag 提供一个有意义的值，consul 并不关心这个值是多少。\n\nConsul 还提供了 recurse 选项来显示所有的 key:\n```shell\nvagrant@n1:~$ consul kv get -recurse\nredis/config/maxconns:25\nredis/config/minconns:1\nredis/config/users/admin:abcd1234\n```\n\n删除一个 key 使用 delete 命令：\n```shell\n$ consul kv delete redis/config/minconns\nSuccess! Deleted key: redis/config/minconns\n```\n\n使用 recurse 选项可以删除指定的 prefix：\n```shell\n$ consul kv delete -recurse redis\nSuccess! Deleted keys with prefix: redis\n```\n\n更新 value 继续使用 put 命令：\n```\n$ consul kv put foo bar\n$ consul kv get foo\nbar\n$ consul kv put foo zip\n$ consul kv get foo\nzip\n```\n\nConsul 还支持原子操作，使用 Check-And-Set option 即可：\n```shell\n$ consul kv put -cas -modify-index=123 foo bar\nSuccess! Data written to: foo\n\n$ consul kv put -cas -modify-index=123 foo bar\nError! Did not write to foo: CAS fail\n```\n第一次修改成功了，第二次修改失败因为 modify-index 已经变更了，不再是 123。\n\n## 参考资料\n\n- https://www.consul.io/intro/getting-started/kv.html","src/content/posts/consul-kv.mdx","62a830c74c5f0af1","consul-kv.mdx","cookiecutters-for-fast-python-project",{"id":265,"data":267,"body":273,"filePath":274,"digest":275,"legacyId":276,"deferredRender":22},{"title":268,"summary":269,"date":270,"tags":271,"group":196,"featured":38},"使用 cookiecutter 快速构建 Python 项目","# 什么是 cookiecutter",["Date","2017-09-12T00:00:00.000Z"],[272],"cli","# 什么是 cookiecutter\n\n\n[cookiecutter](https://github.com/audreyr/cookiecutter) 是一款 CLI 用来帮助开发者从模板快速构建项目，比如利用 https://github.com/audreyr/cookiecutter-pypackage Python 开发者可以快速构建 Python 项目。\n\n# 如何使用？\n\n安装 `pip install cookiecutter`\n\n安装完成可以直接使用模板所在的 repo 进行项目创建，第一次使用模板**必须指定模板所在仓库地址** `cookiecutter https://github.com/audreyr/cookiecutter-pypackage` 或者 `cookiecutter gh:audreyr/cookiecutter-pypackage`。\n\ncookiecutter 会在第一次使用模板的时候 clone 模板到 $HOME/.cookiecutters 目录 `/Users/zhyq0826/.cookiecutters/cookiecutter-pypackage`。\n\n之后再次使用已经 clone 的模板可以直接使用名称 `cookiecutter cookiecutter-pypackage`。\n\n# cookiecutter-pypackage\n\ncookiecutter-pypackage 模板提供了 Python 项目常用的大部分配置包括\n\n```\n├── AUTHORS.rst\n├── CONTRIBUTING.rst\n├── HISTORY.rst\n├── LICENSE\n├── MANIFEST.in\n├── Makefile\n├── README.rst\n├── docs\n├── main.py\n├── markdown\n├── requirements_dev.txt\n├── setting.py\n├── setup.cfg\n├── setup.py\n├── tests\n├── tox.ini\n├── travis_pypi_setup.py\n\n```\n\n> 发现好工具，会用好工具，节省时间，珍爱生命 😁。","src/content/posts/cookiecutters-for-fast-python-project.mdx","eb8bc1a74e6eb83e","cookiecutters-for-fast-python-project.mdx","consul-service",{"id":277,"data":279,"body":286,"filePath":287,"digest":288,"legacyId":289,"deferredRender":22},{"title":280,"summary":281,"date":282,"tags":283,"group":224,"featured":38},"Consul 服务注册和查询","前文我们已经简单介绍 Consul 的安装和启动了，本篇我们来开始在 consul 中注册和使用 service",["Date","2018-04-28T00:00:00.000Z"],[284,224,285],"服务","service","前文我们已经简单介绍 Consul 的安装和启动了，本篇我们来开始在 consul 中注册和使用 service\n\n## 定义 service\n\nService 可以通过 [service 定义](https://www.consul.io/docs/agent/services.html)或者 API 调用进行注册，但是使用配置文件定义是最通用的形式。\n\n首先创建一个目录用来存放配置文件，Consul 会从配置目录中加载所有配置文件，一种在 unix 系统中通用的做法是在定义一个 `/etc/consul.d` 目录。\n\n```shell\nmkdir consul.d\n```\n\n然后创建一个文件用来存放我们定义的服务，在这个配置中我们还提供了一个 tag 用来做服务查询：\n\n```\n$ echo '{\"service\": {\"name\": \"web\", \"tags\": [\"python\"], \"port\": 8888}}' | tee consul.d/web.json\n```\n\n这里我们定义了名称是 web 并且跑在 8888 端口的 web 服务。\n\n重启 agent 并且提供配置目录：\n\n```shell\nconsul agent -dev -node=zhaoyongqiang -config-dir=consul.d\n==> Starting Consul agent...\n==> Consul agent running!\n           Version: 'v1.0.0'\n           Node ID: '2705278f-db30-b1a8-9607-1107a4524395'\n         Node name: 'zhaoyongqiang'\n        Datacenter: 'dc1' (Segment: '\u003Call>')\n            Server: true (Bootstrap: false)\n       Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, DNS: 8600)\n      Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)\n           Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false\n\n==> Log data will now stream in as it occurs:\n\n    2017/11/16 11:36:32 [DEBUG] Using random ID \"2705278f-db30-b1a8-9607-1107a4524395\" as node ID\n    2017/11/16 11:36:32 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:2705278f-db30-b1a8-9607-1107a4524395 Address:127.0.0.1:8300}]\n    2017/11/16 11:36:32 [INFO] raft: Node at 127.0.0.1:8300 [Follower] entering Follower state (Leader: \"\")\n    2017/11/16 11:36:32 [INFO] serf: EventMemberJoin: zhaoyongqiang.dc1 127.0.0.1\n    2017/11/16 11:36:32 [INFO] serf: EventMemberJoin: zhaoyongqiang 127.0.0.1\n    2017/11/16 11:36:32 [INFO] consul: Handled member-join event for server \"zhaoyongqiang.dc1\" in area \"wan\"\n    2017/11/16 11:36:32 [INFO] consul: Adding LAN server zhaoyongqiang (Addr: tcp/127.0.0.1:8300) (DC: dc1)\n    2017/11/16 11:36:32 [INFO] agent: Started DNS server 127.0.0.1:8600 (udp)\n    2017/11/16 11:36:32 [INFO] agent: Started DNS server 127.0.0.1:8600 (tcp)\n    2017/11/16 11:36:32 [INFO] agent: Started HTTP server on 127.0.0.1:8500 (tcp)\n    2017/11/16 11:36:32 [WARN] raft: Heartbeat timeout from \"\" reached, starting election\n    2017/11/16 11:36:32 [INFO] raft: Node at 127.0.0.1:8300 [Candidate] entering Candidate state in term 2\n    2017/11/16 11:36:32 [DEBUG] raft: Votes needed: 1\n    2017/11/16 11:36:32 [DEBUG] raft: Vote granted from 2705278f-db30-b1a8-9607-1107a4524395 in term 2. Tally: 1\n    2017/11/16 11:36:32 [INFO] raft: Election won. Tally: 1\n    2017/11/16 11:36:32 [INFO] raft: Node at 127.0.0.1:8300 [Leader] entering Leader state\n    2017/11/16 11:36:32 [INFO] consul: cluster leadership acquired\n    2017/11/16 11:36:32 [INFO] consul: New leader elected: zhaoyongqiang\n    2017/11/16 11:36:32 [DEBUG] consul: Skipping self join check for \"zhaoyongqiang\" since the cluster is too small\n    2017/11/16 11:36:32 [INFO] consul: member 'zhaoyongqiang' joined, marking health alive\n    2017/11/16 11:36:32 [INFO] agent: Synced service 'web'\n```\n\n注意输出包含了 \"synced\" the web service，consul 已经成功把定义的服务导入 service catlog 了。\n\n## 查询服务\n\n一旦服务注册之后，我们就可以使用 DNS 或者 HTTP 的方式查询 service 了。\n\n### DNS 查询\n\n服务注册之后可以通过 DNS 进行服务查询，service 的 DNS name 是 **NAME.service.consul**，默认情况下所有的 DNS names 总是在 consul namespace 中，namespace 可以进行 [配置](https://www.consul.io/docs/agent/options.html#domain) ，service 的 subdomain 用来告知 Consul 我们需要查询的 service 名称，在这里就是 NAME：\n\n```shell\n% dig @127.0.0.1 -p 8600 web.service.consul                                                                          \n\n; \u003C\u003C>> DiG 9.8.3-P1 \u003C\u003C>> @127.0.0.1 -p 8600 web.service.consul\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER\u003C\u003C- opcode: QUERY, status: NOERROR, id: 25186\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0\n;; WARNING: recursion requested but not available\n\n;; QUESTION SECTION:\n;web.service.consul.        IN  A\n\n;; ANSWER SECTION:\nweb.service.consul. 0   IN  A   127.0.0.1\n\n;; Query time: 87 msec\n;; SERVER: 127.0.0.1#8600(127.0.0.1)\n;; WHEN: Thu Nov 16 11:46:31 2017\n;; MSG SIZE  rcvd: 52\n```\n\n可以看到一个带有节点 ip 的 record 会返回，record 只能 hold IP address。\n\n我们也可以通过 DNS 查询完整的 address/port pair:\n\n```shell\n± % dig @127.0.0.1 -p 8600 web.service.consul SRV\n\n; \u003C\u003C>> DiG 9.8.3-P1 \u003C\u003C>> @127.0.0.1 -p 8600 web.service.consul SRV\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER\u003C\u003C- opcode: QUERY, status: NOERROR, id: 50494\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 2\n;; WARNING: recursion requested but not available\n\n;; QUESTION SECTION:\n;web.service.consul.        IN  SRV\n\n;; ANSWER SECTION:\nweb.service.consul. 0   IN  SRV 1 1 8888 zhaoyongqiang.node.dc1.consul.\n\n;; ADDITIONAL SECTION:\nzhaoyongqiang.node.dc1.consul. 0 IN A   127.0.0.1\nzhaoyongqiang.node.dc1.consul. 0 IN TXT \"consul-network-segment=\"\n\n;; Query time: 36 msec\n;; SERVER: 127.0.0.1#8600(127.0.0.1)\n;; WHEN: Fri Nov 17 16:19:30 2017\n;; MSG SIZE  rcvd: 137\n```\n\nSRV 记录表明 web service 在端口 8888 上并且存在于 zhaoyongqiang.node.dc1.consul 这个节点上。\n\n我们也可以使用 tag 过滤需要出现的 web service，形如 **TAG.NAME.service.consul**，比如使用我们定义 service 时使用的 tag python：\n\n```shell\ndig @127.0.0.1 -p 8600 python.web.service.consul\n\n; \u003C\u003C>> DiG 9.8.3-P1 \u003C\u003C>> @127.0.0.1 -p 8600 rails.web.service.consul\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER\u003C\u003C- opcode: QUERY, status: NOERROR, id: 14331\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0\n;; WARNING: recursion requested but not available\n\n;; QUESTION SECTION:\n;rails.web.service.consul.  IN  A\n\n;; ANSWER SECTION:\nrails.web.service.consul. 0 IN  A   127.0.0.1\n\n;; Query time: 15 msec\n;; SERVER: 127.0.0.1#8600(127.0.0.1)\n;; WHEN: Fri Nov 17 16:23:39 2017\n;; MSG SIZE  rcvd: 58\n```\n\n### HTTP 查询\n\n除了 DNS 也可以使用 HTTP 的方式查询 web service\n\n```\n± % curl http://localhost:8500/v1/catalog/service/web\n\n[\n    {\n        \"ID\": \"2705278f-db30-b1a8-9607-1107a4524395\",\n        \"Node\": \"zhaoyongqiang\",\n        \"Address\": \"127.0.0.1\",\n        \"Datacenter\": \"dc1\",\n        \"TaggedAddresses\": {\n            \"lan\": \"127.0.0.1\",\n            \"wan\": \"127.0.0.1\"\n        },\n        \"NodeMeta\": {\n            \"consul-network-segment\": \"\"\n        },\n        \"ServiceID\": \"web\",\n        \"ServiceName\": \"web\",\n        \"ServiceTags\": [\n            \"python\"\n        ],\n        \"ServiceAddress\": \"\",\n        \"ServicePort\": 8888,\n        \"ServiceEnableTagOverride\": false,\n        \"CreateIndex\": 6,\n        \"ModifyIndex\": 6\n    }\n]\n```\n\nhttp api 可以返回所有定义了该服务的节点信息，稍后我们在 [health checks](https://www.consul.io/intro/getting-started/checks.html) 会看到，通常情况下你指向查询健康状态是 passing 的实例节点。\n\n```shell\ncurl 'http://localhost:8500/v1/health/service/web?passing'\n[\n    {\n        \"Node\": {\n            \"ID\": \"db363ec4-ba40-8563-fa35-b9fd762aaf2b\",\n            \"Node\": \"zhaoyongqiang\",\n            \"Address\": \"127.0.0.1\",\n            \"Datacenter\": \"dc1\",\n            \"TaggedAddresses\": {\n                \"lan\": \"127.0.0.1\",\n                \"wan\": \"127.0.0.1\"\n            },\n            \"Meta\": {\n                \"consul-network-segment\": \"\"\n            },\n            \"CreateIndex\": 5,\n            \"ModifyIndex\": 6\n        },\n        \"Service\": {\n            \"ID\": \"web\",\n            \"Service\": \"web\",\n            \"Tags\": [\n                \"python\"\n            ],\n            \"Address\": \"\",\n            \"Port\": 8888,\n            \"EnableTagOverride\": false,\n            \"CreateIndex\": 6,\n            \"ModifyIndex\": 6\n        },\n        \"Checks\": [\n            {\n                \"Node\": \"zhaoyongqiang\",\n                \"CheckID\": \"serfHealth\",\n                \"Name\": \"Serf Health Status\",\n                \"Status\": \"passing\",\n                \"Notes\": \"\",\n                \"Output\": \"Agent alive and reachable\",\n                \"ServiceID\": \"\",\n                \"ServiceName\": \"\",\n                \"ServiceTags\": [],\n                \"CreateIndex\": 5,\n                \"ModifyIndex\": 5\n            }\n        ]\n    }\n]\n```\n\n\n\n## 更新 service\n\nservice 更新可以通过重新定义配置文件或者 HTTP 接口进行更新，更新配置文件可以向 agent 发送 SIGHUP 来达到不重启服务而更新配置的目的。\n\n## 参考资料\n\n- https://www.consul.io/intro/getting-started/services.html","src/content/posts/consul-service.mdx","8ef3fa79cd930ff1","consul-service.mdx","deep-understand-python-package",{"id":290,"data":292,"body":298,"filePath":299,"digest":300,"legacyId":301,"deferredRender":22},{"title":293,"summary":294,"date":295,"tags":296,"group":196,"featured":38},"深入理解 Python package","Python 是通过 module 组织代码的，module 即一个 py 文件，module 又是通过 package 来组织的，package 是一个包含 的文件夹，代码，module，package 它们三者的关系就是：module 包含代码，package 至少包含一个为...",["Date","2017-09-14T00:00:00.000Z"],[297],"package","Python 是通过 module 组织代码的，module 即一个 py 文件，module 又是通过 package 来组织的，package 是一个包含 `__init__.py` 的文件夹，代码，module，package 它们三者的关系就是：module 包含代码，package 至少包含一个为 `__init__.py` 的 module。\n\n```\npackage\n├── __init__.py\n├── submodule.py\n└── subpackage\n    └── __init__.py\n\n```\n\nPython 的 package 以及 package 中的 `__init__.py` 共同决定了 package 中的 module 是如何被外界访问的。\n\n{/* more */}\n\n\n# 空的 `__init__.py` \n\n不包含任何代码的 `__init__.py` 只用来标识一个文件夹是一个 package，而 package 是可以被导出的。\n\n```python\nfrom package import item\n\n```\n\n此处的 `item` 可以是 package 中包含的 submodule 或  subpackage。\n\n```\n>>> from package import submodule\n>>> from package import subpackage\n>>> \n```\n\n\n# `__init__.py` 不为空\n\n\n如果 `__init__.py` 不为空，其中包含的任何变量，包括 function、class、variable 以及 任何被导入的 module 都可以通过 package 导出。\n\n```python\nfrom package import item\n\n```\n\n此处的 `item` 可以是 `__init__.py` 中的任何变量。\n\n\n# package 的初始化工作\n\n一个 package 被导入，不管在什么时候 `__init__.py` 中的代码只执行一次。\n\n```\n>>> import package\nhello world\n>>> import package\n>>> import package\n>>> \n\n```\n\n由于 package 被导入时 `__init__.py` 中的可执行代码会被执行，所以小心在 package 中放置你的代码，尽可能消除它们产生的副作用，比如把代码尽可能的进行封装成函数或类。\n\n# 从 package 中导入变量的顺序\n\n```python\n\nfrom package import item\n\n```\n\nimport 语句首先检查 `item` 是否是 `__init__.py` 中定义的变量，然后检查其是不是一个 subpackage，如果不是再去检查其是不是一个 module，都不是将抛出 `ImportError`。\n\n\n在 `import item.subitem.subsubitem` 语句时，除了最后一个 subsubitem 之外其他 item 都必须是 package，而最后一个 subsubitem 必须是一个 package 或者 module，不能是他前一个 item 定义的 function、class、variable。\n\n\n# 使用 `*` 导入 \n\n在 `from package import *` 语句中，如果 `__init__.py` 中定义了 `__all__` 变量，一个 list，仅仅只有这个 list 中定义的 submodule 或者变量将会被导出。\n\n如果 `__init__.py` 中没有 `__all__` 变量，导出将按照以下规则执行：\n\n1. 此 package 被导入，并且执行 `__init__.py` 中可被执行的代码\n2. `__init__.py` 中定义的 variable 被导入\n3. `__init__.py` 中被显式导入的 module 被导入","src/content/posts/deep-understand-python-package.mdx","8a20a31ad3872829","deep-understand-python-package.mdx","ember-best-practice",{"id":302,"data":304,"body":311,"filePath":312,"digest":313,"legacyId":314,"deferredRender":22},{"title":305,"summary":306,"date":307,"tags":308,"group":310,"featured":38},"Ember 最佳实践","用 Go 写的发布系统前端用的是 ember 做的，之所以用 ember 是因为三年前用 ember 实现了一套做 CMS 的框架，ember-semantci-ui 和 ember-easy-orm，两个东东几乎涵盖了做 CMS 需要的方方面面：数据加载层、loading和消息...",["Date","2018-12-26T00:00:00.000Z"],[309],"ember","JavaScript","用 Go 写的发布系统前端用的是 ember 做的，之所以用 ember 是因为三年前用 ember 实现了一套做 CMS 的框架，[ember-semantci-ui](https://github.com/wecatch/ember-semantic-ui) 和 [ember-easy-orm](https://github.com/wecatch/ember-easy-orm)，两个东东几乎涵盖了做 CMS 需要的方方面面：数据加载层、loading和消息管理、各种 ui、form 管理等等，其实这几年由于 react 和 vue 发展迅猛，基于 react 和 vue 的 cms 系统已经有不少了，比如 ant design 等，之所以还用 ember 有几个原因：\n\n第一，我是个后端程序员对前端不是特别熟悉，从头开始学习 react 以及 vue 并且做能够做出非常复杂的应用而且可维护性也非常好，时间来不及。\n\n第二，对于前端的东西，我其实很想做到方方面面都能控制到才行，由于之前用 ember 写过 ui 层和 model 层的组件，对数据加载、状态管理、消息管理、form 管理等已经形成了非常成熟的方案，于是就很懒的在替换了。\n\n\n当然如果有着非常成熟的 react 之流的现成方案能用，还是用 react 吧，阿里最近出的 fusion 就很不错。\n\n\n## 先简单聊一下 ember\n\nEmber 这个框架非常的复杂，东西很多，但是文档写的又比较抽象，不太好懂，新版本比之前简化了太多东西，但是还是比较复杂，由于 ember 已经规定好了 route，template，component，controller等应该怎么写，所以一旦懂了之后，基本上就是按部就班实现，而且 ember 自身的规范可以说就是团队的规范，不需要再去另寻最佳实践了。\n\n\nEmber 周边的 plugin 应该没有 react 多，但是由于 Ember 是基于 jQuery 的，所以 jQuery 的插件基本都能用，这是一个优势。\n\n\n## 框架和库\n\n从头开发一个完整的 APP 费时费力，ember 有很多第三方的 plugin 非常好用，提供了一系列的功能\n\n- https://github.com/poteto/ember-cli-flash  消息通知\n- https://github.com/DockYard/ember-composable-helpers  常用 helper\n- https://github.com/wecatch/ember-easy-orm     ORM 层，比 ember-data 简单，和 ember-semantic-ui 紧密结合\n- https://github.com/wecatch/ember-semantic-ui  CMS ui 层\n- https://github.com/jmurphyau/ember-truth-helpers 常用 helper，语法友好\n- https://github.com/thoov/ember-websockets websocket\n- https://github.com/simplabs/ember-simple-auth 权限认证\n\n借助这些第三方框架能够非常快速的实现各种功能\n\n## loading 和网络状态响应\n\n\nEmber 支持在 route 层的 model 解析前后 beforeModel 和 afterModel 挂载 loading hook，也支持全局 route 和各个子 route 挂载自定义 loading，可以说是毫不费力就就可以实现各种 loading，但是一个体验真正好用的 loading 需要能够覆盖数据加载的各个阶段：准备网络请求，发起网络请求，等待响应，解析结果等等，loading 和 加载提示几乎是无缝结合的，loading 结束的时候提示应该根据当前请求的状态立马出来，这样才能给用户以平滑的体验，让整个 APP 显示出活的状态。\n\n为此在 [ember-easy-orm](https://github.com/wecatch/ember-easy-orm) 通过暴露 ajax 请求阶段的各种 hook 来实现 loading 的 start 和 stop 以及消息的及时响应。\n\n\n## 记录问题解决的方案\n\n\nEmber 是大而全的框架，而且受众比较小，一旦出现问题真的就是考验解决问题的能力，因此一旦解决了某个问题，最好立马记录下来，以防下次的时候遗忘。\n\n我在 https://github.com/wecatch/emberjs-guide/ 写了一个 guide 用来记录 ember 开发的方方面面，感兴趣的可以参考一下。\n\n\n## 理解 component 的生命周期\n\n维护性好的 ember APP 大量的逻辑实现都是封装在 component 中，因此理解 component 的整个生命周期并且能在各个阶段正确实现业务逻辑是 component 可维护性高的一个重要前提。\n\n官方 guide 对 component lifecycle 有详细说明 https://guides.emberjs.com/release/components/the-component-lifecycle/\n\n## 做好 model 状态管理\n\n\n如果 APP form 很多，非常容易变得混乱，所以最好能对每个 form 都显示定义，并且通过 model 和 form 一一映射起来，需要变更更改 model 和 对应的 form 文件即可。\n\n\n## 让后端 APP 支持 ember 的路由\n\nEmber 的路由实现是在前端做的，也就是说所有路由规则是 JavaScript 做的拦截，后端应用并没有定义这些路由，如果后端发生 404 需要保证 404 的页面渲染能进入 ember APP 的页面，这样才能触发前端的路由，所以不论你的后端是 Python 还是 Go 都需要做好 404 状态的渲染。","src/content/posts/ember-best-practice.mdx","0d1064f6f4024224","ember-best-practice.mdx","envoy-503",{"id":315,"data":317,"body":323,"filePath":324,"digest":325,"legacyId":326,"deferredRender":22},{"title":318,"summary":319,"date":320,"tags":321,"group":322,"featured":38},"istio 网关 envoy 503 问题总结","### 问题起因",["Date","2019-10-22T00:00:00.000Z"],[],"未分组","### 问题起因\n\n公司云上服务报在做灰度部署的时候报 503 问题，经过多日的定位于排查终于理清了 503 的来龙去脉。\n\n### 背景技术\n\n我司云上服务用的是 istio 做的网关，而 [istio]([https://istio.io](https://istio.io/)默认又用的是 [envoy](https://www.envoyproxy.io/) 做的代理，istio 作为一个 [service mesh](https://www.redhat.com/en/topics/microservices/what-is-a-service-mesh) 的存在，天然对流量管控很擅长，结合 k8s 非常容易实现灰度发布、蓝绿发布。\n\n### http 协议的 503 状态码\n\n假设任何主动发起连接的一方是 client，任何被动接受连接的一方是 server，503 表示 server 服务能力出现了问题，也就是说 503 是 server 端告知的 client 的一种状态，server 此时至少还有连接的能力，并且告知连接他的 client 503。有些时候如果 server 的负载过高，也有可能不会发送 503 的状态，而是直接拒绝连接。\n\n### 什么时候 istio 网关会报 503\n\n明确 503 的具体含义，我们来一起分析一下 istio 网关的 503。\n\n![](https://static.git-star.com/request-path-istio.jpg)\n\n首先明确这里的网关实际是指流量从外部进入 k8s 集群的入口，也就是 k8s 的边缘节点，因而实际上能感知到网关 503 的是下游服务 downstream ，也就是连接网关的应用程序，此时网关作为 server 为 downstream 提供服务，**1. 如果网关负载过高，连接超时，对 downsream 服务报就会 503 或者直接拒绝 downstream 的连接请求**。\n\n网关作为 k8s 集群的流量出入口，是 downstream 和 upstream 的中转站，而这里 upstream 就是指 k8s 集群内部 Pod 中的应用程序。如果应用程序出现不可用，upstream 就会对网关报 503或者直接拒绝网关的请求，此时 upstream 是 server，网关是 client，这个时候网关对连接他的 downstream 如何处理？报 503。这是 503 的 case 之二：**2. k8s 集群内的应用程序负载过高，对网关报 503或者拒绝网关连接，网关把这个信息以 503 形式传递给 downstream**。\n\n还有一种情况是，**3. 如果请求正在被 upstream 处理，这个时候由于意外情况关闭了 upstream 服务**，此时网关收到的是类似 `upstream connect error or disconnect/reset before headers`  的错误，连接被中断，此时对网关也会把这种情况以 503 的形式报给 downstream ，这是 case 之三。\n\n以上三种是 istio 网关 503 情况最常见的三种情形，还有一种是更新 istio 规则之后由于规则同步需要时间，导致规则生效的间隙可能会有 503 的情况出现，这个不在此文中细表。\n\n### istio 网关灰度部署 503 问题的本质\n\n我司遇到 503 是灰度发布的时候，而灰度发布是借由 istio 的提供的带权重的流量切换机制实现的，就是建立多个 subset，不同的 subset weight 不同。在继续深入之前，这里有必须稍微讲讲 envoy 的几个核心概念以及其作为 k8s 边缘节点入口网关是如何做灰度发布的。\n\nistio 实现了一套 [xDS](https://www.servicemesher.com/istio-handbook/data-plane/envoy-xds-protocol.html) 的协议，借助这套协议，istio 可以对 k8s API server 进行监控，一旦发现上游 k8s service 有新的 Pod 加入，就会把这个信息发送到网关的 envoy，envoy 收到这个信息之后就会更新它的 [cluster](https://www.servicemesher.com/istio-handbook/data-plane/envoy-terminology.html)，cluster 就是 envoy 的 upstream，envoy 把 [route](https://www.servicemesher.com/istio-handbook/data-plane/envoy-terminology.html) 的流量通过 [host](https://www.servicemesher.com/istio-handbook/data-plane/envoy-terminology.html) 以及一些其他流量匹配规则分发给对应的 cluster。假设有 host 是 www.sanyuesha.com ，route 配置的流量规则是所有请求这个 host 流量都由 cluster A 负责，而 cluster A 是由 k8s 集群满足 A.default.svc.cluster.local 的服务提供的，这个服务对应的 Pod 是 a1 和 a2:\n\n![](https://static.git-star.com/istio-route-rule1.png)\n\n\n\n在未进行权重分配流量之前，所有流量都根据对应负载均衡算法分配到所有的 Pod，istio 提供了 subset 的机制来对流量进行权重分配，而这个机制的实现其实就是使用 Pod 的 label 进行筛选形成两组不通的 cluster 的过程。\n\n![](https://static.git-star.com/istio-route-rule2.png)\n\n灰度部署就是对相同的 service 不同的 Pod 进行版本区分，逐步切换流量的过程。为了实现灰度部署，首先要对 Pod 进行版本区分，不同 Pod 打上不同的标签，然后告诉 envoy 建立两个不同的 cluster 来实现流量的版本切分。流量通过这种方式一点点从老版本切换到新版本，等全部切换完成之后，释放掉老版本占用的资源。But! 在最后释放资源时，这里就有一个很 tricky 的问题。\n\n对于旧的 Pod 资源来说，如果没有了流量本来是可以删除的，但是为了减少 envoy 中的 route 规则(规则多了会造成网关 CPU 负载变高)，我们也对envoy的virtualservice进行了清理，也就是把subset删除，恢复成默认的没有 subset 的 virtualservice，这个时候 envoy 指向的后端的 cluster 就是 A.default.svc.cluster.local 指向的所有的 Pod。问题就在于清理 subset 和清理 Pod 的顺序我们在实现灰度部署时没有在意。\n\n如果先清理 subset，此时流量会流向 A.default.svc.cluster.local 所指向的所有 Pod，也就是旧的 Pod 就会重新接管流量，此时再删除 Pod 肯定会报 503。\n\n如果先清理 Pod，网关会感知到 Pod 不健康从而把已经没有流量的旧 Pod 节点从 cluster 中摘除，此时再清理 subset，则不会有 503 出现。\n\n### 总结\n\n使用 istio 做灰度部署切流量的时候要重点注意规则切换和 Pod 资源清理的顺序，还有一种解决灰度流量切换的方法是始终使用两个 subset：v1 和 v2，每次部署使用这两个 subset 做新老版本交替切换流量。","src/content/posts/envoy-503.mdx","b3d25d4789871adb","envoy-503.mdx","distributed-lock-with-redis",{"id":327,"data":329,"body":337,"filePath":338,"digest":339,"legacyId":340,"deferredRender":22},{"title":330,"summary":331,"date":332,"tags":333,"group":336,"featured":38},"如何用 redis 造一把分布式锁","## 基本概念",["Date","2016-08-20T00:00:00.000Z"],[334,335],"lock","distributed","redis","## 基本概念\n\n### 锁\n\n> [wiki](https://en.wikipedia.org/wiki/Lock_(computer_science):In computer science, a lock or mutex (from mutual exclusion) is a synchronization mechanism for enforcing limits on access to a resource in an environment where there are many threads of execution. A lock is designed to enforce a mutual exclusion concurrency control policy.\n> 在计算机科学中，锁或互斥量是一种同步机制，用于在多线程执行环境中，强行限制对资源访问。锁常被用于同步并发控制。\n\n简单来讲，锁是用来控制多线程执行对资源的并发访问的。比如当一个资源只允许在任意时刻只有一个执行线程对其进行写操作，那当其他线程要访问资源时，就必须要检查该该资源上是否存在`写操作锁`，如果存在，必须要等待锁的释放并获得锁之后才能对资源进行访问。\n\n{/* more */}\n\n### 悲观锁\n\n悲观锁假设在一个完整事务发生的过程中，总是会有其他线程会更改所操作的资源，因此线程总是对资源加锁之后才会对其做更改。\n\n### 乐观锁\n\n乐观锁假设在一个完整事务发生的过程中，不一定会有其他线程会更改资源，一旦发现资源被更改，则停止当前事务回滚所有操作。\n\n### 分布式锁\n\n常见的锁有多线程锁、数据库事务中的行级锁、表级锁等，这些锁的特点都是发生在单一系统环境中，如果需要在不同的进程、不同机器和系统等分布式环境中控制对资源的访问，这时候我们需要一把分布式锁。\n\n不言而喻，分布式锁就是为了解决分布式环境中对资源的访问限制而诞生的。\n\n## 如何设计一把分布式锁\n\n\n我们用 redis 来实现这把分布式的锁，redis 速度快、支持事务、可持久化的特点非常适合创建分布式锁。\n\n\n### 分布式环境中如何消除网络延迟对锁获取的影响\n\n锁，简单来说就是存于 redis 中一个唯一的 key。一般而言，redis 用 `set` 命令来完成一个 key 的设置(加锁)，使用 `get` 命令获取 key 的信息(检查锁)。由于网络延迟的存在，简单的使用 `set` 和 `get` 命令可能会带来如下问题：\n\n线程 A 检查锁是否存在(get)-->否-->加锁(set)，在 A 发起加锁命令但是还没有加锁成功的时候，可能线程 B 已经完成了 `set` 操作，锁被 B 获得，但是 A 也发起了加锁请求，由于 `set` 命令并不检查 key 的存在，B 的锁很可能会被 A 的 `set` 操作破坏。\n\n幸运的是，redis 提供了另一个命令 `setx` : 当指定的 key 不存在时，设置 key 的值为指定 value，如果存在，不做任何操作，成功则返回 1，失败则返回 0。也就是只要命令返回成功，线程就能正确获得锁，不需要再做类似 `get` 检查操作。\n\n使用 `setx` 可以消除网络延迟对锁设置的影响。\n\n### 加锁的客户端发生 crash 导致锁不能被正确释放应该怎么处理？\n\n加锁成功并操作完成之后，就需要加锁线程对锁进行释放，以让出资源的控制权。释放锁，就是删除 redis 中这个唯一的 key，但是一定要保证删除的这个 key 是该线程创建的，因而锁创建时必须携带执行线程的唯一特征以标示创建者的身份，在这里就是这个唯一 key 对应的 value。\n\n如果加锁的线程出现异常 crash 了而不能及时删除锁，则会导致锁一直无法被正确释放，资源处于一直被占有，别的线程处于一直等待的状态。为了避免这样的情况，锁一定要在异常发生之后可以自己释放，以让出资源的控制权，可以使用 redis 的超时机制来达到这个目的。超时时间视不同的业务场景而定，一般是最大允许等待时间。需要注意的是，只有在加锁成功之后才可以对 key 设置 TTL，否则很容易导致 key 被多个线程不断设置 TTL 而无法过期。\n\n```python\n  if CONN.setnx(lockname, identifier):\n    CONN.expire(lockname, timeout)\n```\n\n\n### 加锁之后如何有效监测锁是否被篡改？\n\nredis 提供了 pipeline 和事务操作来保证多个命令可以在一个事务内全部完成从而减少多次网络请求带来的开销，watch  命令又可以在事务开始执行之前对所要操作的 key 执行监测，从而保证了事务的完整性和一致性。因此，为了防止锁篡改，可以在加锁完成之后对锁进行 watch 操作，一旦锁发生变化，则终止事务，回滚操作。\n\n```python\npipe = CONN.pipeline(True)\npipe.watch(lock)\n```\n\n### 提供锁的宿主机( redis 服务器) crash 导致锁不能被正确建立和释放该如何处理？\n\n\n不论是通信故障或是服务器故障而导致的锁服务器无法响应，此时都会导致客户端加锁和释放锁的请求无法完成，因此一定要有相应的应急处理，以确保程序流程的完整体验，加强客户端的健壮性。比如相应的超时提示，异常告警等。\n\n\n## 哪些边界需要注意\n\n1.只有锁正确释放才算是整个事务的完整结束，如果锁释放失败，比如被篡改、锁服务器异常等，不同的业务可以根据自己的需求进行变动和调整。\n\n2.设置 TTL 一定要在加锁成功之后，否则所有获取锁的客户端都会尝试 TTL 导致锁无法过期。\n\n3.锁的过期时间也就是获取锁的客户端的最大等待时间，这个时间以执行的事务能够容忍的最长时间为限\n\n\n## 一个简单的 python 实现\n\n{% gist 5e474f42c8167ab32a6627ddd837fc83 redis_lock.py %}\n\n\n在上面这个实现中，如果锁释放(release_lock)失败，客户端可以尝试对当前的操作进行回滚或自定义处理方式。\n\n如果业务的事务是在 redis 中执行的，完全可以用 redis 的 pipeline 和事务(开始前对锁键进行 watch )来完成所有操作，执行完成之后正确删除锁即可，这样 release_lock 的操作就可以不需要单独进行了。\n\n```python\ntry:\n    pipe.watch(lock)\n    pipe.multi()\n    #TODO transaction with redis command\n    pipe.delete(lock)\n    pipe.unwatch(lock)\nexcept:\n    #TODO transaction failes\n    pass\nelse:\n    #TODO transaction success\n    pass\n```","src/content/posts/distributed-lock-with-redis.mdx","e44d4c0e73f244c4","distributed-lock-with-redis.mdx","first-art-for-my-life",{"id":341,"data":343,"body":348,"filePath":349,"digest":350,"legacyId":351,"deferredRender":22},{"title":344,"summary":345,"date":346,"tags":347,"group":129,"featured":38},"程序人生的第一件艺术品",">没有一点儿疯狂，生活就不值地过，同样，没有一件自己的艺术品，程序人生就是不完整的",["Date","2016-01-12T00:00:00.000Z"],[],">没有一点儿疯狂，生活就不值地过，同样，没有一件自己的艺术品，程序人生就是不完整的\n\n我不是一个善于总结的人，因为看着自己的过去，就如同对着镜子不断检视自己犯得错误，数落那曾经的幼稚和愚蠢，徒增懊恼。\n\n但是掺杂程序的人生却必须不断地审视，重构，一旦对bug恣意放纵，不管不问，这样的人生必将坎坷不断，难以运转。\n\n所以这算是一篇象征性的总结，对某一段程序人生的重构和梳理，为的是让自己不至于看得不明不白，将来别人接管时，也能一目了然，这是对程序人自己起码的要求，也是对别的程序人起码的尊重。\n\n>我原以为可以用代码写诗，但是敲出来的只是烦躁和不安\n\n{/* more */}\n\n当开始北漂，投身于这个忙碌的世界，为生活而奔波，代码的世界渐渐变得不再理想主义，越来越功利，原来想改变世界的野心都变成了不断被引用的自嘲，原来游走于指尖键盘的优雅逐渐消失，取而代之的是焦躁和不安，以及对未来的迷茫和恐惧。细思极恐。\n\n于是，2014年的某个时候，wecatch 这个名字诞生了，寓意不输于这个时代。从那之后，反反复复看`肖生克的救赎`和`阿甘正传`, 借着前者的耐心和后者的无畏，希望自己可以像一个匠人一样，磨砺出一件一件可以造福别人的艺术品。以此，才不愧于对代码的喜爱，不愧于那许多个不眠之夜的思考和敲打。\n\n\n>忙，却似乎也没忙成什么，时间被碾得如此之碎，一阵风吹过，稀里哗啦全都不知去向，以至于我试图回想这一年到底干了些什么时，发现自己简直是从一场昏迷中醒来\n\n\n生活的琐碎有时候是幸福的，有时候也是可怕的，它像一场支离破碎的梦境，拼接不出一场完整的戏，等如梦初醒之时，所有的镜头都有可能不忍直视，难以剪切。匆匆之间，时间流逝，一切如初，誓言不在。\n\n忙，有时候会扼杀一切微小的可能，会成为任何无法创造的借口。时间一日日过去，转头想，好像只有忙。\n\n于是 [GitStar](https://git-star.com) --专为程序人打造的 Github Star 管理工具--诞生于异地的宾馆之中，诞生于疾驰的高铁上，诞生于睡前的半小时之间，诞生于周末的兴奋和疲惫当中，wecatch 创造了第一个属于他的艺术品，也是我的艺术品，我们的艺术品。\n\n\n>时间是最厉害的杀手, 也是最好的见证者\n\n[GitStar](https://git-star.com) 不仅仅是个开始吧","src/content/posts/first-art-for-my-life.mdx","8f6c36f823805a74","first-art-for-my-life.mdx","five-keys-to-a-killer-go-cli",{"id":352,"data":354,"body":359,"filePath":360,"digest":361,"legacyId":362,"deferredRender":22},{"title":355,"summary":356,"date":357,"tags":358,"group":50,"featured":38},"创建一个杀手级 Go Cli 的 5 个关键点","> 本文翻译自 https://blog.alexellis.io/5-keys-to-a-killer-go-cli/。 > > 本文的作者是 OpenFaaS 的作者，原文中作者结合了自身开发 OpenFaaS 经历说明的 CLI 应该需要的注意事项，翻译过程中为了方便理解很...",["Date","2018-05-23T00:00:00.000Z"],[272],"> 本文翻译自 https://blog.alexellis.io/5-keys-to-a-killer-go-cli/。\n>\n> 本文的作者是 [OpenFaaS](https://github.com/openfaas) 的作者，原文中作者结合了自身开发 OpenFaaS 经历说明的 CLI 应该需要的注意事项，翻译过程中为了方便理解很多已经略去，但是不妨碍整体理解作者表达使用 Go 创建优秀 CLI 的意图以及方法。\n\nCLI（命令行接口）是一种文本接口，其提供了一种快速、自动化的方式与应用程序打交道，并且还可以和其他命令行程序接口创建新的工作流。\n\n## 选择 Go 创建 CLI\n\n选择 Go 创建 CLI 的优势\n\n**Compiles to a single static binary — 能够编译成单独的二进制包** \n\nGo 可以非常方便的根据平台打包成二进制包发布，根据平台的不同，只需要在编译的时候提供不同的环境变量即可：\n\n```shell\nGOOS=windows go build -o cli.exe\nGOOS=linux go build -o cli\nGOARCH=armv7 GOOS=linux go build -o cli-rpi\n```\n\n**Consistent style — 一致的风格**\n\n无论你的项目是基于何种编辑器，Go 总是提供一致的代码风格，这点和 Nodejs 不同，后者总是包含很多种不同的 \"task runners\" 让人眼花缭乱。\n\nGo 在风格保持方面的设计可以说非常不含糊，这样的设计有利于开发者进行协作。\n\n**Fast on every platform — 在任何平台都很快**\n\n编译后 Go 二进制包加载非常快相比 Nodejs 来说。\n\n**Easy to create a REST client — 创建 REST 风格的 client 非常容易**\n\nGo 提供了非常丰富的 http client，并且内置了对 xml、json 的支持，社区的第三方库也提供了对 YAML 的支持\n\n## Parse flags & arguments\n\nGo 标准库提供了 flags 包来创建 CLI 应用程序：\n\n```Go\npackage main\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n)\n\nfunc main() {\n\tvar image string\n\tflag.StringVar(&image, \"image\", \"\", \"Docker image\")\n    flag.Parse()\n    \n\tif len(image) == 0 {\n\t\tfmt.Fprintf(os.Stderr, \"You must specify a Docker image name\")\n\t}\n\n\tfmt.Printf(\"Your Docker image was: %s\", image)\n}\n```\n\nGo 的简单朴可以让你仅仅使用一个文件就能够编译成要执行的二进制包。\n\n如果你觉得 flags 包提供的特性已经无法满足你的 CLI ，你可以考虑使用 [Cobra](https://github.com/spf13/cobra) 。\n\n[Cobra](https://github.com/spf13/cobra) 被 Docker、Kubernetes 等知名开源软件使用，Cobra 也可以让创建 CLI 的文档变得非常简单。除此之外，Cobra 支持动词名词的语法，这有助于提升 CLI 的用户体验：\n\n```shell\nfaas-cli -deploy -image=functions/alpine -name=cat -fprocess=/bin/cat\n\n```\n\nTo：\n\n```shell\nfaas-cli deploy --image=functions/alpine --name=cat --fprocess=/bin/cat\n\n```\n\n## 自动化一切\n\n使用一个免费公开的 CI 平台来自动化 build 工作，比如 Travis，这样可以让 contributors 检测他们的贡献是否可以被集成。\n\n使用 Github release 来跟踪项目的变化和里程碑，可以在 Travis 中创建一个 post-build action 来自动打包发布各个平台的应用。\n\n如果你使用 Docker ，每当要发布新的 release 同时也发布对应的 Docker 镜像。\n\n## 集成包管理器\n\n如果你想要你的受众非常容易使用你的 CLI，最好让你的 CLI 支持使用包管理器安装：\n\n- Mac\n\n  大多数开发者的环境都是 Mac，所以提供 brew 的支持是个明智的选择\n\n- Linux\n\n  对于 Linux 可以提供命令行安装和使用的方案，比如 `curl -sL https://cli.openfaas.com | sh`\n\n- Windows\n\n  大多数 Windows 用户倾向于使用安装的方式，Windows 平台的好用的 shell 工具在不断增多，也可以考虑提供一种 shell 的安装方式\n\n无论是支持哪个平台的包管理，优先确保你的工作是可自动化的，而且升级能够平滑进行。\n\n## 接受社区的贡献和收集反馈\n\n为用户提供一种非常方便的反馈方式。基础的反馈和统计可以通过 Github 或者 brew 来完成。有些关键性的项目是可以通过第三方工具收集反馈，比如通过 brew、Visual Studio Code 等：\n\n- 哪个命令被使用\n- OS、CLI version、location 等等","src/content/posts/five-keys-to-a-killer-go-cli.mdx","54905cb6e339c5f1","five-keys-to-a-killer-go-cli.mdx","go-channel",{"id":363,"data":365,"body":371,"filePath":372,"digest":373,"legacyId":374,"deferredRender":22},{"title":366,"summary":367,"date":368,"tags":369,"group":50,"featured":38},"理解 Go channel","> 此篇介绍 go channel",["Date","2017-08-03T00:00:00.000Z"],[370],"channel","> 此篇介绍 go channel\n\n## 什么是 goroutine\n\n> They're called goroutines because the existing terms — threads, coroutines, processes, and so on — convey inaccurate connotations. A goroutine has a simple model: it is a function executing in parallel with other goroutines in the same address space. It is lightweight, costing little more than the allocation of stack space. And the stacks start small, so they are cheap, and grow by allocating (and freeing) heap storage as required.\n\n正如官方所言，goroutine 是一个轻量级的执行单元，相比线程开销更小，完全由 Go 语言负责调度，是 Go 支持并发的核心。开启一个 goroutine 非常简单:\n\n\n```go\npackage main\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tgo fmt.Println(\"goroutine message\")\n\ttime.Sleep(1) //1\n\tfmt.Println(\"main function message\")\n}\n```\n\n `#1` 的代码是必须的，这是为了让新开启的 goroutine 有机会得到执行，开启一个 goroutine 之后，后续的代码会继续执行，在上面的例子中后续代码执行完毕程序就终止了，而开启的 goroutine 可能还没开始执行。\n\n如果尝试去掉 `#1` 处的代码，程序也可能会正常运行，这是因为恰巧开启的 goroutine 只是简单的执行了一次输出，如果 goroutine 中耗时稍长就会导致只能看到主一句 `main function message` 。 \n\n换句话话说，这里的 `time.sleep` 提供的是一种调度机制，这也是 Go 中 channel 存在的目的：负责消息传递和调度。\n\n\n## Channel \n\nChannel 是 Go 中为 goroutine 提供的一种通信机制，借助于 channel 不同的 goroutine 之间可以相互通信。channel 是有类型的，而且有方向，可以把 channel 类比成 unix 中的 pipe。Go 通过 `\u003C-` 操作符来实现 channel 的写和读，send value `\u003C-` 在 channel 右侧，receive value `\u003C-` 在左侧，receive value 不赋值给任何变量是合法的。\n\n```go\ni := make(chan int)//int 类型\ns := make(chan string)//字符串类型\nr := make(\u003C-chan bool)//只读\nw := make(chan\u003C- []int)//只写\n\u003C- w //合法的语句\n```\n\nChannel 最重要的作用就是传递消息。\n\n```go\npackage main\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tc := make(chan int)\n\tgo func() {\n\t\tfmt.Println(\"goroutine message\")\n\t\tc \u003C- 1 //1\n\t}()\n\t\u003C-c //2\n\tfmt.Println(\"main function message\")\n}\n```\n例子中声明了一个 int 类型的 channel，在 goroutine 中在代码 `#1` 处向 channel 发送了数据 `1` ，在 main 中 `#2` 处等待数据的接收，如果 c 中没有数据，代码的执行将发生阻塞，直到有 goroutine 开始往 c 中 send value。\n\n这是 channel 最简单的用法之一：同步，这种类型的 channel 容量是 0，称之为 **unbuffered channel**。\n\n## Unbuffered channel\n\nChannel 可以设置容量，表示 channel 允许接收的消息个数，默认的 channel 容量是 0 称为 **unbuffered channel** ，对 unbuffered channel 执行 **读** 操作 value := \u003C-ch 会一直阻塞直到有数据可接收，执行 **写** 操作 ch \u003C- value 也会一直阻塞直到有 goroutine 对 channel 开始执行接收，正因为如此在同一个 goroutine 中使用 unbuffered channel 会造成 deadlock。\n\n\n```go\npackage main\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tc := make(chan int)\n\tc \u003C- 1\n\t\u003C-c\n\tfmt.Println(\"main function message\")\n}\n```\n\n执行报 `fatal error: all goroutines are asleep - deadlock!` ，读和写相互等待对方从而导致死锁发生。\n\n![来自 www.goinggo.net](https://static.git-star.com/Screen+Shot+2014-02-16+at+10.10.54+AM.jpg)\n\n\n## Buffered channel\n\n如果 channel 的容量不是 0，此类 channel 称之为 **buffered channel** ，buffered channel 在消息写入个数 **未达到容量的上限之前不会阻塞** ，一旦写入消息个数超过上限，下次输入将会阻塞，直到 channel 有位置可以再写入。\n\n![来自 www.goinggo.net](https://static.git-star.com/Screen+Shot+2014-02-17+at+8.38.15+AM.jpg)\n\n```go\n\tpackage main\n\timport (\n\t\t\"fmt\"\n\t)\n\t\n\tfunc main() {\n\t\tc := make(chan int, 3)\n\t\tgo func() {\n\t\t\tfor i := 0; i \u003C 4; i++ {\n\t\t\t\tc \u003C- i\n\t\t\t\tfmt.Println(\"write to c \", i)\n\t\t\t}\n\t\t}()\n\t\n\t\tfor i := 0; i \u003C 4; i++ {\n\t\t\tfmt.Println(\"reading\", \u003C-c)\n\t\t}\n\t}\n```\n\n\n上面的例子会输出：\n\n```go\nwrite to c 0\nreading 0\nwrite to c 1\nreading 1\nwrite to c 2\nreading 2\nwrite to c 3\nreading 3\n```\n\n根据上文对 buffered channel 的解释，这个例子中 channel `c` 的容量是 3，在写入消息个数不超过 3 时不会阻塞，输出应该是：\n\n```go\nwrite to c 0\nwrite to c 1\nwrite to c 2\nreading 0\nreading 1\nreading 2\nwrite to c 3\nreading 3\n```\n\n问题在哪里？问题其实是在 `fmt.Println` ，一次输出就导致 goroutine 的执行发生了切换(相当于发生了 IO 阻塞)，因而即使 c 没有发生阻塞 goroutine 也会让出执行，一起来验证一下这个问题。\n\n\n```go\npackage main\nimport (\n\t\"fmt\"\n\t\"strconv\"\n)\n\nfunc main() {\n\tc := make(chan int, 3)\n\ts := make([]string, 8)\n\tvar num int = 0\n\tgo func() {\n\t\tfor i := 0; i \u003C 4; i++ {\n\t\t\tc \u003C- i\n\t\t\tnum++\n\t\t\tv := \"inner=>\" + strconv.Itoa(num)\n\t\t\ts = append(s, v)\n\t\t}\n\t}()\n\n\tfor i := 0; i \u003C 4; i++ {\n\t\t\u003C-c\n\t\tnum++\n\t\tv := \"outer=>\" + strconv.Itoa(num)\n\t\ts = append(s, v)\n\t}\n\n\tfmt.Println(s)\n}\n```\n\n这里创建了一个 slice 用来保存 c 进行写入和读取时的执行顺序，num 是用来标识执行顺序的，在没有加入 Println 之前，最终 s 是 [inner=>1 inner=>2 inner=>3 inner=>4 outer=>5 outer=>6 outer=>7 outer=>8] ，输出结果表明 c 达到容量上线之后才会发生阻塞。\n\n相反有输出语句的版本结果则不同：\n\n\n```go\npackage main\nimport (\n\t\"fmt\"\n\t\"strconv\"\n)\n\nfunc main() {\n\tc := make(chan int, 3)\n\ts := make([]string, 8)\n\tvar num int = 0\n\tgo func() {\n\t\tfor i := 0; i \u003C 4; i++ {\n\t\t\tc \u003C- i\n\t\t\tnum++\n\t\t\tv := \"inner=>\" + strconv.Itoa(num)\n\t\t\ts = append(s, v)\n\t\t\tfmt.Println(\"write to c \", i)\n\t\t}\n\t}()\n\n\tfor i := 0; i \u003C 4; i++ {\n\t\tnum++\n\t\tv := \"outer=>\" + strconv.Itoa(num)\n\t\ts = append(s, v)\n\t\tfmt.Println(\"reading\", \u003C-c)\n\t}\n\n\tfmt.Println(s)\n}\n```\n\n[outer=>1 inner=>2 outer=>3 inner=>4 inner=>5 inner=>6 outer=>7 outer=>8] 输出结果能表明两个 goroutine 是交替执行，也就是说 IO 的调用 Println 导致 goroutine 的让出了执行。\n\n## 使用 select 读取多个 channel\n\nGo 提供了 select 语句来处理多个 channel 的消息读取。\n\n\n```go\npackage main\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tc1 := make(chan string)\n\tc2 := make(chan string)\n\n\tgo func() {\n\t\tfor {\n\t\t\tc1 \u003C- \"from 1\"\n\t\t\ttime.Sleep(time.Second * 2)\n\t\t}\n\t}()\n\n\tgo func() {\n\t\tfor {\n\t\t\tc2 \u003C- \"from 2\"\n\t\t\ttime.Sleep(time.Second * 2)\n\t\t}\n\t}()\n\n\tgo func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase msg1 := \u003C-c1:\n\t\t\t\tfmt.Println(msg1)\n\t\t\tcase msg2 := \u003C-c2:\n\t\t\t\tfmt.Println(msg2)\n\t\t\t}\n\t\t}\n\t}()\n\n\tvar input string\n\tfmt.Scanln(&input)\n\n}\n```\n\n\nselect 语句可以从多个可读的 channel 中随机选取一个执行，注意是 **随机选取。** \n\n## 关闭 Channel\n\nChannel 可以被关闭 `close` ，**channel 关闭之后仍然可以读取**，但是向被关闭的 channel send 会 panic。如果 channel 关闭之前有值写入，关闭之后将依次读取 channel 中的消息，读完完毕之后再次读取将会返回 channel 的类型的 zero value：\n\n\n```go\npackage main\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tc := make(chan int, 3)\n\tgo func() {\n\t\tc \u003C- 1\n\t\tc \u003C- 2\n\t\tc \u003C- 3\n\t\tclose(c)\n\t}()\n\n\tfmt.Println(\u003C-c)\n\tfmt.Println(\u003C-c)\n\tfmt.Println(\u003C-c)\n\tfmt.Println(\u003C-c)\n\tfmt.Println(\u003C-c)\n\tfmt.Println(\u003C-c)\n}\n```\n\n输出 1 2 3 0 0 0 ，0 是 int channel c 的 zero value。\n\n\n```go\npackage main\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tc := make(chan int, 3)\n\tgo func() {\n\t\tc \u003C- 1\n\t\tc \u003C- 2\n\t\tc \u003C- 3\n\t\tclose(c)\n\t}()\n\n\tfor i := range c {\n\t\tfmt.Println(i)\n\t}\n}\n```\n\nc 可以进行 range 迭代，如果 channel 没有被关闭 range 会一直等待 channel，但是关闭 channel 之后可以隐式的中断 range 的迭代\n\n\n## 判断 channel 的关闭\n\nGo 提供了 ok 表达式来判断 channel 的关闭状态。\n```go\nvalue, ok \u003C- c\n```\n如果 channel 是关闭状态，ok 是 false，value 是 channel 的 zero value，否则 ok 是 true 表示 channel 未关闭，value 表示 channel 中的值。\n\n\n## 参考资料\n\n- https://www.miek.nl/go\n- http://guzalexander.com/2013/12/06/golang-channels-tutorial.html","src/content/posts/go-channel.mdx","ceb16e1a88641b09","go-channel.mdx","first-rule-for-architecture",{"id":375,"data":377,"body":382,"filePath":383,"digest":384,"legacyId":385,"deferredRender":22},{"title":378,"summary":379,"date":380,"tags":381,"group":129,"featured":38},"无处不在的架构","## 概念",["Date","2017-05-03T00:00:00.000Z"],[161],"## 概念\n\n### Architecture\n\nArchitecture is both the process and the product of planning, designing, and constructing buildings and other physical structures. —— From wiki https://en.wikipedia.org/wiki/Architecture。\n\nArchitecture 意在计划、设计、构建建筑物的过程。\n\n### Software architecture\n\nSoftware architecture refers to the high level structures of a software system, the discipline of creating such structures, and the documentation of these structures…..The architecture of a software system is a metaphor, analogous to the architecture of a building.—— From wiki https://en.wikipedia.org/wiki/Software_architecture\n\nsoftware architecture 和构建一座实体建筑是非常相似的，都具有计划、设计、构建的过程。\n\n{/* more */}\n\n## 软件架构关注什么\n\n**Software architecture is about making fundamental structural choices which are costly to change once implemented.**\n\nwiki 的这句话恰如其分的解释了软件架构需要关注的：软件架构就是在做选择，而这些选择一旦实施，其改变成本相对较高。\n\n\n## 哪些地方需要架构\n\n不只有那些 high level 层面的东西才需要架构，在软件的整个生命周期中，架构几乎都有体现。\n\n需求的提取和抽象，application 的部署，project package 的组织和命名，甚至到 module 、class 、function、variable 的组织命名都需要架构。\n\n可以说只要是需要做决定的地方，都需要架构。换句话说，每个程序员都是架构师，差别只在于做出的选择好坏有别，差异巨大。\n\n这些差异来自于做选择的能力，用更准确的概念描述就是**权衡的能力**，英文是 **tradeoff**。\n\n## 什么是 tradeoff\n\ntrade 交易，off 牺牲，tradeoff 就指用牺牲什么来达到某种交易，有取有舍，取舍中做出选择。\n\n### tradeoff 需要我们知道事物的不同方面\n\n任何时候我们做 tradeoff 之前都需要了解我们所面对的事务，这是 tradeoff 的前提。\n\n举个例子，要做一个电商系统，在 mysql、mongodb、postgresql 做出选择就需要知道每个 database 的特性(简单列举，仅做说明)：\n\n- mysql 支持事务、分布式部署，典型的关系型数据库\n- mongodb 不支持事务、分布式部署，典型的非关系型数据库\n- postgresql 支持事务、分布式部署，非关系型数据库，市场使用率没有 mysql 高\n\n电商系统要求强一致性、支持事务，这是基本要求，所以 mongodb 遭淘汰，mysql 使用人数众多，已在行业中积累了丰富的案例和经验，规避了很多未知的风险，相比之下 postgresql 就显得比较小众，因而选择 mysql。\n\n任何事物都有利有弊，但利弊都不是无限大，而且他们的利弊都只有在特定情况下才会显得特别重要。\n\n选择 mysql 是因为它支持事务，强一致性，市场占有率高，这是其**利**。\n\n当规模达到一定程度之后，mysql 在扩展、性能等方面就没有其他一些 nosql 数据库做得好，这是其**弊**。\n\n现实的情况是，很多人根本不会有机会感受到 mysql 的弊。\n\n### tradeoff 需要我们能够量化事务的利弊\n\n量化就是要有数据支撑我们的选择，了解了不同事务的不同方面仅仅只能帮助我们做出粗略的选择，尽快删选掉那些不合格的选项，想要进一步判断选择的正确与否就需要我们对选择的事物进行全方位的衡量和量化。\n\nmysql 在特定 linux 版本、特定磁盘的 QPS 能达到多少？\n\n数据规模不同时，mysql 的读写每秒分别都是多少？\n\nmysql 在 1000 的并发、1 万的并发、10 万的并发下需要什么样的集群规模？\n\n每个问题背后都需要我们做出非常细致的研究和测试，得出详细数据指标，这些指标才是真正支持我们做选择的可靠依据。\n\n了解了 tradeoff 的重要性，那我们如何培养这种选择的能力？\n\n## 选择能力的培养\n\n### 丰富的知识储备是前提\n\n世界上有很多知识是我们自己都不知道自己不知道，这就是现实。\n\n为什么我们没有做出好的选择，因为我们根本不知道还有那些选择，而且我们竟然**自己也不知道自己不知道**，为此甚至还沾沾自喜以为自己做出了好选择。\n\n这也是为什么面对同样的选择，不同的人会有完全不同的反应。因为彼此的知识储备根本不在一个层面，理解程度当然高低不同。\n\n如果根本不知道 postgresql，又如何谈得上对它的选择。\n\n### 靠事实说话的理工科思维\n\n理工科思维讲究有没有道理，有没有说服力。这个道理不是建立在想当然的感觉、权威、道德等缺乏可靠事实的标准之上。\n\n实验、测量、分析、数据这些带有强烈理工科思维的词汇是体现依靠事实说话的有力证明。\n\n以理工科的方式对选择的利弊进行量化分析，列依据，摆事实，如何选择将一目了然。\n\n| Operation                          | Time (nsec) |\n| ---------------------------------- | ----------- |\n| Compress 1KB bytes with Zippy      | 3,000       |\n| Read 1MB sequentially from memory  | 250,000     |\n| Disk seek                          | 10,000,000  |\n| Read 1MB sequentially from disk    | 20,000,000  |\n| System call overhead               | 400         |\n| Context switch between processes   | 3000        |\n| fork() (statically-linked binary)  | 70,000      |\n| fork() (dynamically-linked binary) | 160,000     |\n\nfrom https://everythingisdata.wordpress.com/2009/10/17/numbers-everyone-should-know/\n\n## 无处不在的架构\n\n架构反应的是 program 的设计过程，考虑的是 program 的未来，何时何地开始 program 的架构？\n\n从开始给 program 起名字就应该考虑架构，好的名字是 program 核心含义的直接表达，react、jquery、docker 无一例外都有非常响亮且有意义的名字。\n\nfunction 的设计、class 的命名、package 的引用关系都是架构的体现，所谓见微知著，这些代码的细节最直接影响着一个 program 的质量。\n\n架构是一种思维模式的体现，是程序员面对代码的意志表达，从今天做出的选择或写的代码开始你的架构之路吧，架构无处不在。","src/content/posts/first-rule-for-architecture.mdx","df41ab3aa77eae6f","first-rule-for-architecture.mdx","go-concurrency-with-shared-data-2",{"id":386,"data":388,"body":396,"filePath":397,"digest":398,"legacyId":399,"deferredRender":22},{"title":389,"summary":390,"date":391,"tags":392,"group":395,"featured":38},"并发 Go 程序中的共享变量 (二)：锁","> 本系列是阅读 \"The Go Programming Language\" 理解和记录。",["Date","2018-09-03T00:00:00.000Z"],[393,394],"锁","concurrency","Go 读书笔记","> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\n上一节我们提到了避免 data race 的一种方法是使用 lock，而 Go 的 `Mutex type` 正好就提供了能够满足需要的 lock，直接看例子：\n\n```go\n\nimport \"sync\"\n\nvar (\n    mu    sync.Mutex\n    balance int\n)\n\nfunc Deposit(amount int){\n    mu.Lock()\n    balance = balance + amount\n    mu.Unlock()\n}\n\nfunc Balance() int {\n    mu.Lock()\n    b := balance\n    mu.Unlock()\n    return b\n}\n\n```\n\n每当有 goroutine 需要获取 balance，首先需要通过 mutex 获得一个排他锁，如果其他的 goroutine 已经获得了 lock，当前 goroutine 会被阻塞直到这个锁被释放。Mutex lock 就是通过这种机制的来保护共享数据的安全的，我们把锁保护起来的区域称之为 `critical section`。\n\n通过锁来保护 shared data 是一种很常用的机制，其重点在于判别 **critical section **和**适时释放锁**，在上面的例子中锁的释放是在完成 balance 的操作之后开始释放，由于代码量很少，这样的写法并不会引起太大的问题。在复杂的程序中，critical section 的逻辑可能会很复杂，特别是在 critical section 发生错误需要提前返回这时候就需要对**锁进行提前释放**，因此合理安排 lock 和 unlock 的出现时机变得非常重要，幸运地是 Go 有 `defer` 语句可以很好的解决这个问题：借助 defer，unlock 能够在 critical section 正确结束或错误返回包括 panic 都能得到执行。\n\n```go\nfunc Balance() int {\n    mu.Lock()\n    defer mu.Unlock()\n    return balance\n}\n\n```\n\n除了锁的释放时机，critical section 的判定更是直接决定了程序能否按照正确的逻辑执行，一起开下面的例子。\n\n```go\nfunc Withdraw(amount int) bool {\n    Deposit(-amount)\n    if Balance() \u003C 0 {\n        Deposit(amount)\n        return false // insufficient funds\n    }\n    return true\n}\n```\n\n`Deposit` 和 `Balance` 是上面我们加了锁的两个函数，虽然 `Withdraw` 的执行不会造成 balance 无故消失的错误但是却导致了另外一个问题，考虑 `Withdraw` 在多个 goroutine 中执行，如果一个 goroutine 执行的时候导致 balance 是负的，则会导致另一个 goroutine 逻辑不能正确执行。比如现实中 balance 有 100 ，有一个 goroutine 发起了 110 withdraw 操作，导致 balance 是负的，而另一个 goroutine 即使发起的是 10 withdraw 操作也会失败，虽然 balance 的最终结果是对的，但一个合法的 withdraw 却失败了，这在现实中是无法接受的，就好比明明账上有 100 却无法支付一顿 10 的早餐。导致这个错误的原因就是：**Withdraw 不是原子操作**。\n\n**什么是原子操作 atomic operation？原子操作就是一组操作，要么全部执行要么全部不执行，不会发生部分执行，部分不执行的情况**。`Withdraw` 函数中的一些列操作虽然用 lock 锁住了，但是这些步骤是割裂的，并不是连续的，这样会导致 `Withdraw` 在并发执行过程中，其它的 goroutine 能够看到当前 `Withdraw` 未执行完成的结果。一个解决办法是 `Withdraw` 函数也加锁。\n\n```go\nfunc Withdraw(amount int) bool {\n    mu.Lock()\n    defer mu.Unlock()\n    Deposit(-amount)\n    if Balance() \u003C 0 {\n        Deposit(amount)\n        return false // insufficient funds\n    }\n    return true\n}\n```\n\n由于 mutex 是不可重入的，如果 Withdraw 函数也用了 lock 则会发生死锁：\n```shell\nfatal error: all goroutines are asleep - deadlock!\n```\n\n对于上面的问题，一种通用的做法是，把 Deposit 单独实现，一个是具有 lock 的，对外使用，一个是没有 lock 的，供有 lock 的调用:\n```go\nfunc Deposit(amount int) {\n    mu.Lock()\n    deposit(amount)\n    mu.Unlock()\n}\n\nfunc Withdraw(amount int) bool {\n    mu.Lock()\n    defer mu.Unlock()\n    deposit(-amount)\n    if balance \u003C 0 {\n        deposit(amount)\n        return false // insufficient funds\n    }\n    return true\n}\n\nfunc deposit(amount int) {\n    balance = balance + amount\n}\n```\n\n`Withdraw` 例子恰好说明了在使用锁的时候需要考虑 critical section ，这在任何时候使用 mutex 时都需要注意。","src/content/posts/go-concurrency-with-shared-data-2.mdx","a1345c0cc95f3f1a","go-concurrency-with-shared-data-2.mdx","go-common-mistake-1",{"id":400,"data":402,"body":408,"filePath":409,"digest":410,"legacyId":411,"deferredRender":22},{"title":403,"summary":404,"date":405,"tags":406,"group":50,"featured":38},"Go 常见错误之一：值拷贝和 for 循环中的单一变量","在 Go 常见的错误一文中 http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/ 有这么一段代码：",["Date","2017-10-24T00:00:00.000Z"],[407],"mistake","在 Go 常见的错误一文中 http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/ 有这么一段代码：\n\n```Go\n\npackage main\n\nimport (  \n    \"fmt\"\n    \"time\"\n)\n\ntype field struct {  \n    name string\n}\n\nfunc (p *field) print() {  \n    fmt.Println(p.name)\n}\n\nfunc main() {  \n    data := []field{{\"one\"},{\"two\"},{\"three\"}}\n\n    for _,v := range data {\n        go v.print()\n    }\n\n    time.Sleep(3 * time.Second)\n    //goroutines print: three, three, three\n}\n\n```\n\n{/* more */}\n\n把 field slice 的类型改为 pointer 结果又不同：\n\n```Go\n\npackage main\n\nimport (  \n    \"fmt\"\n    \"time\"\n)\n\ntype field struct {  \n    name string\n}\n\nfunc (p *field) print() {  \n    fmt.Println(p.name)\n}\n\nfunc main() {  \n    data := []*field{{\"one\"},{\"two\"},{\"three\"}}\n\n    for _,v := range data {\n        v := v\n        go v.print()\n    }\n\n    time.Sleep(3 * time.Second)\n    //goroutines print: one, two, three\n}\n```\n\n这两段代码的差异究竟是如何导致结果的不同？\n\n我对上面的代码 for 循环中的部分进行了一下改造，改造之后对应的代码分别是：\n\nslice 是非指针\n```Go\n    data := []field{{\"one\"},{\"two\"},{\"three\"}}\n\n    for _,v := range data {\n        pp := (*field).print\n        go pp(&v) //非 pointer\n    }\n```\n\n slice 是指针\n```Go\n    data := []*field{{\"one\"},{\"two\"},{\"three\"}}\n\n    for _,v := range data {\n        pp := (*field).print\n        go pp(v) // pointer\n    }\n```\n\n改造之后再去看原来的代码就能看出最明显的差异在 `print` 的这个 method 的 `receiver` 的传递上。\n\n在 Go 中**函数的调用是值拷贝 copy value**，而且**在 for 循环中 v 的变量始终是一个变量**。\n\n如果 v 是 pointer，print 这个 method 接收的是指针的拷贝，for 循环体中每次迭代 v 的 pointer value 都是不同的，所以输出不同。\n\n如果 v 是一个普通的 struct，for 循环体中每次迭代 &v 都是 v 这个变量本身的 pointer，也就是总是指向同一个 field，由于在很大程度上这段代码中的 goroutine 都是在 for 结束之后才执行，而此时 v 将会指向最后一个 field，也就是 `{\"three\"}`，所以输出相同。\n\n\n有人说 one、two、three 的随机输出是因为 CPU 是多核的原因导致的，如果改成单核就是顺序输出，这样的说法并不是特别准确。理论上来讲 goroutine 的调度是有一定的随机性的，也就是即使是单核输出也有可能是随机的，只是在运行如此简单的例子时一般机器环境都不会导致这 3 个简单的 goroutine 出现交叉执行。比如可以在 print 输出之前模拟 io 繁忙的来达到即使是单核也可能是随机输出的目的。\n\n```Go\n    if rand.Intn(100) > 20 {\n        time.Sleep(1 * time.Second)\n    }\n```","src/content/posts/go-common-mistake-1.mdx","bc1a59ee4c3ee67a","go-common-mistake-1.mdx","go-concurrency-with-shared-data-4",{"id":412,"data":414,"body":420,"filePath":421,"digest":422,"legacyId":423,"deferredRender":22},{"title":415,"summary":416,"date":417,"tags":418,"group":395,"featured":38},"并发 Go 程序中的共享变量 (四)：内存同步","> 本系列是阅读 “The Go Programming Language” 理解和记录。",["Date","2018-10-11T00:00:00.000Z"],[419,394],"内存同步","> 本系列是阅读 “The Go Programming Language” 理解和记录。\n\n\n在上一小节中 [go-concurrency-with-shared-data-3](/blog/go-concurrency-with-shared-data-3)，我们在实现 `Balance` 方法也需要一个排他锁，不论这个排他锁是通过 channel 实现还是互斥锁实现都是可以的，在我们的例子中是通过**读写锁**实现的。\n\n```go\nfunc Balance() int {\n    mu.RLock()\n    defer mu.RUnlock()\n    return balance\n}\n```\n\n但是不像 `Deposit` 方法那样需要读取 balance 并且加上 amount，`Balance` 只有一种操作，就是读取 Balance 并返回，所以即使有其它的 goroutine 在这中间有执行操作也不会造成什么问题。真的是这样么？\n\n实际上我们还是需要锁，理由有二：\n\n**第一**，`Balance` 不能在其他操作执行期间执行，比如 Withdraw 执行中的时候，实际上已经少了 balance，但是实际读取的 balance 可能还是一个旧值。\n\n**第二**，同步不仅仅和 goroutine 的执行顺序相关，同步也会影响内存。\n\n在现代计算机中，一般都会有多个 CPU，每个有 CPU 有自己的主存缓存。为了性能，写到主存的数据一般都会在每个 CPU 内部首先缓存起来，然后在必要的时候提交到主存。**这些修改的提交的顺序可能和 goroutine 的执行顺序不同**。而同步原语比如说 channel 或者互斥锁的主要目的就是让 CPU 把 buffer 的数据提交到主存中，以便其它执行在其它 CPU 上的 goroutine 能够看到这些提交带来变化。\n\n考虑以下代码的输出：\n```go\nvar x, y int\ngo func(){\n    x = 1                   // A1\n    fmt.Print(\"y:\", y, \" \") // A2 \n}()\n\ngo func(){\n   y = 1                    // B1\n   fmt.Print(\"x:\", x, \" \")  // B2\n}()\n```\n\n正如前面文章所提到的，**两个 goroutine 并发执行，而且在没有使用互斥机制的情况下共享变量，存在 data race**，因此在看到不确定的结果时不应该感到惊讶。我们可能会看到由于代码的执行顺序的不同而有不同的输出：\n```go\n\ny:0 x:1\nx:0 y:1\nx:1 y:1\ny:1 x:1\n\n```\n这四行输出可以解释为 A1,B1,A2,B2 或者 B1,A1,A2,B2。但是有一种结果可能会让你感到吃惊：\n```\nx:0 y:0\ny:0 x:0\n```\n但是现实情况是：由于 CPU 或者编译器以及其它一些因素的影响，这种结果是有可能发生的。那么这 4 句语句如何交错执行才能产生这样的结果？\n\n在单个 goroutine 中，每个语句带来的影响可以说是严格按照他们的执行顺序而产生的，goroutine 是线性一致的（sequentially consistent）。但是在多个 goroutine 中，**如果没有显式的同步机制，比如 channel 或者互斥锁，没有办法保证 goroutine 彼此之间看到影响都是严格按照执行顺序的先后而产生的**。虽然 goroutine A 肯定是先观测到 x = 1 执行完毕之后才去读取 y 的值，但是它没有办法确保 goroutine B 对 y 的修改一定能看的到，所以 goroutine A 可能读取的还是一个 y 的旧值：0。\n\n理解并发执行的这种尝试常常很有意思，就好像并发的结果确实是 goroutine 之间的这些语句交错执行而产生的，事实可能并不是如此，正如上面的例子展示出来的一样结果都是 0 的输出，goroutine 的执行完全由可能是 A2,A1,B2,B1。这是由于赋值语句和 Print 语句指向都是不同的变量，编译器可能会得出一个论是：**这两条语句的执行结果相互不影响从而交换了这两条语句的执行顺序**。如果这两个 goroutine 是在不同的 CPU 上执行，每个 CPU 都有自己的 cache，其中一个 goroutine 写到 cache 中的数据是不能被另一个 goroutine 中的 Print 语句看到的，直到数据被同步到主从中。\n\n所有并发的问题都能被这些已经建立的简单模式所解决：\n\n**要么保证变量只在单个 goroutine 中使用**；\n\n**要么在多个 goroutine 之间使用互斥锁**。","src/content/posts/go-concurrency-with-shared-data-4.mdx","7693bb26efde0ba9","go-concurrency-with-shared-data-4.mdx","go-concurrency-with-shared-data-3",{"id":424,"data":426,"body":430,"filePath":431,"digest":432,"legacyId":433,"deferredRender":22},{"title":427,"summary":416,"date":428,"tags":429,"group":395,"featured":38},"并发 Go 程序中的共享变量 (三)：读写锁",["Date","2018-09-11T00:00:00.000Z"],[393,394],"> 本系列是阅读 “The Go Programming Language” 理解和记录。\n\n\n在上篇中 [go-concurrency-with-shared-data-2](/blog/go-concurrency-with-shared-data-2) 我们的获取 balance 的方法也用了锁：\n\n```go\nfunc Balance() int {\n    mu.Lock()\n    defer mu.Unlock()\n    return balance\n}\n\n```\n\n这样带来什么问题呢？假设有一个场景，用户需要频繁的查询 balance，这会导致 lock 被频繁的调用，不但 `Balance` 函数彼此之间需要等待对方锁的释放，同时也会影响到 `Widthdraw` 和 `Deposit` 函数的调用：\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nvar (\n    mu      sync.Mutex\n    balance int\n)\n\nfunc Balance() int {\n    fmt.Println(\"Balance wait for another goroutine release lock\")\n    mu.Lock()\n    fmt.Println(\"Balance acquired lock\")\n    defer mu.Unlock()\n    return balance\n}\n\nfunc Balance2() int {\n    mu.Lock()\n    fmt.Println(\"Balance2 acquired lock\")\n    defer mu.Unlock()\n    time.Sleep(10 * time.Second)\n    fmt.Println(\"Balance2 release lock\")\n    return balance\n}\n\nfunc Deposit(amount int) {\n    mu.Lock()\n    deposit(amount)\n    mu.Unlock()\n}\nfunc Withdraw(amount int) bool {\n    mu.Lock()\n    defer mu.Unlock()\n    deposit(-amount)\n    if balance \u003C 0 {\n        deposit(amount)\n        return false // insufficient funds\n    }\n    return true\n}\nfunc deposit(amount int) {\n    balance = balance + amount\n}\n\nfunc main() {\n    balance = 100\n    wait := make(chan int)\n    go func() {\n        fmt.Println(\"Balance2 == >\", Balance2())\n        wait \u003C- 1\n    }()\n    time.Sleep(2 * time.Second)  // 此处 sleep 操作是为了 Balance2 优先获得执行\n    fmt.Println(\"Balance ==>\", Balance())\n    \u003C-wait\n}\n\n```\n\n为了演示方便，代码中构造了两个读取 balance 的函数 `Balance` 和 `Balance2`，假设在 `Balance2` 由于某种原因读取 balance 的操作需要等待一段时间，这个时候如果 `Balance2` 不结束 `Balance` 就无法执行，输出结果如下：\n```shell\nBalance2 acquired lock\nBalance wait for another goroutine release lock\nBalance2 release lock\nBalance2 == > 100\nBalance acquired lock\nBalance ==> 100\n```\n由输出结果不难看出（程序中的 IO 操作能够引起 goroutine 执行的切换，所以需要小心对待 print 才能正确演示我们要的结果），Balance 必须要等到 Balance2 释放锁之后才能获取 balance，程序的整个执行过程中并没有修改 balance 的操作，也就是如果仅仅只有读取 balance 的操作，它们的并发执行是安全的，但是由于 `sync.Mutex` 的使用，这将导致这种并发安全的操作也会带来不必要的性能损耗：**锁的频繁获取和释放**。这里如果有一种特殊的锁能够允许对 balance 的读取操作可以并行执行，但是一旦遇到修改操作就必须要等待锁的获取才能继续读取，这部分的性能损耗就可以弥补。幸运地是，Go 提供了这种锁，称之为 **multiple readers，single writer** 锁：`sync.RWMutex`。\n\n我们对上面的代码进行小小的修改，替换获取锁和释放锁的代码：\n\n```go\n\nvar (\n    mu      sync.RWMutex\n    balance int\n)\n\nfunc Balance() int {\n    fmt.Println(\"Balance wait for another goroutine release lock\")\n    mu.RLock() // 修改处\n    fmt.Println(\"Balance acquired lock\")\n    defer mu.RUnlock()  // 修改处\n    return balance\n}\n\nfunc Balance2() int {\n    mu.RLock()   // 修改处\n    fmt.Println(\"Balance2 acquired lock\")\n    defer mu.RUnlock()  // 修改处\n    time.Sleep(10 * time.Second)\n    fmt.Println(\"Balance2 release lock\")\n    return balance\n}\n\n```\n\n执行输出如下：\n\n```shell\nBalance2 acquired lock\nBalance wait for another goroutine release lock\nBalance acquired lock\nBalance ==> 100\nBalance2 release lock\nBalance2 == > 100\n```\n\n可以看到即使 Balance2 没有释放锁，Balance 依然可以获得锁，程序整体的执行效率提升了，尤其是读越多，效果越显著。\n\n使用了 RLock 的 Balance 依然在遇到 Widthdraw 等已经通过 Lock 获取锁的 函数执行时必须要继续等待：\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nvar (\n    mu      sync.RWMutex\n    balance int\n)\n\nfunc Balance() int {\n    fmt.Println(\"Balance wait for another goroutine release lock\")\n    mu.RLock()\n    fmt.Println(\"Balance acquired lock\")\n    defer mu.RUnlock()\n    return balance\n}\n\nfunc Deposit(amount int) {\n    mu.Lock()\n    fmt.Println(\"Deposit acquired lock\")\n    defer mu.Unlock()\n    time.Sleep(5 * time.Second)\n    deposit(amount)\n}\n\nfunc Withdraw(amount int) bool {\n    mu.Lock()\n    defer mu.Unlock()\n    deposit(-amount)\n    if balance \u003C 0 {\n        deposit(amount)\n        return false // insufficient funds\n    }\n    return true\n}\n\nfunc deposit(amount int) {\n    balance = balance + amount\n}\n\nfunc main() {\n    balance = 100\n    wait := make(chan int)\n    go func() {\n        Deposit(100)\n        wait \u003C- 1\n    }()\n    time.Sleep(1 * time.Second)\n    fmt.Println(\"Balance ==>\", Balance())\n    \u003C-wait\n}\n\n```\n\n即使使用 RLock，Balance 函数还是需要等待 Deposit 释放锁，说明我们的目的达到了：**多读并行，一写排它**。\n\n`sync.RWMutex` 提供的 RLock 只能用于 critical section 没有对 shared variable 进行写的情况，但是记住要始终谨慎对待，因为有很多隐式的对 shared variable 的修改不是很容易察觉，比如其它调用函数的读取计数器等。","src/content/posts/go-concurrency-with-shared-data-3.mdx","540bad9f40082130","go-concurrency-with-shared-data-3.mdx","go-defer",{"id":434,"data":436,"body":442,"filePath":443,"digest":444,"legacyId":445,"deferredRender":22},{"title":437,"summary":438,"date":439,"tags":440,"group":50,"featured":38},"理解 Go defer","## defer 的作用和执行时机",["Date","2017-07-23T00:00:00.000Z"],[441],"defer","## defer 的作用和执行时机\n\ngo 的 defer 语句是用来**延迟执行函数的**，而且延迟发生在**调用函数 return 之后**，比如\n\n```go\nfunc a() int {\n  defer b()\n  return 0\n}\n```\n\nb 的执行是发生在 return 0 之后，注意 defer 的语法，关键字 defer 之后是函数的调用。\n\n\n## defer 的重要用途一：清理释放资源\n\n由于 defer 的延迟特性，defer 常用在函数调用结束之后清理相关的资源，比如\n\n```go\nf, _ := os.Open(filename)\ndefer f.Close()\n```\n\n文件资源的释放会在函数调用结束之后借助 defer 自动执行，不需要时刻记住哪里的资源需要释放，打开和释放必须相对应。\n\n用一个例子深刻诠释一下 defer 带来的便利和简洁。\n\n代码的主要目的是打开一个文件，然后复制内容到另一个新的文件中，没有 defer 时这样写：\n\n```\nfunc CopyFile(dstName, srcName string) (written int64, err error) {\n    src, err := os.Open(srcName)\n    if err != nil {\n        return\n    }\n\n    dst, err := os.Create(dstName)\n    if err != nil { //1\n        return\n    }\n\n    written, err = io.Copy(dst, src)\n    dst.Close()\n    src.Close()\n    return\n}\n```\n\n代码在 `#1` 处返回之后，src 文件没有执行关闭操作，可能会导致资源不能正确释放，改用 defer 实现：\n\n```\nfunc CopyFile(dstName, srcName string) (written int64, err error) {\n    src, err := os.Open(srcName)\n    if err != nil {\n        return\n    }\n    defer src.Close()\n\n    dst, err := os.Create(dstName)\n    if err != nil {\n        return\n    }\n    defer dst.Close()\n\n    return io.Copy(dst, src)\n}\n```\n\nsrc 和 dst 都能及时清理和释放，无论 return 在什么地方执行。\n\n鉴于 defer 的这种作用，defer 常用来释放数据库连接，文件打开句柄等释放资源的操作。\n\n## defer 的重要用途二：执行 recover\n\n被 defer 的函数在 return 之后执行，这个时机点正好可以捕获函数抛出的 panic，因而 defer 的另一个重要用途就是执行 recover。\n\nrecover 只有在 defer 中使用才更有意义，如果在其他地方使用，由于 program 已经调用结束而提前返回而无法有效捕捉错误。\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n    defer func() {\n        if ok := recover(); ok != nil {\n            fmt.Println(\"recover\")\n        }\n    }()\n\n    panic(\"error\")\n\n}\n\n```\n\n记住 defer 要放在 panic 执行之前。\n\n## 多个 defer 的执行顺序\n\ndefer 的作用就是把关键字之后的函数执行压入一个栈中延迟执行，多个 defer 的执行顺序是后进先出 LIFO ：\n\n```go\n  defer func() { fmt.Println(\"1\") }()\n  defer func() { fmt.Println(\"2\") }()\n  defer func() { fmt.Println(\"3\") }()\n```\n\n输出顺序是 321。\n\n这个特性可以对一个 array 实现逆序操作。\n\n## 被 deferred 函数的参数在 defer 时确定\n\n这是 defer 的特点，一个函数被 defer 时，它的参数在 defer 时进行计算确定，即使 defer 之后参数发生修改，对已经 defer 的函数没有影响，什么意思？看例子：\n\n```go\nfunc a() {\n    i := 0\n    defer fmt.Println(i)\n    i++\n    return\n}\n```\n\na 执行输出的是 0 而不是 1，因为 defer 时，i 的值是 0，此时被 defer 的函数参数已经进行执行计算并确定了。\n\n再看一个例子：\n\n```go\nfunc calc(index string, a, b int) int {\n    ret := a + b\n    fmt.Println(index, a, b, ret)\n    return ret\n}\n\nfunc main() {\n    a := 1\n    b := 2\n    defer calc(\"1\", a, calc(\"10\", a, b))\n    a = 0\n    return\n}\n```\n\n执行代码输出 \n\n```shell\n10 1 2 3 \n1 1 3 4\n```\n\ndefer 函数的参数 第三个参数在 defer 时就已经计算完成并确定，第二个参数 a 也是如此，无论之后 a 变量是否修改都不影响。\n\n## 被 defer 的函数可以读取和修改带名称的返回值\n\n```go\nfunc c() (i int) {\n    defer func() { i++ }()\n    return 1\n}\n```\n\n被 defer 的函数是在 return 之后执行，可以修改带名称的返回值，上面的函数 c 返回的是 2。\n\n## 参考资料\n\nhttps://blog.golang.org/defer-panic-and-recover","src/content/posts/go-defer.mdx","e8f439d286035a7d","go-defer.mdx","go-concurrency-with-shared-data",{"id":446,"data":448,"body":453,"filePath":454,"digest":455,"legacyId":456,"deferredRender":22},{"title":449,"summary":390,"date":450,"tags":451,"group":395,"featured":38},"并发 Go 程序中的共享变量 (一)：data race",["Date","2018-08-23T00:00:00.000Z"],[452,394],"race condition","> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\n在 Go 的程序中，如果只有一个 goroutine 也就是只有一个 main goroutine 存在时，所有代码都是顺序执行的，也就是说程序的执行步骤就是它们的逻辑顺序，一个步骤是否能在另一个步骤之前或者之后发生时非常确定的。然而如果一个 Go 程序有两个或者多个 goroutine 存在，我们就很难确定一个 event(事件) x 是否发生在另一个 goroutine 中的 event(事件) y 之前，之后，还是同时发生。如果我们不能确定 x 和 y 的发生顺序，则说 x 和 y 是并发的 concurrent。\n\n考虑一个概念 **concurrency safe**，这个概念是指一个在顺序执行的程序中能够正常执行的 function 如果可以并发的执行，并且在不采用任何同步措施的情况下执行结果依然正确，那么这个 function 是 concurrency safe 的，也就是说它可以并发的执行。同理，如果一个 type 的所有方法以及对它自身的所有操作是 concurrency safe 的，则这个 type 是 concurrency safe 的。\n\n我们在编写一个 Go 程序时并不需要保证所有的使用的 type 都是 concurrency safe 的，只在需要对某个 type 进行并发操作的情况下保证 type 是 concurrency safe 的，大多数情况下我们应该尽量保证对程序 variable 的访问都尽量在单个 goroutine 完成或者使用互斥锁来保护我们需要访问的程序区域。\n\n在继续探讨我们的话题之前，我们必须要知道 Go 中 **race condition** 就是说程序在多个 goroutine 交互执行的情况下可能会给出不正确的结果。理解 race condition 讲的是什么，是理解并发程序的关键所在。\n\n下面我们用一个简单的例子来说明 race condition 可能会带来的问题，这个例子展示了读取账户余额和向账户中存钱的这两个操作。\n\n```go\n// Package bank implements a bank with only one account.\npackage bank\nvar balance int\nfunc Deposit(amount int) { balance = balance + amount }\nfunc Balance() int { return balance }\n```\n\n如果这两个操作是以下面的形式发生在两个 goroutine 中：\n```go\n // Alice:\n go func() {\n     bank.Deposit(200)                // A1\n     fmt.Println(\"=\", bank.Balance()) // A2\n }()\n\n  // Bob:\n go bank.Deposit(100)                 // B\n\n```\n\n最终结果可能会有以下几种形式：\n\n| Alice first | Bob first  | Alice /Bob /Alice |\n| ----------- | ---------- | ----------------- |\n| 0           | 0          | 0                 |\n| A1  200     | B  100     | A1 200            |\n| A2  \"= 200\" | A1 300     | B 300             |\n| B  300      | A2 \"= 300\" | A2 \"= 300\"        |\n|             |            |                   |\n\n在这几种结果中最终的 balance 都是 300，差异仅仅是在 Alice 看到的 balance 是 200 还是 300 的差异，看起来并没有造成太大的影响，在此我们首先来解释一下为什么会有这样的差异。\n\n在现代计算机结构中，多核 CPU 对内存的操作并不是完全实时的，每个 CPU 为了能够加速对内存的访问都会有 cache，CPU 把内存的数据读出来之后，进行修改然后重新写入内存的过程中，可能其它的 CPU 已经对内存区域进行修改了，这就是多核 CPU 在对 shared data  进行存取时引入的 race condition。为了能够防止这种情况的发生，很多 CPU 指令都提供了原子操作来保证对内存的修改是唯一且正确的。\n\n在上面的例子中，由于两个 goroutine 对 balance 这个同一内存区域读取的时机差异，就有可能会造成不同的执行顺序输出的结果是不同的。\n\n而下面这种执行顺序造成的影响在现实世界中是不能容忍的。\n\n| action | balance |                            |\n| ------ | ------- | -------------------------- |\n| A1r    | 0       | balance + amount           |\n| B      | 100     | balance = balance + amount |\n| A1w    | 200     | balance = ...              |\n| A2     | 200     | Println(\"= \", balance)     |\n\n最终 B 操作的 100 消失了！这样的程序我们称之为 race condition 中的 **data race**，用一句话概括其含义就是：**Data race 经常发生在多个 goroutine 存取同一个 variable 时，至少有一个 goroutine 会执行修改操作** 。\n\n**如何避免 data race？**\n\n第一种方式是**避免对共享 variable 进行写操作**\n\nGo 中 map 不是 concurrency safe，如果在多个 goroutine 中不加锁而直接对 map 操作就很难避免错误的结果出现：\n\n```go\nvar icons = make(map[string]image.Image)\nfunc loadIcon(name string) image.Image\n     // NOTE: not concurrency-safe!\nfunc Icon(name string) image.Image \n{\n    icon, ok := icons[name]\n    if !ok {\n        icon = loadIcon(name)\n        icons[name] = icon\n    }\n    return icon\n}\n```\n\n上面的例子中对 icons 的操作不是 concurrency safe。\n\n第二种方式是**避免在多个 goroutine 中存取变量**\n\nGo 中这样的操作很常见，为了保证数据的准确性，只在一个 goroutine 中执行对 variable 的所有操作，其他 goroutine 通过 channel 向该 goroutine 进行请求来实现对 variable 的存取和更新，这样保证了 variable 的存取都只在一个 goroutine 中进行，这也充分对 Go 的理念进行阐释：**Do not communicate by sharing memory; instead, share memory by communicating**。\n\n第三种方式是**使用锁来保护共享的 variable 来保证任意时刻只有一个 goroutine 对变量进行修改**\n\n关于锁的使用，我们会在下一节进行详细介绍。","src/content/posts/go-concurrency-with-shared-data.mdx","03dbe915b3e245c4","go-concurrency-with-shared-data.mdx","go-goroutine-channel-3",{"id":457,"data":459,"body":464,"filePath":465,"digest":466,"legacyId":467,"deferredRender":22},{"title":460,"summary":390,"date":461,"tags":462,"group":395,"featured":38},"Go goroutine 和 channel 详解 (三) ：unbuffered channel",["Date","2018-08-14T00:00:00.000Z"],[463,50],"synchronous","> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\n## Channel 的分类\n\nChannel 根据 capacity 的大小，分为 unbuffered channel 和 buffered channel，在创建 channel 时可以指定 channel 的容量，如果不指定默认是 0，我们称这种 channel 是 unbuffered channel。\n\n## Unbuffered channel 同步特性\n\n在一个 unbuffered channel 上执行 send 操作会阻塞当前的 goroutine 直到另一个 goroutine 对这个 channel 执行 receive 操作，此时发送的 value 通过 channel 进行传递，两个 goroutine 继续后续的执行。相反如果是 receive 操作先执行，则 receive 的 goroutine 阻塞直到有另一个 goroutine 对 channel 执行 send 操作。\n\n**正是因为 unbuffered channel 的这种特性，unbuffered channel 也称之为 synchronous channel**。\n\n\n## Unbuffered channel 实践之一：同步\n\n```go\npackage main\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n    c := make(chan int)\n    go func(){\n        c \u003C- 1\n    }\n    \u003C-c\n    fmt.Println(\"main goroutine finish \")\n}\n```\n上面的代码展示了利用 unbuffered channel 完成同步的能力，main goroutine 会一直等待直到满足特定条件时才会结束。\n\n## Unbuffered channel 实践之二：pipeline\n\n在 pipeline 的应用场景中，channel 是不同 goroutine 之间传递消息的通道，而且一个 goroutine 输出作为另一个 goroutine 的输入：\n\n![pipeline](https://static.git-star.com/WX20171229-170322.png)\n\n以下代码展示了其用法：\n```go\nfunc main() {\n    naturals := make(chan int)\n    squares := make(chan int)\n    // Counter\n    go func() {\n        for x := 0; ; x++ {\n            naturals \u003C- x\n        }\n    }()\n    // Squarer\n    go func() {\n        for {\n            x := \u003C-naturals\n            squares \u003C- x * x\n        }\n    }()\n    // Printer (in main goroutine)\n    for {\n        fmt.Println(\u003C-squares)\n    }\n}\n```\n\nnaturals 是 Counter 的输出，是 Squarer 的输入，一个 goroutine 的结果作为另一个的输入，各个 goroutine 使用 channel 形成了一个流水线，由于是同步的 channel，一个 goroutine 想要产生输出，必须等待另一个 goroutine，goroutine 之间形成了同步等待关系。\n\n\n## 参考资料\n\n- The Go Programming Language","src/content/posts/go-goroutine-channel-3.mdx","7c598de8eeb7a681","go-goroutine-channel-3.mdx","go-goroutine-channel-2",{"id":468,"data":470,"body":475,"filePath":476,"digest":477,"legacyId":478,"deferredRender":22},{"title":471,"summary":390,"date":472,"tags":473,"group":395,"featured":38},"Go goroutine 和 channel 详解 (二) ：channel",["Date","2017-12-01T00:00:00.000Z"],[474,50],"goroutine","> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\n## 定义\n\n如果说 goroutine 是并发执行的一个 Go program， channel 就是它们之间的连接通道，它提供了 goroutine 之间相互通信的机制。Channel 是有类型的，channel 中使用的 type 称之为 element type，比如 int 类型的 channel 写作为 `chan int`。\n\nGo 使用 make 内建函数创建 channel。\n```go\nch := make(chan int)\n```\n同 map 一样，一个 channel 引用着 make 创建的底层数据结构上，当把 channel 当做函数参数传递时，实际上是拷贝一份 reference，也就是说函数内部和外部引用的是相同的数据结构，所以在函数内部可以直接修改 channel 的值。同其它 reference type 一样，**channel 的 zero value 是 nil**。\n\n\n## Channel 是可比较的\n\n**Channel 是可比较的，如果两个 channel 的类型相同，它们可以彼此相互比较**：\n\n```go\nch01 := make(chan int)\nch02 := make(chan int)\nif ch01 == ch02 {\n    fmt.Println(\"ch01 == ch02\")\n} else {\n    fmt.Println(\"ch01 != ch02\")\n}\n```\n\n两个不是 nil 的 channel 比较实际上比较的他们的 reference 是否相同，如果他们都引用同一个 channel，则他们相同:\n\n```go\nfunc main() {\n    ch01 := make(chan int)\n    func02(ch01, ch01)\n}\n\nfunc func02(a chan int, b chan int) {\n    if a == b {\n        fmt.Println(\"a == b\")\n    }\n}\n```\n\n当然 channel 也可以和 nil 比较，没有初始化的 channel 就是 nil:\n```go\nvar ch02 chan int\nif ch02 == nil {\n    fmt.Println(\"ch02 is nil\")\n}\n\n```\n\n## Channel 的基本操作\n\nChannel 有三种基本的操作 send、receive、close。\n\n### Send\n\nChannel 支持 send 操作，意思是向 channel 中发送数据，Go 使用 `\u003C-` 操作符来实现 send：\n```go\nch \u003C- x //send\n```\n\nSend 时 `\u003C-` 在 channel 右侧。\n\n### Receive\n\nChannel 还支持 receive 操作，意思是从 channel 中取出数据，Go 也是使用 `\u003C-` 操作符来实现 receive：\n```go\nx := \u003C- ch //receive\n```\n\nReceive 时 `\u003C-` 在左侧，如果一个执行 receive 时没有用任何变量来赋值，则该值被抛弃，receive 的这个操作常常被用来做状态同步：\n\n```go\n\u003C- ch\n```\n\n### Close\n\nChannel 还支持第三种操作 `close`，如果 channel 被 close，表明 channel 不会再 send 任何值了，如果还继续对 channel 执行 receive 操作，当 channel 中的值消耗完毕之后，之后返回的是对应 element type 的 zero value，如果对 channel 执行 send 操作，将会引起 panic：\n```go\nclose(ch)\nch \u003C- x  // panic\n```\n\nClose 操作常常和 for 语句配合使用，表示一个 channel 不再产生新的值：\n```go\n\nfor x := range ch {\n   fmt.Print(x) \n}\n\n```\n\nClose channel 之后，for 循环将结束。\n\n\n## 参考资料\n\n- The Go Programming Language","src/content/posts/go-goroutine-channel-2.mdx","f0027d47a358b90a","go-goroutine-channel-2.mdx","go-env",{"id":479,"data":481,"body":486,"filePath":487,"digest":488,"legacyId":489,"deferredRender":22},{"title":482,"summary":483,"date":484,"tags":485,"group":50,"featured":38},"Go 基础环境搭建和环境变量详解","Go 的下载和安装，已经有很多文章介绍了，这里不再赘述，详情参见：",["Date","2018-05-07T00:00:00.000Z"],[],"Go 的下载和安装，已经有很多文章介绍了，这里不再赘述，详情参见：\n\n- [Go语言开发环境搭建详解](https://mp.weixin.qq.com/s/Rrvk1fD-wuu0FMUeE0kWlw)\n- [Go 官方 install](https://golang.org/doc/install)\n\n\nGo 的环境变量可以使用 `go env` 命令查看:\n\n```shell\nGOARCH=\"amd64\"\nGOBIN=\"\"\nGOCACHE=\"/Users/zhaoyongqiang/Library/Caches/go-build\"\nGOEXE=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"darwin\"\nGOOS=\"darwin\"\nGOPATH=\"/Users/zhaoyongqiang/go-workspace\"\nGORACE=\"\"\nGOROOT=\"/usr/local/Cellar/go/1.10.2/libexec\"\nGOTMPDIR=\"\"\nGOTOOLDIR=\"/usr/local/Cellar/go/1.10.2/libexec/pkg/tool/darwin_amd64\"\nGCCGO=\"gccgo\"\nCC=\"clang\"\nCXX=\"clang++\"\nCGO_ENABLED=\"1\"\nCGO_CFLAGS=\"-g -O2\"\nCGO_CPPFLAGS=\"\"\nCGO_CXXFLAGS=\"-g -O2\"\nCGO_FFLAGS=\"-g -O2\"\nCGO_LDFLAGS=\"-g -O2\"\nPKG_CONFIG=\"pkg-config\"\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/k_/4_4w_0c909bg9xfdvx0s_8pw0000gn/T/go-build042190142=/tmp/go-build -gno-record-gcc-switches -fno-common\"\n```\n\n- GOARCH  — 支持的处理器架构\n- GOBIN  — go install 命令安装可执行文件的位置\n- GOCACHE\n- GOEXE\n- GOHOSTARCH\n- GOHOSTOS\n- GOOS\n- GOPATH\n- GORACE\n- GOROOT — Go 安装目录\n- GOTMPDIR\n- GOTOOLDIR\n- GCCGO\n- CC\n- CXX\n- CGO_ENABLED\n- CGO_CFLAGS\n- CGO_CPPFLAGS\n- CGO_CXXFLAGS\n- CGO_FFLAGS\n- CGO_LDFLAGS\n- PKG_CONFIG\n- GOGCCFLAGS\n\n其中有两个变量和日常开发联系最紧密，一个是 GOROOT，一个是 GOPATH，所有变量的具体含义详见 https://golang.org/cmd/go/#hdr-Environment_variables 。\n\n## GOROOT\n\n简而言之 GOROOT 就是 Go 的安装目录，如果一台机器上有多个 Go 版本并存就需要注意 GOROOT 的设置，不同的 Go 版本使用不同的目录，对应的 Go 项目正确设置 Go 版本。\n\n## GOPATH\n\nGOPATH 是 Go 项目中最重要的一个目录，其决定了使用 Go 命令比如 `go install` 、`go get` 要把执行文件和源码放到哪个位置，决定开发 Go 项目依赖包是如何导入的，可以说如果要开发完整的 Go 项目首先要设置的就是 GOPATH，官方详见 https://golang.org/cmd/go/#hdr-GOPATH_environment_variable。\n\n### GOPATH 的组成\n\n- src 源码文件目录，包括使用 go get 安装的第三包\n- pkg 编译打包之后的 lib，主要是 *.a 文件\n- bin 可执行文件，go install 命令会把可执行文件放入该目录\n\n```shell\n.\n├── bin\n│   ├── go-outline\n│   ├── go-symbols\n│   ├── gocode\n│   ├── godef\n│   ├── golint\n│   ├── gopkgs\n│   ├── goplay\n│   ├── gorename\n│   ├── goreturns\n│   └── guru\n├── pkg\n│   └── darwin_amd64\n│       ├── github.com\n│       ├── go-tutorial\n│       ├── golang.org\n│       └── gopkg.in\n└── src\n    ├── github.com\n    │   ├── MichaelTJones\n    │   ├── acroca\n    │   ├── go-sql-driver\n    │   ├── golang\n    │   ├── haya14busa\n    │   ├── nsf\n    │   ├── ramya-rao-a\n    │   ├── rogpeppe\n    │   ├── skratchdot\n    │   ├── sqs\n    │   ├── uudashr\n    │   └── zhyq0826\n    ├── golang.org\n    │   └── x\n    └── gopkg.in\n        └── mgo.v2\n```\n\n### GOPATH 如何设定\n\nGOPATH 的设定并没有严格规范，只要当前环境变量中可以找到正确的 GOPATH 目录即可，可以按照如下规则设定：\n\n**每个用户一个 GOPATH**\n\n为了开发方便，对于个人开发者来说，可以在当前用环境变量中设置 GOPATH，比如 linux 用户可以修改 `.bash_profile` 文件设置：\n\n```shell\nexport GOPATH=$HOME/go\n```\n\n**一个项目一个 GOPATH**\n\n如果是团队开发，往往会设计多个项目，每个项目的 Go 版本和第三方依赖都有差别，可以使用每个 Go 项目一个GOPATH，这样可以最大程度上降低开发中的包和版本冲突。\n\n**注意**：GOPATH 可以设置多个值，也就是 GOPATH 允许设置多个目录，这种情况下使用 go get 安装的包默认放在第一个目录。","src/content/posts/go-env.mdx","ae35a07d1f092fc1","go-env.mdx","go-goroutine-channel-1",{"id":490,"data":492,"body":496,"filePath":497,"digest":498,"legacyId":499,"deferredRender":22},{"title":493,"summary":390,"date":494,"tags":495,"group":395,"featured":38},"Go goroutine 和 channel 详解 (一) ：goroutine",["Date","2017-12-01T00:00:00.000Z"],[474,50],"> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\nGo 支持两种方式的并发模型: communicating sequential processes(CSP) 和 shared memory multithreading，前者是 goroutine 和 channel 并发模型实现的基础，后者是传统的共享内存的方式，也就是多线程模型。\n\n如何理解 CSP ？简单来说就是通过在不同的 goroutine 之间传递 value 来维护并发的下不同 goroutine 的状态，但是对变量的使用、修改要限制在单一的 goroutine 中。\n\n\n## 定义\n\n在 Go 中可以并发执行的活动单元称之为 goroutine。当一个 Go 程序启动时，一个执行 main function 的 goroutine 会被创建，称之为 `main goroutine`。创建新的 goroutine 可以使用 go 语句，像这样: go f()，其中 `f` 是一个函数。使用 go 语句开启一个新的 goroutine 之后，go 语句之后的函数调用将在新的 goroutine 中执行，而不会阻塞当前的程序执行。\n\n\n```go\n\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    go spinner(100 * time.Millisecond)\n    const (\n        n = 45\n    )\n    fibN := fib(n)\n    fmt.Printf(\"\\rFibonacci(%d) = %d\\n\", n, fibN)\n}\n\nfunc spinner(delay time.Duration) {\n    for {\n        for _, r := range `_\\|/` {\n            fmt.Printf(\"\\r%c\", r)\n            time.Sleep(delay)\n        }\n    }\n}\n\nfunc fib(x int) int {\n    if x \u003C 2 {\n        return x\n    }\n\n    return fib(x-1) + fib(x-2)\n}\n\n```\n\n在这个例子中，`go spinner()` 和 `fib` 两个函数的执行是互不影响的，也就是说它们是两个可以同时执行。\n\n\n## 例子：并发的时钟 server\n\n\n为了更好的演示 goroutine 在并发场景下的使用以及它带来的优势，我们一起来完成一个时钟 server，这个 server 非常简单，每次处理一个来自客户端的请求并把当前的时间格式化之后发回客户端， 我们先实现一个不支持 goroutine 的版本，即一次处理一个连接。\n\n```go\npackage main\n\nimport (\n    \"io\"\n    \"log\"\n    \"net\"\n    \"time\"\n)\n\nfunc main() {\n    listener, err := net.Listen(\"tcp\", \"localhost:8888\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    for {\n        conn, err := listener.Accept()\n        if err != nil {\n            log.Print(err)\n            continue\n        }\n\n        handleConn(conn)\n    }\n}\n\nfunc handleConn(conn net.Conn) {\n    defer conn.Close()\n    for {\n        _, err := io.WriteString(conn, time.Now().Format(\"15:04:05\\n\"))\n        if err != nil {\n            return\n        }\n        time.Sleep(1 * time.Second)\n    }\n}\n\n```\n然后我们在实现一个 client 来与 server 连接，client 只负责连接 server 并回显 server 的消息。\n\n```go\npackage main\n\nimport (\n    \"io\"\n    \"log\"\n    \"net\"\n    \"os\"\n)\n\nfunc main() {\n    conn, err := net.Dial(\"tcp\", \"localhost:8888\")\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    defer conn.Close()\n    mustCopy(os.Stdout, conn)\n}\n\nfunc mustCopy(dst io.Writer, src io.Reader) {\n    if _, err := io.Copy(dst, src); err != nil {\n        log.Fatal(err)\n    }\n}\n\n```\n然后我们开始我们的并发实验，首先执行 server 端程序，然后打开一个终端执行一个 client，可以看到 client 会不断输出当前的时间\n```bash\ngo run ch08_03_netcat1.go\n13:58:50\n13:58:51\n13:58:52\n13:58:53\n13:58:54\n13:58:55\n13:58:56\n13:58:57\n13:58:58\n```\n然后我们再打开一个新的终端执行一个新的 client，发现没有任何输出，但是关闭第一个 client 之后，就会有时间输出。在这个例子中，由于 server 一次只能处理一个 client 的连接，所以当有多个 client 并发连接时，后续的 client 必须排队等候。\n\n使用 goroutine 就可以提高 server 的并发处理能力从而解决这个问题，非常简单，只需要在 server 端处理连接的地方加一个go 关键字即可 `go handleConn(conn)`，启用新的 goroutine 之后，同时开启多个 client 都会有时间输出，server 有了并发处理的能力了。\n\n\n## 例子：echo server\n\nEcho server 是一个演示回声的例子，在这个例子中我们将向 server 发送一段消息，然后 server 会以回声的形式回显，比如发送 `Hello`，server 会回显 `HELLO`、`Hello` 和 `hello`。\n\n\n```go\n\npackage main\n\nimport (\n    \"bufio\"\n    \"fmt\"\n    \"log\"\n    \"net\"\n    \"strings\"\n    \"time\"\n)\n\nfunc main() {\n    listener, err := net.Listen(\"tcp\", \"localhost:8888\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    for {\n        conn, err := listener.Accept()\n        if err != nil {\n            log.Print(err)\n            continue\n        }\n\n        go handleConn(conn)\n    }\n}\n\nfunc handleConn(conn net.Conn) {\n    // 连接不断读取数据并转化\n    input := bufio.NewScanner(conn)\n    defer conn.Close()\n    for input.Scan() {\n        echo(conn, input.Text(), 1*time.Second)\n    }\n}\n\nfunc echo(c net.Conn, shout string, delay time.Duration) {\n    fmt.Fprintln(c, \"\\t\", strings.ToUpper(shout))\n    time.Sleep(delay)\n    fmt.Fprintln(c, \"\\t\", shout)\n    time.Sleep(delay)\n    fmt.Fprintln(c, \"\\t\", strings.ToLower(shout))\n}\n\n```\n在上面的代码中 server 在接收到 client 的连接之后开始读取 client 的数据并回显，回显的过程是间隔延迟一断时间执行。\n\n```go\npackage main\n\nimport (\n    \"io\"\n    \"log\"\n    \"net\"\n    \"os\"\n)\n\nfunc main() {\n    conn, err := net.Dial(\"tcp\", \"localhost:8888\")\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    defer conn.Close()\n    // 从 conn 中读取数据并且送到标准输出\n    go mustCopy(os.Stdout, conn)\n    //从标准输入中读取数据并且送到 conn\n    mustCopy(conn, os.Stdin)\n}\n\nfunc mustCopy(dst io.Writer, src io.Reader) {\n    if _, err := io.Copy(dst, src); err != nil {\n        if err == io.EOF { //check eof ctrl + d\n            os.Exit(1)\n        }\n    }\n}\n\n```\nclient 代码很简单，从标准输入读取数据发送到 server 和从 server 读取数据发送到标准输出。\n\n启动 server，启动一个 client 开启我们的实验。\n\n```\n± % make netcat2                                                               \ngo run ch08_03_netcat2.go\nHello\n     HELLO\n     Hello\n     hello\nMe\n     ME\nHe   Me\nllo  me\n\n     HELLO\n     Hello\n     hello\n```\n在现实世界的回声中，如果同时有多个回声存在应该会有交错出现的现象，但是我们的 client 有两个回声出现时不是交错出现，而是依次返回完一个才继续下一个，为了模拟真实的回声我们还需要一个 goroutine 用来实现回声的交错显现，像这样 `go echo(conn, input.Text(), 1*time.Second)`。\n\n**Goroutine 的参数是在 go 语句执行之后确定的，所以 input.Text() 值是在 go 语句开启之后就确定的**，也就是执行 go 语句时 input.Text() 如果返回消息 a，即使同一个 connection 后来又有消息 b，goroutine 函数的参数依然是 a，这样即使同一个 client 的 connection 会有多个 msg 也会按照我们的要求回显。\n\n对于上面的 Go 程序来说，想要实现一个 server 同时处理多个 connection，而且甚至在同一个 connection 中实现并发需要的仅仅是两个简单的 go 关键字。\n\n## 参考资料\n\n- The Go Programming Language","src/content/posts/go-goroutine-channel-1.mdx","48e64a55fadaed6a","go-goroutine-channel-1.mdx","go-interface-1",{"id":500,"data":502,"body":507,"filePath":508,"digest":509,"legacyId":510,"deferredRender":22},{"title":503,"summary":390,"date":504,"tags":505,"group":395,"featured":38},"Go interface 详解(一) ：介绍",["Date","2017-10-10T00:00:00.000Z"],[506,50],"interface","> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\nGo 中的 interface 是一种类型，更准确的说是一种抽象类型 abstract type，一个 interface 就是包含了一系列行为的 method 集合，interface 的定义很简单：\n\n```Go\npackage io\n\ntype Writer interface {\n    Write(p []byte) (n int, err error)\n}\n```\n\nGo 中的 interface 不同于其它语言，它是隐式的 implicitly，这意味着对于一个已有类型，你可以不用更改任何代码就可以让其满足某个 interface。\n\n\n如果一个 concrete type 实现了某个 interface，我们说这个 concrete type 实现了 interface 包含的所有 method，**必须是所有的 method**。\n\n在 Go 的标准库 `fmt` 中有一系列的方法可以很好的诠释 interface 是如何应用到实践当中的。\n\n{/* more */}\n\n```Go\npackage fmt\n\nfunc Fprintf(w io.Writer, format string, args ...interface{}) (int, error)\n\nfunc Printf(format string, args ...interface{}) (int, error) {\n    return Fprintf(os.Stdout, format, args...)\n}\n\nfunc Sprintf(format string, args ...interface{}) string {\n    var buf bytes.Buffer\n    Fprintf(&buf, format, args...)\n    return buf.String()\n}\n\n```\n\n`Fprintf` 中的前缀 `F` 表示 `File`，意思是格式化的输出被输出到函数指定的第一个 `File` 类型的参数中。\n\n在 `Printf` 函数中，调用 `Fprintf` 时指定的输出是标准输出，这正是 `Printf` 的功能：Printf formats according to a format specifier and writes to standard output，根据指定的格式化要求输出到标准输出，`os.Stdout` 的类型是 `*os.File` 。\n\n同样在 `Sprintf` 函数中，调用 `Fprintf` 时指定的输出是一个指向某个 memory buffer 的指针，其类似一个 `*os.File`。\n\n虽然 `bytes.Buffer` 和 `os.Stdout` 是不同的，但是它们都可以被用于调用同一个函数 `Fprintf`，就是因为 `Fprintf` 的第一个参数是接口类型 `io.Writer` ，而 `bytes.Buffer` 和 `os.Stdout` 都实现了这个 interface，即它们都实现了 `Write` 这个 method，这个 interface 并不是一个 `File` 却完成了类似 `File`的功能。\n\n`Fprintf` 其实并不关心它的第一个参数是一个 file 还是一段 memory，它只是调用了 `Write` method。这正是 interface 所关注的，**只在乎行为，不在乎其值**，这种能力让我们可以非常自由的向 `Fprintf` 传递任何满足 `io.Writer` 的 concrete type，这是 Go interface 带来的 `substitutability` 可替代性，object-oriented programming 的一种重要特性。\n\n看个例子：\n\n```Go\npackage main\n\nimport (\n    \"fmt\"\n)\n\ntype ByteCounter int\n\n\nfunc (c *ByteCounter) Write(p []byte) (int, error) {\n    *c += ByteCounter(len(p)) // convert int to ByteCounter\n    return len(p), nil\n}\n\nfunc main() {\n\n    var c ByteCounter\n    c.Write([]byte(\"hello\"))\n    fmt.Println(c) // 5  #1\n    fmt.Fprintf(&c, \"hello\") #2 \n    fmt.Println(c) // 10  #3\n}\n```\n\n`ByteCounter` 实现了 `Write` method，它满足 `io.Writer` interface，`Write` method 计算传给它的 byte slice 的长度并且赋值给自身，所以 `#1` 输出到标准输出的是它的值 5，正如前文所言，调用 `fmt.Fprintf` 时再次调用了 c 的 `Write` method，所以 `#3` 输出是 10。\n\n这就是 Go 中的 interface 所具有的最基本的功能：作为一种 abstract type，实现各种 concrete type 的行为统一。","src/content/posts/go-interface-1.mdx","310ed4073545e4c4","go-interface-1.mdx","go-interface-2",{"id":511,"data":513,"body":517,"filePath":518,"digest":519,"legacyId":520,"deferredRender":22},{"title":514,"summary":390,"date":515,"tags":516,"group":395,"featured":38},"Go interface 详解(二) ：定义和使用",["Date","2017-10-12T00:00:00.000Z"],[506,50],"> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\n# 定义 interface\n\n正如上文所说，Go interface 是一种类型，一个 interface type 指定了一组 method 集合，如果说一个 concrete type 是一个 interface 的 instance，我们说这个 concrete type 实现了这个 interface 的所有方法。\n\n在 Go 的标准库 `io` package 中定义了很多有用的 interface：\n```Go\npackage io\n\ntype Reader interface {\n    Read(p []byte)(n intm err error)\n}\n\ntype Writer interface {\n    Write(p []byte) (n int, err error)\n}\n\ntype Closer interface {\n    Close() error\n}\n\n```\n\n{/* more */}\n\n`Reader` 代表任何可以去读 byte 的类型，类似的，`Writer` 代表任何可以写入 byte 的类型，`Closer` 代表任何可以执行 close 的类型。除此之外，我们还能在 io package 中发现其它**组合式的 interface**：\n```Go\npackage io\n\ntype ReadWriter interface {\n    Reader\n    Writer\n}\n\ntype ReadWriteCloser interface {\n    Reader\n    Writer\n    Closer\n}\n\n```\n`ReaderWrite` 和 `ReadWriteCloser` 的语法形式和 struct 的 embedding 非常类似，被称为 `embedding interface`，通过这种形式可以便捷的实现一个新的 interface 而不必写出 interface 包含的所有 method。\n\n注意 Go 标准库中对组合 interface 的命名，你应该总是遵循这样的规则。\n\n`ReaderWrite` 也可以用非 embedding 的形式实现：\n```Go\n\ntype ReadWriter interface {\n    Read(p []byte)(n intm err error)\n    Write(p []byte) (n int, err error)\n}\n\n```\n\n或者是二者的组合：\n```Go\n\ntype ReadWriter interface {\n    Read(p []byte)(n intm err error)\n    Writer\n}\n\n```\n\n以上的几种实现都是等价的，但是我们更推崇使用 embedding 的形式。\n\n说完了 interface type 的定义，再说说 interface type 使用。\n\n# 实现 interface 并使用\n\n如果一个 concrete type 实现了某个 interface type，其值可以赋值给 interface type 的 instance。\n```Go\nvar w io.Writer\nw = os.Stdout\nw = new(byte.Buffer)\n\nvar rwc io.ReadWriteCloser\nrwc = os.Stdout\n\n```\n\n甚至赋值符号右边也可以是 interface instance，只要它们的关系满足**左边 interface type method 集合是右边 interface type method 集合的子集**即可：\n```Go\nw = rwc\n```\n`w` method 集合 `{Writer}` 是 `rwc` method 集合 `{Reader, Writer, Closer}` 的子集。\n\n在 Struct 中，在一个类型 T 上直接调用 receiver 是 `*T` 的 method 是合法的，只要 T 是以 variable 的形势存在，看个例子：\n```Go\npackage main\n\nimport (\n    \"fmt\"\n)\n\ntype T struct {\n}\n\nfunc (t *T) String() string {\n    return \"\"\n}\n```\n\n这样是可以的：\n```Go\nvar t T\nt.String()\n```\n\n但是这样不行：\n```Go\nT{}.String()\n```\n\nStruct 这个微妙的细节也体现在 interface 的赋值上，只有 `*T` 实现了 `String` 所以 `*T` 才能满足 interface `Stringer`，这样是可以的：\n```Go\nvar _ fmt.Stringer = &t\n```\n\n但是这样是不行的：\n```Go\n// T does not implement fmt.Stringer (String method has pointer)\nvar _ fmt.Stringer = t \n```\n这也是[理解 go interface 的 5 个关键点](/blog/how-to-understand-go-interface)第5点所讲到的。\n\n虽然 interface type 和 concrete type 之间的关系是隐式的 implicitly，但是在某些情况下显式地声明 concrete type 和 interface 的关系则很有用：\n```Go\nvar _ io.Writer = new(bytes.Buffer)\n```\n`new(bytes.Buffer)` 返回 `bytes.Buffer` 的 pointer，这正是实现 `Writer` 需要的类型。\n\n即使 `nil` 我们也可以显式地进行转换:\n```Go\nvar _ io.Writer = (*bytes.Buffer)(nil)\n```\n\n# Empty interface\n\n还有一种很重要的 interface 需要我们注意：**interface{}**，empty interface 没有任何 method。\n\nMethod 集合是 interface type 和 concrete type 之间关系的契约，也就是说 interface 向 concrete type 提出了要求说，你必须提供我要求的这些方法才能使用我，但是 empty interface 没有提供任何方法是不是不需要任何方法就可以使用它？的确如此。\n```Go\nvar any interface{}\nany = true\nany = 12.34\nany = \"hello\"\nany = map[string]int{\"one\": 1}\nany = new(bytes.Buffer)\n```\n\nEmpty interface 可以让任何类型赋值，但是它没有任何方法该如何真正使用它？这就涉及到 type assertion ，从 `interface{}` 获取真正有用的 concrete value，后面我们会讲到。\n\n# 总结\n\nGo interface 提供了在抽象层的组合和使用，只要你愿意你总是能找到一种方法可以在不修改已有包代码的情况下组合使用包中提供的任何功能。","src/content/posts/go-interface-2.mdx","f866a963bab3ddb9","go-interface-2.mdx","go-http-request-goroutine-leak",{"id":521,"data":523,"body":528,"filePath":529,"digest":530,"legacyId":531,"deferredRender":22},{"title":524,"summary":525,"date":526,"tags":527,"group":50,"featured":38},"Go http request 引起的 goroutine 泄漏","## 问题回放",["Date","2019-09-10T00:00:00.000Z"],[],"## 问题回放\n\n\n线上一个 Go 服务内存一直持续增长，使用 [Go ppof](https://book.eddycjy.com/golang/tools/go-tool-pprof.html) 分析之后发现 `net/http.(*persistConn).writeLoop` 和 `net/http.(*persistConn).readLoop` goroutine 数目多达数万个，很明显发生了 goroutine 泄漏。\n\n\n## 初步定位\n\n\n既然是 `net/http` 相关的代码，一定和 http 请求有关，扫了一下服务中用到的所有 http request，没有发现特别异样的代码，以为是 http 没有主动释放连接导致的，手动在某些 http request 中加入了 `request.Close = true`，发现 goroutine 数目没有明显变化，增加趋势仍在。上面泄漏的代码位于 `net/http/transport` 文件中，是 `persistConn` 这个 struct 的方法，负责对 connection 的读和写，从字面意思不难看出，`persistConn` 是对普通 tcp connection 的封装，以达到连结复用的目的。登陆到出问题主机查看网络连接的情况`netstat -antl` 发现连接数并没有明显的增加，说明 `writeLoop` 和 `readLoop` 并没有长期持有连接不释放，上面 `request.Close = true` 并没有解决问题。\n\n\n## 阅读源码\n\n\n阅读 `http.Client` 发送请求的源码梳理流程，整个 http 请求的读取都是通过实现了 http 协议的 Transport 来实现，Transport 又利用 persistConn 封装了普通的 connection 来达到连接服用的目的，也就是满足 http 中 keep-alive 的需求，一旦一个 `http client` 需要 `keep-alive` 那么这个 connection 就不会断开，重复利用，而 `readLoop` 的逻辑就是一个 for 循环里面几个小的 select，for 循环退出的条件就是 `alive` 变成 `false`：\n```golang\n\nselect {\ncase rc.ch \u003C- responseAndError{res: resp}:\ncase \u003C-rc.callerGone:\n\treturn\n}\n\n\nselect {\ncase bodyEOF := \u003C-waitForBodyRead:\n\tpc.t.setReqCanceler(rc.req, nil) // before pc might return to idle pool\n\talive = alive &&\n\t\tbodyEOF &&\n\t\t!pc.sawEOF &&\n\t\tpc.wroteRequest() &&\n\t\ttryPutIdleConn(trace)\n\tif bodyEOF {\n\t\teofc \u003C- struct{}{}\n\t}\ncase \u003C-rc.req.Cancel:\n\talive = false\n\tpc.t.CancelRequest(rc.req)\ncase \u003C-rc.req.Context().Done():\n\talive = false\n\tpc.t.cancelRequest(rc.req, rc.req.Context().Err())\ncase \u003C-pc.closech:\n\talive = false\n}\n```\n\n这几个 select 都是等待各种 `chan` 满足条件之后才能继续执行，而 goroutine 退出需要满足：\n\n- body 读取完毕\n- request 主动 cancel\n- request context Done 状态 true\n- 当前的 persistConn 关闭\n\n所以上述几个条件不满足，goroutine 将一直存在，也就是如果一个 http request 的 body 没有被用到，那么这个 goroutine 也不会被关闭。查看官方文档：\n```golang\n// The client must close the response body when finished with it:\n\nresp, err := http.Get(\"http://example.com/\")\nif err != nil {\n\t// handle error\n}\ndefer resp.Body.Close()\nbody, err := ioutil.ReadAll(resp.Body)\n// ...\n```\n\n明确要求必须显式关闭 body，于是检查我们的服务发现确实某一个 http 请求的 body 没有被用到，所以没有关闭操作，主动关闭之后 goroutine 开始不增长了。\n\n\n\n## Go 中需要主动关闭 http body\n\n如果之前写过 Python，会觉得关闭 http response body 真的是多此一举，这和整个 Go 实现 http 请求的机制有关系，因为 Go 是通过 goroutine 实现 http 的请求的，一个 http request 可能是由多个 goroutine 组成，而 goroutine 没有办法通过其他机制杀死，只能等待 goroutine 主动退出，所以必须要有机制去通知 goroutine 告诉它们工作结束了可以退出了，一旦这个机制遭到破坏，那么 goroutine 就不会释放。因为上面的 body 没有被使用，没有主动关闭 body，而且请求也没有主动关闭，导致底层的 tcp 连接可能早就断开了，但是上层的持有连接的 goroutine 依然没有释放，除了主动关闭 body 之外，还可以在调用结束之后关闭 request：\n\n```golang\nrequest, err := http.NewRequest(\"GET\", url, bytes.NewReader([]byte(\"\")))\nctx, cancelFunc := context.WithCancel(context.Background())\nrequest = request.WithContext(ctx)\nclient := http.Client{}\nresp, err := client.Do(request)\nif err != nil {\n\treturn false\n}\ndefer cancelFunc()\n```","src/content/posts/go-http-request-goroutine-leak.mdx","5c8c2765bc64d087","go-http-request-goroutine-leak.mdx","go-interface-3",{"id":532,"data":534,"body":538,"filePath":539,"digest":540,"legacyId":541,"deferredRender":22},{"title":535,"summary":390,"date":536,"tags":537,"group":395,"featured":38},"Go interface 详解 (三) ：interface 的值",["Date","2017-10-18T00:00:00.000Z"],[506,50],"> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\n\n# Interface value 的赋值\n\n从概念上来讲，interface value 有两部分组成：type 部分是一个 concrete type，vlaue 部分是这个 concrete type 对应的 instance，它们分别称之为 interface value 的 dynamic type 和 dynamic value。\n\n由于 Go 是静态类型的语言，type 是在编译阶段已经定义好的，而 interface 存储的值是动态的，在上面这个概念模型中，type 部分更准确叫法是 type descriptors，主要是提供 concrete type 的相关信息，包括 method、name 等。\n\n下面这几个语句：\n```Go\nvar w io.Writer\nw = os.Stdout\nw = new(bytes.Buffer)\nw = nil\n```\n变量 `w` 依次存储了三种不同的值，在此我们依次来看看每种不同的值的确切含义。\n\n{/* more */}\n\n语句 `var w io.Writer` 声明并初始化了一个 interface value `w`，其值是 `nil`，此时 type 和 value 部分都是 `nil`。\n\n```\nw:\n    type --> nil\n    value --> nil\n\n```\ninterface value 是否是 nil 取决于其 dynamic type，在 nil 的 interface value 上调用会 panic\n```Go\nw.Write([]byte(\"hello\")) // panic\n```\n\n语句 `w = os.Stdout` 赋值 `*os.File` 类型的 value 给 w，这个赋值操作包含一个隐式的类型转换，用以把 concrete type 转换成 interface type `io.Writer(*os.File)`，在这个转换过程中 dynamic type 被赋值为 `*os.File` 类型，在这里其实是它的 type descriptor，同样得，dynamic value 赋值为 os.Stdout 的一份 copy，一个指向 `os.File` 类型的指针且代表**标准输出**的变量。\n```\nw:\n    type --> *os.File\n    value -------> fd int=1(stdout)\n\n```\n\n在 interface value w 上调用 `Write` method 实际上调用的是 `*os.File` 类型的 Write 方法，于是输出 \"hello\"。\n```Go\nw.Write([]byte(\"hello\")) // \"hello\"\n```\n\n由于在编译阶段，我们并不知道一个 interface value 的 dynamic type 是什么，所以 interface value 的调用必须进行 dynamic dispatch。为了能调用 dynamic value 的 Write method，compiler 必须生成相关代码以便在执行的时候通过 dynamic type 获取对应 method 的真实地址的 copy，在调用的形式上好像是我们直接调用了 dynamic value 的 Write method。\n```Go\nos.Stdout.Write([]byte(\"hello\")) // \"hello\"\n```\n\n语句 `w=new(bytes.Buffer)` 赋值 `*bytes.Buffer` 类型的 value 作为 w 的 dynamic value，对 w 的处理是也类似的，调用 Write method 将调用 `*bytes.Buffer` 的 Write method。\n\n语句 `w=nil` 和初始语句一样将 w 重置为 nil。\n\n\n# Interface value 的比较\n\nInterface value 可以使用 `==` 和 `!=` 语句进行比较的。如果两个 interface value 的 dynamic type 相同，dynamic value 根据 dynamic type 的 `==` 比较操作是相等的，那么这两个 interface value 是相等的。因而 interface value 可以用在 map 中作为key 或者 switch 语句中。\n\n虽然 interface value 本身是可以比较的，但是如果 dynamic type 不支持 compare 操作，那么对两个 dynamic type 相同的 interface value 比较将 panic，比如 slice。\n```Go\nvar x interface{} = []int{1, 2, 3}\nfmt.Println(x == x) // panic: comparing uncomparable type []int\n```\n所以使用时你应该总是留意，interface value 的 dynamic 是不是可以 compare 类型，不管 interface value 单独出现还是出现在其它类型中。\n\n\n# 格式化输出 interface value\n\nGo 提供了格式化输出 interface value 的方法，方便在开发和调试中使用。\n```Go\nvar w io.Writer\nfmt.Printf(\"%T\\n\", w) // \"\u003Cnil>\"\n\nw=os.Stdout\nfmt.Printf(\"%T\\n\", w) // \"*os.File\"\n\nw=new(bytes.Buffer)\nfmt.Printf(\"%T\\n\", w) // \"*bytes.Buffer\"\n```\n\n# 警告：dynamic value 是 nil 的 interface value 并不是 nil\n\nInterface value 是 nil 和 interface value 包含的 dynamic value 是 nil 并不是一回事，**后者不是 nil**，这个潜在的区别给初学 Go 的 developer 造成了一定的困扰。\n```Go\nconst debug = false\n\nfunc main() {\n    var buf *bytes.Buffer\n    if debug {\n        buf = new(bytes.Buffer) // enable collection of output\n    }\n    f(buf) // NOTE: subtly incorrect!\n    if debug {\n        // ...use buf...\n    }\n}\n\n// If out is non-nil, output will be written to it.\nfunc f(out io.Writer) {\n    // ...do something...\n    if out != nil {\n        out.Write([]byte(\"done!\\n\"))\n    }\n}\n```\n\n在上面的代码中，函数 f 中将会出现 panic。由于对于 `*byte.Buffer` 时，当其值是 nil 时也满足 io.Writer 这个 interface，赋值给 out 之后，out 并不是 nil，但是调用 Write 方法时，Write 的 receiver 也就是 out 的 dynamic value 是 nil，因而会 panic。\n\n解决方法是改变 main 中的 buf 为 io.Writer。","src/content/posts/go-interface-3.mdx","313f00f8923f9386","go-interface-3.mdx","go-interface-4",{"id":542,"data":544,"body":548,"filePath":549,"digest":550,"legacyId":551,"deferredRender":22},{"title":545,"summary":390,"date":546,"tags":547,"group":395,"featured":38},"Go interface 详解 (四) ：类型断言",["Date","2017-12-01T00:00:00.000Z"],[506,50],"> 本系列是阅读 \"The Go Programming Language\" 理解和记录。\n\n## Type Assertion\n\nType assertion(断言)是用于 interface value 的一种操作，语法是 x.(T)，x 是 interface type 的表达式，而 T 是 assertd type，被断言的类型。\n\n\n断言的使用主要有两种情景:\n\n**如果 asserted type 是一个 concrete type，一个实例类 type，断言会检查 x 的 dynamic type 是否和 T 相同，如果相同，断言的结果是 x 的 dynamic value**，当然 dynamic value 的 type 就是 T 了。换句话说，对 concrete type 的断言实际上是获取 x 的 dynamic value。\n\n**如果 asserted type 是一个 interface type，断言的目的是为了检测 x 的 dynamic type 是否满足 T，如果满足，断言的结果是满足 T 的表达式，但是其 dynamic type 和 dynamic value 与 x 是一样的**。换句话说，对 interface type 的断言实际上改变了 x 的 type，通常是一个更大 method set 的 interface type，但是保留原来的 dynamic type 和 dynamic value。\n\n\n我们来看两个例子。\n\n**case 1**\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"io\"\n    \"os\"\n)\n\nfunc main() {\n\n    var w io.Writer\n    w = os.Stdout\n    w.Write([]byte(\"hello Go!\"))\n    fmt.Printf(\"%T\\n\", w)\n    fw := w.(*os.File)\n    fmt.Printf(\"%T\\n\", fw)\n}\n\n```\n\n在上面的代码中，w 是一个有 `Write` method 的 interface expression，其 dynamic value 是 os.Stdout，断言 `w.(*os.File)` 针对 concrete type `*os.File` 进行的，那么 f 就是 w 的 dynamic value `os.Stdout`。\n\n**case 2**\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"io\"\n    \"os\"\n)\n\nfunc main() {\n\n    var w io.Writer\n    w = os.Stdout\n    w.Write([]byte(\"hello Go!\"))\n    fmt.Printf(\"%T\\n\", w)\n    rw := w.(io.ReadWriter)\n    fmt.Printf(\"%T\\n\", rw)\n}\n\n```\n\n类似 case 1, 断言 `w.(io.ReadWriter)` 针对 interface type `io.ReadWriter` 进行，那么 rw 是一个 dynamic value 为 `*os.File` 的 interface value。\n\n\n不论是针对 concrete type 还是 Interface type 如果 assert expression 是 nil assert 都会失败。\n\n```go\nvar w io.Writer\nfw := w.(*os.File) //fail\nrw := w.(io.ReadWriter) //fail\n```\n\n通常我们仅仅只是想知道 dynamic value 是哪种 concrete type ，可以借助 ok 表达式。\n```go\nvar w io.Writer = os.Stdout\nf, ok := w.(*os.File) // success: ok, f == os.Stdout\nb, ok := w.(*bytes.Buffer) // failure: !ok, b == nil\n```\n在 ok 表达式中 nil 不会导致 assertion 失败，如果 assertion 成功 ok 是 true 否则是 false，另一个变量在 assertion 失败时是 asserted type 的 zero value。\n\nOK 表达式经常用在 if 语句中：\n```go\nif f, ok := w.(*os.File); ok {\n// ...use f...\n}\n```\n\n## Type Switches\n\nInterface 一般被用在这两种场合，一种是像 io.Reader, io.Writer 那样，一个 interface 的 method 真正含义是表达了实现这个 interface 的不同 concrete type 的相似性，意味着这里充分发挥的是 interface method 的表现力。重点在 method，而不是 concrete type。\n\n一种是利用 interface 可以存储不同 concrete type 的能力，在必要的时候根据不同的 concrete type 做不同的处理，这样的用法就是利用 interface 的 assertion 来判断 dynamic type 的类型来做出具体的判断。重点在 concrete type，而不是 method。\n\n**Type switch 就是利用 interface 存储不同 concrete type 的能力来实现的 assertion**。\n```go\nswitch x.(type) {\n    case nil:\ncase int, uint:\ncase bool:\ncase string:\ndefault:\n}\n\n```\n这种类型的语句叫 type switch，其中 x 是 interface expression，asserted type 是 type 字面量，每个 case 语句可以有一种或多种 types，nil case 匹配的是 x == nil 的情况，default case 匹配的是没有类型匹配的情况。\n\n有时候在 type switch 中我们需要使用 dynamic value，这就需要 type assertion 可以提取 interface 的 dynamic value，同样有这样的语法可以支持这一操作 `switch x := x.(type){}`\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n    var x1 interface{}\n    var x2 int\n    var x3 string\n    var x4 bool\n\n    fmt.Println(sqlQuote(x1))\n    fmt.Println(sqlQuote(x2))\n    fmt.Println(sqlQuote(x3))\n    fmt.Println(sqlQuote(x4))\n}\n\nfunc sqlQuote(x interface{}) string {\n    switch x := x.(type) {\n    case nil:\n        return \"null\"\n    case int, uint:\n        return fmt.Sprintf(\"%d\", x)\n    case bool:\n        if x {\n            return \"true\"\n        }\n\n        return \"false\"\n    case string:\n        return \"string\"\n    default:\n        panic(\"no match case\")\n    }\n}\n\n```\n在上面的例子中被提取的 value 赋值给 x，这在 switch block 中会遮蔽断言表达式 x，但是不会影响 x 在 function 中的使用，因为 switch 和 for 一样也是 block scope。","src/content/posts/go-interface-4.mdx","01f764beffe29ede","go-interface-4.mdx","go-make-and-new",{"id":552,"data":554,"body":561,"filePath":562,"digest":563,"legacyId":564,"deferredRender":22},{"title":555,"summary":556,"date":557,"tags":558,"group":50,"featured":38},"理解 Go make 和 new 的区别","> new 和 make 都可以用来分配空间，初始化类型，但是它们确有不同。",["Date","2017-07-26T00:00:00.000Z"],[559,560],"make","new","> new 和 make 都可以用来分配空间，初始化类型，但是它们确有不同。\n\n## new(T) 返回的是 T 的指针\n\nnew(T) 为一个 T 类型新值分配空间并将此空间初始化为 T 的零值，返回的是新值的地址，也就是 T 类型的指针 *T，该指针指向 T 的新分配的零值。\n\n```go\np1 := new(int)\nfmt.Printf(\"p1 --> %#v \\n \", p1) //(*int)(0xc42000e250) \nfmt.Printf(\"p1 point to --> %#v \\n \", *p1) //0\n\nvar p2 *int\ni := 0\np2 = &i\nfmt.Printf(\"p2 --> %#v \\n \", p2) //(*int)(0xc42000e278) \nfmt.Printf(\"p2 point to --> %#v \\n \", *p2) //0 \n\n```\n\n上面的代码是等价的，new(int) 将分配的空间初始化为 int 的零值，也就是 0，并返回 int 的指针，这和直接声明指针并初始化的效果是相同的。\n\n## make 只能用于 slice,map,channel\n\nmake 只能用于 slice，map，channel 三种类型，make(T, args) 返回的是初始化之后的 T 类型的值，这个新值并不是 T 类型的零值，也不是指针 *T，是经过初始化之后的 T 的引用。\n\n```go\nvar s1 []int\nif s1 == nil {\n    fmt.Printf(\"s1 is nil --> %#v \\n \", s1) // []int(nil)\n}\n\ns2 := make([]int, 3)\nif s2 == nil {\n    fmt.Printf(\"s2 is nil --> %#v \\n \", s2)\n} else {\n    fmt.Printf(\"s2 is not nill --> %#v \\n \", s2)// []int{0, 0, 0}\n}\n\n```\nslice 的零值是 nil，使用 make 之后 slice 是一个初始化的 slice，即 slice 的长度、容量、底层指向的 array 都被 make 完成初始化，此时 slice 内容被类型 int 的零值填充，形式是 [0 0 0]，map 和 channel 也是类似的。\n\n```go\nvar m1 map[int]string\nif m1 == nil {\n    fmt.Printf(\"m1 is nil --> %#v \\n \", m1) //map[int]string(nil)\n}\n\nm2 := make(map[int]string)\nif m2 == nil {\n    fmt.Printf(\"m2 is nil --> %#v \\n \", m2)\n} else {\n    fmt.Printf(\"m2 is not nill --> %#v \\n \", m2) map[int]string{} \n}\n\n\nvar c1 chan string\nif c1 == nil {\n    fmt.Printf(\"c1 is nil --> %#v \\n \", c1) //(chan string)(nil)\n}\n\nc2 := make(chan string)\nif c2 == nil {\n    fmt.Printf(\"c2 is nil --> %#v \\n \", c2)\n} else {\n    fmt.Printf(\"c2 is not nill --> %#v \\n \", c2)//(chan string)(0xc420016120)\n}\n```\n\n## make(T, args) 返回的是 T 的 引用\n\n如果不特殊声明，go 的函数默认都是按值穿参，即通过函数传递的参数是值的副本，在函数内部对值修改不影响值的本身，但是 make(T, args) 返回的值通过函数传递参数之后可以直接修改，即 map，slice，channel 通过函数穿参之后在函数内部修改将影响函数外部的值。\n\n```go\nfunc modifySlice(s []int) {\n    s[0] = 1\n}\n\ns2 := make([]int, 3)\nfmt.Printf(\"%#v\", s2) //[]int{0, 0, 0}\nmodifySlice(s2)\nfmt.Printf(\"%#v\", s2) //[]int{1, 0, 0}\n\n```\n\n这说明 make(T, args) 返回的是引用类型，在函数内部可以直接更改原始值，对 map 和 channel 也是如此。\n\n```go\nfunc modifyMap(m map[int]string) {\n    m[0] = \"string\"\n}\n\nfunc modifyChan(c chan string) {\n    c \u003C- \"string\"\n}\n\nm2 := make(map[int]string)\nif m2 == nil {\n    fmt.Printf(\"m2 is nil --> %#v \\n \", m2) \n} else {\n    fmt.Printf(\"m2 is not nill --> %#v \\n \", m2) //map[int]string{}\n}\n\nmodifyMap(m2)\nfmt.Printf(\"m2 is not nill --> %#v \\n \", m2) // map[int]string{0:\"string\"}\n\n\nc2 := make(chan string)\nif c2 == nil {\n    fmt.Printf(\"c2 is nil --> %#v \\n \", c2)\n} else {\n    fmt.Printf(\"c2 is not nill --> %#v \\n \", c2)\n}\n\ngo modifyChan(c2)\nfmt.Printf(\"c2 is not nill --> %#v \", \u003C-c2) //\"string\"\n\n```\n\n## 很少需要使用 new\n\n以下代码演示了 **struct 初始化的过程**，可以说明不使用 new 一样可以完成 struct 的初始化工作。\n```go\n\ntype Foo struct {\n    name string\n    age  int\n}\n\n//声明初始化\nvar foo1 Foo\nfmt.Printf(\"foo1 --> %#v\\n \", foo1) //main.Foo{age:0, name:\"\"}\nfoo1.age = 1\nfmt.Println(foo1.age)\n\n//struct literal 初始化\nfoo2 := Foo{}\nfmt.Printf(\"foo2 --> %#v\\n \", foo2) //main.Foo{age:0, name:\"\"}\nfoo2.age = 2\nfmt.Println(foo2.age)\n\n//指针初始化\nfoo3 := &Foo{}\nfmt.Printf(\"foo3 --> %#v\\n \", foo3) //&main.Foo{age:0, name:\"\"}\nfoo3.age = 3\nfmt.Println(foo3.age)\n\n//new 初始化\nfoo4 := new(Foo)\nfmt.Printf(\"foo4 --> %#v\\n \", foo4) //&main.Foo{age:0, name:\"\"}\nfoo4.age = 4\nfmt.Println(foo4.age)\n\n//声明指针并用 new 初始化\nvar foo5 *Foo = new(Foo)\nfmt.Printf(\"foo5 --> %#v\\n \", foo5) //&main.Foo{age:0, name:\"\"}\nfoo5.age = 5\nfmt.Println(foo5.age)\n\n```\n\nfoo1 和 foo2 是同样的类型，都是 Foo 类型的值，foo1 是通过 var 声明，Foo 的 filed 自动初始化为每个类型的零值，foo2 是通过字面量的完成初始化。foo3，foo4 和 foo5 是一样的类型，都是 Foo 的指针 *Foo。**但是所有 foo 都可以直接使用 Foo 的 filed，读取或修改，为什么？**\n\n如果 x 是可寻址的，&x 的 filed 集合包含 m，x.m 和 (&x).m 是等同的，go 自动做转换，也就是 foo1.age 和 foo3.age 调用是等价的，go 在下面自动做了转换。\n\n因而可以直接使用 struct literal 的方式创建对象，能达到和 new 创建是一样的情况而不需要使用 new。\n\n## 小结\n\nnew(T) 返回 T 的指针 *T 并指向 T 的零值。\nmake(T) 返回的初始化的 T，只能用于 slice，map，channel。","src/content/posts/go-make-and-new.mdx","260b631f3f8c7f89","go-make-and-new.mdx","go-new-programmer-best-practice",{"id":565,"data":567,"body":573,"filePath":574,"digest":575,"legacyId":576,"deferredRender":22},{"title":568,"summary":569,"date":570,"tags":571,"group":50,"featured":38},"新手 Go 程序员的最佳实践","> 无意中在 medium 看到了一篇文章《Best practices for a new Go developer》，读完之后略有启发，摘录文章观点至此共飨，感兴趣读者可以直接阅读原文，原文很长也很散乱。",["Date","2017-07-30T00:00:00.000Z"],[572],"","> 无意中在 medium 看到了一篇文章《Best practices for a new Go developer》，读完之后略有启发，摘录文章观点至此共飨，感兴趣读者可以直接阅读原文，原文很长也很散乱。\n\n# 1\n\n工欲善其事必先利其器，真正写用 Go 编写代码之前先准备好你的环境，可以考虑从官方文档 [How to Write Go Code](https://golang.org/doc/code.html)。\n\nGo 提供了非常优秀的工具来保证代码的风格和质量，比如：gofmt，godoc，goimports，学会使用它们。\n\n对于新手来说不要着急一开始就想要完整的 Go 程序，你应该认真熟悉 Go 的基本语义和特性，认真读完 官方的 [Effictive Go](https://golang.org/doc/effective_go.html)\n\n# 2\n\n不要害怕犯错，对于一门新的语言，大家都是平等，即使是用 Go 写过一到两年程序的人也会犯一些低级的错误。\n\n要学会顺势而为，学会用 Go 的方式去写 Go 的程序，比如要遵循 Go conventions，不要像 C 一样在 Go 中总是使用指针。\n\n新手都应该看看这篇文章 http://talks.golang.org/2012/splash.article，它有助于你了解 Go 是如何诞生的，它的哲学理念是什么。\n\n\n# 3\n\n新手不要一开始就过渡关注 goroutine，channel 这些涉及并发的概念，你有可能滥用 channel 而不知道节制，毕竟 Go 在很多方面都表现的非常节制。\n\n理解 interface，了解它的潜力，学会用组合和 interface 创建健壮的 Go 代码， 它是 Go 最富有天赋的能力之一。\n\n如果你之前使用的其它 object-oriented 语言，暂时忘掉那些关于 OO 的特性和思维，虽然 Go 支持 OO，但 Go 不是基于类的语言，不支持类的继承。\n\n# 4 \n\nGo 是强类型语言，意味着实现非常复杂的系统 API 时有可能会像 Java 或 C++ 一样使用大量的预定义类型，使代码变得脆弱丑陋，这并不是真正的 Go。Go 的 interface 和闭包特性允许我们写出更优雅更通用的实现。\n\n学会高效的使用闭包，为此可以学习一些函数式编程语言的理论，或者学学 Ruby，可以看看 The Well-Grounded Rubyist 这本书，然后尝试在 Go 编程中尝试使用这些知识。\n\n学会测试 Go 程序，学会使用 Go 相关的测试工具 unit testing，beachmarking testing，利用测试不断纠正和提高 Go 程序的质量，可以看看这个 http://github.com/feyeleanor/GoSpeed。\n\n# 5\n\n不要强迫你把过去其它语言的经验带入 Go，每个语言都是不同的，如果你是第一次接触 Go，让自己用一个全新的视角去看待它，也就是你需要尝试从语言的创作者以及社区的角度去理解它。\n\n\n一开始使用 Go，尽量避免使用 third party library，可能它们能简化你正在做的事情，但从长远角度来看，它们也妨碍了你对这么语言的理解。\n\n从标准库中学习如何写出更好的 Go 代码，比如你可以从 `net/http` package 中学习如何使用 concurrency，也可以去看看  Rob Pike 关于 concurrency 的视频。\n\n# 6\n\n尝试使用 composition 而不是 inheritance，基于 OO 的 inheritance 的思维方式会妨碍你写出优雅的 Go 代码。\n\n拥抱 interface。\n\n并不是所有的都是 object。\n\n\n> A language that doesn’t affect the way you think about programming, is not worth knowing. — Alan Perlis\n\n如果一门语言没有影响你对编程的思考，这么语言就不值得学习。\n\n# 7\n\n- 保持函数短小，变量名不要太长\n- 不要像写其它语言一样写 Go，Go 不是 Java，不是 Python，不是 Ruby。\n- 花点时间搞懂 named and unnamed types。\n- 学会构建完整的 Go project，并且发布它们。\n- Interface 很重要，你应该学会使用它们，很多你遇到的问题都可以用 interface 解决。\n- 学习阅读源码是学习 Go 的一种极佳的方式。\n- 保持简洁，简洁是 Go 的一个重要特性之一，避免过度工程化。\n- 以更小的单元实现你的代码功能，然后组合它们。\n\n\n# 小结\n\n\n这时间上有很多朴素的道理，很多人都知道，但是这些道理并没有给知道的人带来什么改变，比如勤奋不一定能成功，还是很多人很勤奋，有了好运气也不一定能成功，还是很多人天天盼望走狗屎运，前者太勤奋了，没有时间思考，后者不知道勤奋，总是抱有幻想。\n\n学习语言也是一样，不要着急实践，要先想一想，看一看，看完之后不能太懒，还要动手练一练。","src/content/posts/go-new-programmer-best-practice.mdx","afbff0523d81c719","go-new-programmer-best-practice.mdx","go-json",{"id":577,"data":579,"body":585,"filePath":586,"digest":587,"legacyId":588,"deferredRender":22},{"title":580,"summary":581,"date":582,"tags":583,"group":50,"featured":38},"理解 Go 中的 JSON","> 本文是基于 Go 官方和 https://eager.io/blog/go-and-json/ 进行翻译整理的",["Date","2018-05-07T00:00:00.000Z"],[584],"json","> 本文是基于 Go 官方和 https://eager.io/blog/go-and-json/ 进行翻译整理的\n\nJSON 是一种轻量级的数据交换格式，常用作前后端数据交换，Go 在 [encoding/json](https://golang.org/pkg/encoding/json/ ) 包中提供了对 JSON 的支持。\n\n## 序列化\n\n把 Go struct 序列化成 JSON 对象，Go 提供了 [Marshal](https://golang.org/pkg/encoding/json/#Marshal) 方法，正如其含义所示表示编排序列化，函数签名如下：\n\n```go\nfunc Marshal(v interface{}) ([]byte, error)\n```\n\n举例来说，比如下面的 Go struct：\n\n```go\ntype Message struct {\n    Name string\n    Body string\n    Time int64\n}\n```\n\n使用 Marshal 序列化：\n\n```go\nm := Message{\"Alice\", \"Hello\", 1294706395881547000}\nb, err := json.Marshal(m) \nfmt.Println(b) //{\"Name\":\"Alice\",\"Body\":\"Hello\",\"Time\":1294706395881547000}\n```\n\n在 Go 中并不是所有的类型都能进行序列化：\n\n- JSON object key 只支持 string\n- Channel、complex、function 等 type 无法进行序列化\n- 数据中如果存在循环引用，则不能进行序列化，因为序列化时会进行递归\n- Pointer 序列化之后是其指向的值或者是 nil\n\n**还需要注意的是**：只有 struct 中支持导出的 field 才能被 JSON package 序列化，即**首字母大写的 field**。\n\n## 反序列化\n\n反序列化函数是 [Unmarshal](https://golang.org/pkg/encoding/json/#Unmarshal) ，其函数签名如下：\n\n```go\nfunc Unmarshal(data []byte, v interface{}) error\n```\n\n如果要进行反序列化，我们首先需要创建一个可以接受序列化数据的 Go struct：\n\n```go\nvar m Message\nerr := json.Unmarshal(b, &m)\n```\n\nJSON 对象一般都是小写表示，Marshal 之后 JSON 对象的首字母依然是大写，如果序列化之后名称想要改变如何实现，答案就是 **struct tags**。\n\n## Struct Tag\n\nStruct tag 可以决定 Marshal 和 Unmarshal 函数如何序列化和反序列化数据。\n\n### 指定 JSON filed name\n\nJSON object 中的 name 一般都是小写，我们可以通过 struct tag 来实现：\n\n```go\ntype MyStruct struct {\n    SomeField string `json:\"some_field\"`\n}\n```\n\nSomeField 序列化之后会变成 some_field。\n\n### 指定 field 是 empty 时的行为\n\n使用 `omitempty` 可以告诉 Marshal 函数如果 field 的值是对应类型的 zero-value，那么序列化之后的 JSON object 中不包含此 field：\n\n```go\ntype MyStruct struct {\n    SomeField string `json:\"some_field,omitempty\"`\n}\n\nm := MyStruct{}\nb, err := json.Marshal(m) //{}\n```\n\n如果 `SomeField == “”` ，序列化之后的对象就是 `{}`。\n\n### 跳过 field\n\nStruct tag “-” 表示跳过指定的 filed：\n\n```go\ntype MyStruct struct {\n    SomeField string `json:\"some_field\"`\n    Passwd string `json:\"-\"`\n}\nm := MyStruct{}\nb, err := json.Marshal(m) //{\"some_feild\":\"\"}\n```\n\n即序列化的时候不输出，这样可以有效保护需要保护的字段不被序列化。\n\n## 反序列化任意 JSON 数据\n\n默认的 JSON 只支持以下几种 Go 类型：\n\n- `bool` for JSON booleans\n\n- `float64` for JSON numbers\n\n- `string` for JSON strings\n\n- `nil` for JSON null\n\n在序列化之前如果不知道 JSON 数据格式，我们使用 `interface{}` 来存储。`interface {}` 的作用详见本博的其他文章。\n\n有如下的数据格式：\n\n```go\nb := []byte(`{\"Name\":\"Wednesday\",\"Age\":6,\"Parents\":[\"Gomez\",\"Morticia\"]}`)\n```\n\n如果我们序列化之前不知道其数据格式，我们可以使用 `interface{}` 来存储我们的 decode 之后的数据：\n\n```go\nvar f interface{}\nerr := json.Unmarshal(b, &f)\n```\n\n反序列化之后 f 应该是像下面这样：\n\n```go\nf = map[string]interface{}{\n    \"Name\": \"Wednesday\",\n    \"Age\":  6,\n    \"Parents\": []interface{}{\n        \"Gomez\",\n        \"Morticia\",\n    },\n}\n```\n\nkey 是 string，value 是存储在 interface{} 内的。想要获得 f 中的数据，我们首先需要进行 type assertion，然后通过 range 迭代获得 f 中所有的 key ：\n\n```go\nm := f.(map[string]interface{})\nfor k, v := range m {\n    switch vv := v.(type) {\n    case string:\n        fmt.Println(k, \"is string\", vv)\n    case float64:\n        fmt.Println(k, \"is float64\", vv)\n    case []interface{}:\n        fmt.Println(k, \"is an array:\")\n        for i, u := range vv {\n            fmt.Println(i, u)\n        }\n    default:\n        fmt.Println(k, \"is of a type I don't know how to handle\")\n    }\n}\n```\n\n## 反序列化对 slice、map、pointer 的处理\n\n我们定义一个 struct 继续对上面例子中的 `b` 进行反序列化：\n\n```go\ntype FamilyMember struct {\n    Name    string\n    Age     int\n    Parents []string\n}\n\nvar m FamilyMember\nerr := json.Unmarshal(b, &m)\n```\n\n这个例子是能够正常工作的，你一定也注意到了，struct 中包含一个 slice `Parents` ，slice 默认是 nil，之所以反序列化可以正常进行就是因为 Unmarshal 在序列化时进行了对 slice `Parents` 做了初始化，同理，对 map 和 pointer 都会做类似的工作，比如序列化如果 Pointer 不是 nil 首先进行 dereference 获得其指向的值，然后再进行序列化，反序列化时首先对 nil pointer 进行初始化\n\n## Stream JSON\n\n除了 marshal 和 unmarshal 函数，Go 还提供了 Decoder 和 Encoder 对 stream JSON 进行处理，常见 request 中的 Body、文件等：\n\n```go\n\njsonFile, err := os.Open(\"post.json\")\nif err != nil {\n    fmt.Println(\"Error opening json file:\", err)\n    return\n}\n\ndefer jsonFile.Close()\ndecoder := json.NewDecoder(jsonFile)\nfor {\n    var post Post\n    err := decoder.Decode(&post)\n    if err == io.EOF {\n        break\n    }\n\n    if err != nil {\n        fmt.Println(\"error decoding json:\", err)\n        return\n    }\n\n    fmt.Println(post)\n}\n```\n\n## 嵌入式 struct 的序列化\n\nGo 支持对 nested struct 进行序列化和反序列化:\n\n```go\n\ntype App struct {\n\tId string `json:\"id\"`\n}\n\ntype Org struct {\n\tName string `json:\"name\"`\n}\n\ntype AppWithOrg struct {\n\tApp\n\tOrg\n}\n\nfunc main() {\n\tdata := []byte(`\n        {\n            \"id\": \"k34rAT4\",\n            \"name\": \"My Awesome Org\"\n        }\n    `)\n\n\tvar b AppWithOrg\n\n\tjson.Unmarshal(data, &b)\n\tfmt.Printf(\"%#v\", b)\n\n\ta := AppWithOrg{\n\t\tApp: App{\n\t\t\tId: \"k34rAT4\",\n\t\t},\n\t\tOrg: Org{\n\t\t\tName: \"My Awesome Org\",\n\t\t},\n\t}\n\tdata, _ = json.Marshal(a)\n\tfmt.Println(string(data))\n}\n```\n\nNested struct 虽然看起来有点怪异，有些时候它将非常有用。\n\n## 自定义序列化函数\n\nGo JSON package 中定了两个 Interface [Marshaler](http://golang.org/pkg/encoding/json/#Marshaler) 和 [Unmarshaler](http://golang.org/pkg/encoding/json/#Unmarshaler) ，实现这两个 Interface 可以让你定义的 type 支持序列化操作。\n\n## 错误处理\n\n总是记得检查序列或反序列化的错误，可以让你的程序更健壮，而不是在出错之后带着错误继续执行下去。\n\n## 参考资料\n\n- https://blog.golang.org/json-and-go\n- https://eager.io/blog/go-and-json/","src/content/posts/go-json.mdx","b5bab55c9cc77931","go-json.mdx","go-nil",{"id":589,"data":591,"body":597,"filePath":598,"digest":599,"legacyId":600,"deferredRender":22},{"title":592,"summary":593,"date":594,"tags":595,"group":50,"featured":38},"理解 Go nil","golang 中的 nil 是不同于其他语言的，为了更好的理解 nil，在此我将尝试一步一步揭示 nil 在 golang 中的一些操作和现象。",["Date","2017-06-11T00:00:00.000Z"],[596],"nil","golang 中的 nil 是不同于其他语言的，为了更好的理解 nil，在此我将尝试一步一步揭示 nil 在 golang 中的一些操作和现象。\n\n## 1. nil 是不能比较的\n\n**code-1** [Play](https://play.golang.org/p/FM7oW794sU) \n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n    fmt.Println(nil==nil)\n}\n```\ncode-1 输出\n\n```\ntmp/sandbox318449491/main.go:8: invalid operation: nil == nil (operator == not defined on nil)\n```\n\n这点和 python 等动态语言是不同的，在 python 中，两个 None 值永远相等。\n\n```python\n>>> None == None\nTrue\n>>> \n```\n\n从 go 的输出结果不难看出，`==` 对于 nil 来说是一种未定义的操作。\n\n## 2. 默认 nil 是 typed 的\n\n**code-2** [Play](https://play.golang.org/p/PVGa9tCWSs)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tfmt.Printf(\"%T\", nil) \n\tprint(nil)\n}\n\n```\n\ncode-2 输出\n\n```\ntmp/sandbox379579345/main.go:9: use of untyped nil\n```\n\nprint 的输出时未指定类型的，因而无法输出\n\n## 3. 不同类型 nil 的 address 是一样的\n\n**code-3** [Play](https://play.golang.org/p/YQkFQx1hPi)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tvar m map[int]string\n\tvar ptr *int\n\tfmt.Printf(\"%p\", m)\n\tfmt.Printf(\"%p\", ptr)\n}\n\n```\n\nm 和 ptr 的 address 都是 0x0\n\n## 4. 不同类型的 nil 是不能比较的\n\n   **code-4** [Play](https://play.golang.org/p/20q0oe2Iu5)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tvar m map[int]string\n\tvar ptr *int\n\tfmt.Printf(m == ptr)\n}\n\n```\n\ncode-4 输出\n\n```\ntmp/sandbox618627491/main.go:10: invalid operation: m == ptr (mismatched types map[int]string and *int)\n\n```\n\n## 5. nil 是 map，slice，pointer，channel，func，interface 的零值\n\n**code-5** [Play](https://play.golang.org/p/VeDuWMU4QR)\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\nfunc main() {\n\tvar m map[int]string\n\tvar ptr *int\n\tvar c chan int\n\tvar sl []int\n\tvar f func()\n\tvar i interface{}\n\tfmt.Printf(\"%#v\\n\", m)\n\tfmt.Printf(\"%#v\\n\", ptr)\n\tfmt.Printf(\"%#v\\n\", c)\n\tfmt.Printf(\"%#v\\n\", sl)\n\tfmt.Printf(\"%#v\\n\", f)\n\tfmt.Printf(\"%#v\\n\", i)\n}\n```\n\ncode-5 输出\n\n```\nmap[int]string(nil)\n(*int)(nil)\n(chan int)(nil)\n[]int(nil)\n(func())(nil)\n\u003Cnil>\n```\n\n[zero value](https://golang.org/ref/spec#The_zero_value) 是 go 中变量在声明之后但是未初始化被赋予的该类型的一个默认值。\n\n> 正确理解 nil 是正确理解 go 中类型的重要一环，因而 nil 的任何细节在遇到之后都不要错过，要做到相应的记录。","src/content/posts/go-nil.mdx","23db5577eadff7c7","go-nil.mdx","go-no-reference-type",{"id":601,"data":603,"body":609,"filePath":610,"digest":611,"legacyId":612,"deferredRender":22},{"title":604,"summary":605,"date":606,"tags":607,"group":50,"featured":38},"严格来说 Go 没有引用类型","## 什么是引用类型",["Date","2017-08-10T00:00:00.000Z"],[608],"引用类型","## 什么是引用类型\n\n简单类说就是不同的变量内存地址是一样的，也就是说同一个内存地址有不同的别名。\n\n**code-1**\n```python\n>>> dd = dict()\n>>> c = dd\n>>> id(c)\n4476836672\n>>> id(dd)\n4476836672\n>>> \n```\n`code-1` 中的 Python 代码显示 c 和 dd 两个变量的内存地址都是一样的。\n\n## Immutable type 不是引用类型\n\nInt，string，bool 这些 immutable 类型不会有引用类型\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n    var a, b, c = 0, 0, 0\n    fmt.Println(&a) //0xc420072188\n    fmt.Println(&b) //0xc4200721b0\n    fmt.Println(&c) //0xc4200721b8\n    d := a\n    fmt.Println(&d) //0xc4200721d0\n\n    var s = \"a\"\n    fmt.Println(&s) //0x1040c108\n    s += \"b\"\n    fmt.Println(&s) //0x1040c108\n}\n\n```\n\n\n变量 a 赋值给 d ，d 和 a 的地址不同，字符串 s 二次赋值之后地址没有改变，在 immutable type 中不存在两个变量内存地址是一样的。\n\n## Map 可以在函数内部改变，但是 map 不是引用类型\n\nGo 中函数传参是按值传递，在函数内部无法改变函数外部的值，但是 map 可以，是不是 map 是引用类型。\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n\n    var m map[int]string = map[int]string{\n        0: \"0\",\n        1: \"1\",\n    }\n    mm := m\n    fmt.Printf(\"%p\\n\", &m) //0xc42002a028\n    fmt.Printf(\"%p\\n\", &mm) //0xc42002a030\n    fmt.Println(m) // map[0:0 1:1]\n    fmt.Println(mm) //map[1:1 0:0]\n    changeMap(m)\n    fmt.Printf(\"%p\\n\", &m) //0xc42002a028\n    fmt.Printf(\"%p\\n\", &mm)//0xc42002a030\n    fmt.Println(m) //map[2:2 0:0 1:1]\n    fmt.Println(mm) //map[0:0 1:1 2:2]\n}\n\nfunc changeMap(mmm map[int]string) {\n    mmm[2] = \"2\"\n    fmt.Printf(\"changeMap func %p\\n\", mmm) //changeMap func 0xc420014150\n}\n\n```\n可以明确看到 main 中的 mm 和 m 地址完全不同，调用函数 changeMap 之后，它们的值都发生了改变，在函数 changeMap 内部，参数 mmm 的地址和 m 以及 mm 都不同，证实 map 并不是引用传参。\n\n再一个例子。\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n    var m map[int]string\n    makeMap(m)\n    fmt.Println(m == nil) //true\n}\n\n\nfunc makeMap(m map[int]string) {\n    m = make(map[int]string)\n}\n\n```\n如果是引用传参 main 函数中的输出不应该是 true。\n\n## Channel 也是按值传参\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n    c1 := make(chan int)\n    fmt.Printf(\"%p\\n\", &c1) //0xc42002a038\n    go func() {\n        changeChan(c1)\n    }()\n\n    fmt.Println(\u003C-c1)\n}\n\nfunc changeChan(c chan int) {\n    fmt.Printf(\"changeChan %p\\n\", &c) //0xc42002a040\n    c \u003C- 0\n}\n\n```\n例子中的 channel 在函数内发生了值传递，但是函数内部和外部的 channel 地址不同。\n\n\n## Map 不是引用类型，为什么可以在函数内部改变\n\nGo 源代码中显示 https://golang.org/src/runtime/hashmap.go map 底层是一个指向 hmap 的指针，这就可以解释即使函数传参是按值传递，由于传递的是指针的拷贝，指针指向的底层 hmap 并没有改变，所以可以在函数内部改变 map 。\n\n\n> Go 中没有引用类型","src/content/posts/go-no-reference-type.mdx","ee2bb7dcc789cd00","go-no-reference-type.mdx","go-o-o",{"id":613,"data":615,"body":621,"filePath":622,"digest":623,"legacyId":624,"deferredRender":22},{"title":616,"summary":617,"date":618,"tags":619,"group":50,"featured":38},"Go 中的面向对象","Go 不是基于 class 的语言，但是 Go 提供了强大的类型系统来实现 OO（Object Oriented），关于如何正确使用 OO 的争论网上已经非常多了，在此我们秉承 Go 提供的面向对象机制来实现不同的例子和使用模式，借此了解 Go 中的 OO。",["Date","2017-08-17T00:00:00.000Z"],[620],"面向对象","Go 不是基于 class 的语言，但是 Go 提供了强大的类型系统来实现 OO（Object Oriented），关于如何正确使用 OO 的争论网上已经非常多了，在此我们秉承 Go 提供的面向对象机制来实现不同的例子和使用模式，借此了解 Go 中的 OO。\n\n\n## 使用 embed type 实现继承\n\nGo 中的嵌入类型 `embed type` 本质上是一种 composition，Go 不像其它 OO 语言那样提供基于类的继承，那些继承体现的是 `is-a` 关系，但是 Go 不是。\n\nGo 通过 embed type，可以实现 method 和 field 的复用。\n\n```go\n\npackage main\n\nimport (\n    \"fmt\"\n)\n\ntype Person struct {\n    name string\n    age  int\n}\n\nfunc (p *Person) sayName() {\n    fmt.Println(p.name)\n}\n\ntype Student struct {\n    Person\n    name string\n}\n\nfunc main() {\n    p := Person{name: \"C\"}\n    p.sayName() // #1 C\n\n    s1 := Student{name: \"Java\"}\n    s1.sayName() // #2 此行输出空字符串\n\n    s2 := Student{name: \"Java\", Person: Person{name: \"VB\"}}\n    s2.sayName()         // #3 VB\n    fmt.Println(s2.name) // #4 Java\n    fmt.Println(s2.Person.name) //#5 VB\n}\n```\n\n`Person` 是 `Student` 的 embed type，因而 Student 可以直接使用 Person 的 field 和 method，需要注意的是：\n\n1.Student 中的同名属性可以遮蔽 embed type 的属性，`#4` 的输出\n2.Student 虽然可以直接调用 embed type 的 method，但是 method 的 receiver 仍然是 embed type，所以 `#2` 输出为空。\n3.直接通过 embed type 继承，embed type 无法获取被嵌入类型的属性，原因由 2 导致。\n\n\n## 类型组合的强大魔力\n\nGo 支持任意类型的 embed type，当然也包括 interface type，通过组合就可以实现多种不同行为的任意组合，这也是 Go 倡导**以更小的单元实现你的代码功能，然后组合它们**的理念。\n\n\n```go\n\n// student 行为\ntype StudentTalk interface {\n    talk()\n}\n\n// teacher 行为\ntype TeacherTalk interface {\n    say()\n}\n\n```\n首先定义两个 interface 用来表示不同的行为。\n\n\n```go\n\n// people 行为\ntype PeopleTalk interface {\n    StudentTalk\n    TeacherTalk\n}\n```\n\n通过 embed type 把定义的两个 interface 组合为新的 interface `PeopleTalk`，此时 PeopleTalk 继承了两个 interface 的 method 集合，也就是 PeopleTalk 拥有了 StudentTalk 和 TeacherTalk 的 method 合集。\n\n```go\n\ntype Person struct {\n    TeacherTalk\n    StudentTalk\n}\n\n```\nPerson 也内嵌了 TeacherTalk 和 StudentTalk，对 Person 来说既可以理解成**继承了两个 interface 的 method 集合**，也可以理解是 Person 拥有**两个类型为 TeacherTalk 和 StudentTalk 的 field**，它们的分别可以被赋值为实现了它们的 struct 的值。\n\n\n```go\ntype Student struct{}\n\nfunc (s *Student) talk() {\n    fmt.Println(\"student talk\")\n}\n\ntype Teacher struct{}\n\nfunc (t *Teacher) say() {\n    fmt.Println(\"teacher say\")\n}\n```\nStruct Student 和 Teacher 分别实现了 StudentTalk 和 TeacherTalk。\n\n\n```go\nfunc meet(p PeopleTalk) {\n    fmt.Println(\"====>people meet\u003C====\")\n    meetTeacher(p)\n    meetStudent(p)\n}\n\nfunc meetTeacher(ps TeacherTalk) {\n    fmt.Println(\"====>teacher meet\u003C====\")\n    ps.say()\n}\n\nfunc meetStudent(ps StudentTalk) {\n    fmt.Println(\"====>student meet\u003C====\")\n    ps.talk()\n}\n\nfunc main() {\n    t := Teacher{}\n    s := Student{}\n    // Person 实现了 PeopleTalk 方法，通过 Teacher 和 Student 实例\n    p := Person{TeacherTalk: &t, StudentTalk: &s}\n    meet(p)\n}\n\n```\n上面这段 Go 代码展示了 interface 组合带来的魔力，meet function 的参数是 PeopleTalk，而 Person 的实例 p 由于通过实例 t 和 s 实现了 PeopleTalk 的 method，也就是说 p 可以直接通过 meet 函数传递，**meet 的参数 PeopleTalk**，而且实现了 PeopleTalk 必然实现了 StudentTalk 和 TeacherTalk，因为 PeopleTalk 是由它们组合而成的，进而可以在 meet 函数中可以直接调用 meetTeacher 和 meetStudent，它们各自的参数分别是 TeacherTalk 和 StudentTalk。","src/content/posts/go-o-o.mdx","9c6981328e8d194b","go-o-o.mdx","go-slice",{"id":625,"data":627,"body":633,"filePath":634,"digest":635,"legacyId":636,"deferredRender":22},{"title":628,"summary":629,"date":630,"tags":631,"group":50,"featured":38},"理解 Go 中的 Slice","## 什么是 slice",["Date","2018-07-31T00:00:00.000Z"],[632],"slice","## 什么是 slice\n\nSlice 是一种变长的序列，其所有的元素具有相同的数据类型，表达式为 `[]T` ，看上去很像没有 size 的数组。\n\nSlice 是一种和数组相关联的轻量的数据结构，其包含三部分：一个指向底层数组的指针，一个 length，一个 capacity。指针指向的是底层数组中 slice 的第一个元素，**length 是 slice 拥有元素的个数，capacity 是底层数组中 slice 的第一个元素到数组末尾的长度**。\n\n![](https://static.git-star.com/go-slices-usage-and-internals_slice-struct.png)\n\n**Slice 的结构会导致多个 slice 实际引用的是同一个数组**。Slice 的这种结构决定了如果一个函数的参数是 slice，那么可以在函数的内部对 slice 进行修改，所以 slice 同 map、chan 一样可以被调用者修改。\n\n注意，如果一个函数的参数是 slice，在函数内部要避免对 slice 进行修改操作。\n\n## slice 初始化\n\n声明一个 slice 形式如：\n\n``` go\nvar s []int\n```\n\n一个未被初始化的 slice 其值是 nil，此时 slice 的 length 和 capacity 都是 0。初始化 slice 有两种方式：\n\n**第一种是 literal**\n\n```go\nvar s = []int{0, 1, 2, 3}\n```\n\n这种形式的初始化还可以指定每个元素的 index:\n\n```\nvar s = []int{0:0, 1:1, 2:2}\n```\n\n也可以夸越多个元素指定 index：\n\n```go\nvar s = []int{0:0, 3:3}\nfmt.Println(len(s)) // 4\n```\n\n**第二种是 make**\n\n```go\ns := make([]int, 3, 6)\n```\n\n使用 make 初始化可以指定 slice 的 length 和 capacity。\n\n## slice 的切片操作\n\nSlice 支持使用切片操作，我们声明一个 months 的 array：\n\n```go\nmonths := [...]string{ 1: \"January\", 2: \"February\", 3: \"Marcy\", 4: \"April\", 5: \"May\", 6: \"June\", 7: \"July\", 8: \"August\", 9: \"September\", 10: \"October\", 11: \"November\", 12: \"December\"}\n```\n\n切片操作 s[i:j]，0\u003C=i\u003C=j\u003C=cap(s)，创建了一个新的 slice，其 length 是 j-i，容量是从 i 开始到底层数组末尾的所有元素，i 和 j 可以省略一个或都省略，因而 s[:]、s[:j]、s[i:] 都是合法的。省略 i 则表示从 0 开始，省略 j 则表示底层数组的末尾。\n\n![](https://static.git-star.com/WX20180801-082445@2x_meitu_1.jpg)\n\n\n\n```go\nQ2 := months[4:7]\nfmt.Println(Q2) //[April May June]\nfmt.Println(\"Q2 len\", len(Q2)) //Q2 len 3\nfmt.Println(\"Q2 cap\", cap(Q2)) //Q2 cap 9\n\nsummer := months[6:9]\nfmt.Println(summer) //[June July August]\nfmt.Println(\"summer len\", len(summer))//summer len 3\nfmt.Println(\"summer cap\", cap(summer))// summer cap 7\n```\n\n从上面的例子不难看出，capacity 是 slice 中的第一个元素到底层数组的末尾的长度，length 是 slice 的实际长度。\n\n## slice 切片操作边界范围\n\nslice 的切片是有明确边界范围的。\n\n**在 capacity 范围内扩充 slice**\n\n如果 slice 的 j 不超过 capacity，调整 j 的大小可以扩充 slice：\n\n```go\nafterSummer := summer[:4]\nfmt.Println(afterSummer) //[June July August September]\nfmt.Println(\"afterSummer len\", len(afterSummer)) //afterSummer len 4\nfmt.Println(\"afterSummer cap\", cap(afterSummer))//afterSummer cap 7\n```\n\n**超过 capacity 报 panic**\n\n如果 slice 的 j 超过 capacity 会报 panic:\n\n```go\nafterSummer = summer[:8] //panic: runtime error: slice bounds out of range\nfmt.Println(afterSummer)\n```\n\nsummer 的 capacity 是 7，则 j 最大到 7，超过 capacity 则出错。\n\n**超过 length 报 panic**\n\n如果 slice 的 i 超过 length 会报 panic:\n\n```go\nafterSummer = summer[4:] //panic: runtime error: slice bounds out of range\n```\n\nsummer 的 length 是 3，则 i 最大到 3，超过 length 则出错\n\n## slice 的比较操作\n\n两个 slice 是不能相互比较的，slice 唯一能够比较的操作时 nil\n```go\nif s == nil {\n\n}\n```\n但是这个操作很少用到，判断一个没有任何元素的 slice 可以用 len(s) == 0，即使 s 是一个未初始化的 slice，值为 nil 也不影响。\n\n## append 操作\n\n内建的 append 函数把一个元素添加到 slice 的末尾，由于 slice 底层是一个数组，有可能发生数组的长度不够使用的情况，append 会在此时创建一个新的数组并且 double 数组的长度，把新元素添加之后返回新的 slice，下面的代码返回结果可以证明此观点:\n\n```go\nfunc main() {\n    var y []int\n    for i := 0; i \u003C 10; i++ {\n        y = append(y, i)\n        fmt.Printf(\"%d cap=%d\\t%v\\n\", i, cap(y), y)\n    }\n}\n\n//out\n0 cap=1 [0]\n1 cap=2 [0 1]\n2 cap=4 [0 1 2]\n3 cap=4 [0 1 2 3]\n4 cap=8 [0 1 2 3 4]\n5 cap=8 [0 1 2 3 4 5]\n6 cap=8 [0 1 2 3 4 5 6]\n7 cap=8 [0 1 2 3 4 5 6 7]\n8 cap=16        [0 1 2 3 4 5 6 7 8]\n9 cap=16        [0 1 2 3 4 5 6 7 8 9]\n```\n\n实际中 go slice 的增长策略会比这个要更复杂。\n\n由于 append 会自动创建新的 slice，所以如果 slice 是 nil 也支持使用 append 操作：\n\n```go\nvar x []int\nx = append(x, 10)\n```\n\n\n## 参考资料\n\n- The Go Programming Language\n- https://blog.golang.org/go-slices-usage-and-internals","src/content/posts/go-slice.mdx","4098d2fd334f98a0","go-slice.mdx","go-project-best-practice",{"id":637,"data":639,"body":645,"filePath":646,"digest":647,"legacyId":648,"deferredRender":22},{"title":640,"summary":641,"date":642,"tags":643,"group":50,"featured":38},"Go 项目最佳实践","最近 2 个月断断续续用 Go 实现了一个发布系统，主要特性包括：",["Date","2018-12-26T00:00:00.000Z"],[644],"最佳实践","最近 2 个月断断续续用 Go 实现了一个发布系统，主要特性包括：\n\n- 主机管理\n- 应用管理\n- 服务的部署和发布\n\n这是第一次使用 Go 实现复杂系统，记录一下最佳实践。\n\n## 库和框架使用\n\n### 更接近 Go 风格的简单 web framework\n\nweb 框架用的是 gorilla 的一套：\n\n- github.com/gorilla/context\n- github.com/gorilla/handlers\n- github.com/gorilla/mux\n- github.com/gorilla/websocket\n\n在用的过程中还发现了 mux 的一个问题，见[Middleware does not work because of subrouter order](https://github.com/gorilla/mux/issues/393)，这个问题根本原因就是遍历 route 时一旦发现有有不匹配的情况，后续 route 就不会在遍历了，这个问题也在打包前端 app 的时候出现过比较诡异语法错误的现象，原因就是配置的 `NotFoundHandler` 路由拦截了前端 js 文件的加载，因此配置 `NotFoundHandler` 要在 router 的最后进行。\n\n这个问题 mux 社区有相关的 pull request 已经解决了，截止发文之前一直都没有合并到主干。\n\n### 易用性胜于性能的日志组件\n\n日志考察了好几个，基本上都是格式化的日志，有的追求了性能，易用性差点，有的追求好用，性能又差点，考虑的发布系统的性能不是最需要考量的，最后采用了 [logrus](https://github.com/sirupsen/logrus) 。\n\n\n### 简单的 ORM 框架\n\nORM 工具用的是 [gorm](https://github.com/jinzhu/gorm)，在我的这个场景之下，完全够用，可维护性也很好，一点教训是复杂语句尽量使用纯 SQL。\n\n\n### TCP Client\n\n用了 [buffstreams](https://github.com/StabbyCutyou/buffstreams) 这个库做发布日志回传工具，是个一个简单的 TCP client 和 TCP Server ，采用 [protobuf](https://github.com/golang/protobuf) 数据传输协议\n\n\n### 缓存\n\n用了 [go-cache](https://github.com/patrickmn/go-cache) 这个工具缓存每个部署任务回传的消息，一定时间会自动清除，类似 redis 的 expire。\n\n\n### 支持异步的系统命令执行库\n\n使用 [cmd](https://github.com/go-cmd/cmd) 执行部署命令和采集部署日志，这个库封装了系统的 `exec.Command` 支持非阻塞的执行系统命令，支持异步获取命令的执行错误和输出\n\n\n### 统一打包，发挥 Go 部署简单的优势\n\n\n静态文件打包工具使用 [packr](https://github.com/gobuffalo/packr) 把前端用到的静态文件打包到 Go 的二进制程序中执行，这样发布 Go 程序只需要一个静态包即可，非常方便。\n\n\n\n### 其他第三方库\n\n- https://github.com/upyun/go-sdk\n- https://github.com/xanzy/go-gitlab\n- https://github.com/hashicorp/consul\n\n\n发布过程中需要和 gitlab 以及文件上传服务打交道，用了一个社区的 gitlab API 库，由于使用的 consul 做服务发现与注册用，也用了 consul 官方提供的 API，文件上传用的又拍云 SDK。\n\n### 消息协议\n\n用的是 [protobuf](https://github.com/golang/protobuf)\n\n\n## 项目结构最佳实践\n\n由于 Go 的 import 规则对目录结构是有严格要求的，这就需要提前安排好每个 package 的功能，为的是防止一旦发生目录变动，更改 import 语句代价不小。\n\n由于是 web 项目，整个项目结构和普通 web 项目结构很相似：\n\n```\n.\n├── Makefile\n├── README.md\n├── apps                后端 APP\n├── db                  数据库连接\n├── ember-app-espire    前端 APP\n├── helpers             和 model 层交互的 business layer\n├── logshow             日志回显组件\n├── main.go             入口文件\n├── models              ORM 中的 model\n├── pbmessage           protobuf\n├── resources           表单对应的 Go struct，称之为 form struct\n├── script\n├── services            接口响应对应的 playload，称之为 JSON struct\n├── static\n├── templates           html 目录\n├── tests\n├── utils               第三方工具\n└── worker              执行部署任务的 worker\n\n```\n\n有几个原则是整个项目结构划分一直坚持的：\n\n- 前端 APP 提交的 form 和 后端响应返回的 playload 必须显示定义\n- 后端 APP 层要严格按照路由进行划分\n- worker 单独成包，不能依赖除 utils、service、resource 包之外的其他任何业务层的包，方便移植和拆分\n- 工具包必须要有 test case\n\n\n### 后端 APP 结构\n\n```\n\napps\n├── app\n│   └── app.go\n├── cloud\n│   └── cloud.go\n├── computer\n│   └── computer.go\n├── consul\n│   └── consul.go\n├── domain\n│   └── domain.go\n├── gitlab\n│   └── gitlab.go\n├── home\n│   └── home.go\n├── router.go\n└── service\n    └── service.go\n\n```\n\n后端 APP 按照业务和路由规则进行分组，不同的业务分属不同的组，在根目录的 router 中统一组装然后注册到 server 中。\n\n这样做的好处是业务的可移植性强，如果愿意甚至都可以做热插拔。\n\n\n### 执行任务部署的 worker\n\n```\nworker\n├── cmd.go\n├── job.go\n├── log.go\n├── main.go\n└── run.go\n```\n\nworker 是单独部署的一个进程，主要是轮询部署任务，然后执行部署，实时报告部署状态和日志，分层结构是按照部署任务的步骤划分的。\n\n\n\n### 独立第三方 sdk 和工具库\n\n整个项目中都要用到日志、http client、第三方 sdk 等，这部分功能单独出来形成了项目的整个工具库\n\n```\nutils\n├── consul\n│   └── consul.go\n├── format\n│   └── format.go\n├── gitlab\n│   └── gitlab.go\n├── http\n│   └── http.go\n├── log\n│   └── log.go\n├── ucloud\n│   ├── ucloud.go\n│   └── ucloud_test.go\n├── upyun\n│   ├── upyun.go\n│   └── upyun_test.go\n└── util.go\n\n```\n\n第三方单独在封装就是怕第三方接口变动时需要改业务逻辑，封装之后即使第三方接口字段等发生变化，只要按照需要的格式进行一层转换即可。\n\n## 选好依赖管理\n\n项目一开始没有用任何依赖管理，后来随着依赖的不断变多，用了 dep 来做包管理，再后来发现 dep 升级包非常痛苦，这个时候 Go module 出了一段时间了，于是换上了 Go module。\n\nGo module 比 dep 好用，速度快，而且在规则上要比 dep 简单，感兴趣的可以看 https://colobu.com/2018/08/27/learn-go-module/ 的文章对 Go module 的介绍，Go module 兼容 dep ，初始化时会自动导入 dep 管理的所有依赖。\n\n如果你的项目可以升级到支持 Go module 的版本，或者换管理包的代价还能承受，最好换上 Go module 能省去很多不必要的麻烦。\n\n\n## 善用 Go 的异步特性\n\nGo 的异步支持是从语言层面就开始了，所以非常适合在同一个进程内开多个轮询任务，做工作流比使用其他语言要容易很多，因为工作流就是各种不能中断的 runner 一直执行的过程，而且各个 runner 之间需要进行消息同步。\n\nRunner 自然用协程实现，消息同步用 chan，在实现工作流之前，务必要先设计个好需要多少个流程，每个流程之间需要同步哪些消息，提前设计好，再用代码去实现。\n\n\n## 使用 make 自动化 build \n\nGo 作为静态语言需要频繁的构建和发布，可以使用第三方工具自动检测 Go 源文件的变化自动 make 或者自己自己写一个定时 build 。\n\n尽量使用环境变量来从入口 main 传入需要定制的参数，减少配置在仓库中暴露的风险，也符合 12 factor 对应用部署的要求。","src/content/posts/go-project-best-practice.mdx","9d28f6beabf44d95","go-project-best-practice.mdx","go-stand-lib-file",{"id":649,"data":651,"body":658,"filePath":659,"digest":660,"legacyId":661,"deferredRender":22},{"title":652,"summary":653,"date":654,"tags":655,"group":657,"featured":38},"Go 文件操作详解","Go 在 os 中提供了文件的基本操作，包括通常意义的打开、创建、读写等操作，除此以外为了追求便捷以及性能上，Go 还在 io/ioutil 以及 bufio 提供一些其他函数供开发者使用，今天在这篇文章中，我们介绍一些常用文件操作在 Go 中是如何使用的。",["Date","2019-03-08T00:00:00.000Z"],[50,656],"file","Go 标准库","Go 在 [os](https://golang.org/pkg/os/) 中提供了文件的基本操作，包括通常意义的打开、创建、读写等操作，除此以外为了追求便捷以及性能上，Go 还在 [io/ioutil](https://golang.org/pkg/io/ioutil/) 以及 [bufio](https://golang.org/pkg/bufio/) 提供一些其他函数供开发者使用，今天在这篇文章中，我们介绍一些常用文件操作在 Go 中是如何使用的。\n\n## File 文件类型\n\nGo 在 os 中定义了 [File](https://golang.org/pkg/os/#File) 类型：\n```go\ntype File struct {\n        // contains filtered or unexported fields\n}\n```\n\n打开一个文件进行读直接使用 [`os.Open` ](https://golang.org/pkg/os/#Open):\n```go\nfile, err := os.Open(\"msg.txt\")\n```\n\n`os.Open` 只接受一个文件名参数，默认打开的文件只支持读操作，文件的读写 `flag` 是以常量的形式定义的 [Constants](https://golang.org/pkg/os/#pkg-constants)   分别是：\n\n```go\nconst (\n        // Exactly one of O_RDONLY, O_WRONLY, or O_RDWR must be specified.\n        O_RDONLY int = syscall.O_RDONLY // open the file read-only.\n        O_WRONLY int = syscall.O_WRONLY // open the file write-only.\n        O_RDWR   int = syscall.O_RDWR   // open the file read-write.\n        // The remaining values may be or'ed in to control behavior.\n        O_APPEND int = syscall.O_APPEND // append data to the file when writing.\n        O_CREATE int = syscall.O_CREAT  // create a new file if none exists.\n        O_EXCL   int = syscall.O_EXCL   // used with O_CREATE, file must not exist.\n        O_SYNC   int = syscall.O_SYNC   // open for synchronous I/O.\n        O_TRUNC  int = syscall.O_TRUNC  // truncate regular writable file when opened.\n)\n```\n\n以 `os.Open` 打开的文件其实就只有 `O_RDONLY` flag。\n\n### 文件读取\n\n读取文件操作时通过 `File` 的方法 [Read](https://golang.org/pkg/os/#File.Read) 进行的，这个方法接受一个参数 `buf []byte` ，默认读取的内容大小是 `len(buf)`，并且返回读取的字节 size 和错误（如果有的话），如果读取到了文件末尾，则返回 0以及`io.EOF`。\n\n```go\nif err != nil {\n    fmt.Println(err)\n}\nbuf := make([]byte, 126)\nn, err := file.Read(buf)\nif err != nil {\n    fmt.Println(err)\n}\n\nfmt.Printf(\"%d = %q\", n, buf)\n```\n\n## 按行读取\n\n在大多数文件操作中，我们可能只需要的一行行读取文件就可以满足需要，在 Go 中如何读取行呢？至少在 [os](https://golang.org/pkg/os/) 这个 package 中好像没有找到相关操作，其实 Go 已经在其他包中提供了这个操作 [bufio](https://golang.org/pkg/bufio/)。\n\nbufio 顾名思义就是带 buffer 的 IO，由于频繁读写磁盘会有相当的性能开销，因为一次磁盘的读写就是一次系统的调用，所以 Go 提供了一个 buffer 来缓冲读写的数据，比如多次写磁盘 bufio 就会把数据先缓冲起来，待 buffer 装满之后一次性写入，又比如多次读数据，bufio 会预先按照 buffer 的大小（一般是磁盘 block size 的整数倍）尽量多的读取数据，也就是采用预读的技术以提高读的性能。\n\nbufio 提供了 [Reader](https://golang.org/pkg/bufio/#Reader) 、[Writer](https://golang.org/pkg/bufio/#Writer)、[Scanner](https://golang.org/pkg/bufio/#Scanner) 来进行文件的读写，其中 Reader 和 Scanner 都支持按行读取文件。\n\n### Reader 读取行\n\n使用 Reader 的[ReadLine](https://golang.org/pkg/bufio/#Reader.ReadLine) 按行读，其中 file 表示我们刚才打开的文件：\n\n```go\nreader := bufio.NewReader(file)\nbuf, _, err = reader.ReadLine()\n```\n\nReadLine 读取文件的一行，默认是以 `\\r\\n` 或者 `\\n` 分割，并且不包括分割符，如果行太长超过了内部 buffer 的大小，第二个返回值 isPrefix 就会被设置，直到 isPrefix 为 false 为止，表示一行读取完成。\n\n除了 ReadLine 之外，[ReadBytes](https://golang.org/pkg/bufio/#Reader.ReadBytes) 也支持按行读取，区别是 ReadBytes 需要显示的指定分隔符，而且其返回的数据中包括分割符：\n\n```go\nbuf, err = reader.ReadBytes('\\n')\nfmt.Printf(\"%d = %q\", len(buf), buf) //输出包含 \\n\n\n```\n\n除了对行的读取，bufio.Reader 还包含 [ReadRune](https://golang.org/pkg/bufio/#Reader.ReadRune)、ReadSlice、ReadString 等读取内容的函数。\n\n###  Scanner 读取行\n\nScanner 其实类似于 Reader，但是 scanner 有更强的便捷性，scanner 的主要目的就是利用各种分隔符来读取行，他提供了 SplitFunc 来自定义对文件内容的分割:\n\n```go\nscanner := bufio.NewScanner(file)\nfor scanner.Scan() {\n    fmt.Println(scanner.Text())\n}\n```\n\n上面的代码会把文件 file 的内容按行输出，为什么恰好会按行输出？主要原因是 scanner 提供的默认的 [SplitFunc](https://golang.org/pkg/bufio/#Scanner.Split) 是 [ScanLines](https://golang.org/pkg/bufio/#ScanLines)，也就是 scanner.Text() 方法使用就是这个 splitfunc。\n\n接下类我们使用一个自定义的 SplitFunc 来实现从文本中找到可以转换成数字的字符。\n\n```go\nr := strings.NewReader(\"123 456 k789 123\")\nsplit := func(data []byte, atEOF bool) (advance int, token []byte, err error) {\n    // scanWords 按照 space 进行分割\n    advance, token, err = bufio.ScanWords(data, atEOF)\n    fmt.Printf(\"data=%q\\n\", data)\n    fmt.Printf(\"advance=%d\\n\", advance)\n    fmt.Printf(\"token=%q\\n\", token)\n    fmt.Printf(\"atEOF=%t\\n\", atEOF)\n    if strings.Trim(string(token), \" \") != \"\" {\n        _, err = strconv.ParseInt(string(token), 10, 32)\n    }\n\n    return\n}\n\nscanner := bufio.NewScanner(r)\nscanner.Split(split)\n\nfor scanner.Scan() {\n    fmt.Println(\"scan text=\", scanner.Text())\n    fmt.Println(\"=======\")\n}\n\nif err := scanner.Err(); err != nil {\n    fmt.Printf(\"%s\", err)\n}\n```\n\n上面的例子中我们定义了一个 SplitFunc，正如 SplitFunc 签名一样，他接受三个参数，分别是待处理的数据 data，是否还有更多的数据要处理的标识 atEOF，然后返回的是当前已经处理的数据的字节长度 advance，已经处理的字节数组 token，以及一个可选的错误 err。\n\n**advance 的计算是从当前剩下要处理的数据首位 0 的位置开始一直到下一个分割符，并且包含分隔符占用的字节**，可以对照看以下输出就能明白：\n\n```\ndata=\"123 456 k789 123\"\nadvance=4         //从 1 开始直到下一个空格\ntoken=\"123\"\natEOF=false\nscan text= 123\n=======\ndata=\"456 k789 123\"\nadvance=4\ntoken=\"456\"\natEOF=false\nscan text= 456\n=======\ndata=\"k789 123\"   \nadvance=5   //从 k 开始直到下一个空格\ntoken=\"k789\"\natEOF=false\nstrconv.ParseInt: parsing \"k789\": invalid syntax%\n```\n\n而且需要注意的是，scanner 在遇到一个错误之后就停止 Scan 了，上面的 ParseInt 发生错误之后之后的 Scan 也不会输出。\n\n## File 类型和 bufio\n\n![](https://static.git-star.com/go-file.jpg?a)\n\n如图 File 是实现了`io.Reader` 和 `io.Writer` 两个 interface 的 type，而 bufio 提供的几种操作都以这两个 interface 为基础实现文件的读写，也就是说只要 type 实现了 io.Reader 就可以使用 bufio 读取，实现了 io.Writer 就可以使用 bufio 输出。\n\n```go\nstr := strings.NewReader(strings.Repeat(\"ab\", 10))\nbuf := make([]byte, 2)\nreader := bufio.NewReader(str)\n```\n\n如上代码 str 是一个 string 的 Reader，然后就可以使用 bufio进行高效读取。\n\n## 文件的输出\n\n文件的写入类似文件的读取，Go 提供了 [Create](https://golang.org/pkg/os/#Create)、 [OpenFile](https://golang.org/pkg/os/#OpenFile) 打开文件进行写入或追加。\n\nCreate 会打开一个文件，默认的模式是 O_RDWR 即读和写，如果原来的文件已经存在则清空，如果不存在则新创建一个。\n\n```go\nfile, err := os.Create(\"new.txt\")\nif err != nil {\n    fmt.Println(err)\n}\n\ndefer file.Close()\n\nfile.WriteString(time.Now().Local().String())\n```\n\nOpenFile 提供了更灵活的方式打开一个文件，他接受三个参数，依次是文件名，打开文件的 flag，以及文件权限。\n\n```go\nfile, err := os.OpenFile(\"new.txt\", os.O_RDWR|os.O_CREATE, 0775)\nif err != nil {\n    fmt.Println(err)\n}\n\ndefer file.Close()\nfile.WriteString(time.Now().Local().String())\n```\n\n除了 WriteString，file 类型还提供了 [Write](https://golang.org/pkg/os/#File.Write) 方法，区别是 Write 接受的是 []byte 。\n\n### 使用 bufio.Writer 进行文件输出\n\n上面我们提到过 bufio 提供了 Writer 来进行高效的输出，如何使用呢？\n\nWriter 实际上是一个内部包含 buffer 的特殊 struct，其结构大致如下：\n\n```go\ntype Writer struct {\n    err error\n    buf []byte\n    n   int\n    wr  io.Writer\n}\n```\n\nbuf 这个 field 就是缓冲输出内容的，当满足指定 size 之后，Writer 才会把 buf 中的内容通过 wr 写到输出对象。\n\n```go\nwr := bufio.NewWriterSize(os.Stdout, 38)\n\tcount := 0\n\tfor {\n\t\twr.WriteString(time.Now().Format(\"2006-01-02 15:04:05\"))\n\t\ttime.Sleep(time.Second * 1)\n\t\tfmt.Println(\"\\ncount \", count)\n\t\tcount++\n\t\tif count > 10 {\n\t\t\tbreak\n\t\t}\n\n\t}\nwr.Flush()\n\n```\n\n上面的代码会在 buf 的 size 满足 38 之后输出到标准输出，可以运行代码查看输出时间隔 2 秒产生的:\n\n```shell\ncount  0\ncount  1\n2019-03-10 14:01:022019-03-10 14:01:03\ncount  2\ncount  3\n2019-03-10 14:01:042019-03-10 14:01:05\ncount  4\ncount  5\n2019-03-10 14:01:062019-03-10 14:01:07\ncount  6\ncount  7\n2019-03-10 14:01:082019-03-10 14:01:09\ncount  8\ncount  9\n2019-03-10 14:01:102019-03-10 14:01:11\ncount  10\n2019-03-10 14:01:12   \n```\n\n默认情况下 bufio.Writer 指定的 size 大小是 [defaultBufSize](https://golang.org/src/bufio/bufio.go?s=14124:14193#L17) = 4096，像上面的代码一样可以通过 NewWriterSize 来改变这个大小。\n\n需要注意的是，Writer 在遇到错误之后不会接着执行后面的输出，看以下代码：\n\n```go\ntype Writer int\n\nfunc (*Writer) Write(p []byte) (n int, err error) {\n\tfmt.Printf(\"Write: %q\\n\", p)\n\treturn 0, errors.New(\"IO Error!\")\n}\n\nfunc main() {\n\twr := bufio.NewWriterSize(new(Writer), 3)\n\twr.Write([]byte{'a'})\n\twr.Write([]byte{'b'})\n\twr.Write([]byte{'c'})\n\twr.Write([]byte{'d'})\n\terr := wr.Flush()\n\tfmt.Println(err)\n}\n\n```\n\n输出：\n\n```\nWrite: \"abc\"\nIO Error!\n```\n\n最后一个字符 d 没有输出\n\n## ioutil 包的文件读写\n\n除了上面提到的对文件的读写操作，[io/ioutil](https://golang.org/pkg/io/ioutil/) 中提供了几个便捷的函数来读写文件，分别是：\n\n[WriteFile](https://golang.org/pkg/io/ioutil/#WriteFile) 、[ReadFile](https://golang.org/pkg/io/ioutil/#ReadFile) ，他们可以直接对文件进行写入和读取，省去了一个打开的过程。","src/content/posts/go-stand-lib-file.mdx","668244d49d1e7caa","go-stand-lib-file.mdx","go-test",{"id":662,"data":664,"body":670,"filePath":671,"digest":672,"legacyId":673,"deferredRender":22},{"title":665,"summary":666,"date":667,"tags":668,"group":50,"featured":38},"Golang 测试","Go 提供了 来执行测试，这个命令会在当前 package 中寻找符合 的文件，并在文件中寻找符合 、、 函数执行测试，如果想要执行当前 package 中的所有测试，可以执行 ，这个命令会搜索当前目录以及子目录中的所有符合条件的测试文件，详细测试规则看 。",["Date","2019-08-21T00:00:00.000Z"],[669],"test","Go 提供了 `go test` 来执行测试，这个命令会在当前 package 中寻找符合 `*_test.go` 的文件，并在文件中寻找符合 `TestXxx(*testing.T) {}` 、`BenchmarkXxx(b *testing.B){}`、`ExampleXxxx(){}` 函数执行测试，如果想要执行当前 package 中的所有测试，可以执行 `go test ./...` ，这个命令会搜索当前目录以及子目录中的所有符合条件的测试文件，详细测试规则看 `go help testfunc` 。\n\n### Go 测试是并行还是串行\n\n默认情况下 `go test` 在**不同的 package 之间是并行执行测试**，在**每个 package 内部是串行执行测试**。如果想要在 package 内部开启并行测试，需要在测试函数中显式执行 `t.Parallel()` 告诉 `go test` 这个函数可以与其他测试并行执行，一旦开启并行测试，一定要确保测试函数之间的资源竞争的问题已经得到正确的解决，否则可能会有意想不到的问题。\n\nGo 提供了可以限制 package 之间并行测试的命令：\n\n```bash\ngo test -parallel 1 -p 1\n```\n\n`-parallel 1` 表示允许同时执行并行测试的函数数目是 1，默认是 GOMAXPROCS，`-p 1` 表示允许并行测试的 test binary 同时只有一个，默认是 CPU的核数。Go 执行测试的时候是把每个 package 都 build 成 binary 之后再去执行，这个数目就是设置在被 go test 同时执行的 package 的 binary 有几个。\n\n还有一种可以让多个 package 并行测试的办法是测试的时候指定多个 package：\n\n```bash\ngo test p1 p2 p3\n```\n\n通过这种方式执行测试时，三个包是并行执行的。\n\n所以如果想要让你的测试执行速度加快，其中一种办法就是把**测试放到不同的 package 中**，如果某个 package 中测试文件很多，可以把这些文件单独成包：\n\n```bash\ngraphql/test\n├── mutation\n│   └── mutation_test.go\n└── query\n    └── query_test.go\n```\n\n如果你的并行测试依赖于 database 这样的外部系统，确保你使用的 database 在每个 test package 之间是相互独立的，比如上述 mutation_test.go 和 query_test.go 使用了相同的表结构的不同数据库。\n\n### Go test flags\n\n上面限制 Go 并行测试的其实都是 Go 提供的 test flag，详细见 https://golang.org/cmd/go/#hdr-Testing_flags  ， 其中有几个对日常测试很重要的 flag 这里单独来讲讲。\n\n#### `-v`\n\n表示输出测试的详细信息，有助于本地开发调试，对应的代码 `testing.Verbose()` 。\n\n#### `-short`\n\n表示只想执行运行时间比较短的测试，这个 flag 一般会结合 `testing.Skip()` ，可以让开发这选择跳过执行时间较长的测试：\n\n```go\nfunc TestCountMallocs(t *testing.T) {\n  if testing.Short() {\n    t.Skip(\"skipping malloc count in short mode\")\n  }\n  // rest of test...\n}\n```\n\n#### `-timeout`\n\n指定测试执行的超时时间，如果测试时间很长，可以通过这个 flag 强制测试停止\n\n`-run`\n\n指定想要执行的测试函数名称，通过正则匹配要执行的测试函数名称\n\n`-parallel`\n\n指定在同一个package 内并行执行的测试函数数目，默认是 GOMAXPROCS\n\n#### `-p`\n\n指定同时执行 build 和 test 的包的数目，默认是 CPU 核数，可以指定 `-p 1` 限制对包的测试一个一个串行执行。\n\n#### `-cpu`\n\n指定需要在哪些CPU上执行测试 ` go test -cpu=1,2,4` ，默认情况下测试都只会在一个 CPU 上执行，如果想要在多个 CPU 上都执行一遍测试，可以通过环境变量指定 GOMAXPROCS ，`GOMAXPROCS=2 go test` 表示在 2 个 CPU 上执行测试，也就是测试会执行 2 次。\n\n#### `-args`\n\n指定测试的命令参数，一般这个 flag 放在 go test 命令的最后\n\n### 使用不同名包打破引用循环\n\nGo test 支持在不同名的 package 属于同一个目录：\n\n```bash\n\n├── builder.go\n├── builder_test.go\n├── compare.go\n├── compare_test.go\n├── example_test.go\n├── export_test.go\n├── reader.go\n├── reader_test.go\n├── replace.go\n├── replace_test.go\n├── search.go\n├── search_test.go\n├── strings.go\n├── strings.s\n└── strings_test.go\n```\n\n只要包名是以 package_test 形式命名即可：\n\n```go\npackage strings_test\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/rand\"\n\t\"reflect\"\n\t\"strconv\"\n\t. \"strings\"\n\t\"testing\"\n\t\"unicode\"\n\t\"unicode/utf8\"\n\t\"unsafe\"\n)\n```\n\n这样的目的是如果被测试的包 A 被 B 引用了，A 的测试文件又引用了 B，从而会形成循环引用，使用不同的包名，可以打破这种引用关系，Go 标准库的 strings 就是这种案例。\n\n### 参考\n\n- https://splice.com/blog/lesser-known-features-go-test/\n- https://golang.org/cmd/go/#hdr-Testing_flags\n- https://deepzz.com/post/the-command-flag-of-go-test.html","src/content/posts/go-test.mdx","d216e972464dca26","go-test.mdx","go-style",{"id":674,"data":676,"body":682,"filePath":683,"digest":684,"legacyId":685,"deferredRender":22},{"title":677,"summary":678,"date":679,"tags":680,"group":50,"featured":38},"写出 Go 风格的代码","此文是 Golang wiki 上 https://github.com/golang/go/wiki/CodeReviewComments 的翻译与理解。",["Date","2019-07-25T00:00:00.000Z"],[681],"style","此文是 Golang wiki 上 https://github.com/golang/go/wiki/CodeReviewComments 的翻译与理解。\n\n\n## Gofmt\n\n优先使用工具统一代码风格，避免无意义的争论，使用 gofmt 或者 goimports。\n\n\n## 注释语句 Comment Sentences\n\n\n注释以要注释的对象开头，尽量使用完整的句子进行注释，哪怕看上去有点冗余，\n\n\n```golang\n// Request represents a request to run a command.\ntype Request struct { ...\n\n// Encode writes the JSON encoding of req to w.\nfunc Encode(w io.Writer, req *Request) { ...\n\n```\n\n\n## 上下文 Contexts\n\n对于来自 RPC 或 HTTP 调用的请求，显示把 context 作为函数的第一个参数。\n\n```golang\nfunc F(ctx context.Context, /* other arguments */) {}\n```\n\n如果函数不是 request specific 的，可以使用 `context.Background` 代替。\n\n不要把 context 作为 context 的 memeber，而是是吧 context 作为 struct method 的第一个参数，有个例外是如果 method 必须\n要满足某个 interface 或者某个第三方 pkg 的签名。\n\n在函数签名中不要使用自定义 context 以及 context 提供之外的 interface。\n\n如果有应用程序数据要传递，优先考虑作为参数传递，其次是作为 receiver 或全局变量，最后再考虑是不是可以作为 context value 传递。\n\ncontext 是不可变的，所以可以把 context 在多次调用的上下文中分享同一个 context，以共享 dealine、cancellation、credentials 等。\n\n\n## 拷贝 Copy \n\n如果要 copy 从一个 package 中的某个 struct 时，一定要小心，尤其拷贝一个带 slice 的 struct，有可能会导致两个 struct 引用同一个底层\narray。\n\n一般来说不要 copy T 的 method receiver 是 `*T` 的 struct。\n\n## 声明空的 slice Declaring Empty Slices\n\n优先使用 `var t []string`，而不是 `t := []string{}`，虽然二者功能上是一样的，len 都是 zero，但是前者是 nil，后者不是 nil。前者 json \n之后是 null，后者是 []，但是前者依然是推荐写法。\n\n如果要设计 interface 避免区分 slice 的 nil 或者 not nil 以及 zero length。\n\n\n## 文档注释 Doc Comments\n\n所有顶层可导出对象都应该有文档注释，不可导出对象也应该如此，详见 https://golang.org/doc/effective_go.html#commentary 。\n\n## 不要 panic Don’t Panic\n\n使用 error 和多个返回值解决 error 的问题，不要用 panic，除非你显示知道自己这么做的原因。\n\n\n## 例子 Examples\n\n任何时候写一个 pkg 都要附带可以执行的例子。\n\n\n## Goroutine 的生命周期 Goroutine Life Time\n\n每开启一个 Goroutine，一定要明确 Goroutine 何时或者是否要结束，根本原因是 Goroutine leak。\n\n\n>Goroutines can leak by blocking on channel sends or receives: the garbage collector will not terminate a goroutine even if the channels it is blocked on are unreachable.\nEven when goroutines do not leak, leaving them in-flight when they are no longer needed can cause other subtle and hard-to-diagnose problems. Sends on closed channels panic. Modifying still-in-use inputs \"after the result isn't needed\" can still lead to data races. And leaving goroutines in-flight for arbitrarily long can lead to unpredictable memory usage.\nTry to keep concurrent code simple enough that goroutine lifetimes are obvious. If that just isn't feasible, document when and why the goroutines exit\n\n\n## 错误处理 Handle Errors\n\n见 https://golang.org/doc/effective_go.html#errors ，不要使用 `_` 丢弃错误，如果一个函数返回错误，校验错误确保函数的正确执行，处理错误或者返回它，哪怕是 panic 。\n\n## 导入 Imports\n\n除非是为了避免名称冲突，否则不要重命名导入包，优先重命名本地或者 project-specific 的包。\n\n包以 blank line 的形式分组展示，标准包在顶层。\n\n使用 goimport 工具。\n\n\n## 导入空 ImportBlank\n\n\n仅仅在入口函数或者测试时执行 `_ pkg` 形式的导入。\n\n\n\n## 错误的缩进 Indent Error Flow\n\n\n```golang\n\n// 推荐写法\nif err != nil {\n\t// error handling\n} else {\n\t// normal code\n}\n\n\n// 不推荐写法\nif err != nil {\n\t// error handling\n\treturn // or continue, etc.\n}\n\n\n// 不推荐写法\nif x, err := f(); err != nil {\n\t// error handling\n\treturn\n} else {\n\t// use x\n}\n\n// 推荐写法\nx, err := f()\nif err != nil {\n\t// error handling\n\treturn\n}\n// use x\n```\n\n\n## 命名返回参数 Named Result Parameters\n\n\n如果一个函数返回多个类型相同的结果或者返回的结果上下文语义不明确，可以使用命名参数：\n```golang\n\n// 不推荐写法\nfunc (f *Foo) Location() (float64, float64, error)\n\n// 推荐写法\nfunc (f *Foo) Location() (lat, long float64, err error)\n\n```\n\n\n## 包名 package name\n\nhttp://blog.golang.org/package-names\n\n\n## 传值 Pass Values\n\n\n传值而不是指针，大的 struct 以及可能会增长的 struct 除外。","src/content/posts/go-style.mdx","29c42e45c512eaf4","go-style.mdx","go-tutorial",{"id":686,"data":688,"body":694,"filePath":695,"digest":696,"legacyId":697,"deferredRender":22},{"title":689,"summary":690,"date":691,"tags":692,"group":50,"featured":38},"Go 入门参考资料","go 的入门书籍教程非常多，这里只介绍几个具有代表性的，足够初学者入门参考。",["Date","2017-07-23T00:00:00.000Z"],[693],"资源","go 的入门书籍教程非常多，这里只介绍几个具有代表性的，足够初学者入门参考。\n\n# 官方教程\n\n## [Language Specification](https://golang.org/ref/spec) \n\ngo 的语法说明以及语言的组织结构，包含大量的细节解释和说明，值得通读一遍\n\n## [A Tour of Go](https://tour.golang.org/)  \n\ngo 官方在线的教程，可执行代码，对 go 语言的执行和抒写有直观的演示，首次学习 go 的练习之地\n\n## [Go wiki](https://github.com/golang/go/wiki)\n\n包含大量第三方的文章和书籍来对某个特定主题的原理进行深入的解释和演示\n\n## [Blog](https://golang.org/blog/)\n\n对某些特定主题进行说明和演示，以及语言自身的特性说明\n\n# 入门 Book\n\n## [An Introduction to Programming in Go](https://www.golang-book.com/books/intro)\n\n英文书，但是写的通俗易懂，入门非常合适\n\n## [The Little Go Book](http://openmymind.net/The-Little-Go-Book/)\n\n英文书，入门读物，有深度有细节\n\n## [Learning Go](https://www.miek.nl/go/)\n\n有一定的原理性讲解，每章附有习题可以练习\n\n## [Go 入门指南](https://github.com/Unknwon/the-way-to-go_ZH_CN)\n\n## [build-web-application-with-golang](https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/preface.md)\n\nBeego 作者写的，中文，除了 go 语言基础也涉及 Go web 编程。\n\n\n# 实例练习\n\n\n## https://gowebexamples.github.io/\n\n大量 web 示例\n\n## https://gobyexample.com/\n\n大量 go 基础示例\n\n\n# 项目练习\n\n## [project-based-learning](https://github.com/tuvttran/project-based-learning#go)\n\n包含完整教程的小项目练习\n\n# 其他资源\n\n- https://github.com/dariubs/GoBooks go 书籍\n- https://golang.org/doc/effective_go.html 官方 effective go\n- https://github.com/golang/go/wiki/Learn 官方 learn wiki","src/content/posts/go-tutorial.mdx","338653c3f24c23e6","go-tutorial.mdx","how-dns-resolve-in-linux",{"id":698,"data":700,"body":707,"filePath":708,"digest":709,"legacyId":710,"deferredRender":22},{"title":701,"summary":702,"date":703,"tags":704,"group":706,"featured":38},"linux 中的 dns 解析","> 我在用 linux 桌面环境有 2 年了，做服务端开发大部分时候都在和 linux 打交道，后来转投 mac，其实本质都是一样的，好奇 linux 下的 dns 解析的过程，看了很多资料发现过程还是比我想象的要复杂，虽然想好好写一写但投入时间还是挺大的，此篇我也许会慢慢更新直...",["Date","2017-11-08T00:00:00.000Z"],[705],"dns","linux","> 我在用 linux 桌面环境有 2 年了，做服务端开发大部分时候都在和 linux 打交道，后来转投 mac，其实本质都是一样的，好奇 linux 下的 dns 解析的过程，看了很多资料发现过程还是比我想象的要复杂，虽然想好好写一写但投入时间还是挺大的，此篇我也许会慢慢更新直到完整，也许可能就写这么一些了。\n\n# 什么是 DNS\n\nDNS 全称是 Domain Name System，大意是域名解析系统，它的职责是把域名翻译成一个一个可以识别的 IP 供不同的计算机设备连接。\n\n\n# linux 有关 DNS 解析的配置和文件\n\nlinux 中有三个文件是关于 dns 解析的：\n\n- /etc/hosts 记录 hostname 对应的ip地址\n- /etc/resolv.conf 设置DNS服务器的ip地址\n- /etc/host.conf 指定域名解析的顺序（是从本地的hosts文件解析还是从DNS解析）\n\n\n`/etc/hosts` 的存在是早期网络并不是特别发达，仅仅在 hosts 中保存主机名和 ip 地址的对应关系即可满足需要，随着网络的发展逐渐出现分布式 DNS 服务，但是 `/etc/hosts` 形式保留下来了。\n\n`/etc/resolv.conf` 是配置DNS 域名和 ip 地址的，网上有很多资料可以参考一下。\n\n\n# 一个域名是如何被解析的\n\n[How the Domain Name System (DNS) Works\n](https://www.verisign.com/en_US/website-presence/online/how-dns-works/index.xhtml) 这篇大致解释了域名被解析的过程，基本可以分为：\n\n- 向根域名服务请求顶级域名所在所在域名服务\n- 向顶级域名服务请求二级域名服务\n- 向二级域名服务请求具体的 ip 地址\n\n真实的解析过程是要更复杂的，参考 [linux下DNS解析（nslookup、dig、host）](http://122269875.blog.51cto.com/1660536/1713947)\n\n\n# 参考资料\n\n- http://122269875.blog.51cto.com/1660536/1713947\n- https://www.nslookuptool.com/chs/\n- http://roclinux.cn/?p=1820\n- http://www.steves-internet-guide.com/dns-guide-beginners/","src/content/posts/how-dns-resolve-in-linux.mdx","cfeede3649e4501f","how-dns-resolve-in-linux.mdx","go-type",{"id":711,"data":713,"body":719,"filePath":720,"digest":721,"legacyId":722,"deferredRender":22},{"title":714,"summary":715,"date":716,"tags":717,"group":50,"featured":38},"理解 Go 类型系统","## Type 的分类",["Date","2017-07-27T00:00:00.000Z"],[718],"type","## Type 的分类\n\n在 Go 中所有需要被定义和声明的对象都是 Type: \n- int\n- string\n- function\n- pointer\n- interface\n- map\n- struct\n- chan \n- ...\n\n和大多数计算机语言一样，Go Type 默认包含常用的基础数据类型，称为 **Pre-declarered types** 比如:\n- boolean\n- numeric\n- string\n\n基础数据类型又可以进一步构成更复杂的类型，称之为 **Composite Types** 比如: \n- array\n- struct\n- map\n- slice\n- channel\n- func\n- interface\n- ...\n\n**Composite Types** 由 **Pre-declared Types** 组成的复杂数据类型，其形式常常是 **Type Literal** ，比如 array 的字面量声明 `var array [10]int` ，map 的字面量 `var dict map[int]string`。\n\nType 可以分为带名称和不带名称的，前者称之为 **Named Type**，后者称之为 **Unnamed Type**。\n\n**Named Types** 就是通过 type 关键字为一个已有的 type 起个别名，像这样 `type NewType ExistingType` NewType 就是别名。**Pre-declared types** 也是 **Named Types**，也可以为 **Pre-Declared Types** 起个别名: `type Integer int`.\n\n**Unamed Types** 是一个 Literal Type，也就是没有名字只有 type 本身，像这样 `[6]int` 、`map[string]int`。\n\n每一个类型都有自己的 **Underlying Type** ，如果 T 是 **Pre-declared type** 或者 **Type Literal**，它们对应的 Underlying Type 就是自身 T，否则 T 的 **Underlying Type** 是 T 定义时引用的类型的 **Underlying Type**，比如 `type T int` 的 Underlying Type 是 `int`，`int` 是 Pre-declared；`type T map[int]string` 的 Underlying Type 是 `map[int]string`，`map[int]string` 是 Type Literal。\n\n## Underlying type\n\n如果两个 type 的 Underlying Type 相同，则它们可以有以下特性。\n\n**1.如果两个 type 都是 named type ，彼此之间不能相互赋值**\n\n```go\ntype NewString string\nvar my string =\"a\"\nvar you NewString = my //cannot use my (type string) as type NewString in assignment\n\n```\n虽然它们的 Underlying Type 都是 string，但 string 类型的 my 不能赋值给 NewString 类型的 you。\n\n**2.如果两个 type 其中一个是 Unnamed Type，彼此之间可以相互赋值**\n\n```go\npackage main\n\ntype Ptr *int\n//named type\ntype Map map[int]string\ntype MapMap Map\n\nfunc main() {\n    var p *int\n    var mm Map\n    var mmm MapMap\n    //m1 m2 是 Unnamed Type\n    var m1 map[int]string = mm\n    var m2 map[int]string = mmm\n    var ptr Ptr = p\n    print(ptr)\n    print(m1)\n    print(m2)\n}\n```\n\n**为什么 type 之间会有这样的差别?**\n\n如果为一个类型起了名字，说明你想要做区分，所以两个 named types 即使 Underlying Type 相同也是不能相互赋值的。\n\n详见[Google Group Topic](https://groups.google.com/forum/#!topic/golang-nuts/4Db2z2dEhfc)\n\n## Named type 和 Unamed type\n\n当 named types 被作为一个 function 的 receiver 时，它就拥有了自己的方法，unamed types 则不能，这是它们的重要区别。\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\ntype NewMap map[int]string\n\nfunc (nm NewMap) add(key int, value string) {\n    nm[key] = value\n}\n\nfunc main() {\n    var p NewMap = make(map[int]string)\n    p.add(10, \"a\")\n    fmt.Println(p) //map[10:a]\n}\n\n```\n\n有个一例外是 **Pre-Declared Types** 不能拥有自己的方法。\n\n```go\npackage main\n\n\nfunc (n int) name(){   \n    print(n)\n}\n\nfunc main() {\n    var n int\n    n.name()\n}\n\n```\n\n编译器会抛出 **cannot define new methods on non-local type int** 错误，不能对包之外的 type 定义方法，解决这个问题就是对 pre-declared types 重新定义别名。\n\n\n## type 的属性继承\n\n\n### 直接继承\n\n已经声明的 Named Type 不会从它的 Underlying Type 或 existing type 继承 method，但是会继承 field。\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\ntype Person struct {\n    name string\n}\n\nfunc (p *Person) Speak() {\n    fmt.Println(\"I am a person\")\n}\n\n//Student 是 Named Type\ntype Student Person\n\nfunc main() {\n    var p Person\n    p.Speak()\n    var s Student\n    s.name = \"jone\"\n    fmt.Println(s.name)\n    // s.Speak()\n}\n\n\n```\n\nNamed Type Student 不会继承来自 Person 的 Speak 的方法，打开注释执行报错 **s.Speak undefined (type Student has no field or method Speak)**，但是 Student 可以继承 Person 的 filed: s.name 可以使用。\n\n> The declared type does not inherit any methods bound to the existing type, but the method set of an interface type or of elements of a composite type remains unchanged:\n\n但是也有例外的情况。\n\n**如果 existing type 是 interface，它的 method set 会被继承**。\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\ntype I interface {\n    Talk()\n}\n\n// existing type 是 I，I 是个接口，可以直接继承 I 的方法，II 等同于 I\ntype II I\n\ntype Person struct {\n    name string\n}\n\nfunc (p *Person) Speak() {\n    fmt.Println(\"I am a person\")\n}\n\nfunc (p *Person) Talk() {\n    fmt.Println(\"I am talking\")\n}\n\nfunc main() {\n    var p Person\n    p.Speak()\n    p.Talk()\n    var i I\n    i = &p\n    i.Talk()\n    var ii II\n    ii = &p\n    ii.Talk()\n}\n\n```\n`II` 继承了 `I` 的 method，所以 Person 也实现了 II。\n\n**如果 existing type 被嵌入新 type 作为 filed  **\n\n如果一个 type TB 被嵌入另一个 type T 作为它的 filed，TB 的所有 field 和 method 都可以在 T 中使用，这种方法称之为 type embedding。\n\n```\npackage main\n\nimport (\n    \"fmt\"\n)\n\ntype I interface {\n    Talk()\n}\n\ntype Person struct {\n    name string\n}\n\nfunc (p *Person) Speak() {\n    fmt.Println(\"I am a person\")\n}\n\nfunc (p *Person) Talk() {\n    fmt.Println(\"I am talking\")\n}\n\ntype People struct {\n    Person\n}\n\nfunc main(){\n    var people People\n    people.name = \"people\"\n    people.Speak()\n    people.Talk()\n}\n```\n\n## type 转换\n\nType 之间是可以相互转换的，但要遵循一定的转换规则，详细请看官方规范 https://golang.org/ref/spec#Conversions。\n\n## 参考代码\n\n文中部分代码\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\ntype I interface {\n    Talk()\n}\n\ntype Person struct {\n    name string\n}\n\nfunc (p *Person) Speak() {\n    fmt.Println(\"I am a person\")\n}\n\nfunc (p *Person) Talk() {\n    fmt.Println(\"I am talking\")\n}\n\ntype Student Person\n\ntype HighStudent Student\n\ntype People struct {\n    Person\n}\n\nfunc main() {\n    var p Person\n    p.Speak()\n    p.Talk()\n    var s Student\n    s.name = \"jone\"\n    fmt.Println(s.name)\n    var hs HighStudent\n    hs.name = \"High jone\"\n    fmt.Println(hs.name)\n    var i I\n    i = &p\n    i.Talk()\n    var people People\n    people.name = \"people\"\n    people.Speak()\n    people.Talk()\n    // s.Speak()\n}\n```\n\n\n## 参考资料\n\n- https://golang.org/ref/spec#Types\n- http://www.laktek.com/2012/01/27/learning-go-types/\n- http://www.tapirgames.com/blog/golang-type-system\n- https://dave.cheney.net/2014/05/24/on-declaring-variables","src/content/posts/go-type.mdx","e3760d60fbb1522a","go-type.mdx","how-teach-child-computer",{"id":723,"data":725,"body":731,"filePath":732,"digest":733,"legacyId":734,"deferredRender":22},{"title":726,"summary":727,"date":728,"tags":729,"group":129,"featured":38},"如何向小孩子解释计算机是什么","Medium 有篇文章 Explaining Programming to 6 Years Old Kids 讲了如何向小孩子解释计算机，过程挺有意思的，作者总结了两个讲解的原则用来把自己的想法告诉小孩子:",["Date","2017-11-09T00:00:00.000Z"],[730],"教育","Medium 有篇文章 [Explaining Programming to 6 Years Old Kids](https://dev.to/tkaczanowski/explaining-programming-to-6-years-old-kids) 讲了如何向小孩子解释计算机，过程挺有意思的，作者总结了两个讲解的原则用来把自己的想法告诉小孩子:\n\n>第一，通过提问和绘画的形式让小孩子参与其中\n第二，通过他们已知的东西来向他们讲解未知的\n\n小孩子注意力不够集中，但是对于他们知道的东西都会踊跃发言，这正是表现他们的好机会，所以通过这样的方式可以更好的让孩子和演讲者形成互动。\n\n除此之外，作者还总结了几个技巧:\n\n- 大人要严肃对待给孩子讲解的事\n- 通过绘画的形式能够很好的抓住孩子的注意力，让他们积极参与\n- 要有耐心，准备好一遍又一遍的向孩子解释\n- 纠正孩子的错误是没有意义的，最重要的的让孩子以他们自己的方式理解你所说的东西\n\n\nps:我打算在孩子 3 岁的时候教孩子学编程，让他认识计算机，😆","src/content/posts/how-teach-child-computer.mdx","a1b109f593ac1aca","how-teach-child-computer.mdx","how-to-respect-programer",{"id":735,"data":737,"body":742,"filePath":743,"digest":744,"legacyId":745,"deferredRender":22},{"title":738,"summary":739,"date":740,"tags":741,"group":129,"featured":38},"如何尊重程序员",">很显然，这是一个已经被多次提及并讨论的话题了，但今天还要再讲讲。",["Date","2015-05-12T00:00:00.000Z"],[127],">很显然，这是一个已经被多次提及并讨论的话题了，但今天还要再讲讲。\n\n\n和朋友们聊天，经常会吐槽那些完全不懂得尊重程序员的产品经理和其他互联网从业者。这些人基本可以分为以下几类。\n\n{/* more */}\n\n## 完全不懂技术，也不学习如何理解技术\n\n很多刚入行的产品经理不少属于此类，他们做产品有一般表现为：\n\n- 没逻辑，没直觉\n- 有直觉，但直觉背后无逻辑，经不起推敲\n- 有逻辑，但逻辑很少自己去验证，只等着产品出来再验证\n- 有直觉，有逻辑，但直觉和逻辑都是粗粒度的\t，很少能做到场景化，故事化，缺乏细节填充，显得空洞\n- 没有大局观，缺乏整体把握，很在乎细节\n\n他们对程序员常抱这样的态度：\n\n- 你是不是能力不行搞不定呀\n- 你在讲什么，完全搞不懂(不懂技术)\n- 原型已经准备好了，就差技术了\n- 这么简单一个页面，你竟然要三天\n- ......\n\n这类人是最可怕的，几乎可以定性为程序员杀手。如果一个程序员不懂拒绝，不去仔细推敲对方给出的产品方案，常会导致返工或浪费时间验证了一个完全错误的方案，而且还需要花费大量的精力向对方解释难以理解的技术可行性，这类人还喜欢纠缠于细节而不注重大局，比如UI的颜色，一像素的差异(还远未到像素级别的考究)，很小的交互，无指导意义的统计等等。\n\n应避免与这类人合作，没有必要浪费任何时间教会他们什么是正确的，什么是错误的。如果是创业，这样的人更应该警惕。\n\n\n## 懂点技术，但是感觉自己什么都明白了\n\n\n大部分程序员都清楚，很多事情表面上看上去很简单，实际往往很复杂。那些略懂技术\n的产品经理或项目经理最容易陷入这样的误区。他们对着程序员指手划脚，那种感觉就好象\n他们已经知道用技术怎么实现了，只是恰巧他们不懂编程而已，原来写代码也挺简单的，没什么大不了的。\n\n的确，程序员这个职业与其他很多职业一样，都很普通，而且很多程序员还自嘲是码农，互联网民工，甚至是 x 丝。可是这并不代表任何一个人都有资格对程序员指指点点。\n\n这类人的特点就是，从来不懂如何尊重沟通的另一方，即程序员。\n\n沟通，本质上是为了表达观点，交流情感或达成共识，但是当这类人开始把和程序员的沟通变成对程序员的批评或指教，沟通就变成了对程序员专业程度的质疑。有这种质疑资格的，只能是更资深的程序员，或者程序员眼中那些值得尊敬的懂行的人。\n\n\n遇到了这样的人，不必对他客气，或者根本不去理会他，随便他说什么，该是什么还是什么。\n\n\n## 老板\n\n老板是程序员绕不过去的一个坎。如果碰上一个喜欢脑袋一热，拍一下就做决定的老板，个中滋味只有自己最能领悟，这种领悟是多么得痛。\n\n面对这样的老板，只有一条路可走：坚持自己认为是正确的事情，然后，顺其自然。\n\n**如何才是尊重程序员**\n\n- 不要随便称呼程序员为码农或 x 丝\n- 任何看上去简单的事情都不一定会简单，明白这个理的人多半做过不简单的事\n- 学习点技术，不要浪费程序员的时间去解释一些非常简单的概念\n- 学会沟通，提意见和指指点点有本质的区别，不同的声音可以有，指点需要资格\n- 一起吐槽产品经理:)\n\n## 后记\n\n尊重是相互的，要想他人尊重自己，首先要自尊。互联网民工，x 丝这样的词不要随随便便拿来自嘲，一旦有了这样的自嘲，就会给了别人嘲讽的机会。\n\n程序员虽然不伟大，但绝不简单。","src/content/posts/how-to-respect-programer.mdx","2607f2292ee3b6bb","how-to-respect-programer.mdx","how-to-understand-go-interface",{"id":746,"data":748,"body":753,"filePath":754,"digest":755,"legacyId":756,"deferredRender":22},{"title":749,"summary":750,"date":751,"tags":752,"group":50,"featured":38},"理解 Go interface 的 5 个关键点","## 1、interface 是一种类型",["Date","2017-07-22T00:00:00.000Z"],[506],"## 1、interface 是一种类型 \n\n\n```go\n\ntype I interface {\n    Get() int\n}\n\n```\n\n首先 **interface 是一种类型**，从它的定义可以看出来用了 type 关键字，更准确的说 interface 是一种**具有一组方法的类型**，这些方法定义了 interface 的行为。\n\ngo 允许不带任何方法的 interface ，这种类型的 interface 叫 **empty interface**。\n\n**如果一个类型实现了一个 interface 中所有方法，我们说类型实现了该 interface**，所以所有类型都实现了 empty interface，因为任何一种类型至少实现了 0 个方法。go 没有显式的关键字用来实现 interface，只需要实现 interface 包含的方法即可。\n\n{/* more */}\n\n\n\n## 2、interface 变量存储的是实现者的值 \n```go\n//1\ntype I interface {    \n    Get() int\n    Set(int)\n}\n\n//2\ntype S struct {\n    Age int\n}\n\nfunc(s S) Get()int {\n    return s.Age\n}\n\nfunc(s *S) Set(age int) {\n    s.Age = age\n}\n\n//3\nfunc f(i I){\n    i.Set(10)\n    fmt.Println(i.Get())\n}\n\nfunc main() {\n    s := S{} \n    f(&s)  //4\n}\n```\n\n这段代码在 `#1` 定义了 interface I，在 `#2` 用 struct S 实现了 I 定义的两个方法，接着在 `#3` 定义了一个函数 f 参数类型是 I，S 实现了 I 的两个方法就说 S 是 I 的实现者，执行 `f(&s)` 就完了一次 interface 类型的使用。\n\ninterface 的重要用途就体现在**函数 f 的参数中**，如果有多种类型实现了某个 interface，**这些类型的值都可以直接使用 interface 的变量存储**。\n```go\ns := S{}\nvar i I //声明 i \ni = &s //赋值 s 到 i\nfmt.Println(i.Get())\n```\n\n不难看出 interface 的变量中存储的是实现了 interface 的类型的对象值，这种能力是 [duck typing](http://en.wikipedia.org/wiki/Duck_typing)。在使用 interface 时不需要显式在 struct 上声明要实现哪个 interface ，只需要实现对应 interface 中的方法即可，go 会自动进行 interface 的检查，并在运行时执行从其他类型到 interface 的自动转换，即使实现了多个 interface，go 也会在使用对应 interface 时实现自动转换，这就是 interface 的魔力所在。\n\n\n## 3、如何判断 interface 变量存储的是哪种类型\n\n一个 interface 被多种类型实现时，有时候我们需要区分 interface 的变量究竟存储哪种类型的值，go 可以使用 `comma, ok` 的形式做区分 `value, ok := em.(T)`：**em 是 interface 类型的变量，T代表要断言的类型，value 是 interface 变量存储的值，ok 是 bool 类型表示是否为该断言的类型 T**。\n\n\n```go\n\nif t, ok := i.(*S); ok {\n    fmt.Println(\"s implements I\", t)\n}\n```\n\nok 是 true 表明 i 存储的是 *S 类型的值，false 则不是，这种区分能力叫 [Type assertions](https://tour.golang.org/methods/15) (类型断言)。\n\n如果需要区分多种类型，可以使用 switch 断言，更简单直接，这种断言方式只能在 switch 语句中使用。\n\n```go\n\nswitch t := i.(type) {\ncase *S:\n    fmt.Println(\"i store *S\", t)\ncase *R:\n    fmt.Println(\"i store *R\", t)\n}\n```\n\n## 4、空的 interface\n\n`interface{}` 是一个空的 interface 类型，根据前文的定义：一个类型如果实现了一个 interface 的所有方法就说该类型实现了这个 interface，空的 interface 没有方法，所以可以认为所有的类型都实现了 `interface{}`。如果定义一个函数参数是 `interface{}` 类型，这个函数应该可以接受任何类型作为它的参数。\n\n```go\nfunc doSomething(v interface{}){    \n}\n```\n\n如果函数的参数  v 可以接受任何类型，那么函数被调用时在函数内部 v 是不是表示的是任何类型？并不是，虽然函数的参数可以接受任何类型，并不表示 v 就是任何类型，在函数 doSomething 内部 v 仅仅是一个 interface 类型，之所以函数可以接受任何类型是在 go 执行时传递到函数的任何类型都被自动转换成 `interface{}`。go 是如何进行转换的，以及 v 存储的值究竟是怎么做到可以接受任何类型的，感兴趣的可以看看 [Russ Cox 关于 interface 的实现](https://research.swtch.com/interfaces) 。\n\n既然空的 interface 可以接受任何类型的参数，那么一个 `interface{}`类型的 slice 是不是就可以接受任何类型的 slice ?\n\n```go\nfunc printAll(vals []interface{}) { //1\n\tfor _, val := range vals {\n\t\tfmt.Println(val)\n\t}\n}\n\nfunc main(){\n\tnames := []string{\"stanley\", \"david\", \"oscar\"}\n\tprintAll(names)\n}\n```\n\n上面的代码是按照我们的假设修改的，执行之后竟然会报  `cannot use names (type []string) as type []interface {} in argument to printAll `  错误，why？\n\n这个错误说明 go 没有帮助我们自动把 slice 转换成 `interface{}` 类型的 slice，所以出错了。**go 不会对 类型是`interface{}` 的 slice 进行转换** 。为什么 go 不帮我们自动转换，一开始我也很好奇，最后终于在 go 的 wiki 中找到了答案 https://github.com/golang/go/wiki/InterfaceSlice 大意是 `interface{}` 会占用两个字长的存储空间，一个是自身的 methods 数据，一个是指向其存储值的指针，也就是 interface 变量存储的值，因而 slice []interface{} 其长度是固定的`N*2`，但是 []T 的长度是`N*sizeof(T)`，两种 slice 实际存储值的大小是有区别的(文中只介绍两种 slice 的不同，至于为什么不能转换猜测可能是 runtime 转换代价比较大)。\n\n但是我们可以手动进行转换来达到我们的目的。\n\n```go\nvar dataSlice []int = foo()\nvar interfaceSlice []interface{} = make([]interface{}, len(dataSlice))\nfor i, d := range dataSlice {\n\tinterfaceSlice[i] = d\n}\n```\n\n## 5、interface 的实现者的 receiver 如何选择\n\n在我们上文的例子中调用 f 是 `f(&s)` 也就是 S 的指针类型，为什么不能是 `f(s)` 呢，如果是 s 会有什么问题？改成 f(s) 然后执行代码。\n\n```shell\ncannot use s (type S) as type I in argument to f:\n\tS does not implement I (Set method has pointer receiver)\n```\n\n这个错误的意思是 S 没有实现 I，哪里出了问题？**关键点是 S 中 set 方法的 receiver 是个 pointer *S** 。\n\ninterface 定义时并没有严格规定实现者的方法 receiver 是个 value receiver 还是 pointer receiver，上面代码中的 S 的 Set receiver 是 pointer，也就是实现 I 的两个方法的 receiver 一个是 value 一个是 pointer，使用 `f(s)`的形势调用，传递给 f 的是个 s 的一份拷贝，在进行 s 的拷贝到 I 的转换时，s 的拷贝不满足 Set 方法的 receiver 是个 pointer，也就没有实现 I。**go 中函数都是按值传递即 passed by value**。\n\n那反过来会怎样，如果 receiver 是 value，函数用 pointer 的形式调用？\n\n```go\ntype I interface {\n\tGet() int\n\tSet(int)\n}\n\ntype SS struct {\n\tAge int\n}\n\nfunc (s SS) Get() int {\n\treturn s.Age\n}\n\nfunc (s SS) Set(age int) {\n\ts.Age = age\n}\n\nfunc f(i I) {\n\ti.Set(10)\n\tfmt.Println(i.Get())\n}\n\nfunc main(){\n  \tss := SS{}\n\tf(&ss) //ponter\n\tf(ss)  //value\n}\n```\n\nI 的实现者 SS 的方法 receiver 都是 value receiver，执行代码可以看到无论是 pointer 还是 value 都可以正确执行。\n\n导致这一现象的原因是什么？\n\n如果是按 pointer 调用，go 会自动进行转换，因为有了指针总是能得到指针指向的值是什么，如果是 value 调用，go 将无从得知 value 的原始值是什么，因为 value 是份拷贝。**go 会把指针进行隐式转换得到 value，但反过来则不行**。\n\n对于 receiver 是 value 的 method，任何在 method 内部对 value 做出的改变都不影响调用者看到的 value，这就是按值传递。\n\n另一个说明上述现象的例子是这样的来自 https://play.golang.org/p/TvR758rfre\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype Animal interface {\n\tSpeak() string\n}\n\ntype Dog struct {\n}\n\nfunc (d Dog) Speak() string {\n\treturn \"Woof!\"\n}\n\ntype Cat struct {\n}\n\n//1\nfunc (c *Cat) Speak() string {\n\treturn \"Meow!\"\n}\n\ntype Llama struct {\n}\n\nfunc (l Llama) Speak() string {\n\treturn \"?????\"\n}\n\ntype JavaProgrammer struct {\n}\n\nfunc (j JavaProgrammer) Speak() string {\n\treturn \"Design patterns!\"\n}\n\nfunc main() {\n\tanimals := []Animal{Dog{}, Cat{}, Llama{}, JavaProgrammer{}}\n\tfor _, animal := range animals {\n\t\tfmt.Println(animal.Speak())\n\t}\n}\n\n```\n\n`#1` Cat 的 speak receiver 是 pointer，interface Animal 的 slice，Cat 的值是一个 value，同样会因为 receiver 不一致而导致无法执行。\n\n## 参考资料\n\n- https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/02.6.md\n- http://jordanorelli.com/post/32665860244/how-to-use-interfaces-in-go\n- https://tour.golang.org/methods/15\n- https://www.miek.nl/go/#interfaces\n- https://github.com/golang/go/wiki/InterfaceSlice\n- https://play.golang.org/p/TvR758rfre\n- https://golang.org/doc/effective_go.html#interfaces\n- http://en.wikipedia.org/wiki/Duck_typing\n\n## 文中用到的代码\n\n[点击下载源码包](https://gist.github.com/zhyq0826/bda38dd5525c0157829bc574e742463c/archive/b3d1a53050dca568767b0efdb83968e67a9c6461.zip)\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\n//1\ntype I interface {\n    Get() int\n    Set(int)\n}\n\n//2\ntype S struct {\n    Age int\n}\n\nfunc (s S) Get() int {\n    return s.Age\n}\n\nfunc (s *S) Set(age int) {\n    s.Age = age\n}\n\ntype SS struct {\n    Age int\n}\n\nfunc (s SS) Get() int {\n    return s.Age\n}\n\nfunc (s SS) Set(age int) {\n    s.Age = age\n}\n\n//3\nfunc f(i I) {\n    i.Set(10)\n    fmt.Println(i.Get())\n}\n\ntype R struct{ i int }\n\nfunc (p *R) Get() int  { return p.i }\nfunc (p *R) Set(v int) { p.i = v }\n\nfunc doSomething(v interface{}) {\n    fmt.Println(\"doSomething called\")\n}\n\nfunc printAll(vals []interface{}) {\n    for _, val := range vals {\n        fmt.Println(val)\n    }\n}\n\ntype Animal interface {\n    Speak() string\n}\n\ntype Dog struct {\n}\n\nfunc (d Dog) Speak() string {\n    return \"Woof!\"\n}\n\ntype Cat struct {\n}\n\nfunc (c *Cat) Speak() string {\n    return \"Meow!\"\n}\n\ntype Llama struct {\n}\n\nfunc (l Llama) Speak() string {\n    return \"?????\"\n}\n\ntype JavaProgrammer struct {\n}\n\nfunc (j JavaProgrammer) Speak() string {\n    return \"Design patterns!\"\n}\n\nfunc main() {\n    s := S{}\n    f(&s) //4\n\n    ss := SS{}\n    f(&ss) //ponter\n    f(ss)  //value\n\n    var i I\n    i = &s\n    fmt.Println(i.Get())\n\n    if _, ok := i.(*S); ok {\n        fmt.Println(\"i store *S\")\n    }\n\n    switch t := i.(type) {\n    case *S:\n        fmt.Println(\"i store *S\", t)\n    case *R:\n        fmt.Println(\"i store *R\", t)\n    }\n\n    doSomething(&s)\n\n    names := []string{\"stanley\", \"david\", \"oscar\"}\n    vals := make([]interface{}, len(names))\n    for index, value := range names {\n        vals[index] = value\n    }\n    // printAll(names)\n    printAll(vals)\n\n    //cannot use Cat literal (type Cat) as type Animal in array or slice literal:\n    // Cat does not implement Animal (Speak method has pointer receiver)\n    //\n    // animals := []Animal{Dog{}, Cat{}, Llama{}, JavaProgrammer{}}\n    // for _, animal := range animals {\n    //  fmt.Println(animal.Speak())\n    // }\n}\n```\n\n**更多阅读**\n\n详解 Go interface 系列\n- [go-interface-1](/blog/go-interface-1)\n- [go-interface-2](/blog/go-interface-2)\n- [go-interface-3](/blog/go-interface-3)\n- [go-interface-4](/blog/go-interface-4)","src/content/posts/how-to-understand-go-interface.mdx","23d5bbfd71cb1355","how-to-understand-go-interface.mdx","linux-kernel-sys",{"id":757,"data":759,"body":764,"filePath":765,"digest":766,"legacyId":767,"deferredRender":22},{"title":760,"summary":761,"date":762,"tags":763,"group":706,"featured":38},"如何修改 linux 内核参数","转自 http://blog.csdn.net/WanGong/article/details/49862953",["Date","2018-03-01T00:00:00.000Z"],[],"转自 http://blog.csdn.net/WanGong/article/details/49862953\n\nLinux在系统运行时修改内核参数(/proc/sys与/etc/sysctl.conf)，而不需要重新引导系统，这个功能是通过/proc虚拟文件系统实现的。\n\n在/proc/sys目录下存放着大多数的内核参数，并且设计成可以在系统运行的同时进行更改, 可以通过更改/proc/sys中内核参数对应的文件达到修改内核参数的目的(修改过后，保存配置文件就马上自动生效)，不过重新启动机器后之前修改的参数值会失效，所以只能是一种临时参数变更方案。适合调试内核参数优化值的时候使用，如果设置值有问题，重启服务器还原原来的设置参数值了。\n \n但是如果调试内核参数优化值结束后，需要永久保存参数值，就要通过修改/etc/sysctl.conf内的内核参数来永久保存更改。但只是修改sysctl文件内的参数值，确认保存修改文件后，设定的参数值并不会马上生效，如果想使参数值修改马上生效，并且不重启服务器，可以执行下面的命令：\n```\nsysctl –p\n```\n \n下面介绍一下/proc/sys下内核文件与配置文件sysctl.conf中变量的对应关系：\n由于可以修改的内核参数都在/proc/sys目录下，所以sysctl.conf的变量名省略了目录的前面部分（/proc/sys）。\n \n即将/proc/sys中的文件转换成sysctl中的变量依据下面两个简单的规则:\n- 去掉前面部分/proc/sys\n- 将文件名中的斜杠变为点\n\n这两条规则可以将/proc/sys中的任一文件名转换成sysctl中的变量名，例如：\n```\n/proc/sys/net/ipv4/ip_forward ＝> net.ipv4.ip_forward\n/proc/sys/kernel/hostname => kernel.hostname\n```\n \n可以使用下面命令查询所有可修改的变量名 \n\n```\nsysctl –a\n```","src/content/posts/linux-kernel-sys.mdx","d1242a5a393d0ed2","linux-kernel-sys.mdx","kubernetes-tutorial-for-beginner",{"id":768,"data":770,"body":776,"filePath":777,"digest":778,"legacyId":779,"deferredRender":22},{"title":771,"summary":772,"date":773,"tags":774,"group":775,"featured":38},"一个小时学会搭建和使用 kubernetes","本文是一个面向 kubernetes 初学者的教程，是我作为一名开发者在开始使用和理解 kubernetes 一点经验总结，它包含两部分，第一部分介绍使用 kubeadm 搭建一个 kubernetes 集群，第二部分使用 kubernetes 部署一个包含多个组件的应用程序，通...",["Date","2019-05-17T00:00:00.000Z"],[775],"kubernetes","本文是一个面向 kubernetes 初学者的教程，是我作为一名开发者在开始使用和理解 kubernetes 一点经验总结，它包含两部分，第一部分介绍使用 kubeadm 搭建一个 kubernetes 集群，第二部分使用 kubernetes 部署一个包含多个组件的应用程序，通过这两部分初学者基本能够理解 kubernetes 的组成以及应用。\n\n作为一个开发者，为什么要了解 kubernetes？因为 kubernetes 做到了让应用的开发、部署、运维整个流程无缝连接，应用的整个生命周期管理从未像现在这样如此贴近一个开发者，对此我只能说很爽很强大。为了简述方便，下文把 kubernetes 统称为 k8s。\n\n# 第一部分，使用 kubeadm 搭建 k8s\n\nk8s 的安装很复杂，搭建高可用的 k8s 集群尤其复杂，本文介绍的 k8s 安装方式是基于官方的工具 kubeadm 完成的，虽然 kubeadm 现在还在开发当中，相信不久的将来 kubeadm 会变成一个真正构建 k8s 集群的标准工具。\n\n\n## 1. 机器准备\n\n\n准备相互连通的三台 linux ，虽然 kubeadm 支持在单节点部署一个 k8s 集群，但是为了能做到真正演示 k8s 集群工作原理，建议使用多个节点。这里我使用的三台云服务机器，基于 Ubuntu 16.04，这也是基于 Ubuntu linux 搭建 k8s 的最低版本。这里三台机器分别是 ubuntu@node1、ubuntu@node2、ubuntu@node3，并且关闭三个节点的 swap。\n\n## 2. 准备 docker\n\n\nk8s 本质上一个容器编排工具，所以容器是 k8s 运作的前提，k8s 支持各种容器运行时，这里我们使用 docker。在 Ubuntu 上安装 docker 参见官方文档 https://docs.docker.com/install/linux/docker-ce/ubuntu/ 。\n\n由于 docker 官方镜像在国内访问特别的慢，docker 环境准备完成之后请配置国内的加速镜像：\n\n```bash\ntee /etc/docker/daemon.json \u003C\u003C-'EOF'\n{\n  \"registry-mirrors\": [\"https://registry.docker-cn.co\"]\n}\nEOF\n\n```\n\n如果提示权限不足，请使用 sudo 命令或 root 用户。\n\n## 3. 安装 k8s 的基础组件\n\n安装 k8s 的最低要求见 https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#before-you-begin :\n- 要求 2CPU 和 2 GB\n- 不能启用 swap\n- 外网可通\n- ...\n\n任选一台机器作 k8s master 节点，后面所有的安装如果没有特殊标明都在 master 上执行，使用 sudo 命令或 root 用户依次执行下面的命令完成以下各个组件的安装，这里我们使用阿里云的 k8s 源进行安装:\n\n```bash\napt-get update && apt-get install -y apt-transport-https\ncurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - \ncat \u003C\u003CEOF >/etc/apt/sources.list.d/kubernetes.list\ndeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\nEOF\napt-get update\napt-get install -y kubelet kubeadm kubectl\n\n\nsystemctl daemon-reload\nsystemctl restart kubelet\n```\n\n这里简单介绍一下这三个组件的作用：\n\n- kubelet 是 work node 节点负责 Pod 生命周期状态管理以及和 master 节点交互的组件\n- kubectl k8s 的命令行工具，负责和 master 节点交互\n- kubeadm 搭建 k8s 的官方工具\n\n## 4. 安装 k8s 依赖的各种镜像\n\n使用 root 执行下面命令\n\n```bash\nkubeadm init --image-repository=gcr.akscn.io/google_containers --pod-network-cidr=192.168.0.0/16\n```\n\n这里我们通过 `--image-repository` 指定了一个国内的镜像，因为 google 官方镜像被国内无法访问，并且指定了 `--pod-network-cidr` 网络情况，这是因为后面我们的组件使用的是 `Calico`这个网络组件，所有这些都不用去在乎它们是什么，只要先按部就班的安装。\n\n安装完成之后会有如下的输出：\n\n```bash\n....\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 10.10.76.89:6443 --token t51nk2.4rtw6twkmca53nbu \\\n    --discovery-token-ca-cert-hash sha256:8356397a4ccd20b2d6506130e8bb4ad13ccc3fe33302296d3c48651601be5bfd\n\n```\n\n按照提示你应该再继续执行以下操作：\n- 让 k8s 的命令可以在非 root 用户下执行\n- 安装 k8s 的网络组件\n\n所以你要记住上面输出的提示操作，找个地方把他们存下来。\n\n## 5. 让非 root 用户可以使用 k8s\n\n```bash\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n为了能够在 worker 节点也可以使用 kubectl 命令，建议再 worker node 加入集群之后，把 `$HOME/.kube/config` 文件也复制一份到 worker node 节点。\n\n\n## 6. 安装 Calico 网络组件\n\nk8s 的网络组件非常多，为了演示方便我们使用 Calico:\n\n\n```bash\nkubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml\nkubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml\n```\n\n安装完成之后检查 corndns :\n\n```bash\nkubectl get pods --all-namespaces\n\n```\n\n确保所有的 STATUS 都是 running 说明安装成功\n\n## 7. 加入 worker node\n\n在上面 kubeadm init 命令的输出中有加入节点的命令:\n\n```bash\n\nkubeadm join 10.10.76.89:6443 --token t51nk2.4rtw6twkmca53nbu \\\n    --discovery-token-ca-cert-hash sha256:8356397a4ccd20b2d6506130e8bb4ad13ccc3fe33302296d3c48651601be5bfd\n\n```\n\n这个 token 是必须的，而且 token 的有效期是 24 小时，分别在其它被选为 work node 的节点执行这个加入命令，token 的获取和使用参考 https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-token/\n\n\n执行完成之后，在 master 节点执行 `kubectl get nodes`，会看到如下输出，说明其他节点加入成功:\n```bash\nNAME           STATUS   ROLES    AGE    VERSION\n10-10-158-97   Ready    \u003Cnone>   2d2h   v1.14.1\n10-10-23-227   Ready    \u003Cnone>   2d2h   v1.14.1\n10-10-76-89    Ready    master   2d2h   v1.14.1\n```\n\n查看组成 k8s 的组件:\n\n```bash\n$ kubectl get pods --namespace=kube-system \nNAME                                  READY   STATUS    RESTARTS   AGE\ncalico-node-9vrt4                     2/2     Running   0          2d22h\ncalico-node-rklrf                     2/2     Running   0          2d22h\ncalico-node-wb7ln                     2/2     Running   0          2d22h\ncoredns-9846cf96-dblrm                1/1     Running   2          2d22h\ncoredns-9846cf96-x7z7l                1/1     Running   2          2d22h\netcd-10-10-76-89                      1/1     Running   2          2d22h\nkube-apiserver-10-10-76-89            1/1     Running   0          2d22h\nkube-controller-manager-10-10-76-89   1/1     Running   0          2d22h\nkube-proxy-2nbm6                      1/1     Running   0          2d22h\nkube-proxy-vvdpk                      1/1     Running   0          2d22h\nkube-proxy-whjqt                      1/1     Running   0          2d22h\nkube-scheduler-10-10-76-89            1/1     Running   0          2d22h\n```\n\n可以看到 k8s 主要有以下核心组组件组成:\n\n- etcd 保存了整个集群的状态；\n- apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制；\n- controller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；\n- scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上；\n- kubelet 负责维护容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理；\n- Container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI）；\n- kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡\n\n# 第二部分，使用 k8s 部署一个完整应用\n\n我们将使用刚才搭建的 k8s 集群部署一个完整的应用，这个应用包含三个组件：一个用 ember 构建的前端 APP，一个用 Python 构建的后端 APP，一个 redis 用作存储节点，组成如下：\n\n![](https://static.git-star.com/k8s-app-tutorial-architecture.png)\n\n为了演示 k8s 强大的能力，在这个应用中，三个 APP 彼此是不知道对方的存在的，也就是我们需要让三个 APP 通过网络能够相互发现对方并取得连接，这样即使他们的 IP 发生变动也不会影响他们之间的交互。\n\n\n## 1. k8s 的基础概念解释\n\nk8s 是通过一个个声明式的资源对象来完成对应用管理的，为了能够覆盖完整的应用生命周期管理，k8s 提供了很多资源对象:\n\n- Autoscaling (HPA)\n- ConfigMap\n- CronJob\n- CustomResourceDefinition\n- DaemonSet\n- Deployment\n- Ingress\n- Job\n- LocalVolume\n- Namespace\n- NetworkPolicy\n- Node\n- PersistentVolume\n- Pod\n- PodPreset\n- ReplicaSet\n- Resource Quota\n- Secret\n- SecurityContext\n- Service\n- ServiceAccount\n- StatefulSet\n- Volume\n\n在这个演示中我们要用到以下几种资源:\n\n**Pod**\n\nPod 是一组紧密关联的容器集合，它们共享 IPC、Network 和 UTS namespace，是 Kubernetes 调度的基本单位。Pod 的设计理念是支持多个容器在一个 Pod 中共享网络和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。可以把 Pod 理解为共享资源的一个或一组进程\n\n\n**Deployment**\n\nDeployment 为 Pod 和 ReplicaSet 提供了一个声明式定义 (declarative) 方法，借用 Deployment 可以完成:\n\n- 创建 Pod 和 ReplicaSet\n- 扩容和缩容\n- 暂停和继续 Deployment\n\n**Namespace**\n\nNamespace 是对一组资源和对象的抽象集合，比如可以用来将系统内部的对象划分为不同的项目组或用户组，默认的 Namespace 是 default。\n\n\n**Service**\n\nService 是对一组提供相同功能的 Pods 的抽象，并为它们提供一个统一的入口。借助 Service，应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。Service 通过标签来选取服务后端，一般配合 Deployment 来保证后端容器的正常运行。\n\n\n## 2. 创建一个 front-end Pod 尝鲜\n\n为了演示方便，我已经在仓库 https://github.com/zhyq0826/kubernetes-tutorial-app 中创建好了 Pod，cd 进入 kubernetes-tutorial-app/step-one，获取我们要创建的 Pod。  k8s 采用声明式的定义，这样方便维护而且容易追溯。\n\n启动一个 Pod 非常简单:\n```bash\nkubectl apply -f ember-app-pod.yaml\n```\n\n然后观察 Pod 的启动情况:\n```bash\nkubectl get pods\n```\n如果能看到容器的状态是 running 说明正确启动了。\n\n创建 Pod 如此简单，我们看一下如何定义 Pod:\n\n```yaml\napiVersion: v1\nkind: Pod                  # 创建的资源类型 pod\nmetadata:\n  name: ember-app          # 资源名称\n  labels:\n    app: ember-app         # pod 标签 用在 service 中进行筛选                         \nspec:                                                \n  containers:\n    - image: zhyq0826/nginx:k8s-ember-app   # 镜像名称 来自 docker hub 公开镜像                          \n      name: ember-app     # pod container 的名称            \n      ports:\n        - containerPort: 80   # 容器监控 port\n```\n这个文件定义了一个 Pod， 这个 Pod 中包含了一个容器，是一个已经做好的 nginx 镜像，这里打包了我们要演示的 front-app，需要注意的是这里我们为 Pod 打上了一个 label: `app=ember-app` ，这个 label 将在下一步我们创建 service 的时候派上用场。\n\n\n这个容器并不能访问，容器只在它内部通过 nginx 监听了 80 端口，如果想让容器可以外部访问，我们需要把容器的端口映射到外部，比如可以像这样:\n```bash\nkubectl port-forward ember-app 88:80\n```\n这个命令的意思把 Pod ember-app 的 80 端口和本机的 88 端口进行映射，然后再通过下面的命令访问容器内的应用:\n```bash\ncurl localhost:88 \n```\n\n## 3. 通过 Service 访问 Pod\n\n在 2 中我们创建了一个 Pod，为了演示 Service 作为负载均衡的特性，我们再创建一个 Pod:\n```bash\nkubectl apply -f ember-app-pod2.yaml\n```\n这样我们就有两个 Pod 了，这两个 Pod 除了名字不同以外，其他都是一样的。\n\n现在我们创建一个 Service 用来访问刚才我们创建的两个 Pod:\n```bash\nkubectl create -f ember-app-service.yaml\n```\n\n这两个文件可以在 `kubernetes-tutorial-app/step-one/` 中找到。\n\n创建 Service 之后我们查看一下 Service:\n```bash\nkubectl get service ember-app-service\nember-app-service   LoadBalancer   10.101.206.188   \u003Cpending>     80:30537/TCP   21h\n```\n\nService 成功启动，然后用 curl 检查我们的服务 `curl 10.101.206.188` 能够访问说明我们的服务启动成功了。\n\n\nService 的作用就是生成一个 proxy 可以动态根据 Pod 的 label 路由的对应的 Pod，查看 Service 的文件定义可以看到:\n```yaml\napiVersion: v1\nkind: Service              # 资源类型\nmetadata:\n  name: ember-app-service\nspec:\n  type: LoadBalancer      # service 类型 有 4 种类型 \n  ports:\n  - port: 80           # service 监听端口 service 类型 是  loadBalance 会在 node 节点暴露一个 port 和 此处的 port 不同 随机的\n    protocol: TCP      # 协议  \n    targetPort: 80     # 目标端口 \n  selector:                \n    app: ember-app     # label 定义的 service 根据 app: ember-app 这个 label 寻找 pod\n```\n\n我们指定了 Service 的 selector 和 Pod 的 label 一样，这是 Service 能够正确访问两个 Pod 的关键，Service 根据 selector 提供的 label 来过滤具有相同 label 的 Pod。\n\n\n![](https://static.git-star.com/k8s-tutorial-app-service.png)\n\n\n## 4. 使用 Deployment 部署 Pod\n\n虽然可以直接使用 Pod 部署应用，但并不是推荐的方式，因为 Pod 自己无法扩容，无法在故障时自动转移，为此 k8s 提供了 Deployment 来实现 Pod 的高可用部署。\n\n在 Deployment 中可以根据自己的需要配置 Pod 的数量，Pod 的升级方式，Pod 故障转移方式等等:\n```yaml\napiVersion: extensions/v1beta1\nkind: Deployment                                          # 资源类型\nmetadata:\n  name: ember-app-deployment\nspec:\n  replicas: 2                                             # pod 副本数量\n  minReadySeconds: 15\n  strategy:\n    type: RollingUpdate                                   # 部署策略 滚动升级\n    rollingUpdate: \n      maxUnavailable: 1                                   # 在升级过程中最多允许几个 pod 不可用\n      maxSurge: 1                                         # 升级过程中允许最多添加几个 pod, 如果 副本是 2 升级过程中要保证可用一直是 2 必须要再加一个 pod\n  template:                                               # 定义 deploy 使用 pod\n    metadata:\n      labels:\n        app: ember-app                                  #  模板定的 pod 的 label 根据这个 label 生成 service\n    spec:                                               # spec 相当于 step-one 中的 pod\n      containers:\n        - image: zhyq0826/nginx:k8s-ember-app\n          imagePullPolicy: Always                         # 镜像策略\n          name: ember-app\n          ports:\n            - containerPort: 80\n```\n\n进入 `kubernetes-tutorial-app/step-two` 目录，然后创建 Deployment:\n```bash\nkubectl apply -f ember-app-deployment.yaml\n```\n\n查看 Pod 可以看到这个 Deployment 启动了两个 Pod:\n```bash\nkubectl get pods\nNAME                                     READY   STATUS    RESTARTS   AGE\nember-app-deployment-f4cb9594b-9xpzz     1/1     Running   0          1m\nember-app-deployment-f4cb9594b-s8bvm     1/1     Running   0          1m\n```\n\n## 5. 构建完整的应用\n\n到目前为止，你已经知道了如何使用 Deployment 创建高可用的应用，并且知道用 Service 来为 Pod 提供供内部集群访问的能力，接下来我们就把我们要部署的后端应用全部部署。\n\n进入 `kubernetes-tutorial-app/step-three` 可以看到:\n\n```bash\n.\n├── ember-app-deployment.yaml\n├── ember-app-service.yaml\n├── python-app-deployment.yaml\n├── python-app-service.yaml\n├── redis-deployment.yaml\n└── redis-service.yaml\n```\n\n可以看到这里我准备了三个 Deployment 和 三个 Service，分别对应着即将要部署的三个应用，并且在 python-app-deployment.yaml 中通过环境变量为 python-app 提供了 redis 的地址:\n\n```yaml\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: python-app-deployment\nspec:\n  replicas: 2\n  minReadySeconds: 15\n  strategy:\n    type: RollingUpdate\n    rollingUpdate: \n      maxUnavailable: 1\n      maxSurge: 1 \n  template:\n    metadata:\n      labels:\n        app: python-app\n    spec:\n      containers:\n        - image: zhyq0826/python:k8s-python-app\n          imagePullPolicy: Always\n          name: python-app\n          ports:\n            - containerPort: 5000\n          env:\n            - name: REDIS_HOST\n              value: redis-service.default.svc.cluster.local   # 利用 k8s 提供的默认 dns 解析，发现 redis 服务\n```\n\nRedis 这个 `redis-service.default.svc.cluster.local` 服务发现功能是通过 k8s 提供的默认的 DNS 就系完成的，组成方式是 `$service_name.$namespace.svc.cluster.local` ，由于在没有指定 namespace 的时候，默认是 default。DNS 解析可以在 python-app Pod 中查看:\n\n```bash\n$ kubectl exec -it python-app-deployment-7b64859cd9-stjpt cat /etc/resolv.conf\nnameserver 10.96.0.10\nsearch default.svc.cluster.local svc.cluster.local cluster.local\noptions ndots:5\n```\n\n可以看到对应的 DNS server 是 10.96.0.10 :\n\n```bash\n$ kubectl get service  --namespace=kube-system\nNAME           TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)                  AGE\ncalico-typha   ClusterIP   10.111.6.44   \u003Cnone>        5473/TCP                 2d13h\nkube-dns       ClusterIP   10.96.0.10    \u003Cnone>        53/UDP,53/TCP,9153/TCP   2d13h\n```\n\n正好是 kube-dns 的地址。\n\n把目录中所有的 Deployment 和 Service 执行完毕，依次执行 `kubectl apply -f *.yaml` 即可，执行完毕之后，一个完整的应用就组成了。由于我们希望 front-app 可以被用户所访问，所以 ember-app-service 的网络类型是 NodePort，也就是在每个节点会启动一个监听端口把所有外部访问的请求转发到 Service 的监听端口，也就完成了 Service 可以被外部网络所访问。\n\n 而 ember-app 由于要访问 python-app ，作为一个前端应用他需要一个可以访问 python-app 的外部地址，为了可以让 ember-app 总是能访问到 python-app 我们在 python-app-service.yaml 中指定主机要绑定的端口 NodePort 32500，这里为了演示方便直接让 python-app 暴露出来，生成环境会把 python-app 挂在 nginx 这种反向代理后面:\n\n```yaml\napiVersion: v1\nkind: Service              # 资源类型\nmetadata:\n  name: python-app-service\nspec:\n  type: NodePort      # service 类型 有 4 种类型 \n  ports:\n  - port: 5000           # service 监听端口 集群内部访问\n    protocol: TCP      # 协议  \n    targetPort: 5000     # 目标端口\n    nodePort: 32500       # 暴露给外部访问  The range of valid ports is 30000-32767\n  selector:                \n    app: python-app     # label 定义的 service 根据 app: python-app 这个 label 寻找 pod%   \n```\n\n这样 ember-app 中就可以通过这个固定的端口访问到 python-app 了:\n\n```javascript\n$.post(`${window.location.protocol}//${window.location.hostname}:${config.backendport}`+'/login', {\"username\": this.username}, (data)=>{\n                this.set('msg', `${data.name} ${data.msg} ${data.count}`)\n            })\n```\n\n最后让我们看一眼我们的应用：\n\n![](https://static.git-star.com/k8s-tutorial-app-show.gif?a=aaa)\n\n这个应用的功能很简单，每次把用户的登陆次数加一存储在 redis 中，并且显示到前端。\n\n## 6. 简单回顾\n\nk8s 让应用的整个部署和维护变得非常简单，而且是第一次让一个开发可以如此便捷的部署自己的应用程序，k8s 的安装如果没有 kubeadm 这样的工具将非常复杂，生成环境使用一定要搭建高可用的 k8s 集群，也就是由多个 etcd 节点和多个 master 节点组成，详细可参考官网 https://kubernetes.io/docs/setup/independent/high-availability/ \n\nk8s 使用声明式的 API 来管理和创建各种资源对象，相比命令式的更容易维护和变更。\n\n参考文章：\n\n- https://kubernetes.feisky.xyz/\n- https://kubernetes.io/\n\n文中涉及的应用完整代码见 https://github.com/zhyq0826/kubernetes-tutorial-app  你可以在你的 k8s 集群中使用他们。\n\n文中 k8s 集群基于 v1.14.1 版本。","src/content/posts/kubernetes-tutorial-for-beginner.mdx","2e4af07292e98b62","kubernetes-tutorial-for-beginner.mdx","md5-intro",{"id":780,"data":782,"body":788,"filePath":789,"digest":790,"legacyId":791,"deferredRender":22},{"title":783,"summary":784,"date":785,"tags":786,"group":78,"featured":38},"说说 MD5","# 什么是 MD5",["Date","2017-09-19T00:00:00.000Z"],[787],"MD5","# 什么是 MD5\n\nMD5 全称是  Message-Digest Algorithm，是一种密码散列函数，可产生一种128位（16字节）的散列值（hash value），MD5 常用于校验数据的完整性以及生成唯一的数据摘要信息。\n\n由于 MD5 被证明无法防止碰撞，也就是会出现两个不一样的数据采用 MD5 加密之后生成相同的摘要，为了的使用场景中提高碰撞的几率，一般会加入一些随机数来保证碰撞的可能性尽可能低。\n\n一般128位的MD5散列被表示为32位十六进制数字。\n\n```python\n>>> import md5\n>>> MD5.new('a').hexdigest()\n'0cc175b9c0f1b6a831c399e269772661'\n```\n\n# 何时使用 MD5\n\nMD5 可以用检验数据的完整性和一致性，因而可以利用 MD5 的这种特点来标识数据的唯一性，在实际开发中 MD5 常被用来\n\n1.爬虫系统中标识 URL 的唯一性\n\n```python\ndef hash_url(url):\n    url = url.strip()\n    url = urllib.unquote(url)\n    try:\n        return hashlib.md5(str(url)).hexdigest()\n    except Exception as e:\n        return hashlib.md5(url.encode('utf-8')).hexdigest()\n```\n\n上面的这段函数可以把爬虫抓取的页面的 URL 进行 MD5 之后存储便于进行唯一性校验，处理 url 之前注意要进行空格过滤和解码，保证数据的前后一致性。\n\n\n2.需要唯一性的其他地方\n\n只要涉及需要唯一性的地方都可以尝试使用 MD5，如果某些场景或业务数据量非常大，需要注意对碰撞的检测。","src/content/posts/md5-intro.mdx","289ac0ae65de61a0","md5-intro.mdx","mac-k8s",{"id":792,"data":794,"body":800,"filePath":801,"digest":802,"legacyId":803,"deferredRender":22},{"title":795,"summary":796,"date":797,"tags":798,"group":775,"featured":38},"在 mac 上搭建一个好用的 k8s 集群","平时开发都在 mac，需要一个可以随意折腾的本地的 k8s 环境，一开始用的是 minikube，但是这个东西在我的 mac 和公司的 mac 上表现不同，最后折腾了一遍还是虚拟机比较合适。",["Date","2019-07-07T00:00:00.000Z"],[799],"环境","平时开发都在 mac，需要一个可以随意折腾的本地的 k8s 环境，一开始用的是 minikube，但是这个东西在我的 mac 和公司的 mac 上表现不同，最后折腾了一遍还是虚拟机比较合适。\n\nmac 上 virtualbox 已经非常好用了，而且免费，推荐使用. 装上 mac 之后，安装一个 ubuntu server 的镜像，系统配置要求最低 2GB，2CPU. 配置网卡 1 为桥接网卡为了和主机通信，网卡 2 为 网络地址转换为了和外网通信。\n\n首先在虚拟机中安装好 docker，具体见 https://yeasy.gitbooks.io/docker_practice/install/ubuntu.html，注意安装时把 ubuntu 的源替换成国内的源 http://mirrors.aliyun.com/ubuntu。\ndocker 安装好之后配置成国内的 docker 源，`sudo vi /etc/docker/daemon.json` 输入以下内容：\n```json\n{\n  \"registry-mirrors\": [\n    \"https://dockerhub.azk8s.cn\",\n    \"https://reg-mirror.qiniu.com\"\n  ]\n}\n```\n\n然后重启 docker：\n```bash\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n切换到 root 用户，禁止系统开启 swap:\n```bash\nvi /etc/fstab\n```\n注释掉 swap，手动关闭已经开启的 swap `swapoff -a`，执行以下命令安装好基础组件:\n```bash\napt-get update && apt-get install -y apt-transport-https\ncurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - \ncat \u003C\u003CEOF >/etc/apt/sources.list.d/kubernetes.list\ndeb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\nEOF\napt-get update\napt-get install -y kubelet kubeadm kubectl\n\nsystemctl daemon-reload\nsystemctl restart kubelet\n```\n\n然后使用如下镜像安装 k8s:\n```bash\nkubeadm init --image-repository=gcr.azk8s.cn/google_containers \n```\n\n切换到普通用户，拷贝相应的证书让 k8s 可以让普通用户访问:\n```bash\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n接着安装网络组件:\n```bash\nkubectl apply -f https://git.io/weave-kube-1.6\n```\n\n安装 dashboard 插件 https://github.com/kubernetes/dashboard:\n```bash\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml\n```\n注意：如果不成功，从仓库中下载 yaml 文件修改镜像的地址为 `gcr.azk8s.cn/google_containers`\n\n安装存储插件 https://rook.io/docs/rook/v1.0/ceph-quickstart.html:\n```bash\ncd cluster/examples/kubernetes/ceph\nkubectl create -f common.yaml\nkubectl create -f operator.yaml\nkubectl create -f cluster-test.yaml\n```\n注意：如果不成功，从仓库中下载 yaml 文件修改镜像的地址为 `gcr.azk8s.cn/google_containers`\n\n\n安装完毕之后检查集群状态:\n```bash\nzhyq@dev:~$ kubectl get pods -n kube-system \nNAME                                  READY   STATUS    RESTARTS   AGE\ncoredns-cf8fb6d7f-5m6pc               1/1     Running   2          7d19h\ncoredns-cf8fb6d7f-dgl7m               1/1     Running   2          7d19h\netcd-dev                              1/1     Running   3          7d19h\nkube-apiserver-dev                    1/1     Running   3          7d19h\nkube-controller-manager-dev           1/1     Running   3          7d19h\nkube-proxy-kgjth                      1/1     Running   3          7d19h\nkube-scheduler-dev                    1/1     Running   3          7d19h\nkubernetes-dashboard-fcfb4cbc-9n59k   1/1     Running   0          9m18s\nweave-net-d6pbh                       2/2     Running   6          7d19h\n\nzhyq@dev:~$ kubectl get pods -n rook-ceph \nNAME                                  READY   STATUS        RESTARTS   AGE\nrook-ceph-agent-82f9n                 1/1     Running       0          10m\nrook-ceph-detect-version-rpv99        0/1     Terminating   0          10s\nrook-ceph-operator-56b7cdb77b-xs8zn   1/1     Running       0          2d22h\nrook-discover-9vlj8                   1/1     Running       0          10m\n```\n\n让主节点接受 Pod 调度:\n```bash\nkubectl taint nodes --all node-role.kubernetes.io/master-\n```\n\n在 mac 本机下载 kubectl 并且加入 bin 目录，通过 ssh 拷贝上面搭建好的 k8s 的 .kube/config 到 mac 的同目录下，配置 kubectl 命令自动补全，使用 zsh：\n```bash\nsource \u003C(kubectl completion zsh)\n```\n\n在 ubuntu 配置 kubectl 命令补全：\n```bash\napt-get install bash-completion\necho 'source /usr/share/bash-completion/bash_completion' >> ~/.bashrc\necho 'source \u003C(kubectl completion bash)' >>~/.bashrc\n```\n\n\n设置虚拟机中的 k8s 为开机启动:\n```bash\nsudo systemctl enable kubelet\n```","src/content/posts/mac-k8s.mdx","5d0e36c3fdec4686","mac-k8s.mdx","microservices-api-gateway",{"id":804,"data":806,"body":813,"filePath":814,"digest":815,"legacyId":816,"deferredRender":22},{"title":807,"summary":808,"date":809,"tags":810,"group":812,"featured":38},"微服务 API Gateway 介绍","## **什么是 API Gateway?**",["Date","2018-03-24T00:00:00.000Z"],[811],"api gateway","微服务","## **什么是 API Gateway?**\n\nAPI Gateway 是微服务架构体系中的一类型特殊服务，它是所有微服务的入口，它的职责是执行路由请求、协议转换、聚合数据、认证、限流、熔断等。\n\n一个系统可以有一个或多个 API Gateway，例如\n\n\n\n![](https://static.git-star.com/api-gateway-1.png)\n\n### Gateway 职责之1: 请求路由和版本控制\n\nAPI Gateway 是微服务的入口，可以根据不同的请求路由到不同的 microservice 上，也可以在 Gateway 上进行路由的版本控制，这样即使后端 microservice 发生了变化，Gateway 的路径依然可以不改变。\n\n![](https://static.git-star.com/api-gateway-entrypoint-1.png)\n\n### Gateway 职责之2: 方便单体应用到微服务的过渡\n\n借助 Gateway 你可以很方便的在 Gateway 之后部署不同的服务，也就是可以同时存在两种不同的服务，这样可以帮助单体应用向微服务渐进式的演化。\n\n![](https://static.git-star.com/api-gateway-evolutinary-design.png)\n\n### Gateway 职责之3: 权限认证\n\n不同的服务之间常常有一些共有的逻辑需要处理，比如权限认证，由于 Gateway 恰巧在各个微服务的前端，可以在 Gateway 实现权限的认证，比如可以在 Gateway 层实现 cookie 或 token 的认证。\n\n![](https://static.git-star.com/api-gateway-auth-1.png)\n\n\n\n### Gateway 职责之4: 数据聚合\n\n由于不同的客户端往往需要的数据完全不同，而这些数据又是不同的 service 提供的，借助 Gateway 我们可以方便完成来自不同 service 的数据聚合，以达到根据不同 client 进行数据定制的目的\n\n![](https://static.git-star.com/api-gateway-aggregation-1.png)\n\n### Gateway 职责之5: 协议转换\n\n鉴于不同的团队采用的数据协议可能完全不同，Gateway 可以根据场景需要对不同的微服务之间进行协议转换。\n\n![](https://static.git-star.com/api-gateway-format-2.png)\n\n\n### Gateway 职责之6: 缓存和限流\n\nGateway 可以做限流和缓存\n\n\n## 常见的 API Gateway 开源解决方案\n\n转载自 http://www.do1618.com/archives/783/\n\n### Tyk\n\n[Github地址](https://github.com/TykTechnologies/tyk) \n\n> Go 实现，有企业版和社区版\n\n[Docker安装测试](https://tyk.io/tyk-documentation/get-started/with-tyk-on-premise/installation/docker/docker-quickstart/)\n\n### kong\n\n[Github地址](https://github.com/Mashape/kong) nginx + lua (openresty)\n\n> 当前版本：Kong 0.9.5 [文档](https://getkong.org/docs/)\n\n### api-umbrella\n\n[官网](https://apiumbrella.io/) \n\n> nginx + lua (openresty)\n\n[Github地址](https://github.com/NREL/api-umbrella)\n\n- [apiumbrella分析--Revisiting, speeding up, and simplifying API Umbrella's architecture](https://github.com/NREL/api-umbrella/issues/86)\n- [apiumbralla同类产品分析](https://github.com/NREL/api-umbrella/issues/159)\n\n### apiaxle\n\n[官网](http://apiaxle.com/) \n\n> Node.js  实现\n\n[Github地址](https://github.com/apiaxle/apiaxle)\n\n### **Netflix zuul**\n\n[GitHub地址](https://github.com/Netflix/zuul)\n\n### **WSO2 API Manager**\n\n[官网](http://wso2.com/products/api-manager/) \n\n> OpenSource， Java","src/content/posts/microservices-api-gateway.mdx","f7a504ab0270afff","microservices-api-gateway.mdx","mongodb-practice-for-four-years-md",{"id":817,"data":819,"body":826,"filePath":827,"digest":828,"legacyId":829,"deferredRender":22},{"title":820,"summary":821,"date":822,"tags":823,"group":825,"featured":38},"创业三年，使用 mongodb 的实践教训","在生产环境中使用 mongodb 始于 2012 年左右，从最初的 master-slave 模式到后来的 master-replication，到评估 mongodb-sharding 并放弃在生产环境中使用，使用 mongodb 作为基础数据库已经服务了上亿用户。在 4 年的...",["Date","2017-02-16T00:00:00.000Z"],[824],"创业","mongodb","在生产环境中使用 mongodb 始于 2012 年左右，从最初的 master-slave 模式到后来的 master-replication，到评估 mongodb-sharding 并放弃在生产环境中使用，使用 mongodb 作为基础数据库已经服务了上亿用户。在 4 年的 mongodb 生产环境使用当中，踩了很多坑也走了不少弯路，在此记录，与君共享。\n\n## No schema 并不代表没有一致性\n\nmongodb 是 nosql 数据库，强调 schema 的灵活性和强大的集群功能，以及牺牲事务带来的巨大性能提升。如果只是用 mongodb 记录日志，一致性并不是很重要，相反如果是关键性业务，鉴于 schema 极强的灵活性，经常会造成 collection 数据结构被变更而且不易察觉，表现的结果是应用程序常会出现诡异而无法深入跟踪原因的 bug 和异常。业务越庞大，这样的改变越是灾难性的。\n\n> 设计之初就对一致性做出非常严格的校验和控制，好消息是 mongodb 3.2 开始已经从数据库层面支持对 collection 结构的校验。每次表结构调整，都要对**历史数据进行相应的变更**。\n\n{/* more */}\n\n## 对开发者使用门槛降低的同时，也是在对躲在暗处的人敞开了大门\n\nmongodb 非常容易安装和使用，无需任何权限设置即可开箱即用，而且默认mongodb 的端口是可以从公网访问的，仅仅这样的设计就已经造成了无数的安全问题，详见[mongodb 赎金门事件](http://coolshell.cn/articles/17607.html)。虽然数据库没有强制要是有口令和用户来管理权限，但是开发者的安全意识不能松懈。\n\n> 任何时候部署mongodb 都应该尽早设置用户、口令以及相关权限。\n\n## 升级要趁早\n\nmongodb 版本的迭代比较稳定，每年会有一到两次版本发布，每次新发布都会带来不少性能改进和优化，也有少量 api 的变动，变化相对较大的是 mongodb 的驱动。为了尽可能早地享受版本升级代来的好处，要制定一套对线上环境进行新版测试、安装、兼容过渡的方案。\n\n> 升级版本不能跨度太大，mongodb 官方也推荐生产环境升级要渐进式的而不是跨越式的，每次升级**一定要备份数据**。\n\n\n## 正确使用索引\n\n和 mysql 等关系型数据库一样，mongodb 也支持索引查询，并且支持在多种数据类型上建立索引。为了能最大限度的利用索引提升查询性能，正确建立和使用非常关键。要确保索引能够正确建立和使用需要做到起码以下几点\n\n1. 非常熟悉 collection 上对应的每个查询和查询对应字段的数据类型\n2. 了解不同索引的区别以及它们的使用场景：single index，compound index，hash index 等\n3. 了解前缀索引的原理和使用原则\n4. 不仅仅要优化索引，如有必要修改字段类型，调整表结构都有助于建立正确的索引\n\n## nosql 不是万能的\n\n软件开发领域没有银弹，nosql 也不是万能的，在有强一致性、事务性场景 mongodb 并不合适，面对这样的场景选择关系型数据库是更明智的选择，不管你有多么喜欢 mongodb 带来的便利。\n\n## 慎用第三方 ORM\n\nORM 隐藏了对数据库操作的细节，这对真正想掌控全局的开发者来说并不是好事。ORM 工具不但使数据变更的过程难以追踪，而且在业务逻辑逐渐复杂之后， 开发者不得不深入ORM 来实现更灵活的拓展。此时，可以选择去 ORM，但是代价将会非常之大。\n\n> 如果你实现的是个 blog，ORM 是个得力助手，如果是个复杂的社交应用，ORM 并不是一个好的选择。","src/content/posts/mongodb-practice-for-four-years-md.mdx","85bb14398c762193","mongodb-practice-for-four-years-md.mdx","mongodb-server-selection",{"id":830,"data":832,"body":837,"filePath":838,"digest":839,"legacyId":840,"deferredRender":22},{"title":833,"summary":834,"date":835,"tags":836,"group":78,"featured":38},"可容错的 server proxy 实现","最近需要对手头的一个 rpc proxy 进行升级改造，升级之后要能做到：",["Date","2018-11-16T00:00:00.000Z"],[825],"最近需要对手头的一个 rpc proxy 进行升级改造，升级之后要能做到：\n\n- 自动上线下线故障节点\n- 支持动态扩容和缩容\n- 支持对后端的 server 进行权重分流和负载均衡\n\n这些目标要实现的功能和 MongoDB driver client 的功能很相似，MongoDB 本身就是分布式的系统，支持 replicateSet 和 shard 模式，每个 server 除了读写限制之外还支持使用 tag 来区分，client 能够根据不同的读写策略以及 tag 路由到不同的 server，比如支持：\n\n- primaryRead\n- secondaryRead\n- nearestRead\n\n而且如果 primary 故障下线了，client 可以自动侦测集群新选举的 primary 进行写操作。\n\n由此可见，MongoDB driver 的设计思路和实现都可以很好的借鉴拿来在我要改造的 rpc client 中实现，这才是开源的真正好处，站在巨人的肩膀上看得更远。\n\n我们先来看看一下 MongoDB driver client 的设计目标，详见[server-selection-next-generation-mongodb-drivers](https://www.mongodb.com/blog/post/server-selection-next-generation-mongodb-drivers)\n\n## 设计 MongoDB client driver 的三个目标\n\nMongoDB client driver 在选择 server 时有三个设计目标：\n\n**1. 第一个目标是可预见的**\n\n比如说如果一个 application 开发时是用的是单机的 MongoDB 实例，但是部署的时候可能是 replicateSet 的 MongoDB 集群，随着演变还有可能使用的是 shard 集群，但是不论 MongoDB  实例是什么模式，application 代码都应该始终都应该保持一致，只在必要的时候做出适当调整。举个例子来说，比如 application 用 driver 查询使用的是 secondary，那么不论 application 部署在单机实例上，replicateSet 实例上，还是 shard 实例上，它都能正常工作。\n\n**2. 第二个目标是有弹性**\n\n这就意味着，如果 driver 在选择某个 server 时检测到 server 故障了，driver 应该尝试去找可替代的 server 而不是立即抛出错误。比如对于写，有故障应该等待 primary 节点恢复，或者在 shard 集群中切换到其他 mongos 上。\n\n\n**3. 第三个目标是选中的 server 应该低时延的**\n\n也就是说如果多个 server 满足某种 operation，低时延的 server 应该首先被选择\n\n\nMongoDB 的设计目标决定了 client driver 除了常规 client 应该包含的部分如：\n\n- network process (网络处理)\n- connection pool (连接池)\n- message process (消息协议处理)\n- error process (容错异常处理)\n\n还包括如下几个组件来帮助它完成以上目标：\n\n- monitor (server 可用性监控、RTT 计算等任务)\n- server selection (按照一定的规则从候选 server 中选出可用 server)\n\n## proxy 的升级改造\n\n我们的 proxy 是 tornado 实现的，基于 tornado 的 TCPServer 和 TCPClient，他们都是基于 tornado 的异步 IOStream。\n\n整个升级过程可以用以下图来描述。\n\n\n![](https://static.git-star.com/1376db068910fb75075c4e4206e8cf93.jpg\n)\n\n\n其中对故障节点健康状态监测是通过 tornado 提供的 [PeriodicCallback](http://www.tornadoweb.org/en/stable/ioloop.html?highlight=perio#tornado.ioloop.PeriodicCallback) 实现的，`PeriodicCallback` 提供了定时任务的启停以及状态检测，如果故障列表中有节点加入，主动触发检测任务的启动，开启周期性检测，每次检测完毕之后，更新每个节点的检测状态（包括检测次数和最后一次检测时间），用于下次检测的决策依据。\n\n为了让检测尽量做到均衡，自己实现了一个有序集合来保存故障节点，一个节点在一个周期内都会有机会被检测一次。\n\n```python\nclass SortedSet(object):\n    \"\"\"有续集合,用来解决 upstream 检测时的顺序问题\n    \"\"\"\n\n    def __init__(self):\n        self._q = collections.deque()\n        self._s = dict()\n\n    def __contains__(self, key):\n        return key in self._s\n\n    def setdefault(self, key, value):\n        if key not in self._s:\n            self._q.append((key, value))\n        return self._s.setdefault(key, value)\n\n    def popleft(self):\n        key, value = self._q.popleft()\n        self._s.pop(key, None)\n        return key, value\n\n    def append(self, item):\n        key, value = item\n        self._s[key] = value\n        self._q.append((key, value))\n\n    def remove(self, key):\n        \"\"\"线性删除\n        \"\"\"\n        self._s.pop(key, None)\n        new_q = collections.deque()\n        while self._q:\n            existed_key, value = self._q.pop()\n            if existed_key != key:\n                new_q.appendleft((existed_key, value))\n\n        self._q = new_q\n\n    def __str__(self):\n        return 'set={0}, queue={1}'.format(self._s, self._q)\n\n    __repr__ = __str__\n\n```\n\n有序集合用了 `dqueue` 和 `dict` 两种结构，dict 提供 O(1) 的查找，dqueue 保证了节点的有序。\n\n得益于与 tornado 的单线程模式，由于没有开启多线程，整个代码都不需要有锁的出现，写的比较顺畅。\n\n\ntornado 这货是我最喜爱的框架之一，为此还造了一个基于它的另一个框架，感兴趣的可以看一下 [turbo](http://github.com/wecatch/app-turbo/)。","src/content/posts/mongodb-server-selection.mdx","c48ded9f3b9e490f","mongodb-server-selection.mdx","mongodb-index",{"id":841,"data":843,"body":848,"filePath":849,"digest":850,"legacyId":851,"deferredRender":22},{"title":844,"summary":845,"date":846,"tags":847,"group":825,"featured":38},"Mongodb 中的索引","在 Mongodb 典型的数据库查询场景中，索引 index 扮演着非常重要的作用，如果没有索引，MongoDB 需要为了找到一个匹配的文档而扫描整个 collection，代价非常高昂。",["Date","2018-03-21T00:00:00.000Z"],[],"在 Mongodb 典型的数据库查询场景中，索引 index 扮演着非常重要的作用，如果没有索引，MongoDB 需要为了找到一个匹配的文档而扫描整个 collection，代价非常高昂。\n\nMongodb 的索引使用的 B-tree 这一特殊的数据结构，借助索引 Mongodb 可以高效的匹配到需要查询的数据，以下图来为例(来自官方)：\n\n![](https://docs.mongodb.com/manual/_images/index-for-sort.bakedsvg.svg)\n\nscore 索引不但可以高效的支持 range 查询，此外也可以让 MongoDB 高效地返回排序之后的数据，Mongodb 的索引同其它数据库系统很相似，Mongodb 的索引是定义在 collection 级别的，支持对任何单个 field 以及任何 sub-field 建立索引。\n\n## 默认的 `_id` index\n\nMongodb 在 collection 创建时会默认建立一个基于`_id`的唯一性索引作为 document 的 primary key，这个 index 无法被删除。\n\nMongodb 支持多种方式创建索引，具体创建方式见官方文档 https://docs.mongodb.com/manual/indexes/#create-an-index\n\n## Single field index - 单索引\n\nSingle field index 是 Mongodb 最简单的索引类型，不同于 MySQL，MongoDB 的索引是有序的  ascending 或 descending。\n\n![](https://docs.mongodb.com/manual/_images/index-ascending.bakedsvg.svg)\n\n\n但是对于 single field index 来说，索引的顺序无关紧要，因为 MongoDB 支持任意顺序遍历 single field index。\n\n在此创建一个 records collection：\n\n```javascript\n{\n  \"_id\": ObjectId(\"570c04a4ad233577f97dc459\"),\n  \"score\": 1034,\n  \"location\": { state: \"NY\", city: \"New York\" }\n}\n```\n\n然后创建一个 single field index：\n\n```javascript\ndb.records.createIndex( { score: 1 } )\n```\n\n上面的语句在 collection 的 score field 上创建了一个 ascending 索引，这个索引支持以下查询：\n```javascript\ndb.records.find( { score: 2 } )\ndb.records.find( { score: { $gt: 10 } } )\n```\n\n可以使用 MongoDB 的 explain 来对以上两个查询进行分析：\n```javascript\ndb.records.find({score:2}).explain('executionStats')\n```\n\n### single index on embedded field - 内嵌字段上的单索引\n\n此外 MongoDB 还支持对 embedded field 进行索引创建：\n\n```javascript\ndb.records.createIndex( { \"location.state\": 1 } )\n```\n\n上面的 embedded index 支持以下查询：\n```javascript\ndb.records.find( { \"location.state\": \"CA\" } )\ndb.records.find( { \"location.city\": \"Albany\", \"location.state\": \"NY\" } )\n```\n\n### sort on single index - 单索引的排序\n\n对于 single index 来说，由于 MongoDB index 本身支持顺序查找，所以对于single index 来说:\n```JavaScript\ndb.records.find().sort( { score: 1 } )\ndb.records.find().sort( { score: -1 } )\ndb.records.find({score:{$lte:100}}).sort( { score: -1 } )\n```\n\n这些查询语句都是满足使用 index 的。\n\n## Compound index - 组合索引\n\nMongodb 支持对多个 field 建立索引，称之为 compound index。Compound index 中 field 的顺序对索引的性能有至关重要的影响，比如索引 {userid:1, score:-1} 首先根据 userid 排序，然后再在每个 userid 中根据 score 排序。\n\n![](https://docs.mongodb.com/manual/_images/index-compound-key.bakedsvg.svg)\n\n### 创建 Compound index\n\n在此创建一个 products collection：\n\n```JavaScript\n{\n \"_id\": ObjectId(...),\n \"item\": \"Banana\",\n \"category\": [\"food\", \"produce\", \"grocery\"],\n \"location\": \"4th Street Store\",\n \"stock\": 4,\n \"type\": \"cases\"\n}\n```\n\n然后创建一个 compound index：\n```JavaScript\ndb.products.createIndex( { \"item\": 1, \"stock\": 1 } )\n```\n\n这个 index 引用的 document 首先会根据 item 排序，然后在 每个 item 中，又会根据 stock 排序，以下语句都满足该索引：\n```JavaScript\ndb.products.find( { item: \"Banana\" } )\ndb.products.find( { item: \"Banana\", stock: { $gt: 5 } } )\n```\n\n条件 {item: \"Banana\"} 满足是因为这个 query 满足 prefix 原则。\n\n### 使用 compound index 需要满足 prefix 原则\n\nIndex prefix 是指 index fields 的左前缀子集，考虑以下索引：\n```JavaScript\n{ \"item\": 1, \"location\": 1, \"stock\": 1 }\n```\n\n这个索引包含以下 index prefix：\n```JavaScript\n{ item: 1 }\n{ item: 1, location: 1 }\n```\n\n所以只要语句满足 index prefix 原则都是可以支持使用 compound index ：\n```JavaScript\ndb.products.find( { item: \"Banana\" } )\ndb.products.find( { item: \"Banana\",location:\"4th Street Store\"} )\ndb.products.find( { item: \"Banana\",location:\"4th Street Store\",stock:4})\n```\n\n相反如果不满足 index prefix 则无法使用索引，比如以下 field 的查询：\n- the **location** field\n- the **stock** field\n- the **location** and **stock** fields\n\n由于 index prefix 的存在，如果一个 collection 既有 **{a:1, b:1}** 索引 ，也有 **{a:1}** 索引，如果二者没有稀疏或者唯一性的要求，single index 可以移除。\n\n### Sort on Compound index - 复合索引的排序\n\n前文说过 single index 的 sort 顺序无关紧要，但是 compound index 则完全不同，考虑有如下场景：\n```JavaScript\ndb.events.find().sort( { username: 1, date: -1 } )\n```\n上面的查询首先根据 username 进行 ascending 排序，然后再对结果进行 date descending 。\n\n下面的查询：\n```JavaScript\ndb.events.find().sort( { username: -1, date: 1 } )\n```\n则是首先根据 username 进行 descending 排序，然后再对 date 进行 ascending 排序。\n\n如果想要索引满足以上两种查询和排序，索引类型需要满足如下条件：\n```JavaScript\ndb.events.createIndex( { \"username\" : 1, \"date\" : -1 } ）\n```\n也就是 **username 和 date 的顺序不同**，如果顺序相同则没有办法满足以上查询，比如：\n```JavaScript\ndb.events.find().sort( { username: 1, date: 1 })\n```\n\n也就是说 sort 的顺序必须要和创建索引的顺序是一致的，一致的意思是不一定非要一样，总结起来大致如下：\n\n|                                    | { \"username\" : 1, \"date\" : -1 } | { \"username\" : 1, \"date\" : 1 } |\n| ---------------------------------- | ------------------------------- | ------------------------------ |\n| sort( { username: 1, date: -1 } )  | 支持                            | 不支持                         |\n| sort( { username: -1, date: 1 } )  | 支持                            | 不支持                         |\n| sort( { username: 1, date: 1 } )   | 不支持                          | 支持                           |\n| sort( { username: -1, date: -1 } ) | 不支持                          | 支持                           |\n\n**即排序的顺序必须要和索引一致，逆序之后一致也可以**，下表清晰的列出了 compound index 满足的 query 语句：\n\n| query                                                    | index                |\n| -------------------------------------------------------- | -------------------- |\n| db.data.find().sort( { a: 1 } )                          | { a: 1 }             |\n| db.data.find().sort( { a: -1 } )                         | { a: 1 }             |\n| db.data.find().sort( { a: 1, b: 1 } )                    | { a: 1, b: 1 }       |\n| db.data.find().sort( { a: -1, b: -1 } )                  | { a: 1, b: 1 }       |\n| db.data.find().sort( { a: 1, b: 1, c: 1 } )              | { a: 1, b: 1, c: 1 } |\n| db.data.find( { a: { $gt: 4 } } ).sort( { a: 1, b: 1 } ) | { a: 1, b: 1 }       |\n\n**即排序的 filed 也要满足 index prefix 原则**。\n\n#### 非 index prefix 的排序\n\n考虑索引 { a: 1, b: 1, c: 1, d: 1 }，即使排序的 field 不满足 index prefix 也是可以的，但前提条件是**排序 field 之前的 index field 必须是等值条件**，\n\n|      | Example                                                 | Index Prefix          |\n| ---- | ------------------------------------------------------- | --------------------- |\n| r1   | db.data.find( { a: 5 } ).sort( { b: 1, c: 1 } )         | { a: 1 , b: 1, c: 1 } |\n| r2   | db.data.find( { b: 3, a: 4 } ).sort( { c: 1 } )         | { a: 1, b: 1, c: 1 }  |\n| r3   | db.data.find( { a: 5, b: { $lt: 3} } ).sort( { b: 1 } ) | { a: 1, b: 1 }        |\n\n上面表格 r1 的排序 field 是 b 和 c，a 是 index field 而且在 b 和 c 之前，可以使用索引；r3 的排序中 b 是范围查询，但是 b 之前的 a 用的也是等值条件，也就是只要排序 field 之前的 field 满足等值条件即可，其它的 field 可以任意条件。\n\n## 如何建立正确索引\n\n前文基本覆盖了日常使用 MongoDB 所需要的主要索引知识，但是如何才建立正确的索引？\n\n### 使用 explain 分析查询语句\n\nMongoDB 默认提供了类似 MySQL explain 的语句来分析查询语句的来对我们正确建立索引提供帮助，在建立索引时我们需要对照 explain 对各种查询条件进行分析。\n\n### 理解 field 顺序对索引的影响\n\n索引的真正作用是帮助我们限制数据的选择范围，比如 Compound index 多个 feild 的顺序如何决定，应该首选可以最大化的缩小数据查找范围的 field，这样如果第一个 field 可以迅速缩小数据的查找范围，那么后续的 feild 匹配的行就会变少很多。考虑语句：\n\n```JavaScript\n{'online_time': {'$lte': present}, 'offline_time': {'$gt': present}, 'online': 1, 'orientation': 'quality', 'id': {'$gt': max_id}}\n```\n\n考虑如下索引\n\n|      | 索引                                                         | nscanded |\n| ---- | ------------------------------------------------------------ | -------- |\n| r1   | {start_time:1, end_time: 1, origin: 1, id: 1, orientation: 1} | 12959    |\n| r2   | {start_time:1, end_time: 1, origin: 1, orientation: 1, id: 1} | 2700     |\n\n由于 field `id` 和 `orientation` 的顺序不同会导致需要扫描的 documents 数量差异巨大，说明二者对对数据的限制范围差别很大，优先考虑能够最大化限制数据范围的索引顺序。\n\n### 监控慢查询\n\n始终对生成环境产生的慢查询进行第一时间分析，提早发现问题并解决。\n\n\n## 参考资料\n\n- https://docs.mongodb.com/manual/core/index-compound/\n- http://www.infoq.com/cn/articles/improve-find-performance-in-mongo","src/content/posts/mongodb-index.mdx","3b4d41f9a5072c9e","mongodb-index.mdx","mongodb-single-table-split",{"id":852,"data":854,"body":860,"filePath":861,"digest":862,"legacyId":863,"deferredRender":22},{"title":855,"summary":856,"date":857,"tags":858,"group":825,"featured":38},"mongodb 单表亿级数据的拆分方案","拆表是一种常见的解决单表数据库瓶颈的方案，在实际的应用场景中能够部分解决单表的写压力和读压力，但是也会带来一些更复杂的影响： - 聚合查询变得困难 - 拆分的键一旦选定，更改会非常困难 - 拆表的过程要保证线上业务不受影响，操作复杂度高",["Date","2016-08-27T00:00:00.000Z"],[859],"表拆分","拆表是一种常见的解决单表数据库瓶颈的方案，在实际的应用场景中能够部分解决单表的写压力和读压力，但是也会带来一些更复杂的影响：\n- 聚合查询变得困难\n- 拆分的键一旦选定，更改会非常困难\n- 拆表的过程要保证线上业务不受影响，操作复杂度高\n\n因此，表的拆分一定要选在恰当的时候进行，过早，付出很大代价也并不会带来性能的提升，过晚，数据量庞大，操作难度加大。\n\n在本次实施的拆分方案中，数据特点是:\n\n- 单表过亿\n- 业务数据是用户对资源的收藏，结构比较单一\n- 只做单向(用户-->数据)查找，不要求反向(数据-->用户)查找\n- 数据处于实时变更状态(新增、删除、查询等操作并存)\n\n{/* more */}\n\n## 如何选择拆分键\n\n本例中，拆分的键就是用户 id，且每个用户关联的资源数据最大不会过万。\n\n## 如何保证拆分的过程中不影响用户的操作？\n\n本例中，表中的数据基本上只有如下操作\n\n- 用户新增一条数据\n- 用户删除一条数据\n- 用户查询数据(有翻页)\n\n\n拆表的基本原理就是对选择的键进行 hash 生成每个键所属的表空间名，也就是说，在任意时刻，任意用户的数据只有以下三种状态\n\n1.全部在旧表中\n2.部分在新表，部分在旧表\n3.全部在新表中\n\n数据拆分的具体工作是要离线进行的，为了能保证用户数据在这样三种状态之下依然具有像单表中一样的一致性，需要业务层在处理当前用户数据时判断用户是否在迁移中，只有处于迁移状态之下，用户数据才需要特别处理。\n\n## 迁移状态如何判断?\n\n当用户数据处于迁移状态，为了保证用户数据全部可用，即要做到不跨表翻页，我们做了如下决定：一旦开始迁移，用户的全部数据就会载入到一个特殊区域(这里我们用了 redis，后面再讨论这样处理可能带来的问题)且保存为有序集数据。\n\n如果用户处于迁移状态，则用户的数据一定存在于这个区域，暂且给此区域命名为 *on_progress*。\n\n## 迁移状态下如何保证用户数据的正确性？\n\n当用户处于迁移状态，用户新增一条数据，则在新表、*on_progress* 、旧表中各写入新增数据，用户删除一条数据，则在新表、*on_progress*、旧表中同时删除该数据。\n\n**这样做的目的是什么?**\n\n处于迁移状态下的用户，*on_progress* 中保存了其所有数据，可以进行翻页操作，*on_progress* 中的所有数据会在离线状态下不断写入新表中，迁移完成之后，旧表中的数据将被删除，*on_progress* 中数据也将被清除，这样用户数据全部进入新表中，后续的所有操作将只在新表上进行。\n\n*on_progress* 中的数据在不断写入新表的过程中，是按照由新-->旧或由旧-->新的顺序进行，在这个过程中：\n\n> 用户删除一条数据\n\n1）有可能该条数据已经写入新表中，所以删除操作要在新表中执行。\n2）*on_progress* 中的数据要始终和用户所有的操作同步来保证数据的正确性和一致性，因而删除操作也要在 *on_progress* 中执行。\n3）如果发生意外导致 *on_progress* 不可用，为维护数据的一致性，删除操作也需要在旧表中进行。\n\n> 用户新增一条数据\n\n1）*on_progress* 中的数据要始终和用户所有的操作同步来保证数据的正确性和一致性，因而 *on_progress* 需要写入一条数据。\n2）在某些边界条件下，*on_progress* (假如数据由旧-->新写入新表) 中的数据迁移完成但还未被删除，用户恰巧写入一条数据，此时用户仍处于迁移状态中，但是离线的迁移操作已经认为迁移停止了，因而此时新增数据需要进入新表才能保证数据最终是正确的。\n3）如果发生意外导致 *on_progress* 不可用，为维护数据的一致性，新增操作也需要在旧表中进行。\n\n\n## on_progress 的选择\n\n在这个方案的实施中，*on_progress* 用了 redis 的有序集，键就是用户的 id，只要检测到用户 id 的存在就认为该用户处于迁移状态中。\n\n迁移完成之后，先删除旧表中的数据，然后再删除 *on_progress* 中有序集。\n\n**判断用户迁移状态**\n\n1.只要用户处于 redis 中，则此时一定是迁移中或迁移完成\n2.只在旧表中找到用户数据，则该用户一定还没有开始迁移\n3.只在新表中找到用户数据，用户已经迁移成功\n\n需要注意的是，选用 redis 可能带来的问题是 redis 宕机会导致迁移中的数据无法恢复(redis 未开持久化操作或其他原因导致数据不能恢复)，只要用户在旧表中有数据存在，则用户删除数据的操作一定也要在旧表中执行，再次恢复迁移时，清除旧表数据，直接载入旧表中的数据到 *on_progress*。\n\n\n\u003Cimg src=\"/images/table-split.png\" alt=\"迁移流程图\" width=\"800\" >","src/content/posts/mongodb-single-table-split.mdx","572279cc8776a330","mongodb-single-table-split.mdx","mongodb-trouble-list",{"id":864,"data":866,"body":872,"filePath":873,"digest":874,"legacyId":875,"deferredRender":22},{"title":867,"summary":868,"date":869,"tags":870,"group":825,"featured":38},"MongoDB 常见故障以及诊断和解决方案","郭德纲经常调侃于谦，说于谦的三大爱好是抽烟、喝酒、烫头，用了这么多年 MongoDB 碰到太多问题，即使以前和现在都不是我在运维，总结下来对百万日活级别的 MongoDB 日常使用的大部分问题都可以归纳到以下几点。",["Date","2018-05-16T00:00:00.000Z"],[871],"故障","郭德纲经常调侃于谦，说于谦的三大爱好是抽烟、喝酒、烫头，用了这么多年 MongoDB 碰到太多问题，即使以前和现在都不是我在运维，总结下来对百万日活级别的 MongoDB 日常使用的大部分问题都可以归纳到以下几点。\n\n## 磁盘不行\n\n早期创业时我们用的 MongoDB 2.4，那个时候 MongoDB 出来没多久，当时的团队很早就在国内生产环境大规模上了 MongoDB，也是为了省钱 MongoDB 节点全是机械磁盘加 raid 5，硬是扛了 100 多万的日活，后期出问题最多就是磁盘，大并发写的时候磁盘 IO 吃紧无法满足性能，有时候莫名其妙卡顿，加缓存上内存优化代码各种招都试了，等到我们拿到融资把机器全换 SSD 之后，问题一下全没了。\n\n**有些钱省不得，省了之后总是会带来更大的麻烦，如果你生成环境用 MongoDB 建议直接 SSD，再说现在都云了，非常容易更换，不像我们当年，扛着磁盘去机房换，累死累活**。\n\n## 内存不够\n\nMongoDB 为了性能几乎把所有热点数据都加载到内存了，很吃内存，早期我们对 MongoDB 不了解，机器都是自建的同样也是为了省钱机器配置都是 8CPU x 16G 的，用户量大时候莫名其妙 MongoDB 进程被操作系统 kill 掉，回顾日志发现大部分原因是 MongoDB 吃了太多内存。后来我们升级到 64G 之后再也没有出现过类似的问题。\n\n**MongoDB 的非常吃内存，如果生产环境大量使用 MongoDB 建议对重点业务机器配置高内存**。\n\n## 索引使用不合理\n\n同 MySQL 一样，如果 MongoDB 的索引使用不合理，会导致大量的慢查询，从而过快消耗完数据库连接，服务器 CPU load 非常高，数据库响应缓慢。MongoDB 的索引的最佳实践官方说的非常透彻，建议好好学习，认真实践：https://docs.mongodb.com/manual/indexes/ 。\n\n除此之外，我也写过一篇关于 MongoDB 索引的文章：[Mongodb 中的索引](/blog/mongodb-index) 读者可参考借鉴。\n\n**什么时候使用索引？**\n\n最好索引在建表之初就设计好，不要等到数据量大到一定程度把问题暴露出来了再去创建索引，那个时候出问题可能就是个大问题了。\n\n## 行记录太大\n\n在一次定位线上应用程序莫名卡顿时，发现了 MongoDB 中一个慢查询，最后诊断下来发现由于开发人员的粗心大意，一条 MongoDB 的 record 竟然达 10m 左右，导致 MongoDB client 在查询和传输数据时都非常的慢。\n\n**MongoDB 单条数据最大不超过 16m，如果再大官方建议使用 gridfs 或者其他文件存储系统，显然 MongoDB 有自己不擅长的地方，在使用时要注意**。\n\n## collection 数据量太大\n\nMongoDB 单节点单表数据达数亿级别时在大并发写入时会变慢，此时可以考虑拆表，如果业务数据量不是很大，可以直接在原有集群上进行。MongoDB 官方提供了 sharding 方案，但是对于一般性业务来说显得过于复杂，可以根据自身的业务特性选择合适的方案实践。\n\n\n## 日常 MongoDB 的诊断\n\n> https://docs.mongodb.com/manual/tutorial/manage-the-database-profiler/\n\nMongoDB 提供了慢查询日志和错误日志来帮助定位和解决问题，慢查询日志可以通过 `db.setProfilingLevel` 设置，共有3个级别分别是：\n- 0 默认级别，不收集任何数据\n- 1 收集满足条件的慢查询\n- 2 所有操作都收集\n\n开启 slow log `db.setProfilingLevel(1, { slowms: 20 })` ，查询慢查询日志 `db.system.profile.find( { millis : { $gt : 5 } } ).pretty()` \n\n除了慢查询日志，`db.serverStatus` 可以查看当前服务器各种状态，包括连接数、锁信息、文档更新删除数量等等能够帮助我们迅速判断服务器的状态。","src/content/posts/mongodb-trouble-list.mdx","6fec88c9662b63ba","mongodb-trouble-list.mdx","my-info-system",{"id":876,"data":878,"body":885,"filePath":886,"digest":887,"legacyId":888,"deferredRender":22},{"title":879,"summary":880,"date":881,"tags":882,"group":884,"featured":38},"关于信息管理系统的思考","# 我理想中的信息系统",["Date","2019-04-12T00:00:00.000Z"],[883],"信息管理","方法论","# 我理想中的信息系统\n\n每天我都要接触很多信息，我需要把这些信息有效的录入到一个系统当中，让系统自动帮助我把这些信息备注归档，这在搞定一书中称之为：**百分之百收集一切未竟之事**，我希望通过建立某种机制，可以让我收集的信息进行自动归类和整理，比如我看到一篇文章，我对该文章建立一个连接，这个文章应该归到相应的分类之下，这个分类可以是一个项目，或者一个待办事项，或者就是有一则消息，可能这个消息对我来说是有用的而已。\n\n网上连接是会消失的，最好的情形是我可以把这个链接的内容做离线存储，也就是我可以以 PDF 或图片等方式把这些数据下载下来存储到私人的存储系统中，这个系统最好的多份存储，比如本地电脑一份，云上一份。\n\n我要能在任何时候捕捉任何想法，然后让这个想法自动归类，**等待处理**，比如我看到二爷的排版的文章，里面提到了排版的一些参数，我想把这些参数提取出来放到三月沙的公众号排版上，这个想法就会促成一次行动。\n\n**所谓的等待处理就是说这个消息的输入一定要对应的输出，而输出可以一是写一篇文章，一项功能的优化。**\n\n# 信息的存储和管理\n\n这套管理系统能够对接我所有的信息获取渠道，无论是哪个渠道获取都能通过这个管理系统进行管理，比如我在看微信公众号，就可以从微信中对我想要获取的信息进行管理，比如我在看 medium 的文章，我就可以从 Chrome 浏览器中对信息进行管理，我在看微博，我就可以把微博中的信息随时放到手机的相应的应用上进行管理。\n\n# 信息的使用和输出\n\n信息获取之后就是如何对信息进行利用，利用信息是让信息变得更有价值，所谓有价值就是**能产生输出**。\n\n# 如何对这套抽象的系统进行形式化\n\n1. 首先要解决的问题是信息的录入，清楚自己的信息的渠道，在每个渠道上都能建立起自己收集信息的方式\n2. 信息如何组织，信息的组织主要包括来源、信息的主题（可标签化的东西）、信息的标题以及摘要、收集时间等\n3. 信息如何输出，输出一定要是完整的成体系的才会有价值，才能对日后起到参考作用。\n\n# 系统中的方法论\n\n不论事面对什么样的信息或者处理什么样的事情都有一套方法论，只要这一套方法论建立完成，对于任何类似的事情都按照按部就班就可以了，这个和我之前说的处理事情的模板是一样的。\n\n方法论是分层的、有适用范围的，不同方法论解决的是不同层次的问题或者不同适用范围的问题，但是目标-->过程-->结果，这种方法论就适用于任何事情，因为任何事情不论事学习减肥、学习做饭还是做一个完整的项目都会经历这三个阶段。所以目标-->过程-->结果这个方法论就适用于任何事情，属于搞定里面说的 5 楼视野的方法论。比如之前整理的信息的获取和分类属于工具性的方法论，这个工具解决的是对信息收集、整理和加工。我之前整理过如何学习一门语言，这种方法论就是具体的领域内的应用：学习一门计算机语言。\n\n如果从一开始就想一个非常大的系统，将会是难以下手，可以从小处构建，比如可以先从构建方法论开始，整理出自己所有的方法论，然后根据这些方法论形成模板\n\n## 方法论的构成和关系\n\n方法论是由一个个问题组成，更高一阶的方法论用以指导更低一阶的方法论，比如顶层方法论是由目标、过程、结果构成，那每提出一个目的都应该拿此方法论进行套用\n\n# 这个高效的信息系统包含什么\n\n准确的是工具化的方法论，从如何读书，以及如何消化一本书，到如何学习一个知识点，以及如何消化一个知识点，借助工具把这些方法论进行形式化，然后再借助形式化的工具帮助形成习惯\n\n# 为什么读书是这个系统中首先应该解决的问题\n\n信息来自于四面八方，来自于各种各样的渠道，如何保证我的思考质量最高，其实只有静思和读书是最直接而且高质量，虽然说有时候很慢。因而读什么书、以及如何去读、如何去消化是迫切需要解决的问题，所以我必须要有一套方法论，来帮助我习惯性地去读书、消化书中的内容。\n\n接下来的行动是如何读书，比如如果一篇文章被归档了说明已经被我处理过了，最好不要出现在视野中\n\n# 文章收藏清单系统的方法论\n\n- 记录每日的收藏，按照日期进行归档\n- 过一段时间自动把每日的收藏进行归档，当成历史清单\n- 每日收藏的连接用标签进行分类","src/content/posts/my-info-system.mdx","a0d495df96b30496","my-info-system.mdx","my-learning",{"id":889,"data":891,"body":896,"filePath":897,"digest":898,"legacyId":899,"deferredRender":22},{"title":892,"summary":893,"date":894,"tags":895,"group":884,"featured":38},"我的学习方法论","# 学习的第1步：认识学习的目的、本质和底层规律",["Date","2017-10-09T00:00:00.000Z"],[],"# 学习的第1步：认识学习的目的、本质和底层规律\n\n## 知识的真正作用以及发展历程\n\n知识发展共经历了三个阶段：\n\n第一阶段，知识数量构建认识优势\n第二阶段，知识获取速度构建认知优势\n第三阶段，知识深度构建认知优势（现在的阶段）\n\n这三个阶段的发展反应了知识管理的核心是通过管理知识提升认知深度，进而改变自己的行为模式。不难看出管理知识的真正目的就是提**升认知深度，改变行为模式**，这也是知识的真正作用。\n\n## 如何提升认知深度\n\n分析 how 之前我们需要知道 what 和 why\n\n什么才是认知深度? 从案例入手分析认知深度反应在哪几个方面：\n**问**：怎么增加团队的认同感\n**答案1**：领导经常开会强调。\n**答案2**：人的认同感来自全力以赴完成一个共同目标，其中付出努力的程度以及共同参与的仪式感都很重要。\n\n答案 2 比答案 1 差别体现在：\n第一，形式上，简单回答是对具体问题或事情本身做出回答，深度回答是分析具体现象之后找出抽象规律。\n第二，思考方式上，简单回答根据自己的直观感受，情绪和经验做出回答，深度回答依托于有实验验证或有数据分析支持的结论。\n第三，效果上，简单回答只能解决一个特定的问题，深度回答能更普遍解决类似的问题，启发我们由表及里地思考问题。\n\n所以深度认知能力是指：\n**在分析问题的时候能够跳出问题本身思考更普遍的情况**\n**在寻求答案的时候，能够根据理由可信度判断是否接受这个结论**\n\n从认知深度的提升也延伸出了一个重要的概念：通过深度认知得出的结论，往往能够解释相似情境中的很多问题，在这些结论中，有些结论经过了更为广泛长期的验证，也在更普遍的领域具有指导意义和应用价值，这些结论是**临界知识**。\n\n**临界知识就是具有普遍指导意义的规律或定律，提升认知深度就是掌握更多的临界知识，并学会应用**。\n**请注意从知识的作用-->定义认知深度-->提高认知深度-->掌握临界知识的思考过程和路径**\n\n## 学习能力差的问题是什么\n\n上面分析了需要学习的真正知识就是要掌握的临界知识，学习能力差也就是体现在学习的知识并不是临界知识，这样的知识只是事务的表层，这样的知识提升的往往是**技术效率**，也就是只要知识发生变化就需要重新学习，由于没有掌握临界知识的底层规律，无法把现有的问题和以往的知识联系起来，无法看透问题的本质可能就是已经掌握的知识的一种另一种表现，这就是学习层次无法提升的重要原因，直接反应出来的是学习能力差，学习效率低。\n\n\n## 哪些知识需要学\n\n按照知识反应的能力把能力对应的课程划分为：\n- 公共基础课：执行能力\n- 专业必修课：专业能力\n- 通用必修课：结构能力\n\n**公共基础课**，就是每个每天都用到的能力，比如时间管理，资料信息管理，沟通谈判技巧\n\n**专业必修课**，专业能力并不是仅仅一个特定领域的知识，而是可以跨学科思考，系统性解决问题的知识，我们要能够做到在自己特定的领域内，夸学科思考，解决问题，能够灵活性应用多个学科的知识，让他们在合适的时机出现在合适的位置为我们解决问题。\n\n**通用必修课**，就是要掌握临界知识，认知事务的更加底层的结构和规律，我们经营的领域是如何产生的，影响这个领域发展的基本动力是什么，有哪些规律会普遍影响这些事务，这就像在深刻理解一场战役为什么爆发，会以什么样的脉络发展，其中起决定性的作用的因素究竟是什么样。\n\n毛泽东抗日战争看透了战争的本质，思考到了底层规律：中日战争的底层决定因素，是中国战略空间的广阔和日本需要速战速决的压力，所以影响战争的决定性因素是空间和时间的博弈。\n\n通过分析真正影响我们认知深度的是通用必修课。\n\n## 学习需要的底层思维\n\n第一，跳出低水平勤奋的误区，不要只做摘记，不对知识进行联系和整理，没有对新旧知识建立关联，不能内化成能力\n\n第二，放慢速度，将获得的知识和已有的知识进行网络状联系，在此过程中内化知识，形成新行为暗示，比如将自己已有的模型思考框架和新的知识相联系看是否能够发现新的规律，因而读书不追求数量，也不一定要去读完，而是需要解决某个问题的时候，主动去寻找这个问题有关的书籍和文章，去观察 — **作者用什么样的思路解决问题？在这个解决方案背后？是否有我熟悉的知识？我还能把这个解决方案应用到什么地方？**\n\n## 学习需要的心态\n\n### 绿灯思维的心态\n\n绿灯思维是防止习惯性防御的思维出现，之所以有习惯性防御是因为我们怕暴露自己的思考背后的思维，因为害怕别人发现它是错误的。\n\n**区分否定我和否定我的观点是不一样的行为，质疑观点不一定是质疑提出观点的人。**\n\n### 慢就是快的心态\n\n快是结果，不是原因，之所以快是因为能力强才快，如果正式需要提高能力的时候就应该慢下来认真学。\n\n高效的学习是知识融汇贯通的结果，有了对重要的、核心知识的深刻理解，我们才能游刃有余运用，对我们大多数人而言，阻碍我们融汇贯通的原因是我们在学习中遇到的一些阻塞没有把它攻克，导致我们其实有自以为知道，其实不知道的知识阻塞。\n\n比如读书，首先找到这本书对自身而言最紧要之处，花慢功夫认真领会，打通知识阻塞，弄懂基本原理。\n\n那什么才是把慢功夫花在真问题上，就是把时间花在重要的就基本概念、有启发的观点和自己没想明白的问题上。\n\n## 学习需要的底层方法\n\n上面提到知识的真正作用是帮助我们提升认知层次进而改变我们的行为模式，而学习的本质又是什么？\n\n学习是一个长期动态变化的过程，在这个动态变化过程中我们其实就是不断对我们提出的假设进行验证，修正，继续假设修正，直到找到一个满足我们要求的假设或者行为，然后不断实践它以产生有用的输出。可以看出，**学习最重要的就是提出假设，验证假设，调整假设，做出决策和行动**。\n\n而我们所有的假设和行动都在什么地方？在我们一点一滴的生活行动当中，因而学习的本质其实就是对我们的生活行动不断进行反思修正的过程，具体来有三个方法可以帮助我们实践这个过程：**反思、以教为学和刻意练习**。\n\n### 反思：提升知识的掌握层次\n\n总结和反思是不同的，总结是对结果的好坏进行分析；而反思是对产生结果的原因进行分析，反思的实质是对假设进行校正。\n\n做事的顺序：做出假设——→采取行动——→产生结果\n反思的顺序：观察结果（现象）——→研究原先假设——→反思校正假设\n\n#### **反思的作用**\n\n- 发现知识误区\n- 促进已有知识产生新知识\n- 检验学习的新知识是否用了起来\n\n### **如何训练反思能力**\n\n- 从小事反思，深入突破\n- 把生活案例化处理\n- 培养记反思日记的习惯\n\n### 以教为学\n\n以教为学顾名思义就是把自己知道的讲给别人，教是也是一个动态的过程，通过教不但可以检测自己学的程度，强化自己学习的记忆的，在别人提出疑问或质疑还能增强我们的认识。\n\n### 刻意练习\n\n刻意练习就是有目的的，有针对性的对自己未掌握以及需要掌握的知识不断进行练习和优化，刻意练习非常重要的一点是：**第一，要有目标，第二，要有反馈**。\n\n刻意练习的过程就是不断构筑自我元认知的过程，而元认知就是需要掌握的知识的最基础的概念以及最基础的规律的理解和运用，通过掌握的知识不断构筑更大的知识单元，直到能够解决复杂的问题。\n\n## 学习需要的能力技巧\n\n技巧是学习的工具，利用这些工具可以让学习事半功倍。\n\n### 记录\n\n记录是主动思考的过程，记录不是流水账，而是实实在在记录发生了什么事情，为什么发生，这样的记录有助于我们回顾和观察事件的整个发生过程，有助于还原事情真相，因为**事情的时间间隔越久，我们就越容易对自己当初的行为动机和想法按照对现在有利的结果进行解读**，这就违背了事情的真相。\n\n\n### 定期回顾\n\n定期回顾就是上面我们介绍的反思，不同于反思，定期回顾是一种习惯性的反思，并且只有记下来了才可能进行定期回顾，不然回顾很容易基于对过去的假象进行回顾。\n\n回顾工作具体要怎么做呢？回顾可以分为三个层次：\n- 周/月度回顾，主要是微观层面审视解决问题的假设和效果；\n- 年度回顾，检视基本思维方式和灵感激发；\n- 五年以上回顾，探寻基本规律如何影响生活。\n\n\n### 付费购买\n\n辣么多知识付费的服务和产品，此条不展开细讲了。\n\n## 发现临界知识\n\n临界知识的思想，核心是用更加可靠学科的研究方法、思想和结论来处理没那么可靠的领域的问题。简言之，就是解决问题最稳妥的办法是拿可信度更高的方法去处理问题。发现临界知识就是找到这些可靠领域提供给我们的科学方法和思想，如何寻找？\n\n1.从自己感兴趣的领域入手，学习这个学科的重要知识\n所有现象层面的知识研究到底层之后，都会联系起来。所以，从自己感兴趣的领域入手去阅读经典的书籍，从中寻找最重要的原理和知识。\n\n2.找到最重要的知识和原理的原始出处\n尽管我们可能发现了事情背后的规律，但是这往往还不够，还要进一步寻找这个规律的原始出处。这个步骤非常重要，也是大多数人在学习研究的时候忽略的一个环节——找到重要的结论是怎么来的。\n\n3.试用更加基本的原理来解释这个知识\n\n4.没有解释的时候，想办法寻找或者自己创造一个假设，并验证\n\n\n## 应用临界知识\n\n刻意练习我们学到的临界知识，是我们真正掌握它的关键。\n\n刻意练习要做到：\n第一，在不同的场景中，重复应用同一个临界知识；\n第二，在不同的时间里，重复应用同一个临界知识。\n\n\n## 总结\n\n此书从更深层次的角度探讨了知识的作用，学习的本质，以及要具备什么样的条件才能学好知识，应用好知识，读罢此书，有一点非常明确，要想从根本上解决我们自身学习效率低的问题，就是不断提高自身对临界知识的掌握，而掌握这些临界知识就需要我们动用自己的所有神经掌握自己专业之内和之外那些底层的知识和规律，以计算机角度来解释这个问题就是，学好算法、网络原理、操作系统、统计学、数学、计算机语言理论等基础知识是保持在变化多端的 IT 领域立足的关键。\n\n\n# 学习的第2步：建立学习目标\n\n目标的重要意义和如何制定好目标已经在 [target-process-result](/blog/target-process-result) 中做了阐述，下面说明如何在学习开始前建立学习的目标。\n\n## 写下自己要学习什么\n\n这一步其实是帮助自己确认目标的过程，一个目标只有写下来才是真正的目标，否则不能称之为目标。遵循 [target-process-result](/blog/target-process-result) 一起来写下一个学习的目标\n\n> **目标**\n学习使用 go 语言，熟悉 go 语言的基本语法和常用库，能够使用 go 语言写一个小网站，能够使用 go 语言做一些常用的功能库\n\n写下目标相当于做出了一个对自己错处了一个承诺，自己必须要兑现这个承诺是对自己的负责。\n\n\n# 学习的第3步：信息分类、获取和管理\n\n## 什么是信息\n\n广义上的信息是指任何能够被传递的内容，文字，声音，视频，图片等，而这里的对自己而言信息是指**有价值的内容**，其包括\n- 一篇文章 (技术性，经济学，心理学等)\n- 一条新闻消息 （科技新闻，经济政策，社会新闻事件）\n- 一个活动消息 （电商促销打折）\n- 一本书\n- 一条微博 （主要是技术性微博转发和一些时政观点）\n\n而这些有价值的内容中，只有能够影响自己行动的信息才是对自己有价值的。任何一个不能影响自己行动的信息流都是在浪费时间。\n\n## 信息的分类和特征\n\n- 随意信息\n- 观点信息\n- 过程信息\n- 具体信息\n- 抽象信息\n\n### 随意信息\n\n此类信息不具有关联性，或逻辑关系非常若，比如历史事件发生年代，人体基本结构知识都属于此类，此类信息要运用相关技巧性来达到记忆的目的。\n\n记住这些信息的技巧\n- 联想\n- 图表\n- 比喻类比\n\n### 观点信息\n\n观点信息是有争论的信息，对于观点信息最重要的有两点\n- 提取观点\n- 通过自己的思考和判断验证观点（查找支持文中观点的相关信息进行验证，或者自己查找信息进行验证）\n\n### 过程信息\n\n过程信息是教导人怎么行动的信息，是讲述一系列动作和操作的信息，比如如何游泳，如何编写游戏，建一所房子和模型都依赖过程信息。面对这类信息，最重要的是不断练习和反复去做。练习过程信息的关键还有要对背景有一定深入的了解，如果你完全不懂原理的练习是是浪费时间不起作用的。\n\n### 具体信息\n\n可观察的，可感受到的信息，此类信息，此类信息适合内在化，就是通过自身想象为此类信息配上图片，声音等然后进行联系和想象。\n\n### 抽象信息\n\n此类新缺乏与感官的联系，但逻辑性很强，想要正确理解抽象信息一定把抽象信息放置于具体的层次来应用和想象。通过把抽象信息进行具体化来理解，比如通过图像图表等方法进行具体的描述和理解。\n\n\n## 收集理解不同信息的关键\n\n面对信息首先要对信息进行分类，然后针对不同的信息运用不同的策略和技巧。比如面对一段过程信息就需要进行练习，否则信息毫无价值。面对一段具体信息，如果很有用，可以记住，否则可以暂时放弃。面对抽象信息需要反复理解，进行具体化直到自己真的弄懂为止。\n\n\n## 信息的来源方式\n\n- 读书\n- 搜索引擎\n- github\n- hacknews\n- 微博\n- 公众号\n- 小密圈\n- 朋友圈\n- 群聊（微信或面对面）\n\n读书时获取知识最好的渠道。\n\n- GitHub 获取的是技术性的趋势和优质的技术资源。\n- 微博和朋友圈是实时新闻和热点事件(关注较少，在所有信息中占用比例很低)。\n- 小密圈，公众号，朋友圈提供了不同圈子人关注点和思考点，是看别人的一条通道。\n- 群聊是通过看别人聊天以及和别人聊天产生的思维碰撞，消息来源于此渠道的也比较少。\n\n通过分析得到最有价值的信息获取渠道是**读书**，其次是搜索引擎，这两者贡献的信息价值最大，根据墨菲定律，2/8原则，应该加大对这两者的投入比例。\n\n\n## 获取信息的方式\n\n1.主动获取，通过搜索引擎，读书等手段\n2.被动获取，浏览公众号和朋友圈以及微博\n\n两种方式占比主动获取是 80%，被动获取是20%，也就是通过被动获取的知识越来越不能满足自己的需要了。\n\n\n## 信息管理的现状\n\n- 各种文章，资源以收藏为主\n- 读书以记录笔记为主\n- 信息散落在各个平台（为知笔记，有道笔记，印象笔记，收藏夹，微信收藏，微博收藏，github，trello，markdown 笔记）\n- 信息没有被消化吸收，越积越多\n- 信息缺乏有效的组织和联系，成碎片化，孤立存在\n\n## 如何管理\n\n信息存在的问题已经提出，首先针对存在的问题来逐一解决\n\n### 解决信息散落在各个平台的问题\n\n统一信息的收集方式，方便整理和使用，删除 Evernote 和 为知笔记内容并弃用，整理有道笔记之后逐渐弃用，统一知识管理工具为\n\n- quiver\n- github issue\n- markdown 笔记\n- trello\n\n微博搜藏和微信搜藏仅仅做短短期管理，整理之后可以删除。\n\n### 定期清理，保持简洁\n\n浏览器收藏夹、微信收藏夹、微博收藏是目前主要的收藏方式，逐渐整理这些收藏夹，然后以**主题**的方式重新组织，让收藏夹都变成短期收藏使用，定期清理，保持简洁。\n\n### 定期整理，周期性调整 --- 记录过程\n\n信息需要进行定期整理和回顾，周期以天，周，月为单位，对信息进行简单归类和整理，逐步建立自己的归类方法。\n\n信息采集主要通过浏览器收藏夹，微信收藏和微博收藏，每天晚上或和周末对这一周期内收藏的信息进行主题式的归纳和分类，以链接的方式收集到 quiver 然后建立一个 主题，用一个 note 的方式，之后在 trello 中建立一个 todo 项目建立该主题的待办，之后进行归纳和梳理，写成文章。\n\n每个月对当月输出的主题进行联系和归纳，形成一个更大的体系。\n\n### 主动联系 ，及时总结和归档 --- 反思回顾\n\n信息之所以孤立存在重要的原因是没有对信息进行加工和主动关联，主动关联意味着需要手动整理和思考信息背后一致和不一致的地方，对一致的地方进行提炼，不一致的地方进行对比修正，形成自我观点和知识，然后实践和使用。\n\n所以解决信息孤立存在的关键是主动关联，归纳，总结和提炼，然后输出。\n\n### 加工输出，形成体系 --- 以教为学，回顾检验\n\n信息整理之后需要进行消化吸收，然后通过以教为学的手段进行输出和检验\n\n### 总结规律\n\n信息的管理一个重要的底层规律就是化简就繁，也就是把信息收集的方式单一化，定时清理和主动归纳联系，形成更有价值的主题和自我体系，然后输出。\n\n## 需要培养的习惯\n\n- 定期检查和整理\n- 识别有用的信息，主动远离无价值的信息，判断标准是能不能影响自己的行动\n\n\n# 学习的第4步：理解和吸收信息\n\n理解就是知道是什么以及怎么做，但是为什么可能不太清楚，在学习的早期可以不需要深入理解为什么，此时的目的只是怎么正确使用\n\n如何达到正确理解，或者说如何检验正确理解了？\n\n能够讲出来或者写出来让其他人明白就达到理解了，坚持写博客和公众号目的也在于此。\n\n\n# 学习的第5步：刻意练习和检验\n\n在《刻意练习：如何从新手到大师》这本书中提到，一个人的能力的强弱表现在长时记忆，也就是说如果对于同样一件事的或知识的理解，能力强的人能够在很久之后依然刻意记得和应用。而如何才能达到这一的记忆效果呢？**答案就是刻意练习，并且是难度适中，能够收到反馈，有足够重复次数，学习者能够从中纠正自己错误的练习**\n\n如何才能让刻意练习发挥出最大的作用？那就是在情境中练习，同样的观点也见《程序员思维训练》一书中。而正是因为人的大脑是具有重塑能力的，也就是也可以不比天生就具有某些才华，那些才华是能通过后天练习得到提升的，当然爱因斯坦或牛顿的能力可能确实不是后天训练可以得到的。这个观点也揭示出学习不是为了发展某些能力，而是创造这些能力。\n\n怎样才能算是做到真正有效的刻意练习？\n第一要有目的，要有非常明确的目标\n第二要专注\n第三要有反馈，有反馈才能知道做的对错好坏才能知道如何调整成最佳\n第四要走出舒适区，不走出舒适区意味着无法取得进步\n\n在刻意练习这本书提到了一个重要的概念：心理表征，是指我们思考某个物体，观点，某些信息或者其他事物对应的心理结构，或抽象，或具体，简单来讲比如提到蒙娜丽莎，你可能会想到达芬奇的画，这就是你的心理表征。\n\n虽然说刻意练习是有目的，但是如果想让刻意练习真正得帮我们建立正确的心里表征，我们需要更进一步对刻意练习有了解。在《刻意练习：如何从新手到大师》讲到，刻意练习最大两个特点是就是：\n- 你练习的行业或领域有杰出的从业者\n- 你可以帮你布置练习作业的导师\n\n也就是找到一个比你更高明的人至关重要，只有这样你才能第一时间找到正确的方法帮助你得到正确的练习。如果你的练习一开始就不是正确的，再怎么刻意也是白费功夫。\n\n如果你自学能力很强，或者你根本找不到导师该怎么进行刻意练习？答案是：专注、反馈和及时纠正，将技能分解成一些组成部分，以便反复练习，并且有效分析、确定你的不足之处，然后想办法来解决它们。\n\n运用刻意练习你将会成为一个杰出人物，这个路线图就是：产生兴趣、变得认真、全力投入。","src/content/posts/my-learning.mdx","198313499a47e48a","my-learning.mdx","mysql-benchmark",{"id":900,"data":902,"body":907,"filePath":908,"digest":909,"legacyId":910,"deferredRender":22},{"title":900,"summary":903,"date":904,"tags":905,"group":906,"featured":38},"mysql-benchmark 是做容量规划和架构设计必不可少的一环，虽说 benchmark 不是特别难，但是做好了不容易，而且受限于所选的硬件环境，想要得到一个通用的测试报告比较困难，当然我还比较懒。我找了不少资料，大部分资料做测试都不是很全，而且文档读起来有难度，本来想那些...",["Date","2017-12-07T00:00:00.000Z"],[],"mysql","mysql-benchmark 是做容量规划和架构设计必不可少的一环，虽说 benchmark 不是特别难，但是做好了不容易，而且受限于所选的硬件环境，想要得到一个通用的测试报告比较困难，当然我还比较懒。我找了不少资料，大部分资料做测试都不是很全，而且文档读起来有难度，本来想那些云厂家卖产品应该有个白皮书之类的，但是他们的官网介绍的都太糙了，简直不像卖产品的，很不专业。折腾一圈找到一个还算靠谱点的 ucloud 自家的测试 https://docs.ucloud.cn/database/udb-mysql/test 以及 http://seanlook.com/2016/03/28/mysql-sysbench/ 一篇写 sysbench 测试工具对 mysql 的压测还算不错，Mariadb 官方也有一篇不错 https://mariadb.org/maria-10-1-mysql-5-7-commodity-hardware/\n\n\n- https://docs.ucloud.cn/database/udb-mysql/test\n- http://seanlook.com/2016/03/28/mysql-sysbench/\n- https://mariadb.org/maria-10-1-mysql-5-7-commodity-hardware/\n- http://www.storagereview.com/sysbench_oltp_benchmark","src/content/posts/mysql-benchmark.mdx","68e0d522d828b2db","mysql-benchmark.mdx","mysql-connect-localhost-and-ip-difference",{"id":911,"data":913,"body":918,"filePath":919,"digest":920,"legacyId":921,"deferredRender":22},{"title":914,"summary":915,"date":916,"tags":917,"group":906,"featured":38},"mysql 不指定 ip 的连接默认都是 localhost","## 问题场景",["Date","2016-10-14T00:00:00.000Z"],[],"## 问题场景\n\n在本地使用 docker 启动了一个 mysql 容器，并把本地的`33067`端口映射到容器内 mysql 的 `3306`，我们假设容器的 ip 地址是 `172.17.0.2`，使用本地的 mysql 客户端尝试连接容器内部的 mysql 服务。\n\n{/* more */}\n\n\n### 方法 1\n\n由于是绑定本地的 33067 端口，所以在连接时指定端口号即可。\n\n```bash\nmysql -uroot -P33067\n```\n\n此时 mysql-client 实际上进入了本地的 mysql 服务，使用 `status` 命令可以查看\n\n```bash\nConnection id:      49\nCurrent database:   \nCurrent user:       root@localhost\nSSL:            Not in use\nCurrent pager:      stdout\nUsing outfile:      ''\nUsing delimiter:    ;\nServer version:     5.5.52-0ubuntu0.14.04.1 (Ubuntu)\nProtocol version:   10\nConnection:     Localhost via UNIX socket\nServer characterset:    latin1\nDb     characterset:    latin1\nClient characterset:    utf8\nConn.  characterset:    utf8\nUNIX socket:        /var/run/mysqld/mysqld.sock\nUptime:         1 hour 35 min 41 sec\n\n```\n\nconnecttion 信息是本地的 unix socket，这样的连接并没有连接到容器内的 mysql。\n\n### 方法 2\n\n尝试指定对应 host 和映射的本地端口，由于映射的是本地端口，所以 host 为 localhost\n\n```bash\nmysql -uroot -hlocalhost -P33067 \n```\n\n依然连接的是本地的 mysql 服务。\n\n\n### 方法 3\n\n直接使用容器的的 ip 地址，默认端口是 3306 \n\n```bash\nmysql -uroot -h172.17.0.2\n```\n\n连接成功，进入容器内部的 mysql 服务。\n\n\n### 方法 4\n\n使用 127.0.0.1 地址，并指定本地映射的端口 33067 \n\n```bash\nmysql -uroot -h127.0.0.1 -P33067 \n```\n\n连接成功，进入容器内部的 mysql 服务。\n\n## 分析\n\n方法 1 和 方法 2 连接的 host 其实都是 localhost（不指定 host，默认是 localhost），此时不论端口指定什么，mysql-client 都尝试使用 unix socket 的通信方式，也就是本地的 socket ，所以如果要连接指定 ip 的 mysql 服务，必须要指定 ip ，即使该 ip 映射的是 localhost。\n\n如上的场景由于容器内的 mysql 服务端口映射到本地的特定端口，即使是这种情况，连接依然需要指定本地 ip 127.0.0.1，而不是本地的 hostname localhost，因为一旦使用了 localhost，mysql-client 就尝试使用本地的 unix socket 连接本地的 mysql 服务。\n\n因而可以得知，mysql 不指定 ip 的连接默认都是 localhost，尝试连接的是本地 mysql 服务，无论端口是什么。\n\n> Beware that by default, the mysql client tries to connect using a unix socket when you tell it to connect to localhost. So do use 127.0.0.1 and not localhost:\n$ mysql -h 127.0.0.1 -P 3306 -u root","src/content/posts/mysql-connect-localhost-and-ip-difference.mdx","0add2565a4c22a81","mysql-connect-localhost-and-ip-difference.mdx","mysql-explain",{"id":922,"data":924,"body":930,"filePath":931,"digest":932,"legacyId":933,"deferredRender":22},{"title":925,"summary":926,"date":927,"tags":928,"group":906,"featured":38},"MySQL explain 详解","转载自 https://www.jianshu.com/p/ea3fc71fdc45",["Date","2018-03-23T00:00:00.000Z"],[929],"explain","转载自 https://www.jianshu.com/p/ea3fc71fdc45\n\nMySQL EXPLAIN命令是查询性能优化不可缺少的一部分，该文主要讲解explain命令的使用及相关参数说明。\n\n## EXPLAIN Output Columns\n\n| 列名          | 说明                                                         |\n| ------------- | ------------------------------------------------------------ |\n| id            | 执行编号，标识select所属的行。如果在语句中没子查询或关联查询，只有唯一的select，每行都将显示1。否则，内层的select语句一般会顺序编号，对应于其在原始语句中的位置 |\n| select_type   | 显示本行是简单或复杂select。如果查询有任何复杂的子查询，则最外层标记为PRIMARY（DERIVED、UNION、UNION RESUlT） |\n| table         | 访问引用哪个表（引用某个查询，如“derived3”）                 |\n| type          | 数据访问/读取操作类型（ALL、index、range、ref、eq_ref、const/system、NULL） |\n| possible_keys | 揭示哪一些索引可能有利于高效的查找                           |\n| key           | 显示mysql决定采用哪个索引来优化查询                          |\n| key_len       | 显示mysql在索引里使用的字节数                                |\n| ref           | 显示了之前的表在key列记录的索引中查找值所用的列或常量        |\n| rows          | 为了找到所需的行而需要读取的行数，估算值，不精确。通过把所有rows列值相乘，可粗略估算整个查询会检查的行数 |\n| Extra         | 额外信息，如using index、filesort等                          |\n\n### id\n\nid是用来顺序标识整个查询中SELELCT 语句的，在嵌套查询中id越大的语句越先执行。该值可能为NULL，如果这一行用来说明的是其他行的联合结果。\n\n### select_type\n\n表示查询的类型\n\n| 类型               | 说明                                                         |\n| ------------------ | ------------------------------------------------------------ |\n| simple             | 简单子查询，不包含子查询和union                              |\n| primary            | 包含union或者子查询，最外层的部分标记为primary               |\n| subquery           | 一般子查询中的子查询被标记为subquery，也就是位于select列表中的查询 |\n| derived            | 派生表——该临时表是从子查询派生出来的，位于form中的子查询     |\n| union              | 位于union中第二个及其以后的子查询被标记为union，第一个就被标记为primary如果是union位于from中则标记为derived |\n| union result       | 用来从匿名临时表里检索结果的select被标记为union result       |\n| dependent union    | 顾名思义，首先需要满足UNION的条件，及UNION中第二个以及后面的SELECT语句，同时该语句依赖外部的查询 |\n| subquery           | 子查询中第一个SELECT语句                                     |\n| dependent subquery | 和DEPENDENT UNION相对UNION一样                               |\n\n### table\n\n对应行正在访问哪一个表，表名或者别名\n\n- 关联优化器会为查询选择关联顺序，左侧深度优先\n- 当from中有子查询的时候，表名是derivedN的形式，N指向子查询，也就是explain结果中的下一列\n- 当有union result的时候，表名是union 1,2等的形式，1,2表示参与union的query id\n\n注意：MySQL对待这些表和普通表一样，但是这些“临时表”是没有任何索引的。\n\n### type\n\ntype显示的是访问类型，是较为重要的一个指标，结果值从好到坏依次是：\nsystem > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL ，一般来说，得保证查询至少达到range级别，最好能达到ref。\n\n| 类型   | 说明                                                         |\n| ------ | ------------------------------------------------------------ |\n| All    | 最坏的情况,全表扫描                                          |\n| index  | 和全表扫描一样。只是扫描表的时候按照索引次序进行而不是行。主要优点就是避免了排序, 但是开销仍然非常大。如在Extra列看到Using index，说明正在使用覆盖索引，只扫描索引的数据，它比按索引次序全表扫描的开销要小很多 |\n| range  | 范围扫描，一个有限制的索引扫描。key 列显示使用了哪个索引。当使用=、 \u003C>、>、>=、\u003C、\u003C=、IS NULL、\u003C=>、BETWEEN 或者 IN 操作符,用常量比较关键字列时,可以使用 range |\n| ref    | 一种索引访问，它返回所有匹配某个单个值的行。此类索引访问只有当使用非唯一性索引或唯一性索引非唯一性前缀时才会发生。这个类型跟eq_ref不同的是，它用在关联操作只使用了索引的最左前缀，或者索引不是UNIQUE和PRIMARY KEY。ref可以用于使用=或\u003C=>操作符的带索引的列。 |\n| eq_ref | 最多只返回一条符合条件的记录。使用唯一性索引或主键查找时会发生 （高效） |\n| const  | 当确定最多只会有一行匹配的时候，MySQL优化器会在查询前读取它而且只读取一次，因此非常快。当主键放入where子句时，mysql把这个查询转为一个常量（高效） |\n| system | 这是const连接类型的一种特例，表仅有一行满足条件。            |\n| Null   | 意味说mysql能在优化阶段分解查询语句，在执行阶段甚至用不到访问表或索引（高效） |\n\n### possible_keys\n\n显示查询使用了哪些索引，表示该索引可以进行高效地查找，但是列出来的索引对于后续优化过程可能是没有用的\n\n### key\n\nkey列显示MySQL实际决定使用的键（索引）。如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。\n\n### key_len\n\nkey_len列显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。使用的索引的长度，在不损失精确性的情况下，长度越短越好 。\n\nEXPLAIN执行计划中有一列 **key_len** 用于表示本次查询中，所选择的索引长度有多少字节，通常我们可借此判断联合索引有多少列被选择了。\n\n在这里 **key_len** 大小的计算规则是：\n\n- 一般地，key_len 等于索引列类型字节长度，例如int类型为4-bytes，bigint为8-bytes；\n- 如果是字符串类型，还需要同时考虑字符集因素，例如：CHAR(30) UTF8则key_len至少是90-bytes；\n- 若该列类型定义时允许NULL，其key_len还需要再加 1-bytes；\n- 若该列类型为变长类型，例如 VARCHAR（TEXT\\BLOB不允许整列创建索引，如果创建部分索引，也被视为动态列类型），其key_len还需要再加 2-bytes;\n\n综上，看下面几个例子：\n\n| 列类型                         | KEY_LEN            | 备注                                                    |\n| ------------------------------ | ------------------ | ------------------------------------------------------- |\n| id int                         | key_len = 4+1 = 5  | 允许NULL，加1-byte                                      |\n| id int not null                | key_len = 4        | 不允许NULL                                              |\n| user char(30) utf8             | key_len = 30*3+1   | 允许NULL                                                |\n| user varchar(30) not null utf8 | key_len = 30*3+2   | 动态列类型，加2-bytes                                   |\n| user varchar(30) utf8          | key_len = 30*3+2+1 | 动态列类型，加2-bytes；允许NULL，再加1-byte             |\n| detail text(10) utf8           | key_len = 30*3+2+1 | TEXT列截取部分，被视为动态列类型，加2-bytes；且允许NULL |\n\n**备注，key_len 只指示了WHERE中用于条件过滤时被选中的索引列，是不包含 ORDER BY/GROUP BY 这部分被选中的索引列。**\n例如，有个联合索引 idx1(c1, c2, c3)，3个列均是INT NOT NULL，那么下面的这个SQL执行计划中，key_len的值是8而不是12：\n\n> SELECT…WHERE c1=? AND c2=? ORDER BY c1;\n\n### ref\n\nref列显示使用哪个列或常数与key一起从表中选择行。\n\n### rows\n\nrows列显示MySQL认为它执行查询时必须检查的行数。注意这是一个预估值。\n\n### Extra\n\nExtra是EXPLAIN输出中另外一个很重要的列，该列显示MySQL在查询过程中的一些详细信息，MySQL查询优化器执行查询的过程中对查询计划的重要补充信息。\n\n| 类型                         | 说明                                                         |\n| ---------------------------- | ------------------------------------------------------------ |\n| Using filesort               | 将用外部排序而不是按照索引顺序排列结果，数据较少时从内存排序，否则需要在磁盘完成排序，代价非常高，**需要添加合适的索引**。注意虽然叫filesort但并不是说明就是用了文件来进行排序，只要可能排序都是在内存里完成的。大部分情况下利用索引排序更快，所以一般这时也要考虑优化查询了。使用文件完成排序操作，这是可能是ordery by，group by语句的结果，这可能是一个CPU密集型的过程，可以通过选择合适的索引来改进性能，用索引来为查询结果排序。 |\n| Using temporary              | 用临时表保存中间结果，常用于GROUP BY 和 ORDER BY操作中，一般看到它说明查询需要优化了，就算避免不了临时表的使用也要尽量避免硬盘临时表的使用。 |\n| Not exists                   | MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行， 就不再搜索了。 |\n| Using index                  | 说明查询是覆盖了索引的，不需要读取数据文件，从索引树（索引文件）中即可获得信息。如果同时出现using where，表明索引被用来执行索引键值的查找，没有using where，表明索引用来读取数据而非执行查找动作。这是MySQL服务层完成的，但无需再回表查询记录。 |\n| Using index condition        | 这是MySQL 5.6出来的新特性，叫做“索引条件推送”。简单说一点就是MySQL原来在索引上是不能执行如like这样的操作的，但是现在可以了，这样减少了不必要的IO操作，但是只能用在二级索引上。 |\n| Using where                  | 通常是进行了全表/全索引扫描后再用WHERE子句完成结果过滤，**需要添加合适的索引**。**注意**：Extra列出现Using where表示MySQL服务器将存储引擎返回服务层以后再应用WHERE条件过滤。 |\n| Using join buffer            | 使用了连接缓存：**Block Nested Loop**，连接算法是块嵌套循环连接;**Batched Key Access**，连接算法是批量索引连接 |\n| impossible where             | where子句的值总是false，不能用来获取任何元组                 |\n| select tables optimized away | 在没有GROUP BY子句的情况下，基于索引优化MIN/MAX操作，或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 |\n| distinct                     | 优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作 |","src/content/posts/mysql-explain.mdx","7a8ed5e37fc0a246","mysql-explain.mdx","mysql-lost-connection-error",{"id":934,"data":936,"body":942,"filePath":943,"digest":944,"legacyId":945,"deferredRender":22},{"title":937,"summary":938,"date":939,"tags":940,"group":906,"featured":38},"MySQL 2013 lost connection error 详解","MySQL 在线上的一个新的部署的服务中报：",["Date","2018-04-23T00:00:00.000Z"],[941],"error","MySQL 在线上的一个新的部署的服务中报：\n\n```mysql\npymysql.err.OperationalError (2013, 'Lost connection to MySQL server during query')\n```\n\n翻阅官方文档解释了这么几种可能性问题，详见：https://dev.mysql.com/doc/refman/5.7/en/error-lost-connection.html\n\n1. 连接 MySQL 服务的网络有问题\n\n   网络问题会导致 MySQL 的 connection 无故断掉，会报这个错误，所以首先检查 client 服务到 MySQL 服务是不是延迟很高。\n\n2. 读取或写入很多行数据，导致数据传输超时\n\n   MySQL [net_read_timeout](https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_net_read_timeout) 和 [net_write_timeout](https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_net_write_timeout) 控制一次连接传输数据等待的时间，如果 server 从 client 读取数据 net_read_timeout 用来控制在 connection 断开之前等待的秒数，如果 server 正在往 client 写入数据，则用 net_write_timeout 控制。\n\n   所以如果有大量的数据进行插入或者读取，注意调整这两个 variable 来控制时间，以防止 connection 被断掉，默认是 30s。\n\n3. 少数情况下，这个错误发生在 connection 初始化的时候\n\n   如果与 MySQL 服务器建立连接非常的慢，而且MySQL 的服务 [connect_timeout](https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_connect_timeout) 又很低，则有可能会发生这样的错误，可以检查初始连接建立的开销，也可以检查 SHOW GLOBAL STATUS LIKE 'Aborted_connects' 来查看是否有大量的连接被断开的情况出现。\n\n4. 如果以上都不是，有可能是数据传输中使用了较大的 string filed 或者 blob filed，导致超过了 [max_allowed_packet](https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_max_allowed_packet)\n\n   检查你的 MySQL 服务，查看是否有连接会传输比较大的数据，此时你可能会遇到 [ER_NET_PACKET_TOO_LARGE](https://dev.mysql.com/doc/refman/5.7/en/error-messages-server.html#error_er_net_packet_too_large)  这个错误，确保你的 max_allowed_packte 是足够大的，足够在一次数据中传输比较大的数据\n\n对照检查了上面的 4 种情况，发现新上线的产品并不满足，查询 MySQL 错误日志，报如下错误：\n\n```shell\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156972  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156967  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156923  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156921  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156880  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156879  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156869  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156854  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156803  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156793  user: 'block_chain'\n\n180422 17:13:57 [Warning] /opt/udb/program/mysql/mysql-5.5.24/bin/mysqld: Forcing close of thread 156786  user: 'block_chain'\n```\n\n从日志中不难看出是 MySQL 进程强行关闭了连接中的线程，也就是说由于连接触发了某种条件导致连接被 MySQL 强制关了。\n\nMySQL 官方有上百个参数，既然是触发某种条件，猜测可能是某个超时设置，查看所有超时相关参数:\n\n```mysql\nshow variables like '%timeout%';\n\nconnect_timeout\t10\ndelayed_insert_timeout\t300\ninnodb_lock_wait_timeout\t50\ninnodb_rollback_on_timeout\tOFF\ninteractive_timeout\t28800\nlock_wait_timeout\t31536000\nnet_read_timeout\t30\nnet_write_timeout\t60\nslave_net_timeout\t3600\nwait_timeout\t300\n```\n\n依次对照每个超时参数的含义最后锁定了**wait_timeout** 这个参数，其含义是：**The number of seconds the server waits for activity on a noninteractive connection before closing it**. \n\n**由于在应用程序中数据库连接池配置的连接回收时间是 600s，MySQL 配置的是 300s，也就是应用程序中认为一个连接还没有到回收的时间，但是 MySQL 自己判断需要强制回收了。**\n\n**解决方案**：尝试把 MySQL 的 **wait_timeout** 调至比应用程序高一些，观察应用程序行为。结果不再报错了，至此就找到了 MySQL 报 `Lost connection to MySQL server during query` 的问题了。\n\n**小结**\n\nMySQL 的这个错误除了官方说的几种 case ，还需要针对自己的业务场景进行适当探索和甄别，具体情况具体分析，也应了那句话**大胆猜想，小心求证**。","src/content/posts/mysql-lost-connection-error.mdx","fbd89970417d590e","mysql-lost-connection-error.mdx","mysql-online-migration-program-and-tool-compare",{"id":946,"data":948,"body":953,"filePath":954,"digest":955,"legacyId":956,"deferredRender":22},{"title":949,"summary":950,"date":951,"tags":952,"group":906,"featured":38},"mysql 在线 scheme 变更方案以及开源工具评测","# mysql schema 变更的一般方案",["Date","2017-10-19T00:00:00.000Z"],[],"# mysql schema 变更的一般方案\n\n变更 mysql table schema 是使用 mysql 的过程中经常需要做的一件事，一般意义变更可以根据场景的不同做不同的操作。\n\n## 直接 alter\n\n如果数据量非常少，读写不频繁，可以直接对表进行 alter，由于数据少直接 alter 并会造成太长时间的锁表，一般情况都是能接受的\n\n## 停机升级\n\n对于数据量特别大的表，如果直接 alter 将导致线上不可用可以考虑停机修改，当然如果停机时间过长不能接受，只能做在线改了\n\n## 不停机在线迁移\n\n很多团队面临的业务都无法停机，在线变更 schema 也确实是很多业务团队都会面临的问题，我曾经做过一次 [Mongodb 亿级拆分方案](/blog/mongodb-single-table-split)，大致思路是：\n1、在应用程序中拦截所有的 update，insert，delete 操作\n2、为数据一致性建立迁移缓冲区，临时保存迁移用户的所有业务数据\n3、在业务代码中利用迁移缓冲区做一致性输出\n4、离线迁移所有用户数据\n\n{/* more */}\n\n\n最核心的需要解决的问题是**拦截所有操作**和**保证用户数据在迁移过程中的一致性**。\n\n在 mysql 中进行在线 schema 变更其实也会面临这样的问题，但往往由于不同团队业务发展的不同，导致拦截所有的操作变得不可能，这就需要借助 mysql 自身的特点进行 schema 变更，思路就是：\n1、建立临时表\n2、原表建立更新触发器\n3、迁移数据\n\n利用 [mysql 触发器](https://dev.mysql.com/doc/refman/5.7/en/trigger-syntax.html) 可以对原表的更改进行跟踪，以达到保证数据一致性的目的。\n\n对于在线变更 mysql schema 已经有不同的团队给出了不同的解决方案。\n\n**[pt-online-schema-change](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html)**\n\nPercona 出品，Perl 实现。\n\n**[OnlineSchemaChange](https://github.com/facebookincubator/OnlineSchemaChange)**\n\nFacebook 出品，Python 实现。\n\n**[gh-ost](https://github.com/github/gh-ost)**\n\nGitHub 出品，Go 实现。\n\n下面简单对三个工具的特性和使用进行了评测\n\n\n# pt-online-schema-change\n\nhttps://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html\n\n## 特征\n\n在线变更 mysql scheme，不阻塞表的 reads 和 writes\n\n```bash\npt-online-schema-change --alter \"ADD COLUMN c1 INT\" D=sakila,t=actor\n```\n\n## 使用 pt 前需要注意和准备的\n\n- 仔细阅读工具文档\n- 审查工具已知的BUG\n- 在非生产环境测试\n- 备份生产环境数据并确认\n\n## pt 的工作方式和原理\n\npt-online-schema-change 模拟了 mysql 内部更改表的方式，但是 pt 是在原始表的副本上进行修改，这意味着原始表不会被 lock，client 依然可以继续读写原始表的数据，这样线上的业务不受影响。\n\npt 的工作方式大致流程如下：\n\n1.创建一个需要修改的 table 的副本，即一张 empty table\n2.根据你的需要修改这张表，\n3.从原始表中复制数据到修改之后的 table\n4.复制完成之后，用新表代替旧表，并删除旧表\n\npt 的复制以 small chunk 的形式执行（见[--chunk-time](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html#cmdoption-pt-online-schema-change-chunk-time)），不同的大小的 chunk 会导致其执行的总时间是千差万别的，而且为了保证数据的一致性，pt 会在 origin table 创建 trigger 来保证对 origin table 的修改反映到 new table 中，所以**必须保证原始表中不存在相同的触发器才能让 pt 正常工作**。\n\npt 在数据 copy 完成之后，会使用 mysql 提供的原子操作 `rename table` 同时修改 origin table 和 new table，修改完成之后drop origin table。\n\n如果 origin table 有外键 refer，将会增加使用 pt 的复杂度以及会有一定的风险，由于外键的存在 pt 将无法使用 atomic 的方式完成表的替换，必须把对应的外键更新完成才可以进行表的修改，pt 支持两种方式来完成这项任务（见[--alter-foreign-keys-method](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html#cmdoption-pt-online-schema-change-alter-foreign-keys-method))\n\n## 使用 pt 的注意事项\n\n\n### 外键带来的影响\n\n\n最终的表和 origin table 有相同的 foreign keys 和 index，但是对象的名字可能稍有差别这样是为了避免冲突。\n\n### pt 的执行操作必须手动指定\n\n安全起见，pt 默认不会执行表的修改，除非你指定了 `—execute` ，默认是未开启的状态，pt 提供了一些列的措施用来避免一些问题的出现和不必要的负载，包括自动检测 replicate 等：\n\n- pt 将拒绝执行如果 origin table 没有 primary key 或 unique index [—alter](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html#cmdoption-pt-online-schema-change-alter)\n- pt 将拒绝执行如果检测到 replicate filter `—[no]check-replication-filters`\n- pt 将停止 copy 如果检测到 replicate 延迟过高 `[—max-lag](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html#cmdoption-pt-online-schema-change-max-lag)`\n- pt 将停止 copy 或者终止操作如果检测到 server 的负载过高 `[—max-load](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html#cmdoption-pt-online-schema-change-max-load) and [—critical-load](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html#cmdoption-pt-online-schema-change-critical-load)`\n- pt 将设置 innodb_lock_wait_timeout=1 and (for MySQL 5.5 and newer) lock_wait_timeout=60 ，保证其操作过程尽量不破坏其他 transaction `[—set-vars](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html#cmdoption-pt-online-schema-change-set-vars)`\n- pt 将拒绝修改表如果有外键约束，除非指定外键的修改方法 `[—alter-foreign-keys-method](https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html#cmdoption-pt-online-schema-change-alter-foreign-keys-method)`\n\n## pt 的下载安装\n\n```\nwget percona.com/get/percona-toolkit.tar.gz\nwget percona.com/get/percona-toolkit.rpm\nwget percona.com/get/percona-toolkit.deb\n```\n根据不同的平台下载和解压即可使用，再次强调使用前一定要在测试环境进行测试、生成环境一定要提前进行备份再去执行，要仔细研究他的文档，对各个参数了如指掌。\n\n## 参考资料\n\n- https://www.2cto.com/net/201612/573563.html\n- https://www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html\n\n# OnlineSchemaChange\n\nhttps://github.com/facebookincubator/OnlineSchemaChange\n\n## 特征\n\nOnlineSchemaChange 和 pt 的工作方式类似，不同的是基于 Python 而且已经在 Facebook 进行了实践，其最初的版本是 PHP 的，改成 Python 之后非常方便开发者对其内部原理进行了解和掌握。\n\n正如 OnlineSchemaChange 文档所说，Facebook 对一致性的要求高于一切，所以 OnlineSchemaChange 会反复对数据的一致性进行校验，然后才会切换表。\n\n## 工作方式和原理\n\nOnlineSchemaChange 会分为如下几个阶段\n\nOSC 所有的语句在 sql_log_bin = 0 模式下工作，他可以再 master 或者 replica 上执行，意味着你可以事先在 replica 执行，待验证没有问题之后切换 replica 为 master。\n\nOSC 的工作分为几个阶段\n\n1.init 阶段\n\n在该阶段，首先做一些必备的检查确保所有需要修改的 schema 满足必要的条件，然后用新的 schema 创建一个 empty table 称之为 `shadow table`，同时创建一个 change table 用来记录异步 dump 和 load 的过程中 origin table 发生的改变叫 `deltas table`，`deltas table` 包含原始表的所有数据和一个自增序列用来跟踪变化的顺序，以及一个 int column 跟踪 dml 语句。\n\n与此同时，insert 、update、delete 三个 trigger 会在 origin table 中创建用来跟踪数据对应的变化，同 pt 一样需要利用 trigger，所以 origin table 上不能有其他的 trigger。\n\n比较特殊点的是 update trigger，如果 origin table 中的 PK column 没有改变，仅仅会在 `deltas table` 中记录更新后的值，如果 PK column 发生了变更，一条 delete 和 insert 语句将会同时记录，它们用来删除旧数据和插入新数据。\n\n2.dump 阶段\n\n一个 consistent snapshot 将打开用于对现有的表创建一个快照 stale view。使用 select NTO OUTFILE dump data 到磁盘以分块的形式，没有 使用 insert NTO ... SELECT FROM 是为了避免锁表。\n\n3.load 阶段\n\n然后从 disk 上 load data 到 mysql 的 shadown table 使用 load data infile，load 完成之后删除这些 dump 的文件。\n\n要确保磁盘空间是足够的，尤其是 origin table 是被压缩过的。\n\n4.replay 阶段\n\n在 dump 和 load 阶段会有很多 DML 发生在 origin  table，change table 会记录这一些利用我们之前创建的 trigger，这些记录会不断 replay 到 shadow table 中，replay 会执行很多次，因为每次 replay 时又有 DML 发生了。\n\n我们不会从 delta table 取数据只会获取变更的 id 和类型，数据本质 replay 时会去再查询。\n\n## 使用限制和要求\n\n- 必须要有主键或唯一性外键\n- 不支持重命名 column\n- origin table 不能有 trigger \n- 不能有外键引用\n- 只有一个 OSC 实例存在\n- Running OSC for the same table on Master and Slave at the same time will break replication.\n- OSC will stop replication on slave by default to avoid MDL lock chaining on slaves\n- OSC is not able to run schema change together with RBR on any MySQL version other than Facebook's MySQL. See more detail in\n- 无法在非 Facebook Mysql 基于 RBR 模式运行 OSC\n\n## 本地测试遇到的问题\n\n\n1.osc 不支持非 mysql 版本的 binlog_format 为 row 的\n\n查看 mysql 的 binlog 格式 `show variables like '$binlog_format%';`\n\n2.mac 下报 UNABLE_TO_GET_DISK_SPACE\n\n```bash\n    raise OSCError('UNABLE_TO_GET_DISK_SPACE', {'path': path})\nOSCError: UNABLE_TO_GET_DISK_SPACE: Unable to read free disk size for path: NULL\n```\n\n可能由于是 mac 系统无法获取磁盘空间，所以指定了一个目录用来存放 dump 出来的文件\n\n3.无法使用 `SELECT INTO OUTFILE` 语句\n\n\n```bash\nGENERIC_MYSQL_ERROR: MySQL Error during stage \"running DDL on db 'blog'\": [1290] The MySQL server is running with the --secure-file-priv option so it cannot execute this statement\n```\n\n指定导出目录之后由于 mysql 的限制 无法使用 `SELECT INTO OUTFILE` 语句，查看当前的 `show variables like '%secure_file_pri%';` 指定导出目录到新建的目录，如果没有自己设置一个再指定导出目录。\n\n\n## 本地测试的一些指标\n\n100 万数据，origin table 数据未发生改动\n\n```bash\nINFO      2017-10-20 12:02:54.863 Time in dump: 19.043s\nINFO      2017-10-20 12:02:54.863 Time in load: 140.702s\nINFO      2017-10-20 12:02:54.863 Time in replay: 0.254s\nINFO      2017-10-20 12:02:54.863 Time in table checksum: 27.589s\nINFO      2017-10-20 12:02:54.863 Time in delta checksum: 0.000s\nINFO      2017-10-20 12:02:54.864 Time holding locks: 1.685s\n```\n\n\n100 万数据，origin table 数据全部发生了改变\n\n```\nINFO      2017-10-20 13:59:07.838 Time in load: 244.596s\nINFO      2017-10-20 13:59:07.839 Time in replay: 805.802s\nINFO      2017-10-20 13:59:07.839 Time in table checksum: 828.422s\nINFO      2017-10-20 13:59:07.839 Time in delta checksum: 0.001s\nINFO      2017-10-20 13:59:07.839 Time holding locks: 1.183s\n```\n\n## 参考资料\n\n- https://github.com/facebookincubator/OnlineSchemaChange/wiki/How-OSC-works\n- http://www.jianshu.com/p/bd9f38340e83\n- http://blog.csdn.net/zhuwinmin/article/details/72875964\n\n\n> gh-ost 要求在集群模式下工作，操作复杂，等有空再更\n\n\n\u003C!-- # gh-ost\n\nhttps://github.com/github/gh-ost\n\ngithub 出品的，没有使用触发器的一种迁移方案，其工作原理和其他方案类似\n\n### **错误一**\n\n2017-10-20 16:27:34 FATAL 127.0.0.1:3306 must have binary logs enabled\n\nhttps://oguya.ch/posts/2016-01-07-enable-mysql-binlog/\n\n2017-10-20T08:33:49.565140Z 0 [ERROR] You have enabled the binary log, but you haven't provided the mandatory server-id. Please refer to the proper server start-up parameters documentation\n\n# mysql 错误\n\n2017-10-20T09:44:46.421571Z 5 [Note] Aborted connection 5 to db: 'information_schema' user: 'root' host: 'localhost' (Got an error reading communication packets)\n\nhttps://www.percona.com/blog/2016/05/16/mysql-got-an-error-reading-communication-packet-errors/\n\nhttp://www.cnblogs.com/ivictor/p/5979731.html\n\n## MySQL · 答疑解惑 · MySQL 的那些网络超时错误\n\nhttp://mysql.taobao.org/monthly/2017/05/04/ -->","src/content/posts/mysql-online-migration-program-and-tool-compare.mdx","4b6f4bd7c713d370","mysql-online-migration-program-and-tool-compare.mdx","mysql-optimization-01",{"id":957,"data":959,"body":967,"filePath":968,"digest":969,"legacyId":970,"deferredRender":22},{"title":960,"summary":961,"date":962,"tags":963,"group":906,"featured":38},"MySQL 优化 01 之慢查询","最近线上生产环境中有些 MySQL 的语句特别慢，跑一个查询需要大概 5 分钟，已经到了不得不解决的地步了。",["Date","2018-11-13T00:00:00.000Z"],[964,965,966],"优化","聚合","join","最近线上生产环境中有些 MySQL 的语句特别慢，跑一个查询需要大概 5 分钟，已经到了不得不解决的地步了。\n\n\n## 案例一：单表复杂语句的聚合计算\n\n### 问题描述\n\n单表数据超过 1500 万，写入不是特别频繁，查询很多，需要对表中订单的费用的进行实时计算，主要是基于时间以及订单状态进行运算。\n\n```sql\nSELECT count(order.id) AS order_count, sum(order.original_total_fee) AS original_total_fee, sum(order.settlement_fee) AS settlement_fee, sum(order.total_fee) AS total_fee, order.seller_id AS order_seller_id\nFROM order\nWHERE order.create_time \u003C '2018-11-10 00:00:00' and create_time > '2016-10-10' AND order.order_status IN ('paid', 'refund_refused') AND order.partner_id IN (105203908, 105203916, 105203958, 105203910) AND  order.seller_id = 96691 AND order.user_id NOT IN (105203908, 105203916, 105203958, 105203910) GROUP BY order.seller_id;\n\n```\n\n表中有以下索引：\n\n```json\n\n{\n    \"data\":\n    [\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 0,\n            \"Key_name\": \"PRIMARY\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 16500090,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_order_id_device_id\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"order_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 16500090,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_order_id_device_id\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"device_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 16500090,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_device_id\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"device_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 4125022,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_device_id\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"order_status\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 4125022,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_device_id\",\n            \"Seq_in_index\": 3,\n            \"Column_name\": \"order_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 16500090,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_seller_id_order_name\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"seller_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 18,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_seller_id_order_name\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"order_name\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 5125,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_seller_id_create_time\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"seller_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 5899,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"order_seller_id_create_time\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"create_time\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 16500090,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_status_seller_id_order_id\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"order_status\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 18,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_status_seller_id_order_id\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"seller_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 31548,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_status_seller_id_order_id\",\n            \"Seq_in_index\": 3,\n            \"Column_name\": \"order_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 16500090,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_seller_id_user_id_create_time\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"seller_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 18,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_seller_id_user_id_create_time\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"user_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 8250045,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_seller_id_user_id_create_time\",\n            \"Seq_in_index\": 3,\n            \"Column_name\": \"create_time\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 16500090,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        }\n    ]\n}           \n\n```\n\n这个 SQL 语句每次执行时间因需要计算的数据大小而异，平均时间再 1 分钟，更长会达到 3 分钟或更久。\n\n\n### 问题分析\n\n这个表已经有不少索引了，先不说这些索引的合理性，单从上面的语句来看，应该尽量使用现存的索引来优化查询，使用 explain 语句分析上面的查询输出如下：\n```json\n\n{\n    \"data\":\n    [\n        {\n            \"id\": 1,\n            \"select_type\": \"SIMPLE\",\n            \"table\": \"order\",\n            \"type\": \"range\",\n            \"possible_keys\": \"order_seller_order_name,order_seller_id_create_time,idx_order_status_seller_id_order_id,idx_seller_id_user_id_create_time\",\n            \"key\": \"order_seller_id_create_time\",\n            \"key_len\": \"12\",\n            \"ref\": null,\n            \"rows\": 22764,\n            \"Extra\": \"Using where\"\n        }\n    ]\n}\n```\n\n可以看到上面的语句使用了 `order_seller_id_create_time` 这个索引，这个不难理解，因为 where 子句中用了 seller_id 的等值以及 create_time 的范围，符合最左前缀的要求，按理来说查询应该不是很慢，rows 显示也就只有几万条数据，不算太大，尝试尽量减少数据范围，继续观察对计算时间的影响，做了以下几种修改：\n\n**缩小 create_time 时间范围**\n\n只有当数据明显减少之后计算时间才会缩短\n\n**简化 where 子句的条件**\n\n去掉 user_id 和 partner_id 的删选，尽量简化 where 子句的删选，索引选择依然没有变，但是如果不缩小数据范围，依然很慢。\n\n在做了以上几种尝试之后，初步能得出结论：**慢不在于查询，而在于聚合运算**。\n\n既然索引本身无助于聚合运算，尝试对数据库硬件进行升级，来保证 MySQL 有充分的资源进行计算，虽然查了一圈没有找到特别详细的描述 MySQL 做聚合运算的原理，猜测肯定会用到不少资源。\n\n\n### 方案尝试\n\n#### 方案一\n\n\n原有 MySQL 实例用的是云，6G 内存，ssd 的实例，直接增加内存到 12G，然后直行上面的运算，并没有显著改善\n\n#### 方案二\n\n\n修改 `innodb_buffer_pool_size` 大小从原来的 4G 到 8G，并且更改 `innodb_buffer_pool_instances` 为 2，让每个 buffer_pool 分配 4G 内存，然后直行上面的计算，速度得到显著改善。\n\n\n### 方案总结\n\n\n**提升硬件资源有利于 MySQL 执行聚合运算**，但是最终是有利于 MySQL 把查询索引都缓存了改善了查询，还是改善了聚合计算所需要的资源在这个场景之下都不太好能得出结论，猜测二者都有可能。\n\n\n[`innodb_buffer_pool_size`](https://dev.mysql.com/doc/refman/5.5/en/innodb-parameters.html#sysvar_innodb_buffer_pool_size) 是 MySQL 为执行 MySQL 查询计算所预留的一个缓存区，本质上是越大越好，因为这样的话，MySQL 会把大部分运算直接在内存中执行，`innodb_buffer_pool_instances` 是为了在并发大的时候提升并发读和并发写的，单个 `innodb_buffer_pool_size` 的大小是 innodb_buffer_pool_size/innodb_buffer_pool_instances，官方建议 innodb_buffer_pool_size 最小不要小于 1G。\n\n\n## 案例二：大表 join 查询\n\n\n### 问题描述\n\n两个大表 join 查询，大表 2000 万以上，小表 1500 万以上\n\n```sql\nSELECT order_base.id AS order_base_id, order_base.user_id AS order_base_user_id\nFROM order_base INNER JOIN order ON order_base.id = order.order_id\nWHERE order.seller_id = 96691 AND order_base.paid_time >= '2015-10-03T16:43:07' AND order_base.paid_time \u003C '2018-11-12T16:43:07' AND order_base.paid = 1 AND order.partner_id NOT IN (105203908, 105203916, 105203958, 105203910) ORDER BY order_base.order_id DESC\n LIMIT 10;\n\n```\n\norder_base 索引如下:\n```json\n{\n    \"data\":\n    [\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 0,\n            \"Key_name\": \"PRIMARY\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 20935372,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 0,\n            \"Key_name\": \"order_id\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"order_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 20935372,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"uuid\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"uuid\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 20935372,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_base_user_id_id\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"user_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 6978457,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_base_user_id_id\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 20935372,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_base_user_id_order_id\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"user_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 20935372,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_base_user_id_order_id\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"order_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 20935372,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_base_user_id_create_time\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"user_id\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 10467686,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_base_user_id_create_time\",\n            \"Seq_in_index\": 2,\n            \"Column_name\": \"create_time\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 20935372,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        },\n        {\n            \"Table\": \"order_base\",\n            \"Non_unique\": 1,\n            \"Key_name\": \"idx_order_base_paid_time\",\n            \"Seq_in_index\": 1,\n            \"Column_name\": \"paid_time\",\n            \"Collation\": \"A\",\n            \"Cardinality\": 20935372,\n            \"Sub_part\": null,\n            \"Packed\": null,\n            \"Null\": \"\",\n            \"Index_type\": \"BTREE\",\n            \"Comment\": \"\",\n            \"Index_comment\": \"\"\n        }\n    ]\n}\n```\n\norder 表索引同 **案例一**。\n\n如果最终没有数据满足条件，这个 SQL 语句非常慢，如果有数据满足条件，速度也不算特别理想。\n\n\n### 问题分析\n\n使用 explain 语句可以看到如下输出：\n```json\n{\n    \"data\":\n    [\n        {\n            \"id\": 1,\n            \"select_type\": \"SIMPLE\",\n            \"table\": \"order\",\n            \"type\": \"index\",\n            \"possible_keys\": \"order_order_id_device_id,order_seller_id_order_name,seller_id_create_time,idx_seller_id_user_id_create_time\",\n            \"key\": \"order_order_id_device_id\",\n            \"key_len\": \"12\",\n            \"ref\": null,\n            \"rows\": 473,\n            \"Extra\": \"Using where\"\n        },\n        {\n            \"id\": 1,\n            \"select_type\": \"SIMPLE\",\n            \"table\": \"order_base\",\n            \"type\": \"eq_ref\",\n            \"possible_keys\": \"PRIMARY,idx_order_base_paid_time\",\n            \"key\": \"PRIMARY\",\n            \"key_len\": \"4\",\n            \"ref\": \"martin_order.order.order_id\",\n            \"rows\": 1,\n            \"Extra\": \"Using where\"\n        }\n    ]\n}\n\n```\n\n关于 explain 语句的输出，详见 [mysql-explain](/blog/mysql-explain)，这里可以明显看到表 order 中的 ref 是 null，type 是 index，也就是是一个索引扫描，也就是说 **order 表可能使用了一个不合理的索引 `order_order_id_device_id` 从而造成了 order 需要进行全索引扫描，这是非常糟糕的索引选择类型，这有可能是造成查询慢的原因之一**。\n\n表 order_base 用的 type 是 eq_ref，意味着 order_base 使用的是唯一性索引或者 primary key，从上不能看出是 primary key，性能较好。\n\n\n### 方案尝试\n\norder 表有很多索引，在这个 join 语句的 where 子句中 order 表主要使用了 seller_id 和 partner_id，已经存在的索引中只有 `order_seller_id_create_time` 满足场景，因而可以在 join 的时候强制表 order 走这个索引：\n\n\n```sql\nSELECT order_base.id AS order_base_id, order_base.user_id AS order_base_user_id\nFROM order_base INNER JOIN order force index(order_seller_id_create_time) ON order_base.id = order.order_id\nWHERE order.seller_id = 96691 AND order_base.paid_time >= '2015-10-03T16:43:07' AND order_base.paid_time \u003C '2018-11-12T16:43:07' AND order_base.paid = 1 AND order.partner_id NOT IN (105203908, 105203916, 105203958, 105203910) ORDER BY order_base.order_id DESC\n LIMIT 10;\n```\n\n再使用 explain 输出如下：\n\n```json\n{\n    \"data\":\n    [\n        {\n            \"id\": 1,\n            \"select_type\": \"SIMPLE\",\n            \"table\": \"order\",\n            \"type\": \"ref\",\n            \"possible_keys\": \"order_seller_id_create_time\",\n            \"key\": \"order_seller_id_create_time\",\n            \"key_len\": \"4\",\n            \"ref\": \"const\",\n            \"rows\": 348810,\n            \"Extra\": \"Using where; Using filesort\"\n        },\n        {\n            \"id\": 1,\n            \"select_type\": \"SIMPLE\",\n            \"table\": \"order_base\",\n            \"type\": \"eq_ref\",\n            \"possible_keys\": \"PRIMARY,idx_order_base_paid_time\",\n            \"key\": \"PRIMARY\",\n            \"key_len\": \"4\",\n            \"ref\": \"martin_order.order.order_id\",\n            \"rows\": 1,\n            \"Extra\": \"Using where\"\n        }\n    ]\n}\n\n```\n\n可以看到表 order 的 type 已经是 ref，表示使用了一个非唯一性索引或者是满足最左前缀的索引，而且 ref 已经成了 const，是非常好的索引选择。\n\n在 join 查询中，需要 match 的总行数是各个表 explain output 中 rows 的乘机，虽然说更改之后表 order 的 rows 明显增多，但是能够合理使用索引，还是明显改善查询速度，优化后的 SQL 语句基本是秒查。\n\n\n**update**\n\n上述优化对于 `order_base.paid = 1` 这个条件删选出的数据如果比较少时确实很快，10 万以下，但是如果非常多还是很慢，后来发现 order 表也有一个类似的 paid 状态，相对来说数据要少很多，换成 `order.order_status='paid'` 会有显著改善，也就是说上述 SQL 语句在不同的查询量级的情况下使用不同的方案更合适。\n\n\n\n## 小结\n\nMySQL 的慢查询大多都集中在索引使用不合理，对 MySQL 的索引原理要有深入理解才能准确定位问题，而且 MySQL 的性能问题是多方面的，有硬件也有数据的影响，要多方面综合考虑。","src/content/posts/mysql-optimization-01.mdx","b0c134451a2721a3","mysql-optimization-01.mdx","mysql-optimization-02",{"id":971,"data":973,"body":978,"filePath":979,"digest":980,"legacyId":981,"deferredRender":22},{"title":974,"summary":975,"date":976,"tags":977,"group":906,"featured":38},"MySQL 优化 02 之连接管理","## 问题描述",["Date","2018-12-29T00:00:00.000Z"],[964],"## 问题描述\n\n\n最近一直在服务端的性能优化，逐个解决线上之前遗留的一些问题，其中有一个问题是后端 rpc service MySQL 连接中出现大量 sleep 的连接，而且时间很长。我们技术栈用的是 Python，用 sqlalchemy 做 ORM 层，在 sqlalchemy 连接池中已经配置了对超过 300s 的连接做 recycle，但是 mysql 的 processlist 中出现了大量超过 300s 的连接。\n\n```\nID          USER    HOST              DB      COMMAND TIME    STATE   INFO\n163487088   user  10.10.91.38:45925   martin  Sleep   28233       NULL\n163492031   user  10.10.91.38:46375   martin  Sleep   26930       NULL\n163517693   user  10.10.115.248:52431 martin  Sleep   20166       NULL\n163517692   user  10.10.115.248:52430 martin  Sleep   20165       NULL\n163520369   user  10.10.115.89:59120  martin  Sleep   19472       NULL\n163531406   user  10.10.195.222:36208 martin  Sleep   16517       NULL\n163535568   user  10.10.195.222:42941 martin  Sleep   15500       NULL\n163545536   user  10.10.91.38:52311   martin  Sleep   9649        NULL\n163548642   user  10.10.131.145:54374 martin  Sleep   7659        NULL\n163548641   user  10.10.131.145:54372 martin  Sleep   7658        NULL\n163548640   user  10.10.131.145:54366 martin  Sleep   7658        NULL\n163550399   user  10.10.131.145:59423 martin  Sleep   6535        NULL\n163551913   user  10.10.138.210:52551 martin  Sleep   5582        NULL\n163551912   user  10.10.138.210:52550 martin  Sleep   5582        NULL\n163551911   user  10.10.138.210:52547 martin  Sleep   5582        NULL\n163551910   user  10.10.138.210:52544 martin  Sleep   5582        NULL\n163551307   user  10.10.115.248:34162 martin  Sleep   5378        NULL\n163553402   user  10.10.1.39:58200    martin  Sleep   4624        NULL\n163553858   user  10.10.91.38:54184   martin  Sleep   4321        NULL\n163554229   user  10.10.55.228:51618  martin  Sleep   4098        NULL\n163553577   user  10.10.46.232:51933  martin  Sleep   3982        NULL\n163553712   user  10.10.46.232:52096  martin  Sleep   3976        NULL\n163554595   user  10.10.131.145:42649 martin  Sleep   3873        NULL\n163554582   user  10.10.1.39:34434    martin  Sleep   3505        NULL\n163556848   user  10.10.3.68:37552    martin  Sleep   2440        NULL\n163557218   user  10.10.46.232:55973  martin  Sleep   2211        NULL\n163556771   user  10.10.67.225:49920  martin  Sleep   2150        NULL\n163557587   user  10.10.67.225:52996  martin  Sleep   1976        NULL\n163558125   user  10.10.67.225:54897  martin  Sleep   1648        NULL\n163558292   user  10.10.1.39:48445    martin  Sleep   1534        NULL\n163558147   user  10.10.138.210:39829 martin  Sleep   1510        NULL\n163558505   user  10.10.131.145:51929 martin  Sleep   1416        NULL\n163558570   user  10.10.105.200:53281 martin  Sleep   1374        NULL\n163558339   user  10.10.165.71:45458  martin  Sleep   1352        NULL\n163558899   user  10.10.141.67:38908  martin  Sleep   1176        NULL\n163558631   user  10.10.131.145:52252 martin  Sleep   1160        NULL\n163558968   user  10.10.115.248:53551 martin  Sleep   1128        NULL\n163559006   user  10.10.1.39:51176    martin  Sleep   1107        NULL\n163559041   user  10.10.1.39:51377    martin  Sleep   1079        NULL\n163559090   user  10.10.15.53:38326   martin  Sleep   1052        NULL\n163559098   user  10.10.138.210:42150 martin  Sleep   1048        NULL\n\n```\n\n\n## 理解 processlist \n\nMySQL 的 processlist 显示的 MySQL 实例与所有 client 的连接状态，默认情况下只显示当前账户下面的连接，root 用户可以查看所有其他用户的连接，也可以为账户赋予 processlist 权限，方便查看所有用户的连接。\n\n可以使用以下 SQL 查看 processlist 的数据，\n\n```sql\nselect * from PROCESSLIST;\nshow PROCESSLIST;\n```\n\nprocesslist 各个 column 的含义在此不一一解释了，不懂的可以参考：\n\n- http://www.ywnds.com/?p=9337\n- https://dev.mysql.com/doc/refman/8.0/en/processlist-table.html\n\n在此重点解释一下 Command 列状态是 Sleep ** Sleep 的状态的连接表示，该连接上在等待有 SQL 命令的执行，也就是说这是一个空闲的连接**，由于 MySQL 的执行速度其实很快，两次使用 processlist 查看同一个连接如果都处于 Sleep 状态，并不表示说这个连接没有被使用，可能其实已经执行过一次 SQL 命令并且结束了。\n\n\n## 问题分析\n\nSleep 状态的连接很多，而且占用时间超过连接池配置的 300s 的占在一半，并且实际 QPS 远没有这么多，说明很多连接其实是一直空闲的状态，基本得不到释放。\n\n我们来举个实际的例子说明 connection pool 的配置中各个参数的影响和关系。某台数据库实例某段时间内连接数在 2k 左右，但是实际 QPS 峰值在 500 左右，也就是说 2k 中的连接只有 1/4 在工作，其他处于空闲状态，设置的 recycle 时间是 300s。假设从时间点 A 算起，过了 300s 之后到达时间点 B，由于峰值 QPS 是 500，也就是 2k 的连接中最多只需要 500，这时 connection pool 在触发检查 connection 的 recycle 时会把连接池从 2k 逐渐减少到 500，connection pool 是 FIFO 的机制，所有 connection 都有机会被获取，因而就有机会被释放。\n\n\n在 sqlalchemy 的实现中，recycle 的操作发生在从 pool 中获取新的连接的时候，如果一个 connection 已经满足 recycle，也就是存在时间超过了 300s，那么会把该连接关闭，然后创建一个新的连接并返回 `/lib/sqlalchemy/pool/base.py:_ConnectionRecord:get_connection`。\n\n\n为了重现 recycle 的机制，在本地写了一个多线程的程序，首先设置 pool 大小是 10，recycle 时间是 90s，用 15 个线程，每隔 60s 去连接数据库，连接池配置如下：\n\n```python\nengine = create_engine(\n    'mysql+pymysql://root:@localhost/blog?charset=utf8',\n    encoding='utf8',\n    echo=False,\n    pool_size=10,\n    pool_recycle=90,\n)\n```\n\n多线程的连接如下：\n```python\n\ndef with_thread_test_pool_recyle():\n    thread_list = []\n    for _ in range(15):\n        t = threading.Thread(target=order_by)\n        thread_list.append(t)\n\n    for t in thread_list:\n        t.start()\n\n    for t in thread_list:\n        t.join()\n\n\ndef test_pool_recyle():\n    while 1:\n        print('thread start')\n        with_thread_test_pool_recyle()\n        print('thread end')\n        time.sleep(60)\n\n```\n\n`order_by` 是一个简单的通过 sqlalchemy session 连接 MySQL 查询的函数。\n\n运行测试用例，通过在 sqlalchemy 代码中浸入日志的办法可以明显观察到 recycle 触发了，而且在本地 MySQL 中观察 show processlist 能够明显看到连接在存活 90s 之后由于触发 recycle 而回收了，当然由于 sqlalchemy 触发回收发生在获取 pool 中的连接时，如果不从 pool 中获取连接 ，recycle 是不会执行的。\n\n\n**上述的回收机制引来一个问题**\n\n假设把连接池的大小设置成 30，并把 recycle 的时间设置成 300s，也就是最大连接数是 30，如果正常的 QPS 是 20，每个请求都能及时归还 connection 到连接池中，那么下次请求一定会复用该连接，也就是说只要 20 个连接就能够满足要求。\n\n现在流量涨到 30 QPS，且每个请求也能及时归还 connection 到连接池中，连接池实际连接会涨到 30，之后流量开始下降 QPS 回归到 20，由于连接池采用的 FIFO 的机制，只要有请求，每个请求都会得到机会触发 recycle，多余的 connection 会被慢慢回收。\n\n一般的服务由于需要利用多核都会开多个进程，在我们刚才分析的上述问题的场景就是监听多个端口的多个 Python 的进程。\n\n当流量突增，根据刚才单进程的分析，即使负载均衡稍微有点不均，每个进程连接池的实际连接大概率都会涨起来，流量退去之后，如果请求依然不均匀，导致部分进程承担了大部分流量，少部分进程只有少量请求分配，或没有请求分配，就会导致被增加的连接得不到触发回收的机会。\n\n## 僵局\n\n如果 sqlalchemy 根据 recycle 回收 connection 没有 bug，也没有任何连接不在 sqlalchemy 管制之下，比如由于 bug 发生内存泄露，sqlalchemy 失去了对 connection 的管理，使得 connection 得不到释放，假设这样的问题不存在，那么影响 connection 回收的时机就是最重要的，而影响时机的主要因素又是请求的分发时机。\n\n因而合理控制好请求的分发让每个进程都能得到均衡的负载应该就可以保证每个进程的 SQL 连接数是均衡的。\n\n但是在我们实际分析的这个场景中，一开始确实我们的代理层转发到后端 rpc service 服务的均衡由于有一个 bug 导致请求转发之后是不均匀的，但是在我们纠正之后，可以明显看到各个 rpc service 进程负载变均衡了，但是大量 Sleep 状态的 MySQL 连接依然存在。\n\n问题陷入了僵局。\n\n## 解开僵局\n\n大量 Sleep 状态的 MySQL connection 依然存在，然后开始分析拥有这些 connection 的进程都有什么特点。\n\n从 processlist 中能够看到连接到 MySQL 的端口，我们在例子中任意取一个端口，根据：\n```\nnetsta -antlp | grep 45925\ntcp        0      0 10.10.149.169:35099     10.10.109.32:3306      ESTABLISHED 32268/python\n```\n能够看到连接 MySQL 的进程 PID，然后根据 PID 获取监听的端口，`turbo` 是启动监听进程的文件名：\n```\nps aux | grep turbo | grep 32268\n```\n\n通过几次尝试发现 Sleep 状态的连接都来自特定的监听端口，然后我们根据负载均衡器的策略对照了一遍终于发现了答案。\n\n我们的负载均衡是自研的，根据自身业务的评估，把后端的机器和进程按照业务进行特定分组，不同的业务使用不同的进程，也就是不同的机器或者相同机器的不同端口。数据库实例也是按照业务的不同进行不同的分组，基本上进程中业务的划分和数据库的业务划分是对等的，但是也不是完全对等，也就是说总有 A 业务的 rpc 调用会连接 B 业务的数据库，但是量非常少，偶尔才会有一个调用出现，问题就是**既然有调用出现，就会产生连接，这个连接池的管理，SQLAlchemy 是通过配置的数据库地址来进行的，也就是一个数据库地址是一个 connection pool，根据我们上面的分析，SQLAlchemy 是在获取新的连接时进行 recycle 的检查，如果一个连接池在创立之后，很少使用或几乎不用，那么该连接池中的 connection 也就没有办法得到释放，因为没有机会触发释放的时机了，正式因为有极个别的 A 业务的进程组使用了 B 业务的数据库，而且请求非常的少，导致 A 业务进程连接到 B 业务数据库的连接都没有机会得到释放，这才导致了 B 业务数据库中大量的 Sleep 状态的连接的出现**\n\n\n## 主动释放连接太长的 MySQL 连接\n\n既然被动检查时间太长，可以考虑进主动检查，也就是每隔一段时间对所有已经建立的连接池进行检查清理，这样基本可以完全杜绝 Sleep 状态的连接的出现，至此这个问题就解决完了。\n\n**如何释放？**\n\n我查阅了 SQLalchemy 处理连接的代码，跟踪了一下整个连接建立的全部过程，SQLalchemy connection 建立的过程都是从 engine 出发，封装 DBAPI connection，然后把封装好的 connection 加入 pool 供应用程序使用，每个 connection 都会和一个 transaction 绑定，而且 SQLalchemy 并没有提供直接遍历 pool 中所有 connection 的 API，可以通过 engine 的 pool 对象获取到，但是不建议这样做，如果 SQLalchemy 版本发生变动，这个属性也有可能发生变化。\n\n最好能直接通过 session 间接操作 connection，但是 session 中没有直接获取底层 connection 的属性，但是 session 提供了一个方法叫：[`invalidate`](https://docs.sqlalchemy.org/en/latest/orm/session_api.html#sqlalchemy.orm.session.Session.invalidate)，这个方法可以把和 session 绑定的 connection 直接关闭而不是又重新放回 pool，因而可以借助这个方法实现主动释放，**基本原理是**：pool 中 connection 是按照 FIFO 的机制循环获取，如果一个 connection 长期处于 Sleep 状态说明这个 connection 很久没有被使用，使用过的 connection Sleep 会重新归 0 开始计算，那么这个进程的连接池的队列上大概率上已经不循环了，所以任意取一个 session 并把它关闭了就有机会把那个需要 recycle 的 connection 关闭，即使没有取到符合条件的也只是释放了一个连接而已，并不会造成太大影响。\n\n后端服务用的 gunicorn 并且模型是 gevent，可以借助 gevent 的非阻塞来定时处理：\n\n```python\nclass MysqlConnectionRecycle(gevent.Greenlet):\n\n    def __init__(self, slist):\n        gevent.Greenlet.__init__(self)\n        self.slist = slist\n\n    def _run(self):\n        while True:\n            gevent.sleep(320)\n            for Session in self.slist:\n                session = Session()\n                try:\n                    session.execute(\"select 1\")\n                    session.invalidate()\n                except Exception as e:\n                    pass\n```\n\n定时器的周期是根据设置 pool 的 recycle 时间来定的，要让定时器在执行时有机会把需要 recycle 的 connection 关闭，所以可以选择略大于定时周期的时间，也可以设置成一个较短的周期，只要对服务的整体性能影响不大即可。\n\n如果 gunicorn 模型是其他模型，如果是 tornado 可以借助 tornado 的 PeriodTask，如果是同步模型，可以借助多线程。","src/content/posts/mysql-optimization-02.mdx","23cb6921264cfe3f","mysql-optimization-02.mdx","mysql-trouble-list",{"id":982,"data":984,"body":989,"filePath":990,"digest":991,"legacyId":992,"deferredRender":22},{"title":985,"summary":986,"date":987,"tags":988,"group":906,"featured":38},"MySQL 常见故障以及诊断和解决方案","此篇是我在生产环境中遇到 MySQL 的一些问题的总结和思考，希望能够帮助更多的人快速定位和解决线上生产环境中遇到的问题。",["Date","2018-04-23T00:00:00.000Z"],[871],"此篇是我在生产环境中遇到 MySQL 的一些问题的总结和思考，希望能够帮助更多的人快速定位和解决线上生产环境中遇到的问题。\n\n## 慢查询太多导致整个库性能下降\n\n这是最常见的一个问题，尤其是在团队开发人员水平参差不齐，对 MySQL 的使用不规范，SQL 语句在代码中乱飞，缺乏严格约束和检验时很容易写出在某些情况下演变成灾难性质的慢查询。\n\n### 问题现象\n\n- 应用程序卡顿\n- 如果设置了最大连接数，可能会报超过最大连接数限制\n- 应用服务器请求堆积，造成大量的 TIME_WAIT \n- 单位时间内慢查询明显增多\n- 服务器的连接数比平时正常流量时增多\n\n### 解决方案\n\n1. 查看所有慢查询语句占用的线程，找到然后 kill 掉\n\n```mysql\nselect id,';' from `information_schema`.PROCESSLIST where info like '%table_name%';\n```\n\n2. 尽快禁止业务代码中的慢查询\n\n可以考虑暂时屏蔽相关的功能或暂时下掉相关的业务，并重启服务\n\n3. 检查导致慢查询的原因\n\n慢查询有很多原因会导致，比如更新数据太多，时间太长，没有合理使用索引，表太大等等，要根据的自己的业务情况进行分析和解决\n\n## 主从同步不一致\n\n造成主从不同步的原因有很多，简单列举几个可能的原因：\n\n- 无意中在从库开启了写权限，导致一些数据进入了从库\n- 网络故障导致从库不能更新主库的数据，网络再次恢复时主从延迟太大\n- 其他原因\n\n### 问题现象\n\n从库的数据和主库不一致\n\n### 解决方案\n\n解决主从不一致的一种最好的办法是暂时先下掉从库，并从某一时间点恢复从库，然后再接入主库进行更新。这里有一个问题是暂时下掉从节点会导致其他节点压力骤增，从而导致整个服务有可能崩溃的风险，为了防止这样的问题出现，在设计数据库架构之初就要考虑预留一定的量来处理某个节点故障的问题。\n\n## 在线对大表进行 DDL 导致表锁死\n\n更改表结构在业务不稳定时进行的非常频繁，但是对 online 表结构进行变更要非常小心谨慎，尤其是表的数据量比较大，业务比较复杂，即可能导致业务功能无法使用等严重现象，一般来说超过百万以上的数据都要小心进行表结构变更。\n\n### 问题现象\n\n在线变更表结构导致使用该表的业务假死 \n\n```mysql\nalter table add colum1 string not null default '';\n```\n\n### 解决方案\n\n- 如果数据量比较小（百万以下），数据变更不频繁，可以直接变更\n- 大表可以考虑采用成熟的开源解决方案，详见[mysql 在线 scheme 变更方案以及](/blog/mysql-online-migration-program-and-tool-compare)","src/content/posts/mysql-trouble-list.mdx","06dd4f7bd4de8452","mysql-trouble-list.mdx","mysql-status",{"id":993,"data":995,"body":1001,"filePath":1002,"digest":1003,"legacyId":1004,"deferredRender":22},{"title":996,"summary":997,"date":998,"tags":999,"group":906,"featured":38},"MySQL status 详解","MySQL 提供了一些列的状态用来帮助我们诊断服务状况，有些状态非常有用，可以帮助我们快速定位服务异常，比如最大连接数，当前连接数等等，下表详细列举了所有的状态以及他们的详细解释，具体见官方文档：",["Date","2018-04-22T00:00:00.000Z"],[1000],"status","MySQL 提供了一些列的状态用来帮助我们诊断服务状况，有些状态非常有用，可以帮助我们快速定位服务异常，比如最大连接数，当前连接数等等，下表详细列举了所有的状态以及他们的详细解释，具体见官方文档：\n\nhttps://dev.mysql.com/doc/refman/8.0/en/server-status-variables.html\n\n```mysql\nshow status;\n```\n\n| Variable_name                                  | value       | scope   | explained                                                    |\n| ---------------------------------------------- | ----------- | ------- | ------------------------------------------------------------ |\n| **Aborted_clients**                            | 16031       | global  | 由于客户端没有正确关闭连接导致客户端终止而中断的连接数       |\n| **Aborted_connects**                           | 2           | global  | 试图连接到MySQL服务器而失败的连接数                          |\n| **Binlog_cache_disk_use**                      | 2           | global  | 使用临时二进制日志缓存但超过binlog_cache_size值并使用临时文件来保存事务中的语句的事务数量 |\n| **Binlog_cache_use**                           | 421723      | global  | 使用临时二进制日志缓存的事务数量                             |\n| **Binlog_stmt_cache_disk_use**                 | 0           | Both    |                                                              |\n| **Binlog_stmt_cache_use**                      | 0           |         |                                                              |\n| **Bytes_received**                             | 1248773219  | Both    | 从所有客户端接收到的字节数                                   |\n| **Bytes_sent**                                 | 3248856327  | both    | 发送给所有客户端的字节数                                     |\n| **Com_admin_commands**                         | 785         |         |                                                              |\n| **Com_assign_to_keycache**                     | 0           |         |                                                              |\n| **Com_alter_db**                               | 0           |         |                                                              |\n| **Com_alter_db_upgrade**                       | 0           |         |                                                              |\n| **Com_alter_event**                            | 0           |         |                                                              |\n| **Com_alter_function**                         | 0           |         |                                                              |\n| **Com_alter_procedure**                        | 0           |         |                                                              |\n| **Com_alter_server**                           | 0           |         |                                                              |\n| **Com_alter_table**                            | 0           |         |                                                              |\n| **Com_alter_tablespace**                       | 0           |         |                                                              |\n| **Com_analyze**                                | 0           |         |                                                              |\n| **Com_begin**                                  | 0           |         |                                                              |\n| **Com_binlog**                                 | 0           |         |                                                              |\n| **Com_call_procedure**                         | 0           |         |                                                              |\n| **Com_change_db**                              | 11          |         |                                                              |\n| **Com_change_master**                          | 0           |         |                                                              |\n| **Com_check**                                  | 0           |         |                                                              |\n| **Com_checksum**                               | 0           |         |                                                              |\n| **Com_commit**                                 | 401261      |         |                                                              |\n| **Com_create_db**                              | 0           |         |                                                              |\n| **Com_create_event**                           | 0           |         |                                                              |\n| **Com_create_function**                        | 0           |         |                                                              |\n| **Com_create_index**                           | 7           |         |                                                              |\n| **Com_create_procedure**                       | 0           |         |                                                              |\n| **Com_create_server**                          | 0           |         |                                                              |\n| **Com_create_table**                           | 0           |         |                                                              |\n| **Com_create_trigger**                         | 0           |         |                                                              |\n| **Com_create_udf**                             | 0           |         |                                                              |\n| **Com_create_user**                            | 0           |         |                                                              |\n| **Com_create_view**                            | 0           |         |                                                              |\n| **Com_dealloc_sql**                            | 0           |         |                                                              |\n| **Com_delete**                                 | 0           |         |                                                              |\n| **Com_delete_multi**                           | 0           |         |                                                              |\n| **Com_do**                                     | 0           |         |                                                              |\n| **Com_drop_db**                                | 0           |         |                                                              |\n| **Com_drop_event**                             | 0           |         |                                                              |\n| **Com_drop_function**                          | 0           |         |                                                              |\n| **Com_drop_index**                             | 0           |         |                                                              |\n| **Com_drop_procedure**                         | 0           |         |                                                              |\n| **Com_drop_server**                            | 0           |         |                                                              |\n| **Com_drop_table**                             | 0           |         |                                                              |\n| **Com_drop_trigger**                           | 0           |         |                                                              |\n| **Com_drop_user**                              | 0           |         |                                                              |\n| **Com_drop_view**                              | 0           |         |                                                              |\n| **Com_empty_query**                            | 0           |         |                                                              |\n| **Com_execute_sql**                            | 0           |         |                                                              |\n| **Com_flush**                                  | 0           |         |                                                              |\n| **Com_grant**                                  | 0           |         |                                                              |\n| **Com_ha_close**                               | 0           |         |                                                              |\n| **Com_ha_open**                                | 0           |         |                                                              |\n| **Com_ha_read**                                | 0           |         |                                                              |\n| **Com_help**                                   | 0           |         |                                                              |\n| **Com_insert**                                 | 1460169     |         |                                                              |\n| **Com_insert_select**                          | 0           |         |                                                              |\n| **Com_install_plugin**                         | 0           |         |                                                              |\n| **Com_kill**                                   | 5           |         |                                                              |\n| **Com_load**                                   | 0           |         |                                                              |\n| **Com_lock_tables**                            | 0           |         |                                                              |\n| **Com_optimize**                               | 0           |         |                                                              |\n| **Com_preload_keys**                           | 0           |         |                                                              |\n| **Com_prepare_sql**                            | 0           |         |                                                              |\n| **Com_purge**                                  | 0           |         |                                                              |\n| **Com_purge_before_date**                      | 0           |         |                                                              |\n| **Com_release_savepoint**                      | 0           |         |                                                              |\n| **Com_rename_table**                           | 0           |         |                                                              |\n| **Com_rename_user**                            | 0           |         |                                                              |\n| **Com_repair**                                 | 0           |         |                                                              |\n| **Com_replace**                                | 0           |         |                                                              |\n| **Com_replace_select**                         | 0           |         |                                                              |\n| **Com_reset**                                  | 0           |         |                                                              |\n| **Com_resignal**                               | 0           |         |                                                              |\n| **Com_revoke**                                 | 0           |         |                                                              |\n| **Com_revoke_all**                             | 0           |         |                                                              |\n| **Com_rollback**                               | 668586      |         |                                                              |\n| **Com_rollback_to_savepoint**                  | 0           |         |                                                              |\n| **Com_savepoint**                              | 0           |         |                                                              |\n| **Com_select**                                 | 807572      |         |                                                              |\n| **Com_set_option**                             | 36735       |         |                                                              |\n| **Com_signal**                                 | 0           |         |                                                              |\n| **Com_show_authors**                           | 0           |         |                                                              |\n| **Com_show_binlog_events**                     | 0           |         |                                                              |\n| **Com_show_binlogs**                           | 0           |         |                                                              |\n| **Com_show_charsets**                          | 0           |         |                                                              |\n| **Com_show_collations**                        | 1301        |         |                                                              |\n| **Com_show_contributors**                      | 0           |         |                                                              |\n| **Com_show_create_db**                         | 0           |         |                                                              |\n| **Com_show_create_event**                      | 0           |         |                                                              |\n| **Com_show_create_func**                       | 0           |         |                                                              |\n| **Com_show_create_proc**                       | 0           |         |                                                              |\n| **Com_show_create_table**                      | 22          |         |                                                              |\n| **Com_show_create_trigger**                    | 0           |         |                                                              |\n| **Com_show_databases**                         | 202         |         |                                                              |\n| **Com_show_engine_logs**                       | 0           |         |                                                              |\n| **Com_show_engine_mutex**                      | 0           |         |                                                              |\n| **Com_show_engine_status**                     | 0           |         |                                                              |\n| **Com_show_events**                            | 0           |         |                                                              |\n| **Com_show_errors**                            | 0           |         |                                                              |\n| **Com_show_fields**                            | 171         |         |                                                              |\n| **Com_show_function_status**                   | 10          |         |                                                              |\n| **Com_show_grants**                            | 0           |         |                                                              |\n| **Com_show_keys**                              | 78          |         |                                                              |\n| **Com_show_master_status**                     | 0           |         |                                                              |\n| **Com_show_open_tables**                       | 0           |         |                                                              |\n| **Com_show_plugins**                           | 0           |         |                                                              |\n| **Com_show_privileges**                        | 0           |         |                                                              |\n| **Com_show_procedure_status**                  | 10          |         |                                                              |\n| **Com_show_processlist**                       | 17          |         |                                                              |\n| **Com_show_profile**                           | 0           |         |                                                              |\n| **Com_show_profiles**                          | 0           |         |                                                              |\n| **Com_show_relaylog_events**                   | 0           |         |                                                              |\n| **Com_show_slave_hosts**                       | 0           |         |                                                              |\n| **Com_show_slave_status**                      | 0           |         |                                                              |\n| **Com_show_status**                            | 1322        |         |                                                              |\n| **Com_show_storage_engines**                   | 2           |         |                                                              |\n| **Com_show_table_status**                      | 12          |         |                                                              |\n| **Com_show_tables**                            | 41          |         |                                                              |\n| **Com_show_triggers**                          | 56          |         |                                                              |\n| **Com_show_variables**                         | 1424        |         |                                                              |\n| **Com_show_warnings**                          | 2           |         |                                                              |\n| **Com_slave_start**                            | 0           |         |                                                              |\n| **Com_slave_stop**                             | 0           |         |                                                              |\n| **Com_stmt_close**                             | 0           |         |                                                              |\n| **Com_stmt_execute**                           | 0           |         |                                                              |\n| **Com_stmt_fetch**                             | 0           |         |                                                              |\n| **Com_stmt_prepare**                           | 0           |         |                                                              |\n| **Com_stmt_reprepare**                         | 0           |         |                                                              |\n| **Com_stmt_reset**                             | 0           |         |                                                              |\n| **Com_stmt_send_long_data**                    | 0           |         |                                                              |\n| **Com_truncate**                               | 0           |         |                                                              |\n| **Com_uninstall_plugin**                       | 0           |         |                                                              |\n| **Com_unlock_tables**                          | 0           |         |                                                              |\n| **Com_update**                                 | 412234      |         |                                                              |\n| **Com_update_multi**                           | 0           |         |                                                              |\n| **Com_xa_commit**                              | 0           |         |                                                              |\n| **Com_xa_end**                                 | 0           |         |                                                              |\n| **Com_xa_prepare**                             | 0           |         |                                                              |\n| **Com_xa_recover**                             | 0           |         |                                                              |\n| **Com_xa_rollback**                            | 0           |         |                                                              |\n| **Com_xa_start**                               | 0           |         |                                                              |\n| **Compression**                                | ON          | Session | 客户端与服务器之间只否启用压缩协议                           |\n| **Connections**                                | 37499       | global  | 试图连接到(不管是否成功)MySQL服务器的连接数                  |\n| **Created_tmp_disk_tables**                    | 223         | both    | 服务器执行语句时在硬盘上自动创建的临时表的数量               |\n| **Created_tmp_files**                          | 52          | both    | mysqld已经创建的临时文件的数量                               |\n| **Created_tmp_tables**                         | 4676        | both    | 服务器执行语句时自动创建的内存中的临时表的数量，如果Created_tmp_disk_tables较大，你可能要增加tmp_table_size值使临时 表基于内存而不基于硬盘 |\n| **Delayed_errors**                             | 0           | global  | 用INSERT DELAYED写的出现错误的行数(可能为duplicate key)。    |\n| **Delayed_insert_threads**                     | 0           | global  | 使用的INSERT DELAYED处理器线程数。                           |\n| **Delayed_writes**                             | 0           | global  | 写入的INSERT DELAYED行数                                     |\n| **Flush_commands**                             | 2           | global  | 执行的FLUSH语句数                                            |\n| **Handler_commit**                             | 5291398     | both    | 内部提交语句数                                               |\n| **Handler_delete**                             | 0           | both    | 行从表中删除的次数                                           |\n| **Handler_discover**                           | 0           | both    | MySQL服务器可以问NDB CLUSTER存储引擎是否知道某一名字的表。这被称作发现。Handler_discover说明通过该方法发现的次数。 |\n| **Handler_prepare**                            | 4512578     | both    | A counter for the prepare phase of two-phase commit operations. |\n| **Handler_read_first**                         | 268341      | both    | 索引中第一条被读的次数。如果较高，它建议服务器正执行大量全索引扫描；例如，SELECT col1 FROM foo，假定col1有索引 |\n| **Handler_read_key**                           | 1286597     | both    | 根据键读一行的请求数。如果较高，说明查询和表的索引正确       |\n| **Handler_read_last**                          | 59          | both    |                                                              |\n| **Handler_read_next**                          | 35166067    | both    | 按照键顺序读下一行的请求数。如果你用范围约束或如果执行索引扫描来查询索引列，该值增加 |\n| **Handler_read_prev**                          | 1601833     | both    | 按照键顺序读前一行的请求数。该读方法主要用于优化ORDER BY ... DESC。 |\n| **Handler_read_rnd**                           | 20124       | both    | 根据固定位置读一行的请求数。如果你正执行大量查询并需要对结果进行排序该值较高。你可能使用了大量需要MySQL扫描整个表的查询或你的连接没有正确使用键 |\n| **Handler_read_rnd_next**                      | 48760470858 | both    | 在数据文件中读下一行的请求数。如果你正进行大量的表扫描，该值较高。通常说明你的表索引不正确或写入的查询没有利用索引 |\n| **Handler_rollback**                           | 308415      | both    | 内部ROLLBACK语句的数量                                       |\n| **Handler_savepoint**                          | 0           | both    | 在一个存储引擎放置一个保存点的请求数量                       |\n| **Handler_savepoint_rollback**                 | 0           | both    | 在一个存储引擎的要求回滚到一个保存点数目                     |\n| **Handler_update**                             | 412202      | both    | 在表内更新一行的请求数                                       |\n| **Handler_write**                              | 1779011     | both    | 在表内插入一行的请求数                                       |\n| **Innodb_buffer_pool_pages_data**              | 136123      | global  | 包含数据的页数(脏或干净)                                     |\n| **Innodb_buffer_pool_pages_dirty**             | 90          | global  | 当前的脏页数                                                 |\n| **Innodb_buffer_pool_pages_flushed**           | 1534140     | global  | 要求清空的缓冲池页数                                         |\n| **Innodb_buffer_pool_pages_free**              | 158551      | global  | 空页数                                                       |\n| **Innodb_buffer_pool_pages_misc**              | 1006        | global  | 忙的页数，因为它们已经被分配优先用作管理，例如行锁定或适用的哈希索引。该值还可以计算为Innodb_buffer_pool_pages_total - Innodb_buffer_pool_pages_free - Innodb_buffer_pool_pages_data。 |\n| **Innodb_buffer_pool_pages_total**             | 295680      | global  | 缓冲池总大小（页数）                                         |\n| **Innodb_buffer_pool_read_ahead_rnd**          | 0           | global  | InnoDB初始化的“随机”read-aheads数。当查询以随机顺序扫描表的一大部分时发生。 |\n| **Innodb_buffer_pool_read_ahead**              | 19531       |         |                                                              |\n| **Innodb_buffer_pool_read_ahead_evicted**      | 0           |         |                                                              |\n| **Innodb_buffer_pool_read_requests**           | 21113636240 | global  | InnoDB已经完成的逻辑读请求数                                 |\n| **Innodb_buffer_pool_reads**                   | 88282       | global  | 不能满足InnoDB必须单页读取的缓冲池中的逻辑读数量。           |\n| **Innodb_buffer_pool_wait_free**               | 0           | global  | 一般情况，通过后台向InnoDB缓冲池写。但是，如果需要读或创建页，并且没有干净的页可用，则它还需要先等待页面清空。该计数器对等待实例进行记数。如果已经适当设置缓冲池大小，该值应小 |\n| **Innodb_buffer_pool_write_requests**          | 12368792    | global  | 向InnoDB缓冲池的写数量。                                     |\n| **Innodb_data_fsyncs**                         | 74253       | global  | fsync()操作数                                                |\n| **Innodb_data_pending_fsyncs**                 | 0           | global  | 当前挂起的fsync()操作数。                                    |\n| **Innodb_data_pending_reads**                  | 0           | global  | 当前挂起的读数。                                             |\n| **Innodb_data_pending_writes**                 | 0           | global  | 当前挂起的写数。                                             |\n| **Innodb_data_read**                           | 1768591360  | global  | 至此已经读取的数据数量（字节）。                             |\n| **Innodb_data_reads**                          | 108048      | global  | 数据读总数量。                                               |\n| **Innodb_data_writes**                         | 1613970     | global  | 数据写总数量。                                               |\n| **Innodb_data_written**                        | 26343557632 | global  | 至此已经写入的数据量（字节）。                               |\n| **Innodb_dblwr_pages_written**                 | 767070      | global  | 已经执行的双写操作数量                                       |\n| **Innodb_dblwr_writes**                        | 7475        | global  | 双写操作已经写好的页数                                       |\n| **Innodb_have_atomic_builtins**                | ON          | global  |                                                              |\n| **Innodb_log_waits**                           | 0           | global  | 我们必须等待的时间，因为日志缓冲区太小，我们在继续前必须先等待对它清空 |\n| **Innodb_log_write_requests**                  | 1800108     | global  | 日志写请求数。                                               |\n| **Innodb_log_writes**                          | 830562      | global  | 向日志文件的物理写数量。                                     |\n| **Innodb_os_log_fsyncs**                       | 25144       | global  | 向日志文件完成的fsync()写数量。                              |\n| **Innodb_os_log_pending_fsyncs**               | 0           | global  | 挂起的日志文件fsync()操作数量。                              |\n| **Innodb_os_log_pending_writes**               | 0           | global  | 挂起的日志文件写操作                                         |\n| **Innodb_os_log_written**                      | 1207160320  | global  | 写入日志文件的字节数。                                       |\n| **Innodb_page_size**                           | 16384       | global  | 编译的InnoDB页大小(默认16KB)。许多值用页来记数；页的大小很容易转换为字节。 |\n| **Innodb_pages_created**                       | 28311       | global  | 创建的页数。                                                 |\n| **Innodb_pages_read**                          | 107812      | global  | 读取的页数。                                                 |\n| **Innodb_pages_written**                       | 767070      | global  | 写入的页数。                                                 |\n| **Innodb_row_lock_current_waits**              | 0           | global  | 当前等待的待锁定的行数。                                     |\n| **Innodb_row_lock_time**                       | 3132098728  | global  | 行锁定花费的总时间，单位毫秒。                               |\n| **Innodb_row_lock_time_avg**                   | 45551       | global  | 行锁定的平均时间，单位毫秒。                                 |\n| **Innodb_row_lock_time_max**                   | 51930       | global  | 行锁定的最长时间，单位毫秒。                                 |\n| **Innodb_row_lock_waits**                      | 68760       | global  | 一行锁定必须等待的时间数。                                   |\n| **Innodb_rows_deleted**                        | 0           | global  | 从InnoDB表删除的行数。                                       |\n| **Innodb_rows_inserted**                       | 5766040     | global  | 插入到InnoDB表的行数。                                       |\n| **Innodb_rows_read**                           | 25304573020 | global  | 从InnoDB表读取的行数。                                       |\n| **Innodb_rows_updated**                        | 412198      | global  | InnoDB表内更新的行数。                                       |\n| **Innodb_truncated_status_writes**             | 0           | global  |                                                              |\n| **Key_blocks_not_flushed**                     | 0           | global  | 键缓存内已经更改但还没有清空到硬盘上的键的数据块数量。       |\n| **Key_blocks_unused**                          | 26787       | global  | 键缓存内未使用的块数量。你可以使用该值来确定使用了多少键缓存 |\n| **Key_blocks_used**                            | 1583        | global  | 键缓存内使用的块数量。该值为高水平线标记，说明已经同时最多使用了多少块。 |\n| **Key_read_requests**                          | 167263      | global  | 从缓存读键的数据块的请求数。                                 |\n| **Key_reads**                                  | 143381      | global  | 从硬盘读取键的数据块的次数。如果Key_reads较大，则Key_buffer_size值可能太小。可以用Key_reads/Key_read_requests计算缓存损失率。 |\n| **Key_write_requests**                         | 49572       | global  | 将键的数据块写入缓存的请求数。                               |\n| **Key_writes**                                 | 48333       | global  | 向硬盘写入将键的数据块的物理写操作的次数。                   |\n| **Last_query_cost**                            | 0           | global  | 用查询优化器计算的最后编译的查询的总成本。用于对比同一查询的不同查询方案的成本。默认值0表示还没有编译查询。 默认值是0。Last_query_cost具有会话范围。 |\n| **Max_used_connections**                       | 2256        | global  | 服务器启动后已经同时使用的连接的最大数量。                   |\n| **Not_flushed_delayed_rows**                   | 0           | global  | 等待写入INSERT DELAY队列的行数。                             |\n| **Open_files**                                 | 52          | global  | 打开的文件的数目。                                           |\n| **Open_streams**                               | 0           | global  | 打开的流的数量(主要用于记录)。                               |\n| **Open_table_definitions**                     | 54          | global  | 缓存的.frm文件数量                                           |\n| **Open_tables**                                | 128         | global  | 当前打开的表的数量。                                         |\n| **Opened_files**                               | 96828       | global  | 文件打开的数量。不包括诸如套接字或管道其他类型的文件。 也不包括存储引擎用来做自己的内部功能的文件。 |\n| **Opened_table_definitions**                   | 94          | global  | 已经缓存的.frm文件数量                                       |\n| **Opened_tables**                              | 1525369     | global  | 已经打开的表的数量。如果Opened_tables较大，table_cache 值可能太小。 |\n| **Performance_schema_cond_classes_lost**       | 0           | global  |                                                              |\n| **Performance_schema_cond_instances_lost**     | 0           | global  |                                                              |\n| **Performance_schema_file_classes_lost**       | 0           | global  |                                                              |\n| **Performance_schema_file_handles_lost**       | 0           | global  |                                                              |\n| **Performance_schema_file_instances_lost**     | 0           | global  |                                                              |\n| **Performance_schema_locker_lost**             | 0           | global  |                                                              |\n| **Performance_schema_mutex_classes_lost**      | 0           | global  |                                                              |\n| **Performance_schema_mutex_instances_lost**    | 0           | global  |                                                              |\n| **Performance_schema_rwlock_classes_lost**     | 0           | global  |                                                              |\n| **Performance_schema_rwlock_instances_lost**   | 0           | global  |                                                              |\n| **Performance_schema_table_handles_lost**      | 0           | global  |                                                              |\n| **Performance_schema_table_instances_lost**    | 0           | global  |                                                              |\n| **Performance_schema_thread_classes_lost**     | 0           | global  |                                                              |\n| **Performance_schema_thread_instances_lost**   | 0           | global  |                                                              |\n| **Prepared_stmt_count**                        | 0           | global  | 当前的预处理语句的数量。 (最大数为系统变量: max_prepared_stmt_count) |\n| **Qcache_free_blocks**                         | 0           | global  | 查询缓存内自由内存块的数量。                                 |\n| **Qcache_free_memory**                         | 0           | global  | 用于查询缓存的自由内存的数量。                               |\n| **Qcache_hits**                                | 0           | global  | 查询缓存被访问的次数。                                       |\n| **Qcache_inserts**                             | 0           | global  | 加入到缓存的查询数量。                                       |\n| **Qcache_lowmem_prunes**                       | 0           | global  | 由于内存较少从缓存删除的查询数量。                           |\n| **Qcache_not_cached**                          | 0           | global  | 非缓存查询数(不可缓存，或由于query_cache_type设定值未缓存)。 |\n| **Qcache_queries_in_cache**                    | 0           | global  | 登记到缓存内的查询的数量。                                   |\n| **Qcache_total_blocks**                        | 0           | global  | 查询缓存内的总块数。                                         |\n| **Queries**                                    | 3812538     | global  | 服务器执行的请求个数，包含存储过程中的请求。                 |\n| **Questions**                                  | 3812538     | global  | 已经发送给服务器的查询的个数。                               |\n| **Rpl_semi_sync_master_clients**               | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_net_avg_wait_time**     | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_net_wait_time**         | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_net_waits**             | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_no_times**              | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_no_tx**                 | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_status**                | OFF         | global  |                                                              |\n| **Rpl_semi_sync_master_timefunc_failures**     | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_tx_avg_wait_time**      | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_tx_wait_time**          | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_tx_waits**              | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_wait_pos_backtraverse** | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_wait_sessions**         | 0           | global  |                                                              |\n| **Rpl_semi_sync_master_yes_tx**                | 0           | global  |                                                              |\n| **Rpl_semi_sync_slave_status**                 | OFF         | global  |                                                              |\n| **Rpl_status**                                 | AUTH_MASTER | global  | 失败安全复制状态(还未使用)。                                 |\n| **Select_full_join**                           | 0           | global  | 没有使用索引的联接的数量。如果该值不为0,你应仔细检查表的索引 |\n| **Select_full_range_join**                     | 0           | global  | 在引用的表中使用范围搜索的联接的数量。                       |\n| **Select_range**                               | 56149       | global  | 在第一个表中使用范围的联接的数量。一般情况不是关键问题，即使该值相当大。 |\n| **Select_range_check**                         | 0           | global  | 在每一行数据后对键值进行检查的不带键值的联接的数量。如果不为0，你应仔细检查表的索引。 |\n| **Select_scan**                                | 272978      | global  | 对第一个表进行完全扫描的联接的数量。                         |\n| **Slave_heartbeat_period**                     | 0           | global  | 复制的心跳间隔                                               |\n| **Slave_open_temp_tables**                     | 0           | global  | 从服务器打开的临时表数量                                     |\n| **Slave_received_heartbeats**                  | 0           | global  | 从服务器心跳数                                               |\n| **Slave_retried_transactions**                 | 0           | global  | 本次启动以来从服务器复制线程重试次数                         |\n| **Slave_running**                              | OFF         | global  | 如果该服务器是连接到主服务器的从服务器，则该值为ON。         |\n| **Slow_launch_threads**                        | 0           | global  | 创建时间超过slow_launch_time秒的线程数。                     |\n| **Slow_queries**                               | 48490       | global  | 查询时间超过long_query_time秒的查询的个数。                  |\n| **Sort_merge_passes**                          | 56          | global  | 排序算法已经执行的合并的数量。如果这个变量值较大，应考虑增加sort_buffer_size系统变量的值。 |\n| **Sort_range**                                 | 0           | global  | 在范围内执行的排序的数量。                                   |\n| **Sort_rows**                                  | 42124       | global  | 已经排序的行数。                                             |\n| **Sort_scan**                                  | 23          | global  | 通过扫描表完成的排序的数量。                                 |\n| **Table_locks_immediate**                      | 2717991     | global  | 立即获得的表的锁的次数。                                     |\n| **Table_locks_waited**                         | 1229        | global  | 不能立即获得的表的锁的次数。如果该值较高，并且有性能问题，你应首先优化查询，然后拆分表或使用复制。 |\n| **Tc_log_max_pages_used**                      | 0           | global  |                                                              |\n| **Tc_log_page_size**                           | 0           | global  |                                                              |\n| **Tc_log_page_waits**                          | 0           | global  |                                                              |\n| **Threads_cached**                             | 39          | global  | 线程缓存内的线程的数量。                                     |\n| **Threads_connected**                          | 191         | global  | 当前打开的连接的数量。                                       |\n| **Threads_created**                            | 6070        | global  | 创建用来处理连接的线程数。如果Threads_created较大，你可能要增加thread_cache_size值。缓存访问率的计算方法Threads_created/Connections。 |\n| **Threads_running**                            | 3           | global  | 激活的（非睡眠状态）线程数。                                 |\n| **Uptime**                                     | 21457       | global  | 服务器已经运行的时间（以秒为单位）。                         |\n| **Uptime_since_flush_status**                  | 21457       | global  | 最近一次使用FLUSH STATUS 的时间（以秒为单位）。              |","src/content/posts/mysql-status.mdx","bb5d4828e49e3f65","mysql-status.mdx","mysql-system-variable",{"id":1005,"data":1007,"body":1013,"filePath":1014,"digest":1015,"legacyId":1016,"deferredRender":22},{"title":1008,"summary":1009,"date":1010,"tags":1011,"group":906,"featured":38},"MySQL system variable 详解","MySQL system variable 提供了 MySQL 服务器的常用配置项，为 MySQL 的日常问题诊断、排查、性能调优提供了非常灵活的选择，具体见官方文档：",["Date","2018-04-23T00:00:00.000Z"],[1012],"variable","MySQL system variable 提供了 MySQL 服务器的常用配置项，为 MySQL 的日常问题诊断、排查、性能调优提供了非常灵活的选择，具体见官方文档：\n\nhttps://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html\n\n\n\n| **Variable_name**                                     | **Value**                                                    | scope |                                                  |\n| ----------------------------------------------------- | ------------------------------------------------------------ | ----- | ------------------------------------------------ |\n| **auto_increment_increment**                          | 1                                                            |       |                                                  |\n| **auto_increment_offset**                             | 1                                                            |       |                                                  |\n| **autocommit**                                        | ON                                                           |       |                                                  |\n| **automatic_sp_privileges**                           | ON                                                           |       |                                                  |\n| **back_log**                                          | 2000                                                         |       |                                                  |\n| **basedir**                                           | /opt/udb/program/mysql/mysql-5.5.24                          |       |                                                  |\n| **big_tables**                                        | OFF                                                          |       |                                                  |\n| **binlog_cache_size**                                 | 32768                                                        |       |                                                  |\n| **binlog_direct_non_transactional_updates**           | OFF                                                          |       |                                                  |\n| **binlog_format**                                     | MIXED                                                        |       |                                                  |\n| **binlog_stmt_cache_size**                            | 32768                                                        |       |                                                  |\n| **bulk_insert_buffer_size**                           | 8388608                                                      |       |                                                  |\n| **character_set_client**                              | utf8                                                         |       |                                                  |\n| **character_set_connection**                          | utf8                                                         |       |                                                  |\n| **character_set_database**                            | utf8                                                         |       |                                                  |\n| **character_set_filesystem**                          | binary                                                       |       |                                                  |\n| **character_set_results**                             | utf8                                                         |       |                                                  |\n| **character_set_server**                              | utf8                                                         |       |                                                  |\n| **character_set_system**                              | utf8                                                         |       |                                                  |\n| **character_sets_dir**                                | /opt/udb/program/mysql/mysql-5.5.24/share/charsets/          |       |                                                  |\n| **collation_connection**                              | utf8_general_ci                                              |       |                                                  |\n| **collation_database**                                | utf8_general_ci                                              |       |                                                  |\n| **collation_server**                                  | utf8_general_ci                                              |       |                                                  |\n| **completion_type**                                   | NO_CHAIN                                                     |       |                                                  |\n| **concurrent_insert**                                 | AUTO                                                         |       |                                                  |\n| **connect_timeout**                                   | 10                                                           |       |                                                  |\n| **datadir**                                           | /opt/udb/instance/mysql-5.5/udb-ovzdmx/data/                 |       |                                                  |\n| **date_format**                                       | %Y-%m-%d                                                     |       |                                                  |\n| **datetime_format**                                   | %Y-%m-%d %H:%i:%s                                            |       |                                                  |\n| **default_storage_engine**                            | InnoDB                                                       |       |                                                  |\n| **default_week_format**                               | 0                                                            |       |                                                  |\n| **delay_key_write**                                   | ON                                                           |       |                                                  |\n| **delayed_insert_limit**                              | 100                                                          |       |                                                  |\n| **delayed_insert_timeout**                            | 300                                                          |       |                                                  |\n| **delayed_queue_size**                                | 1000                                                         |       |                                                  |\n| **div_precision_increment**                           | 4                                                            |       |                                                  |\n| **engine_condition_pushdown**                         | ON                                                           |       |                                                  |\n| **error_count**                                       | 0                                                            |       |                                                  |\n| **event_scheduler**                                   | OFF                                                          |       |                                                  |\n| **expire_logs_days**                                  | 7                                                            |       |                                                  |\n| **external_user**                                     |                                                              |       |                                                  |\n| **flush**                                             | OFF                                                          |       |                                                  |\n| **flush_time**                                        | 0                                                            |       |                                                  |\n| **foreign_key_checks**                                | ON                                                           |       |                                                  |\n| **ft_boolean_syntax**                                 | + ->\u003C()~*:\"&\\|                                               |       |                                                  |\n| **ft_max_word_len**                                   | 84                                                           |       |                                                  |\n| **ft_min_word_len**                                   | 4                                                            |       |                                                  |\n| **ft_query_expansion_limit**                          | 20                                                           |       |                                                  |\n| **ft_stopword_file**                                  | (built-in)                                                   |       |                                                  |\n| **general_log**                                       | OFF                                                          |       |                                                  |\n| **general_log_file**                                  | /opt/udb/instance/mysql-5.5/udb-ovzdmx/log/mysqld.log        |       |                                                  |\n| **group_concat_max_len**                              | 51200                                                        |       |                                                  |\n| **have_compress**                                     | YES                                                          |       |                                                  |\n| **have_crypt**                                        | YES                                                          |       |                                                  |\n| **have_csv**                                          | YES                                                          |       |                                                  |\n| **have_dynamic_loading**                              | YES                                                          |       |                                                  |\n| **have_geometry**                                     | YES                                                          |       |                                                  |\n| **have_innodb**                                       | YES                                                          |       |                                                  |\n| **have_ndbcluster**                                   | NO                                                           |       |                                                  |\n| **have_openssl**                                      | NO                                                           |       |                                                  |\n| **have_partitioning**                                 | YES                                                          |       |                                                  |\n| **have_profiling**                                    | YES                                                          |       |                                                  |\n| **have_query_cache**                                  | YES                                                          |       |                                                  |\n| **have_rtree_keys**                                   | YES                                                          |       |                                                  |\n| **have_ssl**                                          | NO                                                           |       |                                                  |\n| **have_symlink**                                      | YES                                                          |       |                                                  |\n| **hostname**                                          | 046c68c53211                                                 |       |                                                  |\n| **identity**                                          | 0                                                            |       |                                                  |\n| **ignore_builtin_innodb**                             | OFF                                                          |       |                                                  |\n| **init_connect**                                      |                                                              |       |                                                  |\n| **init_file**                                         |                                                              |       |                                                  |\n| **init_slave**                                        |                                                              |       |                                                  |\n| **innodb_adaptive_flushing**                          | ON                                                           |       |                                                  |\n| **innodb_adaptive_hash_index**                        | ON                                                           |       |                                                  |\n| **innodb_additional_mem_pool_size**                   | 8388608                                                      |       |                                                  |\n| **innodb_autoextend_increment**                       | 8                                                            |       |                                                  |\n| **innodb_autoinc_lock_mode**                          | 1                                                            |       |                                                  |\n| **innodb_buffer_pool_instances**                      | 1                                                            |       |                                                  |\n| **innodb_buffer_pool_size**                           | 1887436800                                                   |       |                                                  |\n| **innodb_change_buffering**                           | all                                                          |       |                                                  |\n| **innodb_checksums**                                  | ON                                                           |       |                                                  |\n| **innodb_commit_concurrency**                         | 0                                                            |       |                                                  |\n| **innodb_concurrency_tickets**                        | 500                                                          |       |                                                  |\n| **innodb_data_file_path**                             | ibdata1:100M:autoextend                                      |       |                                                  |\n| **innodb_data_home_dir**                              | /opt/udb/instance/mysql-5.5/udb-ovzdmx/data                  |       |                                                  |\n| **innodb_doublewrite**                                | ON                                                           |       |                                                  |\n| **innodb_fast_shutdown**                              | 1                                                            |       |                                                  |\n| **innodb_file_format**                                | Antelope                                                     |       |                                                  |\n| **innodb_file_format_check**                          | ON                                                           |       |                                                  |\n| **innodb_file_format_max**                            | Antelope                                                     |       |                                                  |\n| **innodb_file_per_table**                             | ON                                                           |       |                                                  |\n| **innodb_flush_log_at_trx_commit**                    | 2                                                            |       |                                                  |\n| **innodb_flush_method**                               | O_DIRECT                                                     |       |                                                  |\n| **innodb_force_load_corrupted**                       | OFF                                                          |       |                                                  |\n| **innodb_force_recovery**                             | 0                                                            |       |                                                  |\n| **innodb_io_capacity**                                | 2000                                                         |       |                                                  |\n| **innodb_large_prefix**                               | OFF                                                          |       |                                                  |\n| **innodb_lock_wait_timeout**                          | 50                                                           |       |                                                  |\n| **innodb_locks_unsafe_for_binlog**                    | OFF                                                          |       |                                                  |\n| **innodb_log_buffer_size**                            | 8388608                                                      |       |                                                  |\n| **innodb_log_file_size**                              | 536870912                                                    |       |                                                  |\n| **innodb_log_files_in_group**                         | 2                                                            |       |                                                  |\n| **innodb_log_group_home_dir**                         | /opt/udb/instance/mysql-5.5/udb-ovzdmx/data                  |       |                                                  |\n| **innodb_max_dirty_pages_pct**                        | 50                                                           |       |                                                  |\n| **innodb_max_purge_lag**                              | 0                                                            |       |                                                  |\n| **innodb_mirrored_log_groups**                        | 1                                                            |       |                                                  |\n| **innodb_old_blocks_pct**                             | 37                                                           |       |                                                  |\n| **innodb_old_blocks_time**                            | 0                                                            |       |                                                  |\n| **innodb_open_files**                                 | 1024                                                         |       |                                                  |\n| **innodb_purge_batch_size**                           | 20                                                           |       |                                                  |\n| **innodb_purge_threads**                              | 0                                                            |       |                                                  |\n| **innodb_random_read_ahead**                          | OFF                                                          |       |                                                  |\n| **innodb_read_ahead_threshold**                       | 56                                                           |       |                                                  |\n| **innodb_read_io_threads**                            | 8                                                            |       |                                                  |\n| **innodb_replication_delay**                          | 0                                                            |       |                                                  |\n| **innodb_rollback_on_timeout**                        | OFF                                                          |       |                                                  |\n| **innodb_rollback_segments**                          | 128                                                          |       |                                                  |\n| **innodb_spin_wait_delay**                            | 6                                                            |       |                                                  |\n| **innodb_stats_method**                               | nulls_equal                                                  |       |                                                  |\n| **innodb_stats_on_metadata**                          | ON                                                           |       |                                                  |\n| **innodb_stats_sample_pages**                         | 8                                                            |       |                                                  |\n| **innodb_strict_mode**                                | OFF                                                          |       |                                                  |\n| **innodb_support_xa**                                 | ON                                                           |       |                                                  |\n| **innodb_sync_spin_loops**                            | 30                                                           |       |                                                  |\n| **innodb_table_locks**                                | ON                                                           |       |                                                  |\n| **innodb_thread_concurrency**                         | 20                                                           |       |                                                  |\n| **innodb_thread_sleep_delay**                         | 10000                                                        |       |                                                  |\n| **innodb_use_native_aio**                             | ON                                                           |       |                                                  |\n| **innodb_use_sys_malloc**                             | ON                                                           |       |                                                  |\n| **innodb_version**                                    | 1.1.8                                                        |       |                                                  |\n| **innodb_write_io_threads**                           | 8                                                            |       |                                                  |\n| **insert_id**                                         | 0                                                            |       |                                                  |\n| **interactive_timeout**                               | 28800                                                        |       |                                                  |\n| **join_buffer_size**                                  | 131072                                                       |       |                                                  |\n| **keep_files_on_create**                              | OFF                                                          |       |                                                  |\n| **key_buffer_size**                                   | 33554432                                                     |       |                                                  |\n| **key_cache_age_threshold**                           | 300                                                          |       |                                                  |\n| **key_cache_block_size**                              | 1024                                                         |       |                                                  |\n| **key_cache_division_limit**                          | 100                                                          |       |                                                  |\n| **large_files_support**                               | ON                                                           |       |                                                  |\n| **large_page_size**                                   | 0                                                            |       |                                                  |\n| **large_pages**                                       | OFF                                                          |       |                                                  |\n| **last_insert_id**                                    | 0                                                            |       |                                                  |\n| **lc_messages**                                       | en_US                                                        |       |                                                  |\n| **lc_messages_dir**                                   | /opt/udb/program/mysql/mysql-5.5.24/share/                   |       |                                                  |\n| **lc_time_names**                                     | en_US                                                        |       |                                                  |\n| **license**                                           | GPL                                                          |       |                                                  |\n| **local_infile**                                      | ON                                                           |       |                                                  |\n| **lock_wait_timeout**                                 | 31536000                                                     |       |                                                  |\n| **locked_in_memory**                                  | OFF                                                          |       |                                                  |\n| **log**                                               | OFF                                                          |       |                                                  |\n| **log_bin**                                           | ON                                                           |       |                                                  |\n| **log_bin_trust_function_creators**                   | ON                                                           |       |                                                  |\n| **log_error**                                         | /opt/udb/instance/mysql-5.5/udb-ovzdmx/log/mysqld.log        |       |                                                  |\n| **log_output**                                        | TABLE                                                        |       |                                                  |\n| **log_queries_not_using_indexes**                     | OFF                                                          |       |                                                  |\n| **log_slave_updates**                                 | OFF                                                          |       |                                                  |\n| **log_slow_queries**                                  | ON                                                           |       |                                                  |\n| **log_warnings**                                      | 1                                                            |       |                                                  |\n| **long_query_time**                                   | 3                                                            |       |                                                  |\n| **low_priority_updates**                              | OFF                                                          |       |                                                  |\n| **lower_case_file_system**                            | OFF                                                          |       |                                                  |\n| **lower_case_table_names**                            | 0                                                            |       |                                                  |\n| [**max_allowed_packet**](https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_max_allowed_packet)                                | 16777216                                                     |       |                                                  |\n| **max_binlog_cache_size**                             | 18446744073709547520                                         |       |                                                  |\n| **max_binlog_size**                                   | 1073741824                                                   |       |                                                  |\n| **max_binlog_stmt_cache_size**                        | 18446744073709547520                                         |       |                                                  |\n| **max_connect_errors**                                | 1000000                                                      |       |                                                  |\n| **max_connections**                                   | 2000                                                         |       |                                                  |\n| **max_delayed_threads**                               | 20                                                           |       |                                                  |\n| **max_error_count**                                   | 64                                                           |       |                                                  |\n| **max_heap_table_size**                               | 16777216                                                     |       |                                                  |\n| **max_insert_delayed_threads**                        | 20                                                           |       |                                                  |\n| **max_join_size**                                     | 18446744073709551615                                         |       |                                                  |\n| **max_length_for_sort_data**                          | 1024                                                         |       |                                                  |\n| **max_long_data_size**                                | 16777216                                                     |       |                                                  |\n| **max_prepared_stmt_count**                           | 16382                                                        |       |                                                  |\n| **max_relay_log_size**                                | 0                                                            |       |                                                  |\n| **max_seeks_for_key**                                 | 18446744073709551615                                         |       |                                                  |\n| **max_sort_length**                                   | 1024                                                         |       |                                                  |\n| **max_sp_recursion_depth**                            | 0                                                            |       |                                                  |\n| **max_tmp_tables**                                    | 32                                                           |       |                                                  |\n| **max_user_connections**                              | 0                                                            |       |                                                  |\n| **max_write_lock_count**                              | 18446744073709551615                                         |       |                                                  |\n| **metadata_locks_cache_size**                         | 1024                                                         |       |                                                  |\n| **min_examined_row_limit**                            | 0                                                            |       |                                                  |\n| **multi_range_count**                                 | 256                                                          |       |                                                  |\n| **myisam_data_pointer_size**                          | 6                                                            |       |                                                  |\n| **myisam_max_sort_file_size**                         | 9223372036853727232                                          |       |                                                  |\n| **myisam_mmap_size**                                  | 18446744073709551615                                         |       |                                                  |\n| **myisam_recover_options**                            | OFF                                                          |       |                                                  |\n| **myisam_repair_threads**                             | 1                                                            |       |                                                  |\n| **myisam_sort_buffer_size**                           | 8388608                                                      |       |                                                  |\n| **myisam_stats_method**                               | nulls_unequal                                                |       |                                                  |\n| **myisam_use_mmap**                                   | OFF                                                          |       |                                                  |\n| **net_buffer_length**                                 | 8192                                                         |       |                                                  |\n| **net_read_timeout**                                  | 30                                                           |       |                                                  |\n| **net_retry_count**                                   | 10                                                           |       |                                                  |\n| **net_write_timeout**                                 | 60                                                           |       |                                                  |\n| **new**                                               | OFF                                                          |       |                                                  |\n| **old**                                               | OFF                                                          |       |                                                  |\n| **old_alter_table**                                   | OFF                                                          |       |                                                  |\n| **old_passwords**                                     | OFF                                                          |       |                                                  |\n| **open_files_limit**                                  | 150000                                                       |       |                                                  |\n| **optimizer_prune_level**                             | 1                                                            |       |                                                  |\n| **optimizer_search_depth**                            | 62                                                           |       |                                                  |\n| **optimizer_switch**                                  | index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on |       |                                                  |\n| **performance_schema**                                | OFF                                                          |       |                                                  |\n| **performance_schema_events_waits_history_long_size** | 10000                                                        |       |                                                  |\n| **performance_schema_events_waits_history_size**      | 10                                                           |       |                                                  |\n| **performance_schema_max_cond_classes**               | 80                                                           |       |                                                  |\n| **performance_schema_max_cond_instances**             | 1000                                                         |       |                                                  |\n| **performance_schema_max_file_classes**               | 50                                                           |       |                                                  |\n| **performance_schema_max_file_handles**               | 32768                                                        |       |                                                  |\n| **performance_schema_max_file_instances**             | 10000                                                        |       |                                                  |\n| **performance_schema_max_mutex_classes**              | 200                                                          |       |                                                  |\n| **performance_schema_max_mutex_instances**            | 1000000                                                      |       |                                                  |\n| **performance_schema_max_rwlock_classes**             | 30                                                           |       |                                                  |\n| **performance_schema_max_rwlock_instances**           | 1000000                                                      |       |                                                  |\n| **performance_schema_max_table_handles**              | 100000                                                       |       |                                                  |\n| **performance_schema_max_table_instances**            | 50000                                                        |       |                                                  |\n| **performance_schema_max_thread_classes**             | 50                                                           |       |                                                  |\n| **performance_schema_max_thread_instances**           | 1000                                                         |       |                                                  |\n| **pid_file**                                          | /opt/udb/instance/mysql-5.5/udb-ovzdmx/mysqld.pid            |       |                                                  |\n| **plugin_dir**                                        | /opt/udb/program/mysql/mysql-5.5.24/lib/plugin/              |       |                                                  |\n| **port**                                              | 3306                                                         |       |                                                  |\n| **preload_buffer_size**                               | 32768                                                        |       |                                                  |\n| **profiling**                                         | OFF                                                          |       |                                                  |\n| **profiling_history_size**                            | 15                                                           |       |                                                  |\n| **protocol_version**                                  | 10                                                           |       |                                                  |\n| **proxy_user**                                        |                                                              |       |                                                  |\n| **pseudo_thread_id**                                  | 111080103                                                    |       |                                                  |\n| **query_alloc_block_size**                            | 8192                                                         |       |                                                  |\n| **query_cache_limit**                                 | 1048576                                                      |       |                                                  |\n| **query_cache_min_res_unit**                          | 4096                                                         |       |                                                  |\n| **query_cache_size**                                  | 0                                                            |       |                                                  |\n| **query_cache_type**                                  | OFF                                                          |       |                                                  |\n| **query_cache_wlock_invalidate**                      | OFF                                                          |       |                                                  |\n| **query_prealloc_size**                               | 8192                                                         |       |                                                  |\n| **rand_seed1**                                        | 0                                                            |       |                                                  |\n| **rand_seed2**                                        | 0                                                            |       |                                                  |\n| **range_alloc_block_size**                            | 4096                                                         |       |                                                  |\n| **read_buffer_size**                                  | 262144                                                       |       |                                                  |\n| **read_only**                                         | ON                                                           |       |                                                  |\n| **read_rnd_buffer_size**                              | 524288                                                       |       |                                                  |\n| **relay_log**                                         | /opt/udb/instance/mysql-5.5/udb-ovzdmx/relaylog/mysql-relay.log |       |                                                  |\n| **relay_log_index**                                   |                                                              |       |                                                  |\n| **relay_log_info_file**                               | relay-log.info                                               |       |                                                  |\n| **relay_log_purge**                                   | ON                                                           |       |                                                  |\n| **relay_log_recovery**                                | OFF                                                          |       |                                                  |\n| **relay_log_space_limit**                             | 0                                                            |       |                                                  |\n| **report_host**                                       |                                                              |       |                                                  |\n| **report_password**                                   |                                                              |       |                                                  |\n| **report_port**                                       | 3306                                                         |       |                                                  |\n| **report_user**                                       |                                                              |       |                                                  |\n| **rpl_recovery_rank**                                 | 0                                                            |       |                                                  |\n| **rpl_semi_sync_master_enabled**                      | OFF                                                          |       |                                                  |\n| **rpl_semi_sync_master_timeout**                      | 10000                                                        |       |                                                  |\n| **rpl_semi_sync_master_trace_level**                  | 32                                                           |       |                                                  |\n| **rpl_semi_sync_master_wait_no_slave**                | ON                                                           |       |                                                  |\n| **rpl_semi_sync_slave_enabled**                       | OFF                                                          |       |                                                  |\n| **rpl_semi_sync_slave_trace_level**                   | 32                                                           |       |                                                  |\n| **secure_auth**                                       | OFF                                                          |       |                                                  |\n| **secure_file_priv**                                  | /opt/udb/instance/mysql-5.5/udb-ovzdmx/tmp/                  |       |                                                  |\n| **server_id**                                         | 168430248                                                    |       |                                                  |\n| **skip_external_locking**                             | ON                                                           |       |                                                  |\n| **skip_name_resolve**                                 | ON                                                           |       |                                                  |\n| **skip_networking**                                   | OFF                                                          |       |                                                  |\n| **skip_show_database**                                | OFF                                                          |       |                                                  |\n| **slave_compressed_protocol**                         | OFF                                                          |       |                                                  |\n| **slave_exec_mode**                                   | STRICT                                                       |       |                                                  |\n| **slave_load_tmpdir**                                 | /opt/udb/instance/mysql-5.5/udb-ovzdmx/tmp                   |       |                                                  |\n| **slave_net_timeout**                                 | 3600                                                         |       |                                                  |\n| **slave_skip_errors**                                 | OFF                                                          |       |                                                  |\n| **slave_transaction_retries**                         | 10                                                           |       |                                                  |\n| **slave_type_conversions**                            |                                                              |       |                                                  |\n| **slow_launch_time**                                  | 2                                                            |       |                                                  |\n| **slow_query_log**                                    | ON                                                           |       |                                                  |\n| **slow_query_log_file**                               | /opt/udb/instance/mysql-5.5/udb-ovzdmx/log/mysql-slow.log    |       |                                                  |\n| **socket**                                            | /opt/udb/instance/mysql-5.5/udb-ovzdmx/mysqld.sock           |       |                                                  |\n| **sort_buffer_size**                                  | 524288                                                       |       |                                                  |\n| **sql_auto_is_null**                                  | OFF                                                          |       |                                                  |\n| **sql_big_selects**                                   | ON                                                           |       |                                                  |\n| **sql_big_tables**                                    | OFF                                                          |       |                                                  |\n| **sql_buffer_result**                                 | OFF                                                          |       |                                                  |\n| **sql_log_bin**                                       | ON                                                           |       |                                                  |\n| **sql_log_off**                                       | OFF                                                          |       |                                                  |\n| **sql_low_priority_updates**                          | OFF                                                          |       |                                                  |\n| **sql_max_join_size**                                 | 18446744073709551615                                         |       |                                                  |\n| **sql_mode**                                          |                                                              |       |                                                  |\n| **sql_notes**                                         | ON                                                           |       |                                                  |\n| **sql_quote_show_create**                             | ON                                                           |       |                                                  |\n| **sql_safe_updates**                                  | OFF                                                          |       |                                                  |\n| **sql_select_limit**                                  | 18446744073709551615                                         |       |                                                  |\n| **sql_slave_skip_counter**                            | 0                                                            |       |                                                  |\n| **sql_warnings**                                      | OFF                                                          |       |                                                  |\n| **ssl_ca**                                            |                                                              |       |                                                  |\n| **ssl_capath**                                        |                                                              |       |                                                  |\n| **ssl_cert**                                          |                                                              |       |                                                  |\n| **ssl_cipher**                                        |                                                              |       |                                                  |\n| **ssl_key**                                           |                                                              |       |                                                  |\n| **storage_engine**                                    | InnoDB                                                       |       |                                                  |\n| **stored_program_cache**                              | 256                                                          |       |                                                  |\n| **sync_binlog**                                       | 1                                                            |       |                                                  |\n| **sync_frm**                                          | ON                                                           |       |                                                  |\n| **sync_master_info**                                  | 0                                                            |       |                                                  |\n| **sync_relay_log**                                    | 0                                                            |       |                                                  |\n| **sync_relay_log_info**                               | 0                                                            |       |                                                  |\n| **system_time_zone**                                  | CST                                                          |       |                                                  |\n| **table_definition_cache**                            | 400                                                          |       |                                                  |\n| **table_open_cache**                                  | 128                                                          |       |                                                  |\n| **thread_cache_size**                                 | 50                                                           |       |                                                  |\n| **thread_concurrency**                                | 10                                                           |       |                                                  |\n| **thread_handling**                                   | one-thread-per-connection                                    |       |                                                  |\n| **thread_stack**                                      | 262144                                                       |       |                                                  |\n| **time_format**                                       | %H:%i:%s                                                     |       |                                                  |\n| **time_zone**                                         | SYSTEM                                                       |       |                                                  |\n| **timed_mutexes**                                     | OFF                                                          |       |                                                  |\n| **timestamp**                                         | 1524477955                                                   |       |                                                  |\n| **tmp_table_size**                                    | 16777216                                                     |       |                                                  |\n| **tmpdir**                                            | /opt/udb/instance/mysql-5.5/udb-ovzdmx/tmp                   |       |                                                  |\n| **transaction_alloc_block_size**                      | 8192                                                         |       |                                                  |\n| **transaction_prealloc_size**                         | 4096                                                         |       |                                                  |\n| **tx_isolation**                                      | REPEATABLE-READ                                              |       |                                                  |\n| **unique_checks**                                     | ON                                                           |       |                                                  |\n| **updatable_views_with_limit**                        | YES                                                          |       |                                                  |\n| **version**                                           | 5.5.24-ucloudrel1-log                                        |       |                                                  |\n| **version_comment**                                   | Source distribution                                          |       |                                                  |\n| **version_compile_machine**                           | x86_64                                                       |       |                                                  |\n| **version_compile_os**                                | Linux                                                        |       |                                                  |\n| [**wait_timeout**](https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_wait_timeout)                                      | 28800                                                        | Both  | mysql 在关闭一个不活动 connection 之前等待的秒数 |\n| **warning_count**                                     | 0                                                            |       |                                                  |","src/content/posts/mysql-system-variable.mdx","d903555601085f23","mysql-system-variable.mdx","one-time-python-memory-leaks",{"id":1017,"data":1019,"body":1026,"filePath":1027,"digest":1028,"legacyId":1029,"deferredRender":22},{"title":1020,"summary":1021,"date":1022,"tags":1023,"group":196,"featured":38},"Python 内存泄漏排查与分析","## python 内存异常的几种情况",["Date","2014-12-20T00:00:00.000Z"],[1024,1025],"内存泄露","memory link","## python 内存异常的几种情况\n\n- 代码内出现循环引用\n- 全局变量数据太多\n- 进程加载大量数据，长久持有不释放\n\n## 现象\n\n线上生产环境一些 [tornado](https://readthedocs.org/projects/tornado) 服务(主要提供rest服务)进程占用内存过大：百兆到1G ，测试环境的同样服务未出现异常。\n\n## 观察分析\n\n1.确定是否是个别进程的特有现象\n\n在一套环境中部署不同的tornado的服务，排除了tornado和第三方库的可能性。\n\n2.利用linux top 等命令观察异常服务进程内存的增长情况\n\n{/* more */}\n\n人工观察有异常内存的服务进程(2~3个小时观测一次)，发现其内存占有率并不完全统一，即在进程启用之后，有的进程内存占有过大，有的正常，但是在相当长一段时间之后(一天以后)，所有进程内存占有几乎趋于一个稳定的比较大的值。由此可以推断出以下几种情况：\n\n- 生产环境请求复杂，测试环境和生产环境表现不一致，有可能是对某些api的不合法的请求(非法参数未处理)导致内存占用过大\n- 某些api(单次请求的数据量较大)的并发量太大，同一时间内存占有量过大\n- 隐式的改变了全局变量的值，导致变量数据增大，比如全局的list或者dict数据不断被添加\n- 其他未知情况\n\n\n**对代码进行静态分析和检查, 排除了全局变量和循环引用的问题。**\n\n\n\n## 侦测线上api调用前后对进程内存的影响\n\n\n为了能够非常细致的观测到线上api调用前后的进程内存占用率，在api调用的入口记录了当前进程的内存占用，并对日志以进程的id来区分，由于tornado的单进程特性，也可以用端口号来区分，这样日志的划分更稳定，毕竟进程id是个变数。\n\n```\n\n   def log_memory(self):\n        import psutil\n        import os\n        logger_name = ('app_%s'%self.application.settings.get('port'))\n        m_logger = loggers.getLogger(logger_name, '/var/log/app_%s.log'%logger_name)\n        process = psutil.Process(os.getpid())\n        m_logger.info('%s  %s MB'%(self.request.path, process.memory_info()[0]/(1024*1024)))\n        m_logger.info(self.request.arguments)\n\n```\n\n\n[psutil](http://pythonhosted.org/psutil/index.html) 提供了获取进程资源占用如内存，cpu，磁盘，网络等的api。为了能查看api调用的上下文环境，日志中还记录了api的请求参数。\n\n\n\n## 解决\n\n通过的日志分析发现，一个api在某些参数的边界未做处理时，会导致一部分很大的数据被加载到内存中。至此，这个问题的根源终于被找到了。\n\n\n**不过一个疑问是：python的进程内存增大之后，是否会让python解释器认为，该进程使用的峰值内存就是如此而不愿意交换给os呢**","src/content/posts/one-time-python-memory-leaks.mdx","dbce67d12cf3b68a","one-time-python-memory-leaks.mdx","no-place-is-home",{"id":1030,"data":1032,"body":1038,"filePath":1039,"digest":1040,"legacyId":1041,"deferredRender":22},{"title":1033,"summary":1034,"date":1035,"tags":1036,"group":129,"featured":38},"无处是故乡","我在帝都待了十年，在这里工作、买房、养育了 7 号，截止目前，我有生之年三分之一的时间都是在帝都度过的，虽然说我是个不太爱出门的程序员，但是北海、什刹海、后海、前门、天坛、故宫、颐和园、琉璃厂胡同、前门我也算是如数家珍了，虽然豆汁喝不惯，但是老北京卤煮和炒肝我也很爱吃了，我知道自...",["Date","2022-09-25T00:00:00.000Z"],[1037],"人生","我在帝都待了十年，在这里工作、买房、养育了 7 号，截止目前，我有生之年三分之一的时间都是在帝都度过的，虽然说我是个不太爱出门的程序员，但是北海、什刹海、后海、前门、天坛、故宫、颐和园、琉璃厂胡同、前门我也算是如数家珍了，虽然豆汁喝不惯，但是老北京卤煮和炒肝我也很爱吃了，我知道自己并不是北京人，但是北京的蓝天白云，阳光护城河都不拒绝我，我可以在任何时候享受他们，沉浸其中。\n\n转眼间 7 号到了上学的年纪，我不是北京人，7 号自然也不是，但是 7 号可以选择做天津人，因为天津是距离北京很近的城市，而且天津并不拒绝 7 号成为天津人，这意味着 7 号可以自由在天津这个城市接受教育而不受约束，顺理成章 7 号去了天津，我不反感北京不让我成为北京人，我知道中国户籍制度在从诞生至今已经影响深远，不会轻易改变，我也完全不奢望吾辈能有所改善，总之我不是北京人，而且北京有几百万人像我一样不是北京人，大家都活的好好的，我一样也会活的好好的，而且十年了，北京可以算是我的第二个故乡了。所谓故乡，也就是一个生活久了而且习惯了的地方，第一个在山西，虽然我在昆明也待了很久，但是我对那里的水土过敏，但是我来到北京之后这一切都恢复正常了，北京很好。\n\n只是没想到，大疫持续了三年，行将持续下去，不知何时休矣。疫情彻底改变了这个世界，顺带也照出了各路神仙鬼怪。虽然我老老实实工作，勤勤恳恳纳税，不诽议朝政，做自己能改变之事，让这个世界能变得更好，最后发现，当大人物的利益被触碰之时，有人把权力之锤结结实实砸在了我们这些普通人的头上，以大局大义之名义，行懒政惰政之权，以牺牲小我之精神，成大局之利益。而且这样的牺牲是否是符合国法的，没有人会跟你商量，任何时候任何时间权力将以抗疫之名对在京外的人弹窗限制购票劝返，不让进京。诺大的中国，只有北京这么做了，诺大的中国只有北京彻彻底底的拒绝有疫情之地的人员来京，而且采用了和河南对待储户一样的手段，健康宝弹窗，限制购买进京的火车票飞机票，没有哪个城市会通过如此之权力手段来阻止人民的正常流动，但是北京把这样的权力发挥地淋漓尽致。没有人可以管得了北京，没有法律约束得了北京，因为北京有大人物，大人物之所都应该受到庇护，大人物要保护好自己的利益不受外界任何因素的干扰，一个个小我生活的牺牲又算的了什么。一方面权力告诉我们说，他们在乎我们的生命，一方面权力又要告诉我们说，要绝对的服从。我也很矛盾，我怕死，但是当我们一步步忍让着服从的时候，权力却是步步紧逼，深入到任何他可以影响我的地方，无科学之实判定的密接和封控，一刀切的限制进京，科学已经知道了人的基因组成和表达，却依然无法指导我们预防疫情，因为指挥抗议的人不用科学来指导。我无从预测权力之手到底受什么约束，我也无从判断权力之手能否被约束，初中政治教科书已经教给了我，没有约束的自由不能称之为自由，没有约束的权力根本不是权力，而是奴役。\n\n故乡在哪里，即使有疫情的时候，山西也是可以回去的，老家会老老实实根据国家的防疫政策来隔离或者不隔离你，只是我已经离开了山西很久，每次回去我都不会住太久，时间久了我会无所适从，不知道该如何面对，更重要的时，成年人总是着急挣钱养家，没有太多时间留给故乡，也怪自己无能，无法给它带来改变，深感愧疚。\n\n故乡在哪里，北京的天很蓝，尤其是十月金秋的时候，每年我都会去天安门坐一坐或者路过那里驻留一阵子，看着全国各地涌来的游客，看着人民英雄纪念碑，偶尔会被便衣警察查身份证，但是不妨碍我继续待在广场，因为我没有威胁，当然我也见过撒传单的人，他们会迅速被从各个不知道哪里冒出来的便衣包围，按到，押走。天津有疫情了，7号回不来，而我会陪7号，去找7号之前，我可能还会去天安门看看，看看那个每年都能看到的大花篮，它又出现了，也许还是去年那个。\n\n故乡在哪里，天津人说话很逗，天津人在疫情的折磨下，已经很疲倦了，整整一个月的筛查，即使日日有新增，有些人依然我行我素，不带口罩来去自如，即使用蓝色的铁皮封了小区，有人翻过去了，有人钻过去了，总之逃离之后会有短暂的自由。\n\n故乡在哪里，我去了很多城市，大到如省会成都、重庆、贵阳、西安、南京、深圳等等，小到如大理、丽江、顺德、宜昌、乐山等等，大大小小几十个城市，广州很喜欢，广州很热，成都吃的很开心，成都没太阳，昆明太阳很好，但是会过敏，重庆上坡下坎很有意思，重庆也很热，深圳没底蕴，杭州夏天热冬天冷，只有北京天很蓝，冬天有暖气，夏天不会热死，有记忆中的沙尘暴，四季分明，大到没边，坐2个小时地铁可能还还没出五环，胡同后海北海来来往往相看两不厌，总有没去过的地方可以去，冬日的阳光照着小区的流浪猫一朵一朵像冬日开的花，可能唯一的遗憾是没有海，但是可以开2小时去天津钓螃蟹，去阿那亚抓水母，踩沙滩，只是北京终究是他们的北京。\n\n故乡在哪里，无...处...是...故...乡。","src/content/posts/no-place-is-home.mdx","e403a01740f420cc","no-place-is-home.mdx","open-linux-standard-tcp-service",{"id":1042,"data":1044,"body":1049,"filePath":1050,"digest":1051,"legacyId":1052,"deferredRender":22},{"title":1045,"summary":1046,"date":1047,"tags":1048,"group":706,"featured":38},"linux 打开标准的 echo、discard 等 TCP 服务","TCP 默认提供了一些标准的服务，大多数系统为了安全都关闭了这些服务，但是有时候为了了解 TCP 的内部机制需要做一些测试，这些服务能够很好的帮助我们熟悉 TCP 的原理和机制，以 Ubuntu 为例来打开这些标准的服务。",["Date","2018-02-28T00:00:00.000Z"],[],"TCP 默认提供了一些标准的服务，大多数系统为了安全都关闭了这些服务，但是有时候为了了解 TCP 的内部机制需要做一些测试，这些服务能够很好的帮助我们熟悉 TCP 的原理和机制，以 Ubuntu 为例来打开这些标准的服务。\n\n\n## 安装 openbsd-inetd\n\n```\nsudo apt-get install openbsd-inetd\n```\n\n\n## 编辑 /etc/inetd.conf\n\n打开 `/etc/inetd.conf` 文件对需要启用的服务关闭其注释\n\n```\ndiscard     stream  tcp nowait  root    internal\ndiscard     dgram   udp wait    root    internal\ndaytime     stream  tcp nowait  root    internal\ntime        stream  tcp nowait  root    internal\necho        stream  tcp nowait  root    internal\n\n```\n\n## 启动服务\n\n```\nsudo /etc/init.d/openbsd-inetd start\n\n```\n\n## 检查服务\n\n\n```\nnetstat -alt | grep -E 'time|discard|daytime'\n\n(env) zhyq@zhyq:~$ netstat -alt | grep -E 'time|discard|daytime'\ntcp        0      0 *:time                  *:*                     LISTEN     \ntcp        0      0 *:discard               *:*                     LISTEN     \ntcp        0      0 *:daytime               *:*                     LISTEN  \n\n```\n\n## 标准服务一览\n\n\n\n| 名称      | TCP 端口 | UDP 端口 | RFC  | 描述                                       |\n| ------- | ------ | ------ | ---- | ---------------------------------------- |\n| echo    | 7      | 7      | 862  | 服务器返回客户端发送的内容                            |\n| discard | 9      | 9      | 863  | 服务器丢弃客户端发送的内容                            |\n| daytime | 13     | 13     | 867  | 服务器以可读的形式返回时间和日期                         |\n| chargen | 19     | 19     | 864  | 当客户端发送一个数据报时，TCP 服务器发送一串连续的字符流，直到客户端中断连接，UDP 服务器发送一个随机长度的数据报 |\n| time    | 37     | 37     | 868  | 服务器返回一个二进制形式的 32bit，表示从 UTC 时间1900.1.1 至今的秒数 |","src/content/posts/open-linux-standard-tcp-service.mdx","831684221bdca229","open-linux-standard-tcp-service.mdx","optimization-01",{"id":1053,"data":1055,"body":1061,"filePath":1062,"digest":1063,"legacyId":1064,"deferredRender":22},{"title":1056,"summary":1057,"date":1058,"tags":1059,"group":78,"featured":38},"后端性能优化 01","最近业务推送越来越频繁，导致瞬时压力非常大，虽然以前的代码确实很多地方像一坨 shit，实在无法下手从代码重构业务优化了，但是还是从其他方面做了一些调整来把性能提升了。",["Date","2018-12-20T00:00:00.000Z"],[1060],"性能优化","最近业务推送越来越频繁，导致瞬时压力非常大，虽然以前的代码确实很多地方像一坨 shit，实在无法下手从代码重构业务优化了，但是还是从其他方面做了一些调整来把性能提升了。\n\n\n**第一，升级了一下 MongoDB 从 2.4 到 3.2，换成了 wt 引擎以及 ssd 盘**\n\n线上 MongoDB 集群由于云厂商的原因最近总是挂，而且由于使用的 2.4 的版本，导致配置如果出现变动还需要重启实例，之前的资源最早用的是普通云盘，性能确实也一般，平时推送瞬时压力上来，单台 MongoDB 实例连接数能够飙到最高 5000，当然这里面肯定有慢查询的功劳，但是有些数据量其实很小，按照 MongoDB 的脾气，就是全部加载到内存中访问也不是个事，ssd 其实就可以充当一个低配版本的内存了。\n\n\n**第二，使用 openresty，启用了 nginx 缓存**\n\n虽然我已经懒得吐槽产品为啥非要在 feed 流的页面狂加状态，导致每个人的列表都不一样，缓存很难做，还是直到某一天推送压力实在太大，后端服务出现短时不可用，当然只是 feed 流业务，于是我们果断上了对部分单页上了 nginx 缓存，暂时也不理会各种状态的事情了，效果确实很好，部分压力大的接口基本不会穿透到后端 APP。\n\n\n**第三，优化了后端 APP 和 nginx 的连接配置**\n\n在巡查 nginx 日志发现，部分后端 APP 和 nginx 的连接频繁连接断开，造成没有复用的现象，查了一遍 nginx 发现 keepalive 该配的都配了，然后又怀疑是 gunicorn 的问题，最后发现 gunicorn 在 keep-alive 时默认等待时间是 2s 就会关闭连接，实在是太短了，手动调整了一下，后端 APP 和 nginx 的 time_wait 明显变少了，连接建立起来之后断的情况变少了。\n\n\n**第四，优化了部分 MySQL 的连接**\n\n\nFeed 流部分业务对某些 MySQL 连接的特别频繁，让负责业务的程序员看了看之前的代码，发现有些老的需求频繁使用 MySQL 连接，完全没有必要，部分数据可以做全局变量共享，却写了局部的，导致 MySQL 会受到大量请求，于是开始优化提升这些变量称为全局，做缓存，减少 MySQL 连接次数。\n\n\n**第五，升级 MySQL 硬件配置**\n\nMySQL 虽然实例不少，也做了主从结构，在某些耗时的 join 计算以及推送时，有时候还是很慢，于是对部分业务做了升级，把原来的 6G 内存调到了 12G，并且优化了 InnoDB_pool_buffer 的大小，确实解决了不少慢的查询和计算。\n\n\n\n**第六，改造升级了 rpc proxy**\n\n\nRPC proxy 是一个类似 nginx 的代理层，用 tornado 实现，主要做 rpc client 和 后端 server 的中转和负载均衡，单台请求最高能到 1 万 qps，但是不支持容错，导致部分后端节点挂了之后，还是会收到来自 proxy 的请求，于是做了升级改造，支持故障节点自动下线、自动释放故障节点连接池，待节点恢复之后，自动上线供 client 层调用。\n\n升级改造用 tornado 提供的周期性检测特性，也就是在 ioloop 循环时不断检查定时器是否满足条件而去调用，由于 tornado 是个单线程，proxy 内部也没有开启过多线程，所有操作基本无锁，开销很小。\n\n\n**第七，替换 twemproxy 为 codis**\n\ntwemproxy 最大的痛点就是无法平滑扩容，如果 redis 内从不足，需要水平扩容，就需要对原来 redis 中的数据进行手动迁移，比较麻烦，而且 twemproxy 单节点相比 redis 单节点来说性能不足，由于 twemproxy 是单进程的，单节点如果达到 1w qps 已经很卡了，为了解决 twemproxy 的性能问题，必须不断的加机器，或多开进程，然后不断的修改内网域名配置。\n\n\ncodis 扩容是半自动的，运维手动点点可以完成，而且 codis 的单机性能确实要好于 twemproxy。\n\n\n**第八，用 Go 做了一个内部用的发布系统**\n\n\n现在的团队发布用的 walle 和 fabric，用 fabric 写好远程部署脚本，然后再通过 walle 调用，walle 这个工具对于整个团队来说太透明了，出错不容易查看，不知道哪里出问题，必须要运维介入，而且部署日志不友好，于是用 Go 写了一个发布系统替换 walle。\n\n新的部署系统是根据自身业务定制的，支持部署日志回传以及上传到第三方云平台，能够非常方便的查看部署日志，而且通过一个友好的 web 页面可以实时知道当前的部署进度，具体到任意一台主机。","src/content/posts/optimization-01.mdx","c7e16211fe7f639f","optimization-01.mdx","pipenv",{"id":1065,"data":1067,"body":1072,"filePath":1073,"digest":1074,"legacyId":1075,"deferredRender":22},{"title":1068,"summary":1069,"date":1070,"tags":1071,"group":196,"featured":38},"使用 pipenv 和 autoenv 构造一键 Python Project 环境","虽然 Python 的 virtualenv 可以为 Python 的工程提供很好的环境支持免去了很多环境依赖上的麻烦，但是若是项目太多，还是要构建很多虚拟环境，而且每次进不同的项目都需要手动切换非常麻烦，autoenv 和 pipenv可以为 Python 的工程提供 virt...",["Date","2017-10-10T00:00:00.000Z"],[1065],"虽然 Python 的 virtualenv 可以为 Python 的工程提供很好的环境支持免去了很多环境依赖上的麻烦，但是若是项目太多，还是要构建很多虚拟环境，而且每次进不同的项目都需要手动切换非常麻烦，[autoenv](https://pypi.org/project/autoenv/) 和 [pipenv](https://pypi.org/project/pipenv/)可以为 Python 的工程提供 virtualenv **自动构建、自动激活以及灵活的依赖管理**。\n\n{/* more */}\n\n\n# 使用 autoenv 自动激活 env 环境\n\nautoenv 可以在进入项目之后自动检测项目目录的 .env 文件并激活项目所需的 virtualenv 环境，这样能够保证每次切换项目都能自动进入项目自身依赖的虚拟环境。\n\n```bash\nbrew install autoenv\necho \"source $(brew --prefix autoenv)/activate.sh\" >> ~/.bash_profile\n```\n\n# 使用 pipenv 自动构建环境和依赖\n\npipenv 是结合了 virtualenv 和 pip 的构建工具，这样就省去了分开使用二者的麻烦，而且 pipenv 借鉴了开源社区众多包管理工具的优秀特性，真可谓集中家之长来为 Python 提供了一个优秀的包管理工具，其作者就是大名鼎鼎 requests 的作者 [kennethreitz](https://github.com/kennethreitz)。\n\n确保系统上已经有了 Python 和 pip :\n```bash\n$ python --version\nPython 2.7.12\n\n$ pip --version\npip 9.0.1 from /Library/Python/2.7/site-packages (python 2.7)\n```\n\n安装 pipenv :\n```bash\n$ pip install --user pipenv\n```\n\n`--user` 选项将 pipenv 安装在系统的用户目录，避免使用 sudo 权限以及破坏系统原有的依赖，在 Linux 和 macOS 中可以使用 `python -m site --user-base` 查看 pip 用户目录在什么地方：\n```bash\n$ python -m site --user-base\n/Users/zhyq0826/Library/Python/2.7\n```\n\n一般情况下 Python 的用户 bin 目录并没有加入的 shell bin 中，找到该目录并加入到用户 path 中：\n```bash\nexport PATH=$PATH:/Users/zhyq0826/Library/Python/2.7/bin\n```\n\npipenv 结合了 virtualenv 和 pip，借助 pipenv 可以一键创建 virtualenv 环境，也就是说每个项目都可以拥有自己单独的虚拟环境和依赖安装了。\n\n\n```bash\n$ cd myproject\n$ pipenv install \n```\n如果项目中已经有了 `requirements.txt` pipenv 会自动进行转换生成 `Pipfile` 文件，该文件是 pipenv 用来跟踪依赖包信息的文件。\n\n如果出现：\n```bash\nWarning: Your dependencies could not be resolved. You likely have a mismatch in your sub-dependencies.\n  You can use $ pipenv install --skip-lock to bypass this mechanism, then run $ pipenv graph to inspect the situation.\n```\n\n说明在安装过程中有错误，可以按照提示进行操作：\n```bash\npipenv install --skip-lock\n```\n\n在我的 Pro turbo-markdown 目录上安装的提示信息：\n```bash\nCreating a virtualenv for this project…\n⠋Using real prefix '/System/Library/Frameworks/Python.framework/Versions/2.7'\nNew python executable in /Users/zhyq0826/.local/share/virtualenvs/turbo-markdown-BmR5qYdY/bin/python\nInstalling setuptools, pip, wheel...done.\n\nVirtualenv location: /Users/zhyq0826/.local/share/virtualenvs/turbo-markdown-BmR5qYdY\nCreating a Pipfile for this project…\nPipfile.lock not found, creating…\nLocking [dev-packages] dependencies…\nLocking [packages] dependencies…\nUpdated Pipfile.lock (c23e27)!\nInstalling dependencies from Pipfile.lock (c23e27)…\n  🐍   ▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉▉ 0/0 — 00:00:00\nTo activate this project's virtualenv, run the following:\n $ pipenv shell\n```\n把输出的 env 的目录送到 .env 文件，下次 cd 进入项目目录之后会自动激活：\n```bash\necho \"source /Users/zhyq0826/.local/share/virtualenvs/turbo-markdown-BmR5qYdY/bin/activate\" >>.env\n```\n\n# 小结\n\n好工具的使用要趁早，早用早解放，省时又省力😁。","src/content/posts/pipenv.mdx","b6894063d33f961b","pipenv.mdx","procrastiatio-of-programer-life",{"id":1076,"data":1078,"body":1084,"filePath":1085,"digest":1086,"legacyId":1087,"deferredRender":22},{"title":1079,"summary":1080,"date":1081,"tags":1082,"group":129,"featured":38},"拖延症的程序人生","这个博客是由hexo搭起来的，在这之前我还看了",["Date","2014-10-28T00:00:00.000Z"],[1083],"拖延症","这个博客是由[hexo](http://hexo.io)搭起来的，在这之前我还看了\n\n- [pelican](https://github.com/getpelican/pelican)\n- [ghost](https://ghost.org)\n- [jekyll](https://github.com/mojombo/jekyll)\n- [octopress](https://github.com/imathis/octopress)\n\n上手了pelican和jekyll，最终懒得没能把博客跑起来。转眼间过去好几个月了，一直琢磨着要写点东西，关于代码的，关于这些年的生活的，以及关于未来的。迟迟然，最终还是花了点时间用hexo把这个写作的平台搭起来了，申请了域名叫[三月沙](http://sanyuesha.com), 我用了很多年的id。  \n\n{/* more */}\n\n三月沙，意指北方三月的尘沙，在我小时候的农村里，几乎每年的三月都会刮起沙尘暴，肆虐着那片生我养我土地。诚然，我那个时候没想过我将来要当一个什么样的人，记得那个时候我才12岁左右，刚上了初中，突然意识到人是会死掉的，然后就觉得活着还有什么意思呢，再后来我就不在想这个问题了，因为我觉得科学是件有意思的事情，当然我也没意识到搞科学是件多么难的事情。现在，想起来一个科学家的梦想到现实中突然变成了程序员，这个事情说起来也是挺搞的。\n\n川，在国外打来电话说，回去以后我们一定要折腾一下，我说好，一定折腾。\n\n宽，在武汉发来微信说，我们一定搞一搞，一定要用我们的意志和能力改变这个世界，我说好，一定搞。\n\n然后，嘉琪也从昆明来到了北京。\n\n他们和我一样，期待什么东西能被我们的创造所改变，期待那种激动人心的时刻能一起见证。\n\n时间抹杀了很多东西，操着一个大蛋的青春，年轻时那些友情，爱情，可能这些年唯一还留着的就是，想改变点什么的意志了。\n\n意志不死，代码不尽。敬我们。","src/content/posts/procrastiatio-of-programer-life.mdx","0b27cf82f663d4a3","procrastiatio-of-programer-life.mdx","programmer-must-know-number",{"id":1088,"data":1090,"body":1095,"filePath":1096,"digest":1097,"legacyId":1098,"deferredRender":22},{"title":1091,"summary":1092,"date":1093,"tags":1094,"group":129,"featured":38},"程序员必须知道的数字","不论是日常写代码还是做架构都免不了和各种各样的数字过招，虽然说不是学精算的不需要那么的数字敏感，但是理解各种数字背后的含义以及它们的差异能够帮助程序员做出更好的决策，以下所有的资料都来自网络整理并经个人的整理评测，欢迎反馈指正。",["Date","2018-08-16T00:00:00.000Z"],[],"不论是日常写代码还是做架构都免不了和各种各样的数字过招，虽然说不是学精算的不需要那么的数字敏感，但是理解各种数字背后的含义以及它们的差异能够帮助程序员做出更好的决策，以下所有的资料都来自网络整理并经个人的整理评测，欢迎反馈指正。\n\n\n## 存储单位\n\n1 bit 是表示信息最小单位，是二进制中一位表示的信息量，也可以理解为一位表示的不同的信息的个数，n bit 可以表示 2^n 种个数\n1 byte = 8 bit = 2^3 bit\n1 kb = 1024 bytes = 2^10 bytes  (硬件厂商普遍用 1000 软件厂商普遍用 1024) \n1 mb = 1024 kb = 2^20 bytes\n1 g = 1024 mb = 2^30 bytes\n1 tb = 1024 gb\n1 pb = 1024 tb\n1 ASCII码 = 1 byte ，表示如果一个英文字母用 ASCII 码则需要 1 byte 空间存储\n1 个 unicode 英文字符用 utf-8 编码占用 1 byte，1 个 unicode 中文汉字用 utf-8 编码占用 3 bytes\n1 篇 2000 字的中文文章大约需要 2000*3 / 1024 ≈ 6 kb 存储空间\n现代普通计算机的 4 G 内存 = 4\\*1024 mb = 2^32 bytes\n1 亿个 64 位的整数占用内存 ≈ 6 G\n\n\n## 时间延迟\n\n1 ns (纳秒) = 10^-9 seconds = 10^-6 ms (百万分之一毫秒)\n1 us (微妙) = 10^-6 seconds = 1,000 ns = 1/1000 ms (千分之一毫秒)\n1 ms (毫秒) = 10^-3 seconds = 1,000 us = 1,000,000 ns\n\nL1 cache reference = 0.5 ns\nL2 cache reference = 4 ns\nMutex lock/unlock == 17  ns\nMain memory reference  = 100 ns，是 25 倍 L2 cache, 200 倍 L1 cache\nCompress 1K bytes with Zippy = 2,000 ns ≈ 2 us\nRead 1 MB sequentially from SSD = 1,000,000 ns =  1000 us  = 1ms\nRead 1 MB sequentially from memory =  250,000 ns  = 250 us = 0.25ms\nRound trip within same datacenter = 500,000 ns = 500 us = 0.5 ms\nRead 1 MB sequentially from disk = 20,000,000 ns = 20,000 us = 20 ms， 是 80 倍 memory, 20 倍 SSD, \nSend 1K bytes over 1 Gbps network = 10,000 ns  = 10 us = 0.01 ms \nDisk seek  = 10,000,000 ns = 10,000 us = 10 ms，是 20 倍 datacenter roundtrip\n\n## 开源软件\n\n**MySQL** \n一个包含 7 个 varchar(32) fileds，4 个 int(11) feilds，3 个 datetime fields 的表中存储 2000 万数据  ≈ 5 GB\n4 核 6g ssd 机型 5.5 MySQL 的 tps 最高大约是 3.5k 个\n\n**Redis**\n10 万个 64 位整数以 set(key, value) 的方式存储，需要占用约 11 MB 内存\nIntel i7 2.57 GHz set 命令不用 pipline qps ≈ 8 万，使用 pipline 约是 5 倍 ~ 6 倍的性能提升\n\n**rabbitmq**\nIntel i7 2.57 GHz send QPS ≈ 5 万\n\n\n## 参考资料\n\n- https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html\n- http://highscalability.com/blog/2013/1/15/more-numbers-every-awesome-programmer-must-know.html\n- https://gist.github.com/jboner/2841832\n- https://redis.io/topics/benchmarks\n- https://www.cloudamqp.com/blog/2016-11-18-load-testing-and-performance-measurements-rabbitmq.html\n- https://www.rabbitmq.com/blog/2012/04/25/rabbitmq-performance-measurements-part-2/","src/content/posts/programmer-must-know-number.mdx","6bfb66be4fbcdb2a","programmer-must-know-number.mdx","pytest",{"id":1099,"data":1101,"body":1105,"filePath":1106,"digest":1107,"legacyId":1108,"deferredRender":22},{"title":1099,"summary":1102,"date":1103,"tags":1104,"group":196,"featured":38},"> pytest",["Date","2017-11-21T00:00:00.000Z"],[],"> [pytest](https://docs.pytest.org/en/latest/contents.html)\n\n# 特性\n\n\n# 安装和使用\n\n\n# 有用的技巧\n\n\n# 重要的 fixture 介绍","src/content/posts/pytest.mdx","95a58ab279a3491a","pytest.mdx","python-bumpversion",{"id":1109,"data":1111,"body":1117,"filePath":1118,"digest":1119,"legacyId":1120,"deferredRender":22},{"title":1112,"summary":1113,"date":1114,"tags":1115,"group":196,"featured":38},"使用 Python bumpversion 轻松实现版本管理","bumpversion 是用来实现 Python package 的包管理工具，它利用 setup.cfg 文件进行文件内的版本信息查找和替换，pypi。",["Date","2017-09-29T00:00:00.000Z"],[1116],"bumpversion","bumpversion 是用来实现 Python package 的包管理工具，它利用 setup.cfg 文件进行文件内的版本信息查找和替换，[pypi](https://pypi.org/project/bumpversion/)。\n\n# 小版本 bump minor \n\n```\nbumpversion --current-version 0.5.1 minor\n```\n\nversion 从 0.5.1 --> 0.6.0 \n\n# 大版本 bump major\n\n```\nbumpversion --current-version 1.1.9 major\n```\n\nversion 从 1.1.9 --> 2.0.0 \n\n# 补丁修复\n\n```\nbumpversion --current-version 1.1.9 patch\n```\n\nversion 从 1.1.9 --> 1.1.10","src/content/posts/python-bumpversion.mdx","a936723427797f7c","python-bumpversion.mdx","python-copy-deepcopy",{"id":1121,"data":1123,"body":1129,"filePath":1130,"digest":1131,"legacyId":1132,"deferredRender":22},{"title":1124,"summary":1125,"date":1126,"tags":1127,"group":196,"featured":38},"如何理解 Python 浅拷贝和深拷贝","为了让一个对象发生改变时不对原对象产生副作用，此时，需要一份这个对象的拷贝，python 提供了 copy 机制来完成这样的任务，对应的模块是 copy。",["Date","2016-06-18T00:00:00.000Z"],[1128],"copy","为了让一个对象发生改变时不对原对象产生副作用，此时，需要一份这个对象的拷贝，python 提供了 copy 机制来完成这样的任务，对应的模块是 [copy](https://docs.python.org/2/library/copy.html)。\n\n## 浅拷贝:shadow copy\n\n在 `copy` 模块中，有 `copy` 函数可以完成浅拷贝。\n```python\nfrom copy import copy\n```\n在 python 中，标识一个对象唯一身份的是：对象的`id`(内存地址)，对象类型，对象值，而浅拷贝就是创建一个具有相同类型，相同值但不同`id`的新对象。\n\n对可变对象而言，对象的值一样可能包含有对其他对象的引用，浅拷贝产生的新对象，虽然具有完全不同的`id`，但是其值若包含可变对象，这些对象和原始对象中的值包含同样的引用。\n\n```python\n>>> import copy\n>>> l = {'a': [1,2,3], 'b':[4,5,6]}\n>>> c = copy.copy(l)\n>>> id(l) == id(c)\nFalse\n>>> l['a'].append('4')\n>>> c['b'].append('7')\n>>> l\n{'a': [1, 2, 3, '4'], 'b': [4, 5, 6, '7']}\n>>> c\n{'a': [1, 2, 3, '4'], 'b': [4, 5, 6, '7']}\n>>> \n```\n可见浅拷贝产生的新对象中，可变对象的值在发生改变时会对原对象的值产生副作用，因为这些值是同一个引用。\n\n{/* more */}\n\n\n浅拷贝仅仅对对象自身创建了一份拷贝，而没有在进一步处理对象中包含的值，因此使用浅拷贝的典型使用场景是：对象自身发生改变的同时需要保持对象中的值完全相同，比如 list 排序。\n\n```\n>>> def sorted_list(olist, key=None):\n...     copied_list = copy.copy(olist)\n...     copied_list.sort(key=key)\n...     return copied_list\n... \n>>> a = [3,2,1]\n>>> b = sorted_list(a)\n>>> a\n[3, 2, 1]\n>>> b\n[1, 2, 3]\n```\n\n## 深拷贝:deep copy\n\n在 `copy` 模块中，有 `deepcopy` 函数可以完成深拷贝。\n```python\nfrom copy import deepcopy\n```\n\n深拷贝不仅仅拷贝了原始对象自身，也对其包含的值进行拷贝，它会递归的查找对象中包含的其他对象的引用，来完成更深层次拷贝。因此，深拷贝产生的副本可以随意修改而不需要担心会引起原始值的改变。\n\n```python\n>>> import copy\n>>> l = {'a': [1,2,3], 'b':[4,5,6]}\n>>> c = copy.deepcopy(l)\n>>> id(l) == id(c)\nFalse\n>>> l['a'].append('4')\n>>> c['b'].append('7')\n>>> l\n{'a': [1, 2, 3, '4'], 'b': [4, 5, 6]}\n>>> c\n{'a': [1, 2, 3], 'b': [4, 5, 6, '7']}\n>>> \n```\n\n值得注意的是，深拷贝并非完完全全递归查找所有对象，因为一旦对象引用了自身，完全递归可能会导致无限循环。一个对象被拷贝了，python 会对该对象做个标记，如果还有其他需要拷贝的对象引用着该对象，**它们的拷贝其实指向的是同一份拷贝**\n\n```python\n>>> a = [1,2]\n>>> b = [a,a]\n>>> b\n[[1, 2], [1, 2]]\n>>> c = deepcopy(b)\n>>> id(b[0]) == id(c[0])\nFalse\n>>> id(b[0]) == id(b[1])\nTrue\n>>> c\n[[1, 2], [1, 2]]\n>>> c[0].append(3)  #c list 中包含的两份拷贝指向同一处\n>>> c\n[[1, 2, 3], [1, 2, 3]]\n>>> \n```\n\n## 自定义拷贝机制\n\n使用 `_copy_` 和 `__deepcopy__` 可以完成对一个对象拷贝的定制。这里不展开了，有机会再探讨自定义拷贝。","src/content/posts/python-copy-deepcopy.mdx","c32bf89c9c5e9827","python-copy-deepcopy.mdx","python-float",{"id":1133,"data":1135,"body":1141,"filePath":1142,"digest":1143,"legacyId":1144,"deferredRender":22},{"title":1136,"summary":1137,"date":1138,"tags":1139,"group":196,"featured":38},"Python float 和 decimal","在 Python 官方的文档 Floating Point Arithmetic: Issues and Limitations 解释了 Python float 类型的一些问题和限制。",["Date","2017-11-08T00:00:00.000Z"],[1140],"浮点类型","在 Python 官方的文档 [Floating Point Arithmetic: Issues and Limitations](https://docs.python.org/2/tutorial/floatingpoint.html) 解释了 Python float 类型的一些问题和限制。\n\n这里我想记录的是 Python 的 Decimal 类型和 float 的转换问题。\n\nPython 的 Decimal 支持从 str 和 float 进行转换，比如\n\n```python\n>>> from decimal import Decimal\n>>> f = 3.1666666666666666\n>>> Decimal(str(f))\nDecimal('3.16666666667')\n>>> Decimal(f)\nDecimal('3.166666666666666518636930049979127943515777587890625')\n>>> Decimal.from_float(f)\nDecimal('3.166666666666666518636930049979127943515777587890625')\n>>> \n```\n\n比如很明显能看出一个数通过 str 或 float 直接转换都会和真正输入的不一样，这个问题是由于小数以二进制形式在计算机内表达的问题。除此之外，可以很明显看到 float 转换到 str 是经过 round 的，具体可以参考 [converting-a-float-to-a-string-without-rounding-it](https://stackoverflow.com/questions/1317558/converting-a-float-to-a-string-without-rounding-it) ，最终说的都是浮点用二进制表示的问题。\n\n所以在应对精度非常高的浮点的时候，记得一定要**保留指定位的小数**，尤其是在数据库设计时如果需要 Decimal 类型的，记得指定**具体的精度**来使数据在数据库和 Python 中都能保持一致。","src/content/posts/python-float.mdx","aebd8c458fed9c7b","python-float.mdx","python-fasteners",{"id":1145,"data":1147,"body":1152,"filePath":1153,"digest":1154,"legacyId":1155,"deferredRender":22},{"title":1148,"summary":1149,"date":1150,"tags":1151,"group":196,"featured":38},"提供锁机制的 Python fasteners 库","fasteners 是提供多进程或多线程环境之下锁的一个 Python 库，可以快速在在代码中实现文件锁、读写锁，并且其提供了多种方式来获得和使用锁，使用简单。",["Date","2018-04-14T00:00:00.000Z"],[],"[fasteners](http://fasteners.readthedocs.io/en/latest/) 是提供多进程或多线程环境之下锁的一个 Python 库，可以快速在在代码中实现文件锁、读写锁，并且其提供了多种方式来获得和使用锁，使用简单。\n\n```python\nimport time\n\nimport fasteners\n\n@fasteners.interprocess_locked('/tmp/tmp_lock_file')\ndef test():\n    for i in range(10):\n        print('I have the lock')\n        time.sleep(1)\n\nprint('Waiting for the lock')\ntest()\n\n```\n\n文件锁常用来在异步任务中保证只有一个任务在执行，其他任务必须等待文件锁的释放才能执行，利用 fasteners 可以很快实现这一需求，so easy！\n\n更多阅读\n\n[非常有用的 Python 第三方库](/blog/python-lib)","src/content/posts/python-fasteners.mdx","e48c68fc800291be","python-fasteners.mdx","python-getfree-port-number",{"id":1156,"data":1158,"body":1164,"filePath":1165,"digest":1166,"legacyId":1167,"deferredRender":22},{"title":1159,"summary":1160,"date":1161,"tags":1162,"group":196,"featured":38},"在 Python 中获取一个未绑定的端口","> 本文翻译自 Python Getting A Free Port Number : A Multiprocess-safe Recipe",["Date","2018-05-17T00:00:00.000Z"],[1163],"network","> 本文翻译自 [Python Getting A Free Port Number : A Multiprocess-safe Recipe](https://blog.konpat.me/python-getting-a-free-port-number-a-multiprocess-safe-recipe/)\n\n写本文的目的是介绍如何在 Python 中实现一个函数：`get_free_port` 返回一个未使用的端口号，并且这个函数支持在多线程和多进程环境中使用。\n\n这也就意味着 `get_free_port` 可以在任何时候任意地方调用返回的端口号都能被绑定。\n\n事实上，这个目标在逻辑上并不能实现，因为这个函数并不知道它返回的端口号是否已经被使用了，所以最佳的实践方式就是记住所有返回的端口号，每次调用都检查端口号是否已经输出过。\n\n如果我们再增加一个函数用来释放端口就显得更符合逻辑了。\n\n在 Python 中调用 `socket.bind(('', 0))` 会自动绑定一个端口号，所以我们可以借助这一特性来实现：\n\n```python\nimport socket \n\ndef get_free_port():  \n    sock = socket.socket()\n    sock.bind(('', 0))\n    ip, port = sock.getnameinfo()\n    sock.close()\n    return port\n```\n\n 这个函数看上去能工作，但是还远远不够。采用这个方法只能让端口在非常短的时间内不被绑定，难以满足在竞态场景中使用。\n\n由此不难看出，获得一个未被绑定的端口号不难，难的是如何把这个端口号安全正确地返回给调用者。鉴于此，我们需要找到一种机制可以首先保证这个未绑定的端口号不被肆意绑定：\n\n```python\nget a free port -> look at dictionary (and lock file) -> bind a free port -> write a dictionary (and lock file) -> release port -> return the port\n```\n\n使用 `lock file` 能够保证即使端口号未绑定，在未拿到锁之前是不会被其他进程绑定的，在这里使用了。全部代码如下：\n\n```python\n# freeport.py\nimport fasteners\nimport threading\n\nclass BindFreePort(object):\n    def __init__(self, start, stop):\n        self.port = None\n\n        import random, socket\n\n        self.sock = socket.socket()\n\n        while True:\n            port = random.randint(start, stop)\n            try:\n                self.sock.bind(('', port))\n                self.port = port\n                break\n            except Exception:\n                continue\n\n    def release(self):\n        assert self.port is not None\n        self.sock.close()\n\n\nclass FreePort(object):\n    used_ports = set()\n\n    def __init__(self, start=4000, stop=6000):\n        self.lock = None\n        self.bind = None\n        self.port = None\n\n        from fasteners.process_lock import InterProcessLock\n        import time\n        while True:\n            bind = BindFreePort(start, stop)\n\n            if bind.port in self.used_ports:\n                bind.release()\n                continue\n\n            '''\n            Since we cannot be certain the user will bind the port 'immediately' (actually it is not possible using\n            this flow. We must ensure that the port will not be reacquired even it is not bound to anything\n            '''\n            lock = InterProcessLock(path='/tmp/socialdna/port_{}_lock'.format(bind.port))\n            success = lock.acquire(blocking=False)\n\n            if success:\n                self.lock = lock\n                self.port = bind.port\n                self.used_ports.add(bind.port)\n                bind.release()\n                break\n\n            bind.release()\n            time.sleep(0.01)\n\n    def release(self):\n        assert self.lock is not None\n        assert self.port is not None\n        self.used_ports.remove(self.port)\n        self.lock.release()\n```\n\n测试如下：\n\n```python\n#freeport_test.py\nfrom freeport import FreePort\n\ndef get_and_bind_freeport(*args):\n    freeport = FreePort(start=4000, stop=4009)\n    import time\n    time.sleep(1)\n    return freeport.port\n\nclass FreePortClassTest(unittest.TestCase):\n    def test_one_port(self):\n        freeport = FreePort(start=4000, stop=4000)\n        self.assertEqual(freeport.port, 4000)\n        freeport.release()\n\n    def test_many_ports(self):\n        freeport = FreePort(start=4000, stop=4000)\n        self.assertEqual(freeport.port, 4000)\n        freeport.release()\n        freeport = FreePort(start=4000, stop=4000)\n        self.assertEqual(freeport.port, 4000)\n        freeport.release()\n\n    def test_many_ports_conflict(self):\n        def get_port():\n            freeport = FreePort(start=4000, stop=4000)\n            return freeport.port\n\n        def run():\n            self.assertEqual(get_port(), 4000)\n\n        freeport = FreePort(start=4000, stop=4000)\n        self.assertEqual(freeport.port, 4000)\n\n        from multiprocessing import Process\n        p = Process(target=run)\n        p.start()\n        p.join(0.1)\n\n        self.assertTrue(p.is_alive(), 'the process should find it hard to acquire a free port')\n\n        p.terminate()\n        p.join()\n\n        freeport.release()\n\n    def test_multithread_race_condition(self):\n        from multiprocessing.pool import ThreadPool\n        jobs = 100\n        def get_and_bind_freeport(*args):\n            freeport = FreePort(start=4000, stop=4000 + jobs - 1)\n            import time\n            time.sleep(1)\n            freeport.release() # needed because thread will not turn back the file descriptor\n            return freeport.port\n        p = ThreadPool(jobs)\n        ports = p.map(get_and_bind_freeport, range(jobs))\n        self.assertEqual(len(ports), len(set(ports)))\n\n    def test_multiprocess_race_condition(self):\n        from multiprocessing.pool import Pool\n        p = Pool(10)\n        ports = p.map(get_and_bind_freeport, range(10))\n        self.assertEqual(len(ports), len(set(ports)))\n```","src/content/posts/python-getfree-port-number.mdx","26af3a3b924a3e1b","python-getfree-port-number.mdx","python-lib",{"id":1168,"data":1170,"body":1176,"filePath":1177,"digest":1178,"legacyId":1179,"deferredRender":22},{"title":1171,"summary":1172,"date":1173,"tags":1174,"group":196,"featured":38},"非常有用的 Python 第三方库","## http",["Date","2014-12-27T00:00:00.000Z"],[1175],"lib","## http\n\n### requests\n\n易读易懂的 http libary\n\n- [Doc](http://docs.python-requests.org/en/latest/index.html)\n- [PyPi](http://pypi.python.org/pypi/requests)\n- [Github](https://github.com/kennethreitz/requests)\n\n{/* more */}\n\n\n\n### django-rest-framework\n\n基于django 用以构建web api\n\n- [Doc](http://www.django-rest-framework.org/)\n- [Github](https://github.com/tomchristie/django-rest-framework)\n\n### eve\n\n基于Flask, mongodb的 REST API framework\n\n- [Doc](http://python-eve.org/)\n- [Github](https://github.com/nicolaiarocci/eve)\n\n\n\n## 图形图像\n\n### pgmagick\n\npgmagick 是 GraphicsMagick(Magick++) python 绑定 \n\n- [Doc](http://pythonhosted.org/pgmagick/)\n- [PyPi](http://pypi.python.org/pypi/pgmagick/)\n- [Bitbucket](https://bitbucket.org/hhatto/pgmagick)\n\n### Pillow\n\nPIL 一个更友好的实现\n\n- [Doc](http://python-pillow.github.io/)\n- [Github](https://github.com/python-pillow/Pillow)\n\n\n## 分布式&异步队列\n\n### celery\n\ncelery 是基于分布式消息的异步任务队列\n\n- [Doc](http://www.celeryproject.org/)\n- [Github](https://github.com/celery/celery)\n\n### rq\n\n非常简单的基于进程的异步队列\n\n- [Doc](http://python-rq.org/)\n- [Github](https://github.com/nvie/rq)\n\n\n## html&xml 解析\n\n### lxml\n\nlxml 是特性最丰富，最容易使用的xml解析库\n\n- [Doc](http://lxml.de/)\n- [PyPi](http://pypi.python.org/pypi/lxml)\n- [Github](https://github.com/lxml/lxml/)\n\n\n### beautifulsoup4\n\n解析xml和html，用来提取xml和html中的数据\n\n- [Doc](http://www.crummy.com/software/BeautifulSoup/)\n- [PyPi](https://pypi.python.org/pypi/beautifulsoup4)\n- [Code](https://code.launchpad.net/beautifulsoup)\n\n\n### pyquery\n\n类似jquery一样解析xml和html\n\n- [Doc](http://pyquery.readthedocs.org/en/latest/)\n- [Github](https://github.com/gawel/pyquery)\n\n\n## 测试\n\n- nose\n- pytest\n- webtest\n\n## 模板\n\n- jinji2\n\n\n## web framework\n\n- flask\n- tornado\n- pyramid https://trypyramid.com/\n\n## 风格和规范\n\n### autopep8\n\n- [PyPi](https://pypi.python.org/pypi/autopep8/)\n- [Github](https://github.com/hhatto/autopep8)\n\n### pep8\n\n- [Github](https://github.com/jcrocholl/pep8)\n\n\n\n### 文档\n\n### mkdocs\n\npython 项目文档生成工具\n\n- [Doc](http://www.mkdocs.org/)\n- [Github](https://github.com/tomchristie/mkdocs)\n\n\n### Pygments\n\npython 实现的代码高亮库，支持300多种语言\n\n- [Doc](http://pygments.org/)\n- [PyPi](http://pypi.python.org/pypi/Pygments)\n- [Bitbucket](https://bitbucket.org/birkenfeld/pygments-main)\n\n\n## 命令行和linux工具\n\n### psutil\n\n在运行的python进程中获取进程和操作系统信息(CPU, memory, disks, network)，支持多个平台\n\n- [Doc](http://pythonhosted.org/psutil/)\n- [PyPi](https://pypi.python.org/pypi/psutil)\n- [Github](https://github.com/giampaolo/psutil/)\n\n\n### paramiko\n\npython 实现的ssh2 协议库\n\n- [Github](https://github.com/paramiko/paramiko)\n\n### colorama\n\nshell 中输出颜色\n\n- [pip](https://pypi.python.org/pypi/colorama)\n- [Github](https://github.com/tartley/colorama)\n\n\n## 加密和安全\n\n### Passlib\n\n提供各种加密算法，夸平台，支持超过30种常用的加密算法\n\n- [Doc](https://pythonhosted.org/passlib/index.html)\n- [PyPi](http://pypi.python.org/pypi/passlib)\n- [Code](http://code.google.com/p/passlib/source)\n\n## ORM\n\n### sqlacodegen\n\n根据不同的数据库生成 sqlalchemy model\n\nhttps://github.com/agronholm/sqlacodegen\n\n## 并发与并行\n\n### fasteners\n\nlinux 文件锁\n\nhttps://pypi.python.org/pypi/fasteners","src/content/posts/python-lib.mdx","23a4989027cdaa65","python-lib.mdx","python-module-path-find",{"id":1180,"data":1182,"body":1189,"filePath":1190,"digest":1191,"legacyId":1192,"deferredRender":22},{"title":1183,"summary":1184,"date":1185,"tags":1186,"group":196,"featured":38},"如何理解 Python 的模块查找原理与方式","## 基础概念",["Date","2016-05-28T00:00:00.000Z"],[1187,1188],"module","path","## 基础概念\n\n### module\n\n模块， 一个 `py` 文件或以其他文件形式存在的可被导入的就是一个模块\n\n### package\n\n包，包含有 `__init__` 文件的文件夹\n\n### relative path\n  \n相对路径，相对于某个目录的路径\n\n### absolute path\n\n绝对路径，全路径\n\n### 路径查找\n\npython 解释器查找被引入的包或模块\n\n## Python 解释器是如何查找包和模块的\n\n\nPython 执行一个 py 文件，无论执行的方式是用绝对路径还是相对路径，interpreter 都会把文件所在的 directory 加入 sys.path 这个 list 中，Python 就是在 sys.path 中查找包和模块的，sys.path 中的内容本身又是又 Python 的环境变量决定。\n\n{/* more */}\n\n**code-1**\n\n```python\n#test.py\n\nimport os\nimport sys\n\nprint sys.path[0]\n\n# execute\npython test.py\npython /Users/x/workspace/blog-code/p2016_05_28_python_path_find/test.py \n```\n\n执行表明相对路径和绝对路径都输出相同的结果，而且无论哪种执行方式，test.py 所在的文件夹都会被加入 sys.path 的首位，也就是索引为0的位置。\n\n\n## Python 解释器查找包的顺序是什么\n\n\n\n\n解释器查找包，首先搜索 built-in module，其次搜索 sys.path ，**这样的查找顺序将会导致同名包或模块被遮蔽。**\n\n\n**code-2**\n\n```bash\n#ls\n├── os.py\n├── test2.py\n├── redis.py\n\n#test2.py\nimport os\nfrom redis import Redis\n\n#execute test2.py\nTraceback (most recent call last):\n  File \"/Users/x/workspace/blog-code/p2016_05_28_python_path_find/test2.py\", line 1, in \u003Cmodule>\n    from redis import Redis\nImportError: cannot import name Redis\n\n```\n\n由于 `os` 是 built-in module，即使在同目录下有同名模块，解释器依然可以找到正确的 `os` 模块，可以证实 built-in module 不会被遮蔽，而 `redis` 属于第三方模块，默认安装位置是 Python 环境变量中的 site-packages，解释器启动之后会将此目录中的内容加入 sys.path，由于当前目录会在 sys.path 的首位，当前目录的 `redis` 优先被找到，site-packages 中的 `redis` 模块被遮蔽了。\n\n\n## 交互式执行环境的查找顺序\n\n进入交互式执行环境，解释器会自动把当前目录加入 sys.path, 这时当前目录是以相对路径的形式出现在 sys.path 中:\n\n```bash\n>>> import os.path\n>>> import sys\n>>> os.path.abspath(sys.path[0])\n'/Users/x/workspace/blog-code'\n>>> \n```\n\n除此之外，其他与执行一个文件是相同的。\n\n\n## 模块中的 `__file__` 变量\n\n>`__file__` is the pathname of the file from which the module was loaded, if it was loaded from a file. 如果一个模块是从文件加载的，`__file__` 就是该模块的路径名--[Python Doc](https://docs.python.org/2/reference/datamodel.html): \n\n顾名思义，当模块以文件的形式出现 `__file__` 指的是模块文件的路径名，以相对路径执行 `__file__` 是相对路径，以绝对路径执行 `__file__` 是绝对路径。\n\n\n```python\n#test3.py\nprint __file__\n\n#相对路径执行\n\npython test3.py\ntest3.py\n\n#绝对路径执行\npython /Users/x/workspace/blog-code/p2016_05_28_python_path_find/test3.py\n/Users/x/workspace/blog-code/p2016_05_28_python_path_find/test3.py\n```\n\n为了保证`__file__` 每次都能准确得到模块的正确位置，最好对其再取一次绝对路径 `os.path.abspath(__file__)`。\n\n\n**交互式 shell 中的 `__file__`**\n\n\n```bash\n>>> __file__\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nNameError: name '__file__' is not defined\n```\n\n这是因为当前交互式shell的执行并不是以文件的形式加载，所以不存在`__file__` 这样的属性。\n\n\n## sys.argv[0] 变量\n\nsys.argv[0] 是它用来获取主入口执行文件。\n\n\n```\n#test.py\nimport sys\nprint __file__\nprint sys.argv[0]\n```\n\n以上 print 输出相同的结果，因为主执行文件和`__file__`所属的模块是同一个，当我们改变入口文件，区别就出现了。\n\n\n```\n#test.py\nimport sys\nprint __file__\nprint sys.argv[0]\n\n#test2.py\nimport test\n\n#execute test2.py\n/Users/x/workspace/blog-code/p2016_05_28_python_path_find/child/test.py #__file__\ntest2.py #sys.argv[0]\n```\n\n总的来说，sys.argv[0] 是获得入口执行文件路径，`__file__` 是获得任意模块文件的路径。\n\n\n## sys.modules 的作用\n\n既然 Python 是在 sys.path 中搜索模块的，那载入的模块存放在何处？答案就是 sys.modules。模块一经载入，Python 会把这个模块加入 sys.modules 中供下次载入使用，这样可以加速模块的引入，起到缓存的作用。\n\n```bash\n>>> import sys\n>>> sys.modules['tornado']\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nKeyError: 'tornado'\n>>> import tornado\n>>> sys.modules['tornado']\n\u003Cmodule 'tornado' from '/Users/x/python_dev/lib/python2.7/site-packages/tornado/__init__.pyc'>\n```\n\n前面说过 Python 解释器启动之后，会把预先载入 built-in module，可以通过 sys.modules 验证。\n\n```\n>>> sys.modules['os']\n\u003Cmodule 'os' from '/Users/x/python_dev/lib/python2.7/os.pyc'>\n>>> \n```\n\n借助 sys.modules 和 `__file__`，可以动态获取所有已加载模块目录和路径。\n\n```python\n>>> import os\n>>> os.path.realpath(sys.modules['os'].__file__)\n'/Users/x/python_dev/lib/python2.7/os.pyc'\n>>> import tornado\n>>> os.path.realpath(sys.modules['tornado'].__file__)\n'/Users/x/python_dev/lib/python2.7/site-packages/tornado/__init__.pyc'\n```\n\n```python\ndef get_module_dir(name):\n    path = getattr(sys.modules[name], '__file__', None)\n    if not path\n        raise AttributeError('module %s has not attribute __file__'%name)\n    return os.path.dirname(os.path.abspath(path))\n```\n\n\n## summary\n\n总的来说，Python 是通过查找 sys.path 来决定包的导入，并且系统包优先级>同目录>sys.path，Python 中的特有属性 `__file__` 以及 sys.argv[0]，sys.modules 都能帮助我们理解包的查找和导入概念，只要能正确理解 sys.path 的作用和行为，理解包的查找就不是难题了。\n\n文中所有代码见：[github](https://github.com/zhyq0826/blog-code/tree/master/p2016_05_28_python_path_find)\n\n>转载请注明出处","src/content/posts/python-module-path-find.mdx","d6ce535351fd991d","python-module-path-find.mdx","python-multi-threading",{"id":1193,"data":1195,"body":1200,"filePath":1201,"digest":1202,"legacyId":1203,"deferredRender":22},{"title":1196,"summary":1197,"date":1198,"tags":1199,"group":196,"featured":38},"Python 的多线程编程：基础","> 说说 Python 的多线程",["Date","2018-05-23T00:00:00.000Z"],[],"> 说说 Python 的多线程\n\n## 为什么需要线程\n\nPython 是提供多线程支持的，但是使用多线程的场景在哪里？比如说你的程序中有一项任务需要在执行时不影响当前代码的执行，此时多线程就能用得上，也就是借助线程你可以**同时并发的执行多个任务**，这就是线程的在编程中提供的最重要的功能：**并发**。\n\n## 执行一个简单的线程\n\nPython 2 中对线程的支持分别来自 [thread](https://docs.python.org/2/library/thread.htm) 和 [threading](https://docs.python.org/2/library/threading.html) 模块，由于 thread 在 Python 3 中已经重命名了，所以这里我们始终使用 threading:\n\n```python\nimport threading\nimport time\n\n\ndef myfunc(name, sleep):\n    while 1:\n        print(name)\n        time.sleep(sleep)\n\n\nif __name__ == '__main__':\n    threading.Thread(target=myfunc, args=(\"Thread No 2\", 2)).start()\n    while 1:\n        pass\n\n```\n\n在上面的代码中，我们使用 Thread object 开启了一个新的线程并执行，执行代码之后可以看到 \"Thread No 2\" 每隔 2 秒显示一次，开启线程之后的 `while 1` 是必须的，因为主线程必须一直存在才能让子线程得以执行。\n\n## 多线程共享资源保护\n\n多线程执行环境下我们常常需要对共享的资源进行保护以防止多个线程操作同一内存区域而导致的数据错误，因为线程之间是**共享内存的**，一般通过 lock 实现。\n\n```python\nimport threading\nimport time\n\nvalue = 1\n\ndef myfunc(name, sleep):\n    while 1:\n        # entering critical section\n        global value\n        lock.acquire()\n        print (name, \" Now Sleeping after Lock acquired for \", sleep)\n        time.sleep(sleep)\n        value += 1\n        print(name, \"Now releasing lock and then sleeping again\")\n        lock.release()\n        # exiting critical section\n        time.sleep(sleep)   # yield current thread cpu\n\n\nif __name__ == '__main__':\n    lock = threading.Lock()\n    # why run can't start thread many\n    # threading.Thread(target=myfunc, args=(\"Thread No 2\", 2)).run()\n    threading.Thread(target=myfunc, args=(\"Thread No 2\", 2)).start()\n    threading.Thread(target=myfunc, args=(\"Thread No 3\", 2)).start()\n    threading.Thread(target=myfunc, args=(\"Thread No 4\", 2)).start()\n    while 1:\n        pass\n\n```\n\nPython 的 lock 通过 threading 模块的 [Lock](https://docs.python.org/2/library/threading.html#lock-objects) 来实现，对需要共同操作的共享内存区域进行加锁保护，除了 Lock，threading 模块还提供了 Queue、Event、Condition 等机制来保证多线程条件下的同步问题，我会在后续的文章中进行详细阐述。\n\n## GIL\n\nPython 解释器不是线程安全的，而 Python 线程没有优先级，没有线程组，线程不能被停止、挂起、恢复、中断，也就是 Python 提供的线程非常基础简单。实际上每次只有一个线程在执行，这是由于 GIL 的存在导致的，为了支持多线程编程，当前执行线程必须获得 global lock 用来保证共享 Python object 的数据安全，如果没有这个锁，两个线程同时增加一个对象的引用计数时，最终这个计数器可能只加了一次，因而只有获得了 GIL 的线程才能执行对 Python Object 进行操作或者调用 Python C API 函数。\n\n为了支持多线程的程序，Python 解释器必须定期释放和重新获取 GIL 锁，默认是每执行 10 bytecode 的指令之后，可以使用 sys.setcheckinterval 来改变这一行为。GIL 锁也可以在程序遇到 IO 阻塞时释放，比如读取和写入文件，这样其他线程在当前线程等待 IO 完成时执行，一般来说有以下几种情形能够释放 GIL 锁：\n\n-  C  扩展\n- 阻塞 IO\n\n这也是为什么使用 C 来完成 Python 程序更高效的原因所在。\n\n## 方法 join 的作用\n\n上面的例子中我们在主线程中使用了一个 `while 1:pass` 语句来保证多线程可以顺利执行，除此之外线程本身提供了 `join` 方法来告诉主线程等待子线程执行结束：\n\n```python\nimport threading\nimport time\n\nvalue = 1\n\n\ndef myfunc(name, sleep):\n    while 1:\n        # entering critical section\n        global value\n        if value > 6:\n            raise Exception(\"Stop \", name)\n        lock.acquire()\n        print (name, \" Now Sleeping after Lock acquired for \", sleep)\n        time.sleep(sleep)\n        value += 1\n        print(name, \"Now releasing lock and then sleeping again\")\n        lock.release()  # release must be called after acquire lock\n        # exiting critical section\n        time.sleep(sleep)   # yield current thread cpu\n\n\nif __name__ == '__main__':\n    lock = threading.Lock()\n    t1 = threading.Thread(target=myfunc, args=(\"Thread No 2\", 2))\n    t2 = threading.Thread(target=myfunc, args=(\"Thread No 3\", 2))\n    t3 = threading.Thread(target=myfunc, args=(\"Thread No 4\", 2))\n    t1.start()\n    t2.start()\n    t3.start()\n    t1.join()\n    t2.join()\n    t3.join()\n    print(\"main Thread echo done!\")\n\n```\n\njoin 的作用和 `while 1` 类似，都是**告知调用线程要等待直到线程执行结束或者异常退出**，join 还可以接受参数，表示等待多久之后。\n\n## 多线程执行你需要了解和知道的\n\n1.处理器并不保证在 start 开始之后立即运行 run\n2.无法保证线程运行的顺序\n3.对于任意线程来说，它保证 run 中的语句是顺序执行的\n4.等待 io 阻塞时可以让出 CPU 以让其它线程得到执行","src/content/posts/python-multi-threading.mdx","1af5f92dfa4d55b2","python-multi-threading.mdx","python-multi-version-the-same-ubuntu",{"id":1204,"data":1206,"body":1212,"filePath":1213,"digest":1214,"legacyId":1215,"deferredRender":22},{"title":1207,"summary":1208,"date":1209,"tags":1210,"group":196,"featured":38},"同一主机安装多个 Python 版本","app-turbo 为了支持多个 Python 版本必须要在多个版本下进行测试，以 Ubuntu 为例，默认发行版都会有一个Python 2.7 和 一个 Python 3.x 的版本，但是这远不能够满足开发和测试需要。我本人在折腾环境方面是比较懒，很想找一个工具能够自动把所有事...",["Date","2018-05-18T00:00:00.000Z"],[1211],"多版本安装","[app-turbo](https://github.com/wecatch/app-turbo) 为了支持多个 Python 版本必须要在多个版本下进行测试，以 Ubuntu 为例，默认发行版都会有一个Python 2.7 和 一个 Python 3.x 的版本，但是这远不能够满足开发和测试需要。我本人在折腾环境方面是比较懒，很想找一个工具能够自动把所有事情都考虑好，一个命令就搞定，可惜搜罗了几分钟之后，没有找到方案。\n\n>  世间一切的问题，都应该从它开始的地方寻找答案。\n\n进 Python 官方网站，找到 Python 包下载源：https://www.python.org/downloads/， 选择一个我们需要的版本和对应平台的 package 下载。\n\n```shell\nwget https://www.python.org/ftp/python/3.5.5/Python-3.5.5.tgz\n```\n\n解压包：\n\n```shell\ntar xvfz Python-3.5.5.tgz\n```\n\n进入源码目录，查看 README 文件，仔细阅读发现 Python 官方已经提供了多版本安装的方案：\n\n```shell\nOn Unix and Mac systems if you intend to install multiple versions of Python using the same installation prefix (--prefix argument to the configure script) you must take care that your primary python executable is not overwritten by the installation of a different version. \n\nAll files and directories installed  using \"make altinstall\" contain the major and minor version and can thus live side-by-side. \"make install\" also creates ${prefix}/bin/python3 which refers to ${prefix}/bin/pythonX.Y.  \n\nIf you intend to install multiple versions using the same prefix you must decide which version (if any) is your \"primary\" version.  Install that version using \"make install\".  Install all other versions using \"make altinstall\".\n\nFor example, if you want to install Python 2.6, 2.7 and 3.5 with 2.7 being the primary version, you would execute \"make install\" in your 2.7 build directory and \"make altinstall\" in the others.\n```\n\n不难理解，Python 在 configure 阶段已经提供了 `—prefix` 来选择安装的目录。\n\n如果你使用的相同的 prefix 目录，**在安装阶段使用 `make altinstall` 的方式安装会自动带上主版本号的信息**，并且不会覆盖当前环境中默认的 primary Python，如果你想覆盖 primary Python，则使用 `make install` 即可。\n\n有时间了我可能会写个工具一键安装多个 Python 版本，嗯，等有时间了😑。","src/content/posts/python-multi-version-the-same-ubuntu.mdx","c118801aeab7231f","python-multi-version-the-same-ubuntu.mdx","python-string-unicode",{"id":1216,"data":1218,"body":1224,"filePath":1225,"digest":1226,"legacyId":1227,"deferredRender":22},{"title":1219,"summary":1220,"date":1221,"tags":1222,"group":196,"featured":38},"Python 编码错误的本质和解决方案","> Python 常见编码错误 UnicodeDecodeError 和 UnicodeEncodeError 的原理和解决方案",["Date","2016-11-06T00:00:00.000Z"],[1223],"编码","> Python 常见编码错误 UnicodeDecodeError 和 UnicodeEncodeError 的原理和解决方案\n\n## 基础概念\n\n### 字符\ncharacter 构成文本的最小组成单元\n\n### 字节\nbyte 数据在计算机内部的存储单元，一个字节等于一个8位的比特，计算机中的所有数据都是由字节组成\n\n### 字符集\nCharacter set 由多个字符的组成的集合，常见的字符集有ASCII、Unicode、GB2312等\n\n### 字符编码值\n不同的字符集规定了不同的编码规则，编码规则中规定了字符对应的编码值 code point，一个整数值\n\n### 编码\n将字符集中的字符码根据 code point 映射为字节流(byte sequence)的一种具体实现\n\n### 解码\n将字节流解析为字符集中的字符\n\n{/* more */}\n\n---\n\n> 文中 python 皆为 2.x 版本code\n\n初学 python 的人基本上都有过如下类似经历:\n\n**UnicodeDecodeError**\n```python\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n```\n**UnicodeEncodeError**\n```python\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\n```\n这两个错误在 python 中十分常见，一不留神就碰上了。如果你写过c、c++ 或者 java，对比之下一定会觉得 python 这个错误真让人火大。事实也确实如此，我也曾经很火大🔥。\n\n这两个错误究竟意味着什么？可以先从 python 的基本数据类型 string 和 unicode 开始。\n\n\n## string \n字符串(string)其实就是一段**文本序列**，是由一个或多个字符组成(character)，**字符是文本的最小构成单元**，在 python 中可以用以下方式表示字符串:\n\n```bash\n>>> s1 = 'abc'\n>>> s2 = \"abc\"\n>>> s3 = \"\"\"\n  abc\n  \"\"\"\n>>> s4 = '中文'\n>>> for i in [s1, s2, s3, s4]:\n        print type(i)\n\u003Ctype 'str'>\n\u003Ctype 'str'>\n\u003Ctype 'str'>\n\u003Ctype 'str'>\n```\n\n这些变量在 python shell 中对应输出是:\n\n```bash\ns1 --> 'abc'\ns2 --> 'abc'\ns3 --> '\\nabc\\n'\ns4 --> '\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n```\n\ns4 的输出和其它变量明显不同，字面上是一个 16 进制序列，但是 s4 和其它字符串一样，在 python 内部都是用同样方式进行存储的: **字节流(byte stream)，即字节序列**。\n\n**字节是计算机内部最小的可寻址的存储单位**(对大部分计算机而言)，一个字节是由 8 bit 组成，也就是对应 8 个二进制位。其实可以更进一步解释说，python 不仅用字节的方式存储着变量中的字符串文本，python 文件中的所有信息在计算机内部都是用一个个字节表示的，**计算机是用这样的方式存储文本数据的**。\n\n## 字符串用字节如何表示？\n\n答案就是**编码**。计算机是只能识别 0 或 1 这样的二进制信息，而不是 a 或 b 这样对人类有意义的字符，为了让机器能读懂这些字符，人类就发明字符到二进制的映射关系，然后按照这个映射规则进行相应地编码。[ascii](https://en.wikipedia.org/wiki/ascii) 就是这样背景下诞生的一种编码规则。**ascii 也是 python 2.x 默认使用的编码规则。**\n\nascii 规定了常用的字符到计算机是如何映射的，编码范围是 0~127 共 128 个字符。**简单来说它就是一本字典，规定了不同字符的对应的编码值(code point，一个整数值)，这样一来计算机就能用二进制表示了**。比如字符 a 的编码是 97，对应的二进制是 1100001，**一个字节**就足够存储这些信息。字符串 \"abc\" 最终存储就是 `[97] [98] [99]` 三个字节。python 默认情况下就是使用这个规则对字符进行编码，对字节进行解码(反编码)。\n\n```python\n>>> ord('a')\n97\n>>> chr(97)\n'a'\n>>> \n```\n\n由于 ascii 的编码范围非常有限，对超过 ascii 范围之外的字符，python 是如何处理的？很简单，抛错误出来，这就是 `UnicodeEncodeError` 和 `UnicodeDecodeError` 的来源。那 python 会在什么时候抛出这样的错误，也就是说 python 进行编码和解码的操作发生在何时？\n\n## unicode 对象\nunicode 对象和 string 一样，是 python 中的一种**字符对象**(python 中一切皆对象，string 也是)。先不要去想 unicode 字符集、unicode 编码或者 utf-8 这些概念，在此特意加了`对象` 就是为了和后面提到的 unicode 字符集进行区分。这里说的 unicode 就是 python 中的 unicode 对象，构造函数是 `unicode()`。\n\n在 python 中创造 unicode 对象也很简单:\n\n```python\n>>> s1 = unicode('abc')\n>>> s2 = u'abc'\n>>> s3 = U'abc'\n>>> s4 = u'中文'\n```\n\n这些变量在 python shell 中对应输出是:\n```bash\ns1 --> u'abc'\ns2 --> u'abc'\ns3 --> u'abc'\ns4 --> u'\\u4e2d\\u6587'\n```\n同样的，s4 的输出和其它变量不同，这些就是unicode 字符。由于 ascii 能够表示的字符太少，而且不够通用(扩展 ascii 的话题，就是把 ascii 没有利用的剩下大于 127 的位置利用了，在不同的字符集里代表不同的意思)，[unicode 字符集](https://zh.wikibooks.org/wiki/Unicode) 就被造出来了，一本更大的字典，里面有更多的编码值。\n\n## unicode 字符集\n\nunicode 字符集解决了：\n\n- ascii 表达能力不够的问题\n- 扩展 ascii 不够通用的问题\n\n虽然 unicode 字符集表达能力强，又能够统一字符编码规则，但是它并没有规定这些字符在计算机中是如何表示的。它和 ascii 不同，很多字符(编码值大于 255 )没有办法用一个字节就搞定。怎样做到高效快捷地存储这些编码值？于是就有了 unicode 字符集的编码规则的实现：utf-8、utf-16等。\n\n到这里可以简单理清 ascii、unicode 字符集、utf-8等的关系了：ascii 和 unicode 字符集都是一种编码集，由字符和字符对应的整数值(code point)组成，ascii 在计算机内部用一个字节存储，utf-8 是 unicode 字符集存储的具体实现，因为 unicode 字符集没有办法简简单单用一个字节搞定。\n\n回到 s4 对应的输出，这个输出就是 **unicode 字符集对应的编码值(code point)的 16 进制表示**。\n\nunicode 对象是用来表示 unicode 字符集中的字符，这些字符(实际是那个编码值，一个整数) 在 python 中又是如何存储的？有了前文的分析，也许可以猜到，python 依然是通过**编码然后用字节的方式**存储，但是这里的编码就不能是 ascii 了，而是对应 unicode 字符集的编码规则: utf-8、utf-16等。\n\n## unicode 对象的编码\n\nunicode 对象想要正确的存储就必须指定相应的编码规则，这里我们只讨论使用最广泛的 utf-8 实现。\n\n在 python 中对 unicode 对象编码如下：\n\n```python\n>>> s=u'中文'\n>>> s.encode('utf-8')\n'\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n>>> type(s.encode('utf-8'))\n\u003Ctype 'str'>\n```\n\n编码之后输出的是个 string 并以字节序列的方式进行存储。有了编码就会有解码，python 正是在这种编码、解码的过程使用了错误的编码规则而发生了 `UnicodeEncodeError` 和 `UnicodeDecodeError` 错误，因为**它默认使用 ascii 来完成转换**。\n\n## string 和 unicode 对象的转换\n\nunicode 对象可以用 utf-8 编码为 string，同理，string 也可以用 utf-8 解码为 unicode 对象\n\n```python\n>>> u=u'中文'\n>>> s = u.encode('utf-8')\n>>> s\n'\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n>>> type(s)\n\u003Ctype 'str'>\n>>> s.decode('utf-8')\nu'\\u4e2d\\u6587'\n>>> type(s.decode('utf-8'))\n\u003Ctype 'unicode'>\n```\n\n错误的编码规则就会导致那两个常见的异常\n\n```python\n>>> u.encode('ascii')\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\n>>>\n>>> s.decode('ascii')\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n```\n\n这两个错误在某些时候会突然莫名其妙地出现就是因为 python 自动地使用了 ascii 编码。\n\n## python 自动解编码\n\n1.stirng 和 unicode 对象合并\n\n```python\n>>> s + u''\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n>>> \n```\n\n2.列表合并\n\n```python\n>>> as_list = [u, s]\n>>> ''.join(as_list)\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n```\n\n3.格式化字符串\n\n```bash\n>>> '%s-%s'%(s,u)\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n>>> \n```\n\n4.打印 unicode 对象\n\n```python\n#test.py\n# -*- coding: utf-8 -*-\nu = u'中文'\nprint u\n\n#outpt\nTraceback (most recent call last):\n  File \"/Users/zhyq0826/workspace/zhyq0826/blog-code/p20161030_python_encoding/uni.py\", line 3, in \u003Cmodule>\n    print u\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\n```\n\n5.输出到文件\n\n```python\n>>> f = open('text.txt','w')\n>>> f.write(u)\nTraceback (most recent call last):\n  File \"\u003Cinput>\", line 1, in \u003Cmodule>\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\n>>>\n```\n\n---\n\n1，2，3 的例子中，python 自动用 **ascii 把 string 解码为 unicode** 对象然后再进行相应操作，所以都是 `decode` 错误， 4 和 5 python 自动用 ascii 把 unicode 对象编码为字符串然后输出，所以都是 `encode` 错误。\n\n只要涉及到 unicode 对象和 string 的转换以及 unicode 对象输出、输入的地方可能都会触发 python 自动进行解码/编码，比如写入数据库、写入到文件、读取 socket 等等。\n\n到此，这两个异常产生的真正原因了基本已经清楚了: unicode 对象需要**编码**为相应的 string(字符串)才可以存储、传输、打印，字符串需要**解码**为对应的 unicode 对象才能完成 unicode 对象的各种操作，`len`、`find` 等。\n\n```python\nstring.decode('utf-8') --> unicode\nunicode.encode('utf-8') --> string\n```\n\n## 如何避免这些的错误\n\n1.理解编码或解码的转换方向\n\n无论何时发生编码错误，首先要理解编码方向，然后再针对性解决。\n\n2.设置默认编码为 utf-8\n\n在文件头写入 \n\n```python\n# -*- coding: utf-8 -*-\n```\n\npython 会查找: coding: name or coding=name，并设置文件编码格式为 `name`，此方式是告诉 python 默认编码不再是 ascii ，而是要使用声明的编码格式。\n\n3.输入对象尽早解码为 unicode，输出对象尽早编码为字节流\n\n无论何时有字节流输入，都需要尽早解码为 unicode 对象。任何时候想要把 unicode 对象写入到文件、数据库、socket 等外界程序，都需要进行编码。\n\n4.使用 codecs 模块来处理输入输出 unicode 对象\n\n[codecs](https://docs.python.org/2/library/codecs.html) 模块可以自动的完成解编码的工作。\n\n```python\n>>> import codecs\n>>> f = codecs.open('text.txt', 'w', 'utf-8')\n>>> f.write(u)\n>>> f.close()\n```\n\n> 参考文献\n- https://zh.wikibooks.org/wiki/Unicode\n- https://zh.wikibooks.org/wiki/ascii\n- http://www.unicode.org/\n- https://docs.python.org/2/howto/unicode.html\n- http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html\n\n> 注意：转载请注明出处和文章链接","src/content/posts/python-string-unicode.mdx","cb69c9c1c37b3a6c","python-string-unicode.mdx","raft",{"id":1228,"data":1230,"body":1235,"filePath":1236,"digest":1237,"legacyId":1238,"deferredRender":22},{"title":1231,"summary":1232,"date":1233,"tags":1234,"group":78,"featured":38},"理解 raft 算法","> raft 算法是一种共识算法，其解决的分布式环境中的数据一致性的问题",["Date","2019-04-18T00:00:00.000Z"],[1228],"> raft 算法是一种共识算法，其解决的分布式环境中的数据一致性的问题\n\n## leader election\n\n在 raft 算法中，每个节点有三种状态：\n- Follower\n- Candidate\n- Leader\n\n所有的节点初始都是 follower ，如果 follower 节点没有收到任何 leader 节点的消息，这些节点将变成 candidate ，candidate 节点开始向其他节点请求投票，节点会返回投票信息，如果一个 candidate 获得所有节点中的多数投票，则他会变成 leader 状态，这个过程称之为 **leader election**。\n\n![](https://static.git-star.com/raft-election.gif)\n\n在 raft 中有两个 timeout 设置控制着 election 的进行。\n\n第一个是 **election timeout**，意思是 follower 要等待成为 candidate 的时间，这个时间是一个介于 150ms 到 300ms 的值，这个时间结束之后 follower 变成 candidate 开始选举，首先是自己对自己投票，然后向其他节点**请求投票**，如果接收节点在收到投票请求时还没有参与过投票，那么他会把票投给这个请求投票的 candidate，然后重置自身的 election timeout，一旦一个 candidate 拥有所有节点中的大多数投票，他变成一个 leader。\n\n第二个是 **heartbeat timeout**，一旦一个 candidate 成为 leader，他开始向其他 follower 发送 append entries，这些消息发送的频率是通过 heartbeat timeout 指定，follower 会响应每条的 append entry，整个 election 会一直进行直到 follower 停止接受 heartbeat 并且变成 candidate 开始下一轮 election。\n\n假设 leader 故障了，follower 不再收到 heartbeats，新一轮 election 开始，整个过程重复上述步骤。\n\n需要节点中的多数节点的投票才能成为 leader 保证了在每轮选举中只有一个 leader 可以胜出，如果一轮选举中有两个节点同时成为 candidate 将会导致 split vote 发生，如果此时两个 candidate 都收到了相同的票数，他们重置 election timeout 重新开启新一轮选举。\n\n![](https://static.git-star.com/raft-election3.gif)\n\n## log replication\n\nleader 成功选举之后，之后 client 的请求都先经过 leader，每个请求的更改以日志的形势保存在 leader 节点，但这些更改是 uncommitted 状态，为了对这些更改进行提交，leader 首先 replicate 这些更改到 follower，等到 follower 中的大部分提交之后才会 commit 这些更改，commit 之后通知 follower 更改已经 commited，这个系统现在达到了一致的状态，这个过程称之为 **log replication**。\n\n![](https://static.git-star.com/raft-log-replication.gif)\n\n\n## network partitions\n\nraft 算法可以应对 network partitions。\n\n![](https://static.git-star.com/raft-network-partions3-2.gif)\n\n比如由于网络分区导致了 C、D、E 和 A、B 隔离，各自分区中会重新开始选举形各自形成新的 leader\n\n![](https://static.git-star.com/raft-network-partions4.gif)\n\n在各自分区之内，各自 leader 会收到不同的 client 发送的请求，由于在 B 分区内，leader 无法获得多数节点的投票，因而 leader B 上发生的更改不会被提交，等网络分区修复之后，A 和 B 的 term 比较小，他们会自动下线，回滚之前的提交，等待新的 leader 发送 hearbeat\n\n## 参考\n- https://raft.github.io/\n- http://thesecretlivesofdata.com/raft/","src/content/posts/raft.mdx","61f876a78ae7001d","raft.mdx","sql-where-parse",{"id":1239,"data":1241,"body":1247,"filePath":1248,"digest":1249,"legacyId":1250,"deferredRender":22},{"title":1242,"summary":1243,"date":1244,"tags":1245,"group":906,"featured":38},"SQL中的where条件，在数据库中提取与应用浅析","> 此文是阿里数据库内核研发专家何登成的文章 http://hedengcheng.com/?p=577 比较详细的记录了 SQL 语句解析 where 的过程，对于理解 where 中的条件命中 index 有帮助，可以直接去原文，评论区有一些有价值的讨论",["Date","2018-05-18T00:00:00.000Z"],[1246],"sql",">  此文是阿里数据库内核研发专家何登成的文章 http://hedengcheng.com/?p=577 比较详细的记录了 SQL 语句解析 where 的过程，对于理解 where 中的条件命中 index 有帮助，可以直接去原文，评论区有一些有价值的讨论\n\n## 问题描述\n\n一条SQL，在数据库中是如何执行的呢？相信很多人都会对这个问题比较感兴趣。当然，要完整描述一条SQL在数据库中的生命周期，这是一个非常巨大的问题，涵盖了SQL的词法解析、语法解析、权限检查、查询优化、SQL执行等一系列的步骤，简短的篇幅是绝对无能为力的。因此，本文挑选了其中的部分内容，也是我一直都想写的一个内容，做重点介绍：\n\n**给定一条SQL，如何提取其中的where条件？where条件中的每个子条件，在SQL执行的过程中有分别起着什么样的作用？**\n\n通过本文的介绍，希望读者能够更好地理解查询条件对于SQL语句的影响；撰写出更为优质的SQL语句；更好地理解一些术语，例如：MySQL 5.6中一个重要的优化——Index Condition Pushdown，究竟push down了什么？\n\n本文接下来的内容，安排如下：\n\n1. 简单介绍关系型数据库中数据的组织形式；\n2. 给定一条SQL，如何提取其中的where条件；\n3. 最后做一个小的总结； \n\n## 关系型数据库中的数据组织 \n\n关系型数据库中，数据组织涉及到两个最基本的结构：表与索引。表中存储的是完整记录，一般有两种组织形式：堆表(所有的记录无序存储)，或者是聚簇索引表(所有的记录，按照记录主键进行排序存储)。索引中存储的是完整记录的一个子集，用于加速记录的查询速度，索引的组织形式，一般均为B+树结构。 \n\n有了这些基本知识之后，接下来让我们创建一张测试表，为表新增几个索引，然后插入几条记录，最后看看表的完整数据组织、存储结构式怎么样的。(注意：下面的实例，使用的表的结构为堆表形式，这也是Oracle/DB2/PostgreSQL等数据库采用的表组织形式，而不是InnoDB引擎所采用的聚簇索引表。其实，表结构采用何种形式并不重要，最重要的是理解下面章节的核心，在任何表结构中均适用) \n\n```mysql\ncreate table t1 (a int primary key, b int, c int, d int, e varchar(20));\n\ncreate index idx_t1_bcd on t1(b, c, d); \n\ninsert into t1 values (4,3,1,1,’d’);\n\ninsert into t1 values (1,1,1,1,’a’);\n\ninsert into t1 values (8,8,8,8,’h’):\n\ninsert into t1 values (2,2,2,2,’b’);\n\ninsert into t1 values (5,2,3,5,’e’);\n\ninsert into t1 values (3,3,2,2,’c’);\n\ninsert into t1 values (7,4,5,5,’g’);\n\ninsert into t1 values (6,6,4,4,’f’);\n```\n\nt1表的存储结构如下图所示(只画出了idx_t1_bcd索引与t1表结构，没有包括t1表的主键索引)：\n\n\n\n[![t1表的组织结构图](http://pic.yupoo.com/hedengcheng/CGqS51ES/medish.jpg)](http://www.yupoo.com/photos/hedengcheng/87929304/)\n\n \n\n简单分析一下上图，idx_t1_bcd索引上有[b,c,d]三个字段(注意：若是InnoDB类的聚簇索引表，idx_t1_bcd上还会包括主键a字段)，不包括[a,e]字段。idx_t1_bcd索引，首先按照b字段排序，b字段相同，则按照c字段排序，以此类推。记录在索引中按照[b,c,d]排序，但是在堆表上是乱序的，不按照任何字段排序。\n\n## SQL的where条件提取\n\n在有了以上的t1表之后，接下来就可以在此表上进行SQL查询了，获取自己想要的数据。例如，考虑以下的一条SQL：\n\n```mysql\nselect * from t1 where b >= 2 and b \u003C 8 and c > 1 and d != 4 and e != ‘a’; \n```\n\n一条比较简单的SQL，一目了然就可以发现where条件使用到了[b,c,d,e]四个字段，而t1表的idx_t1_bcd索引，恰好使用了[b,c,d]这三个字段，那么走idx_t1_bcd索引进行条件过滤，应该是一个不错的选择。接下来，让我们抛弃数据库的思想，直接思考这条SQL的几个关键性问题： \n\n## 此SQL，覆盖索引idx_t1_bcd上的哪个范围？ \n\n起始范围：记录[2,2,2]是第一个需要检查的索引项。索引起始查找范围由b >= 2，c > 1决定。\n\n终止范围：记录[8,8,8]是第一个不需要检查的记录，而之前的记录均需要判断。索引的终止查找范围由b \u003C 8决定；\n\n## 在确定了查询的起始、终止范围之后，SQL中还有哪些条件可以使用索引idx_t1_bcd过滤？ \n\n根据SQL，固定了索引的查询范围[(2,2,2),(8,8,8))之后，此索引范围中并不是每条记录都是满足where查询条件的。例如：(3,1,1)不满足c > 1的约束；(6,4,4)不满足d != 4的约束。而c，d列，均可在索引idx_t1_bcd中过滤掉不满足条件的索引记录的。\n\n因此，SQL中还可以使用c > 1 and d != 4条件进行索引记录的过滤。\n\n## 在确定了索引中最终能够过滤掉的条件之后，还有哪些条件是索引无法过滤的？\n\n此问题的答案显而易见，e != ‘a’这个查询条件，无法在索引idx_t1_bcd上进行过滤，因为索引并未包含e列。e列只在堆表上存在，为了过滤此查询条件，必须将已经满足索引查询条件的记录回表，取出表中的e列，然后使用e列的查询条件e != ‘a’进行最终的过滤。 \n\n在理解以上的问题解答的基础上，做一个抽象，可总结出一套放置于所有SQL语句而皆准的where查询条件的提取规则：\n\n**所有SQL的where条件，均可归纳为3大类：Index Key (First Key & Last Key)，Index Filter，Table Filter**。\n\n接下来，让我们来详细分析者3大类分别是如何定义，以及如何提取的。\n\n## 大类分别是如何定义\n\n### Index Key\n\n用于确定SQL查询在索引中的连续范围(起始范围+结束范围)的查询条件，被称之为Index Key。由于一个范围，至少包含一个起始与一个终止，因此Index Key也被拆分为Index First Key和Index Last Key，分别用于定位索引查找的起始，以及索引查询的终止条件。 \n\n### Index First Key \n\n用于确定索引查询的起始范围。提取规则：从索引的第一个键值开始，检查其在where条件中是否存在，若存在并且条件是=、>=，则将对应的条件加入Index First Key之中，继续读取索引的下一个键值，使用同样的提取规则；若存在并且条件是>，则将对应的条件加入Index First Key中，同时终止Index First Key的提取；若不存在，同样终止Index First Key的提取。\n\n针对上面的SQL，应用这个提取规则，提取出来的Index First Key为(b >= 2, c > 1)。由于c的条件为 >，提取结束，不包括d。\n\n### Index Last Key \n\nIndex Last Key的功能与Index First Key正好相反，用于确定索引查询的终止范围。提取规则：从索引的第一个键值开始，检查其在where条件中是否存在，若存在并且条件是=、\u003C=，则将对应条件加入到Index Last Key中，继续提取索引的下一个键值，使用同样的提取规则；若存在并且条件是 \u003C ，则将条件加入到Index Last Key中，同时终止提取；若不存在，同样终止Index Last Key的提取。\n\n针对上面的SQL，应用这个提取规则，提取出来的Index Last Key为(b \u003C 8)，由于是 \u003C 符号，因此提取b之后结束。\n\n### Index Filter\n\n在完成Index Key的提取之后，我们根据where条件固定了索引的查询范围，但是此范围中的项，并不都是满足查询条件的项。在上面的SQL用例中，(3,1,1)，(6,4,4)均属于范围中，但是又均不满足SQL的查询条件。\n\nIndex Filter的提取规则：同样从索引列的第一列开始，检查其在where条件中是否存在：若存在并且where条件仅为 =，则跳过第一列继续检查索引下一列，下一索引列采取与索引第一列同样的提取规则；若where条件为 >=、>、\u003C、\u003C= 其中的几种，则跳过索引第一列，将其余where条件中索引相关列全部加入到Index Filter之中；若索引第一列的where条件包含 =、>=、>、\u003C、\u003C= 之外的条件，则将此条件以及其余where条件中索引相关列全部加入到Index Filter之中；若第一列不包含查询条件，则将所有索引相关条件均加入到Index Filter之中。\n\n针对上面的用例SQL，索引第一列只包含 >=、\u003C 两个条件，因此第一列可跳过，将余下的c、d两列加入到Index Filter中。因此获得的Index Filter为 c > 1 and d != 4 。\n\n### Table Filter\n\nTable Filter是最简单，最易懂，也是提取最为方便的。提取规则：所有不属于索引列的查询条件，均归为Table Filter之中。\n\n同样，针对上面的用例SQL，Table Filter就为 e != ‘a’。 \n\n### Index Key/Index Filter/Table Filter小结  \n\nSQL语句中的where条件，使用以上的提取规则，最终都会被提取到Index Key (First Key & Last Key)，Index Filter与Table Filter之中。 \n\nIndex First Key，只是用来定位索引的起始范围，因此只在索引第一次Search Path(沿着索引B+树的根节点一直遍历，到索引正确的叶节点位置)时使用，一次判断即可； \n\nIndex Last Key，用来定位索引的终止范围，因此对于起始范围之后读到的每一条索引记录，均需要判断是否已经超过了Index Last Key的范围，若超过，则当前查询结束；\n\nIndex Filter，用于过滤索引查询范围中不满足查询条件的记录，因此对于索引范围中的每一条记录，均需要与Index Filter进行对比，若不满足Index Filter则直接丢弃，继续读取索引下一条记录； \n\nTable Filter，则是最后一道where条件的防线，用于过滤通过前面索引的层层考验的记录，此时的记录已经满足了Index First Key与Index Last Key构成的范围，并且满足Index Filter的条件，回表读取了完整的记录，判断完整记录是否满足Table Filter中的查询条件，同样的，若不满足，跳过当前记录，继续读取索引的下一条记录，若满足，则返回记录，此记录满足了where的所有条件，可以返回给前端用户。\n\n## 结语\n\n在读完、理解了以上内容之后，详细大家对于数据库如何提取where中的查询条件，如何将where中的查询条件提取为Index Key，Index Filter，Table Filter有了深刻的认识。以后在撰写SQL语句时，可以对照表的定义，尝试自己提取对应的where条件，与最终的SQL执行计划对比，逐步强化自己的理解。 \n\n同时，我们也可以回答文章开始提出的一个问题：MySQL 5.6中引入的Index Condition Pushdown，究竟是将什么Push Down到索引层面进行过滤呢？对了，答案是Index Filter。在MySQL 5.6之前，并不区分Index Filter与Table Filter，统统将Index First Key与Index Last Key范围内的索引记录，回表读取完整记录，然后返回给MySQL Server层进行过滤。而在MySQL 5.6之后，Index Filter与Table Filter分离，Index Filter下降到InnoDB的索引层面进行过滤，减少了回表与返回MySQL Server层的记录交互开销，提高了SQL的执行效率。","src/content/posts/sql-where-parse.mdx","c02c6afed1c4c3d1","sql-where-parse.mdx","small-team-evaluate-project-deadline",{"id":1251,"data":1253,"body":1259,"filePath":1260,"digest":1261,"legacyId":1262,"deferredRender":22},{"title":1254,"summary":1255,"date":1256,"tags":1257,"group":129,"featured":38},"小团队如何准确评估项目时间和节点","创业公司中由于团队人手的限制，经常需要团队成员在不同的项目中进行身份切换，加之处于创业阶段，产品需求本身的变更和迭代速度都会很高，所以常常需要开发人员准确评估项目时间节点，把握开发节奏，才能不影响其他项目的正常进行。",["Date","2014-11-29T00:00:00.000Z"],[1258],"团队协作","创业公司中由于团队人手的限制，经常需要团队成员在不同的项目中进行身份切换，加之处于创业阶段，产品需求本身的变更和迭代速度都会很高，所以常常需要开发人员准确评估项目时间节点，把握开发节奏，才能不影响其他项目的正常进行。\n\n## 那该如何评估以及怎样评估\n\n{/* more */}\n\n一个产品需求从提出到落地大致需要经过以下几个阶段(可能根据需求的复杂度略有不同，这里只讨论一般性需求)\n\n```\n\n提出需求-->需求评估-->开发-->测试-->上线\n\n```\n\n当开发人员面对这么**粗粒度**的节点划分的时候，很难真正想象出项目会遇到什么样的问题，尤其是新人对项目的难度把握不准确，以及对整个团队开发流程不熟悉，非常容易做出不恰当的预估。在此，由于粒度**过粗**，每个阶段在开发人员的印象中都是一个模糊的概念，只有深入到实际开发阶段，可能才会发现每个阶段都没有那么容易，处处是坑，四处碰壁。\n\n以测试为例。一般来说，开发人员日常开发使用的是一套测试环境，包括系统状态，数据库状态，环境依赖等都与线上环境有细微甚至很大的差别，而这个差别可能只有等到上线前一刻才会被发现。可能一开始预估测试时间并不会把这样的意外因素考虑在内，而这样的问题发生势必会影响项目的正常发布，甚至延期。\n\n因而，为了弥补这样的不足，把一个需求从**立项**到**上线**的过程进行更**细粒度**的拆分，提前对每个粒度所面临的场景进行多种可能性预测，并制定相应的解决方案，模拟出项目的真实开发流程，类似战场打仗所用到的沙盘。\n\n\n## 一个真实的开发场景\n\nAPP中添加聊天通讯功能\n\n\n1.**未拆分阶段**\n\n```\n\n    提出需求(通讯功能)---->需求评估(可做)---->开发(客户端,服务端,联合调试)---->测试(客户端测试,服务端测试,产品测试)---->上线\n\n```\n\n2.**拆分需求和功能**\n\n在需求提出阶段可以按照需求的重要性进行等级划分(数字越小重要性越大)\n\n- Level one：必须有的，完成度要在95%以上，不能出现影响用户使用的重大bug\n- Level two: 能够基本完成，完成度80%以上，允许少量的bug存在\n- Level three: 锦上添花的功能，完成最好，也可以放到下一个迭代中\n\n根据不同的 *Level* 来进行开发时间预估，重要的 *Level* 应该给以足够的思考和开发时间\n\n3.**细化实施阶段的步骤(含测试)**\n\n需求按照等级划分清楚，之后开发人员可以对照相应的等级需求进行需求评估，评估完成之后给出实现方案和时间节点。\n\n实现方案根据团队条件的不一样会有很大不同，在此不讨论具体细节，时间节点又是根据具体的实现方案来定夺，而一般的方案都包含以下几个步骤\n\n- 调研\n    - 方案1\n    - 方案2\n- 讨论\n    讨论各个方案确定最终实施方案\n- 实施\n    - 基本功能\n    - UI\n    - 等等\n- 测试\n    - 本地测试\n    - 服务端测试\n    - 联合测试\n    - 测试环境测试\n    - 正式环境测试\n    - 用户测试\n\n开发人员根据这些步骤一步一步去评估每个步骤可能占用的开发时间，以此来决定完成一项功能的时长\n\n**未完待续**","src/content/posts/small-team-evaluate-project-deadline.mdx","2c4c160075ba8e23","small-team-evaluate-project-deadline.mdx","sqlalchemy-model-id-zero",{"id":1263,"data":1265,"body":1272,"filePath":1273,"digest":1274,"legacyId":1275,"deferredRender":22},{"title":1266,"summary":1267,"date":1268,"tags":1269,"group":1271,"featured":38},"如果 SQLAlchemy model 自增主键等于 0","SQLAlchemy 使用 session 生成新的数据根据主键的不同大致有以下几种情况，其中主键是 0 最为特殊。",["Date","2017-05-25T00:00:00.000Z"],[196,906,1270],"主键","SQLAlchemy","SQLAlchemy 使用 session 生成新的数据根据主键的不同大致有以下几种情况，其中主键是 0 最为特殊。\n\n测试环境\n\n- SQLAlchemy  1.0.9\n- mysql 5.6.27\n- pythonn 2.7\n\n{/* more */}\n\n## 不指定主键\n\n新创建 [SQLAlchemy](http://www.sqlalchemy.org/) ORM model instance 不指定主键，默认是 None\n\nModel\n\n```python\nclass Tag(Base):\n    __tablename__ = 'tag'\n    id = Column(Integer, primary_key=True) # 主键自增\n    name = Column(VARCHAR(255), nullable=False)\n    group_id = Column(Integer)\n```\n\n提交之后生成对应的主键\n\n```python\nsession = DBSession()\nt = Tag()\nt.name = random.choice('abcdefgjoiuytreqzxcvbnml')\nt.group_id = random.choice([1, 2, 3, 4, 5])\nprint t.id # None\nsession.add(t)\nsession.commit()\nprint t.id # 1\n```\n\n## 指定一个已经存在的主键\n\n指定一个已经存在的主键 id，SQLAlchemy 并不会校验该数据是否经在 db table 中有了对应的 row，直接执行 insert 语句\n\n```python\nsession = DBSession()\nt = Tag()\nt.id = 1\nt.name = random.choice('abcdefgjoiuytreqzxcvbnml')\nt.group_id = random.choice([1, 2, 3, 4, 5])\nsession.add(t)\nsession.commit() #提交触发异常\nprint t.id\n```\n\n执行报 Duplicate entry for primary 异常，id = 1 的 row 已经存在。\n\n```bash\nsqlalchemy.exc.IntegrityError: (pymysql.err.IntegrityError) (1062, u\"Duplicate entry '1' for key 'PRIMARY'\") [SQL: u'INSERT INTO tag (id, name, group_id) VALUES (%(id)s, %(name)s, %(group_id)s)'] [parameters: {'group_id': 3, 'id': 1, 'name': 'i'}]\n```\n\n## 指定主键是 0\n\n```python\nsession = DBSession()\nt = Tag()\nt.id = 0\nt.name = random.choice('abcdefgjoiuytreqzxcvbnml')\nt.group_id = random.choice([1, 2, 3, 4, 5])\nsession.add(t)\nsession.commit()\nprint t.id # 触发异常\n```\n\n执行报 ObjectDeletedError \n\n```bash\nsqlalchemy.orm.exc.ObjectDeletedError: Instance '\u003CTag at 0x10b4df790>' has been deleted, or its row is otherwise not present.\n```\n\n主键是 0 在提交之后再次获取 model 属性值会触发异常，这是由于已经 commit 的 model 的属性属于 expire 的状态，导致 SQLAlchemy 会从 db 中重新 load。由于 mysql 中默认情况下指定 id 是 0 或者 null 都会触发自增主键执行：\n\n```sql\ninsert into tag (id, name, group_id)values(0, 'a', 1)\ninsert into tag (id, name, group_id)values(null, 'a', 1)\n```\n\n指定主键为 0 实际生成的数据主键并不是 0，而是自增之后的主键。\n\n**不同于 mysql， SQLAlchemy 在指定主键之后实际上会认为主键就是 0，并没有获取实际生成的不为 0 主键，SQLAlchemy 再次 load 数据是按照 id = 0 的主键查找，实际是不存在的**。\n\nmysql 的 [no_auto_value_on_zero](https://dev.mysql.com/doc/refman/5.7/en/sql-mode.html#sqlmode_no_auto_value_on_zero) 控制着自增主键中 id = 0 的行为，默认是关闭的，打开即表示 id = 0 不会触发自增主键的执行。\n\n## 总结\n\nSQLAlchemy 中主键为 0 这一特殊情况导致的问题会在某些场景之下带来不必要的麻烦，解决办法就是：\n\n1. 如果主键属于自增，在 SQLAlchemy 中避免指定主键为 0。\n2. 打开 no_auto_value_on_zero 开关，统一 mysql 和 SQLAlchemy 的行为。","src/content/posts/sqlalchemy-model-id-zero.mdx","7236f1f44b5bc5d4","sqlalchemy-model-id-zero.mdx","sqlalchemy-delete-synchronize-session",{"id":1276,"data":1278,"body":1283,"filePath":1284,"digest":1285,"legacyId":1286,"deferredRender":22},{"title":1279,"summary":1280,"date":1281,"tags":1282,"group":1271,"featured":38},"sqlalchemy session 执行 delete 时 synchronize_session 策略","sqlalchemy 利用 session 执行 delete 时有一个 synchronize_session 参数用来说明 session 删除对象时需要执行的策略，共三个选项：",["Date","2017-06-07T00:00:00.000Z"],[],"```\nsession.query(Tag).filter(Tag.id.in_([1,2,3,4])).delete(synchronize_session='evaluate')\n```\n\nsqlalchemy 利用 session 执行 delete 时有一个 synchronize_session 参数用来说明 session 删除对象时需要执行的策略，共三个选项：\n\n## **False**\n\n>  don’t synchronize the session. This option is the most efficient and is reliable once the session is expired, which typically occurs after a commit(), or explicitly using expire_all(). Before the expiration, objects may still remain in the session which were in fact deleted which can lead to confusing results if they are accessed via get() or already loaded collections.\n\n不同步 session，如果被删除的 objects 已经在 session 中存在，在 session commit 或者 expire_all 之前，这些被删除的对象都存在 session 中。\n\n不同步可能会导致获取被删除 objects 时出错。\n\n## **fetch**\n\n> performs a select query before the delete to find objects that are matched by the delete query and need to be removed from the session. Matched objects are removed from the session.\n\n删除之前从 db 中匹配被删除的对象并保存在 session 中，然后再从 session 中删除，这样做是为了让 session 的对象管理 identity_map 得知被删除的对象究竟是哪些以便更新引用关系。\n\n## **evaluate**\n\n>  Evaluate the query’s criteria in Python straight on the objects in the session. If evaluation of the criteria isn’t implemented, an error is raised.\n> The 'evaluate' strategy performs a scan of all matching objects within the Session; if the contents of the Session are expired, such as via a proceeding Session.commit() call, this will result in SELECT queries emitted for every matching object.\n\n默认值。根据当前的 query criteria 扫描 session 中的 objects，如果不能正确执行则抛出错误，这句话也可以理解为，如果 session 中原本就没有这些被删除的 objects，扫描当然不会发生匹配，相当于匹配未正确执行。\n\n注意这里报错只会在特定 query criteria 时报错，比如 `in` 操作。\n\n```\n\nsession.query(Tag).filter(Tag.id.in_([1,2,3])).delete()\n\nsqlalchemy.exc.InvalidRequestError: Could not evaluate current criteria in Python. Specify 'fetch' or False for the synchronize_session parameter.\n\n```","src/content/posts/sqlalchemy-delete-synchronize-session.mdx","92e711a3d9b597aa","sqlalchemy-delete-synchronize-session.mdx","sqlalchemy-pool-mechanism",{"id":1287,"data":1289,"body":1295,"filePath":1296,"digest":1297,"legacyId":1298,"deferredRender":22},{"title":1290,"summary":1291,"date":1292,"tags":1293,"group":1271,"featured":38},"SQLAlchemy 的连接池机制","SQLAlchemy 自身提供了连接池来管理所有和 database 的连接，pacakge 是 ，简单来说 connection pool 就是一种复用连接的机制，工作流程如下：",["Date","2019-01-02T00:00:00.000Z"],[1294],"连接池","SQLAlchemy 自身提供了连接池来管理所有和 database 的连接，pacakge 是 `sqlalchemy.pool` ，简单来说 connection pool 就是一种复用连接的机制，工作流程如下：\n\n![](https://static.git-star.com/a0b501e5016ede9ad1ff0a2bb23036a0.jpg)\n\n\n从 pool 中获取新的连接，如果没有就创建一个新的连接并返回，在调用连接的 close 之后，连接不会真正的关闭而是返回 pool 供下次使用，过程比较简单，但是在实际实现 pool 的过程中需要考虑很多细节性的东西，下面我们一一来说说 sqlalchemy 的 pool 机制。\n\n\n## Pool 的使用\n\nSQLAlchemy 默认在使用 create_engine 创建新的 engine 时提供了一个 QueuePool，而且可以指定 Pool 的一些属性，包括 pool_size、max_overflow、pool_recycle 等：\n```python\nengine = create_engine('postgresql://me@localhost/mydb',\n                       pool_size=20, max_overflow=0)\n```\n\n- pool_size pool 的大小\n- max_overflow 允许超过 pool_size 多少\n- pool_recycle 设置 DBAPI connection 存活多久断开\n- pool_timeout 从 pool 中获取新的连接等待时间，一般是指等待 pool 中连接可用的时间\n\n\n除了指定 pool 的一些属性之外，create_engine 允许自定义 pool 的实现，只要接口符合 `lib/sqlalchemy/pool/base.py` 中规定的 Pool 即可，这个参数是 create_engine 的 poolclass。\n\n从 pool 中获取一个新的 connection：\n```python\nconn = engine.connect()\n```\n\n归还 connection 到 pool 中：\n```python\nconn.close()\n```\n\n`conn` 是一个实现了 proxy 模式的对象，目的是在 close 时不是真正关闭 connection 而是归还到 pool 中，而且即使没有调用 close 方法，conn 对象在进行 garbage collected 时也会归还到 pool 中。\n\n在执行 close 方法时，需要对该连接进行一些清理工作以保证该连接下次能够正确工作，比如是否 connection 上的锁等等，\n\n## Pool 的事件\n\nSQLAlchemy 默认提供了一些列的 hook 用于处理 connection 在创建时、获取 connection 时、归还 connection 时等等，见[PoolEvents](https://docs.sqlalchemy.org/en/latest/core/events.html#sqlalchemy.events.PoolEvents)。\n\n## 处理失效 connection 的机制\n\nSQLAlchemy 提供了两种处理连接失效的机制，一种是悲观的，一种是乐观的。\n\n\n### 悲观机制\n\n悲观机制是指在每次获取新的 connection 供 application 使用之前，都在 connection 上进行一个简单的测试，比如发送一条简单的 `select 1` 语句以测试当前 database 是否可用，虽然该检测机制会造成一些额外的开销，但确实一种简单可靠能并且能及时发现 database 可用性的机制。\n\n需要注意的是即使采用了预检测机制，也没有办法杜绝在 transaction 执行当中由于 database 发生故障造成的影响，也就是说如果一个 transaction 正在执行过程中，此时由于 database 故障了，transaction 可能会丢失，这类错误还是需要依靠 application 来解决。\n\nPool 的预检测发生在获取新的 connection 时，通过配置 `Pool.pre_ping` 来实现，体现在 create_engine 上是 `pool_pre_ping` 参数：\n```python\nengine = create_engine(\"mysql+pymysql://user:pw@host/db\", pool_pre_ping=True)\n```\n\n如果预检测发现 connection 不可用，当前 connection 会立马被回收，而且在 pool 中创建时间小于当前 connection 的所有 connection 都会被回收。\n\n\n\n### 乐观机制\n\n\n不同于悲观机制，乐观机制是指只在 connection 执行过程中检测 database 是否故障，如果 connection 在执行 transaction 过程中 raise 出 `disconnect` 事件，则会调用 `Pool.recreate()` 把 pool 中所有还未被使用的 connection 全部失效，并且从新的 pool 中创建一个新的 connection 并返回。\n\n同样的，application 需要自己去处理事务执行过程中 connection 中断的情况。\n\n\n### 另一个回收连接的选择 recycle \n\n此外 SQLAlchemy 还提供了 recyle 的机制来处理连接过久的 connection，如果一个 connection 占用时间太长超过了 pool_recyle 设置的时间，pool 会自动失效该连接。\n\n```python\nfrom sqlalchemy import create_engine\ne = create_engine(\"mysql://scott:tiger@localhost/test\", pool_recycle=3600)\n\n```\n\n**需要注意的是 pool 根据 pool_recyle 设置失效时间只会发生在获取新的 connection 的时候。**\n\n\n## 允许应用程序真正关闭连接\n\n不论是 Session 还是 engine，以及 engine 创建的 Connection，都提供了一个 `invalidate` 方法用来关闭底层 DBAPI 的 connection 的机制，也就是说应用程序有权决定是否真正关闭底层连接的权利。","src/content/posts/sqlalchemy-pool-mechanism.mdx","1f9822f530f9cf62","sqlalchemy-pool-mechanism.mdx","sublime-text",{"id":1299,"data":1301,"body":1307,"filePath":1308,"digest":1309,"legacyId":1310,"deferredRender":22},{"title":1302,"summary":1303,"date":1304,"tags":1305,"group":129,"featured":38},"我的 sublime text 配置","我最常用的编辑器是 vi 和 sublime text，vi 多用在服务端，sublime text 常用在桌面环境，我的 sublime 的配置主要包括以下的 package。",["Date","2018-05-12T00:00:00.000Z"],[1306],"sublime","我最常用的编辑器是 vi 和 sublime text，vi 多用在服务端，sublime text 常用在桌面环境，我的 sublime 的配置主要包括以下的 package。\n\n- Anaconda\n- AutoPEP8\n- Boxy Theme\n- BracketHighlighter\n- CSS Format\n- EmberScript\n- Emmet\n- GitGutter\n- GoSublime\n- Handlerbars\n- HTML5\n- HTMLBeautify\n- Insert Nums\n- Jade\n- Javascript Completions\n- Jinja2\n- JsFormat\n- LESS\n- lessc\n- MagincPython\n- Markdown Preview\n- Python Imports Sorter\n- Reactjs\n- Sass\n- Stylus\n- Stylus Clean Completions\n- Swig\n- Terminal\n- Vue Syntax Highlight\n\n## 编辑器主题\n\n编辑主题我用过很多种，一直在换，现在一直在用的是 `Boxy Theme`，用的其中 `Ocean Theme` 可能以后不会再换了。\n\n## Python \n\n支持 Python 的 package 我用过好几个，直到前年 Anaconda 出现，就一直用的它，支持：\n- Go To Definition\n- 格式化\n- Code Auto Complete\n\n仅仅这些功能的便捷程度就已经超过其他包了，而且稳定性好不怎么出问题，除此之外我还用了：\n- AutoPEP8\n- Python Imports Sorter\n抱住我检查 PEP 的错误和格式化包的导入，非常方便。\n\n使用 Anaconda 时一定要注意配置用户环境:\n\n```json\n{\n    \"python_interpreter\": \"/Users/zhaoyongqiang/python_env/bin/python2.7\",\n    \"anaconda_linting_behaviour\": \"save-only\",\n    \"anaconda_gutter_marks\": true,\n}\n```\n帮助 Anaconda 快速找到包。\n\n## Go 支持\n\nGoSublime 是 sublime text 下对 Go 支持最好的包，包括\n- 自动导入\n- 自动补全\n- 格式化\n但是也需要注意配置 GOPATH：\n```json\n{\n    \"env\": {\n        \"PATH\": \"$HOME/zhyq0826/go/bin:$PATH\",\n        \"GOPATH\": \"/Users/zhyq0826/go\"\n    }\n}\n```\n\n## 前端\n\n我现在前端写的比较少了，之前从 HTML 到 less 到 Vuejs、Emberjs 再到 ES2015 都没少写，用了一大堆语法支持和自动补全：\n- CSS Format\n- EmberScript\n- Emmet\n- Handlerbars\n- HTML5\n- HTMLBeautify\n- Javascript Completions\n- JsFormat\n- LESS\n- lessc\n- Reactjs\n- Sass\n- Stylus\n- Stylus Clean Completions\n- Swig\n- Vue Syntax Highlight\nJsFormat 这个工具很好用，常用来格式化 JavaScript 和 JSON。\n\n## Git 支持\n\n`GitGutter` 这个工具提供仓库中文件信息的变更，我只需要这个功能，便于在更改文件时可以看到变化之处。\n\n## 打开终端\n\nTerminal 这个工具能够在文件所在处打开 terminal，非常方便快速切入终端\n\n## Markdown Preview\n\n`Markdown Preview` 预览 markdown 文件\n\n## 其他常用配置\n\n1.默认用 space 替代 tab，大小是 4 个 space\n2.User setting 配置：\n```json\n{\n    \"always_show_minimap_viewport\": true,\n    \"binary_file_patterns\":\n    [\n        \"*.jpg\",\n        \"*.jpeg\",\n        \"*.png\",\n        \"*.gif\",\n        \"*.ttf\",\n        \"*.tga\",\n        \"*.dds\",\n        \"*.ico\",\n        \"*.eot\",\n        \"*.pdf\",\n        \"*.swf\",\n        \"*.jar\",\n        \"*.zip\",\n        \"node_modules/*\",\n        \"bower_components/*\",\n        \"tmp/*\"\n    ],\n    \"bold_folder_labels\": true,\n    \"caret_extra_bottom\": 1,\n    \"caret_extra_top\": 1,\n    \"caret_extra_width\": 1,\n    \"caret_style\": \"blink\",\n    \"color_scheme\": \"Packages/Boxy Theme/schemes/Boxy Monokai.tmTheme\",\n    \"fade_fold_buttons\": false,\n    \"folder_exclude_patterns\":\n    [\n        \".svn\",\n        \".git\",\n        \".hg\",\n        \"CVS\",\n        \"tmp\"\n    ],\n    \"font_size\": 16,\n    \"ignored_packages\":\n    [\n        \"Node Completions\",\n        \"Python\",\n        \"Vintage\"\n    ],\n    \"indent_guide_options\":\n    [\n        \"draw_normal\",\n        \"draw_active\"\n    ],\n    \"line_padding_bottom\": 2,\n    \"line_padding_top\": 2,\n    \"overlay_scroll_bars\": \"enabled\",\n    \"show_encoding\": true,\n    \"show_full_path\": true,\n    \"show_line_endings\": true,\n    \"theme\": \"Boxy Ocean.sublime-theme\",\n    \"translate_tabs_to_spaces\": true\n}\n``` \n字体我喜欢大一点的一般是 16，有些目录在搜索文件时可以排除，用 `folder_exclude_patterns`。","src/content/posts/sublime-text.mdx","d8088deb22eb3839","sublime-text.mdx","superset",{"id":1311,"data":1313,"body":1318,"filePath":1319,"digest":1320,"legacyId":1321,"deferredRender":22},{"title":1314,"summary":1315,"date":1316,"tags":1317,"group":90,"featured":38},"可视化数据平台 superset ：安装和使用","# 什么是 superset",["Date","2017-11-14T00:00:00.000Z"],[1311],"# 什么是 superset\n\nSuperset 是 Airbnb 开源的大数据可视化平台，其特性包括：\n\n- backend 支持几乎所有主流的数据库\n- 支持复杂的权限控制和管理(OpenId, OAuth 等)，满足企业内部不同部门人员对数据的权限要求\n- 丰富的可视化展示，支持自定义创建 dashboard，可分享\n- 可扩展、细粒度的数据库权限控制，满足不同层级人员对数据库权限的要求\n- 数据的展示完全可控，可自定义展示字段、聚合数据、数据源等\n- 深度集成  Druid.io\n\nSuperset 目前由 Apache 孵化，地址是 github.com/apache/incubator-superset\n\n\n# superset 解决什么问题\n\n由 superset 的特性不难看出 superset 要解决的问题：\n\n- 满足企业内部不同部门对数据的要求：老板、运营、产品、商务\n- 细粒度的权限划分和控制，可满足不同层级的人员的不同权限\n- 支持各种主流数据库，hbase、mysql、postgres等\n- 不同数据不同维度的可视化\n- 自定义数据的展示和可视化\n\n\n\n# 下载安装\n\nSuperset 由 Python 构建，可使用 pip 安装 `pip install superset`，详细信息请参考官方文档 https://superset.incubator.apache.org\n, 在此我们重点介绍一下 superset 的使用。\n\n\n# 使用 superset\n\n\n## 添加数据源\n\nSuperset 自带权限管理，在使用之前首先按照官方文档的要求新建超级用户，首次登录使用创建的超级用户即可，之后可以按照自己的需求划分组和用户，权限划分在安全菜单中。\n\n打开 superset 可以看到其菜单分步如下：\n\n![](https://static.git-star.com/3e40ac997b07670e80afe65eff9e7030.png)\n\nsuperset 支持国际化，可在右上角切换自己熟悉的语言，这里我们以中文为例。\n\n在数据源-->数据库列表中添加需要使用的数据库如下：\n\n![](https://static.git-star.com/117068961a97e7c4f0c27c83bba4e692.png)\n\n`SQLAlchemy URI` 选项是我们需要填写的数据库连接，superset 使用 mysql 时默认使用 mysqlclient 做驱动连接数据库，而且还提供了 sqlalchemy 的文档连接，`mysql://scott:tiger@localhost/foo` ，需要注意的**如果 passwd 中包含特殊字符，需要进行转义进行 urlquote**。\n\n填写成功之后点击测试，如果弹窗显示 Ok 表示连接建立成功，此时可以看到数据库的 tables 会在表单下方出现，点击保存。\n\n如果添加数据库保存报 [No module named MySQLdb](https://stackoverflow.com/questions/454854/no-module-named-mysqldb) ，安装 **pip install mysql-python**\n\n数据库配置成功之后开始配置需要使用的 table，在数据源-->数据表添加需要使用的 table 如下：\n\n![](https://static.git-star.com/569ad0be9a27ab7637b309f717a0e407.png)\n\n保存之后回到 table 页，编辑刚才添加的 table，切换到列列表视图，可以看到 table 中包含的所有的列:\n\n![](https://static.git-star.com/84667f739b457c74a590cd17dd790a64.png)\n\n在此可以配置需要查询的字段、聚合字段等。\n\n\n## 探索数据\n\ntable 配置完成就可以使用 superset 进行数据查询和展示了，在 table 页直接点击 table，进入 table explore 页：\n\n![](https://static.git-star.com/dfcde94661de7005dfdea2731965d11c.png)\n\n\n在左侧选项栏依次是：\n\n- 数据源和图表类型\n- 查询时间\n- group by 语句\n- SQL 过滤条件\n\nTime 可选 since 和 until ，表示开始和结束区间，如果图表类型支持自定义信息，还会有图表展示的配置。\n\n配置完成之后点击左上角的 Run query 即可查看结果。\n\n点击左上角 save 可以保存当前的结果为一个 slice，slice 在 superset 中就是一个数据结果集的展示，多个 slice 可以组成一个 dashboard，可以根据不同人员对数据的不同需求建立不同的  dashboard。\n\n![](https://static.git-star.com/4ab9dc16f5dfe1826a463958d1ce9efe.png)\n\n# 常见问题\n\n## 配置数据库报错\n\n如果配置数据库报点击连接测试无法从 url 获取 password 的错误，UI 上对应的是 object None type 错误，直接跳过保存即可。\n\n## csv 导出中文乱码\n\nsuperset 的导出是可以进行配置的，创建 `superset_config.py` 改写其 csv 导出的编码\n\n```python\nCSV_EXPORT = {\n    'encoding': 'utf_8_sig',\n}\n\nSQLALCHEMY_DATABASE_URI = 'mysql://root:@127.0.0.1/superset?charset=utf8'\n```\n\n`superset_config.py` 必须放置在 PYTHONPATH，也就是 Python os.environ 可以获得的地方\n\n\n# 总结\n\nSuperset 正在逐步应用到生产环境中，后续会我会根据团队的使用情况继续介绍更多 superset 的使用。","src/content/posts/superset.mdx","fb633d752dabb466","superset.mdx","talk-about-design",{"id":1322,"data":1324,"body":1330,"filePath":1331,"digest":1332,"legacyId":1333,"deferredRender":22},{"title":1325,"summary":1326,"date":1327,"tags":1328,"group":129,"featured":38},"聊点交互设计","虽然我不是专业前端，但是前端的专业程度应该已经超过了很多专业的前端，第一，我有扎实的计算机基础（在后端侵淫了十年），第二，良好的交互设计感以及对美好事物的追求塑造了我对前端交互的独特感受。当然前端的设计不仅仅是指交互设计，也有很重要的平面设计成分，但是作为一个前端，交互设计是首要...",["Date","2022-10-25T00:00:00.000Z"],[1329],"设计","虽然我不是专业前端，但是前端的专业程度应该已经超过了很多专业的前端，第一，我有扎实的计算机基础（在后端侵淫了十年），第二，良好的交互设计感以及对美好事物的追求塑造了我对前端交互的独特感受。当然前端的设计不仅仅是指交互设计，也有很重要的平面设计成分，但是作为一个前端，交互设计是首要应该掌握的，交互的好坏直接反应了前端程序的易用程度，甚至一定程度上决定了整个程序的用户体验和口碑，比如说黄渤虽然长得不帅，但是演技超群，有修养有内涵，一样可以成为顶流明星，而前端的美感部分可以完全交给设计师，这也从侧面反应了一个事实，大部分设计师只擅长平面设计。\n\n## 交互的基本组成结构\n\n一个完整的交互包含触发交互的对象、交互规则、响应反馈以及以前三者为基础建立的循环模式。\n\n**交互对象**很好理解，就是触发交互的元素，也可以称之为**触发器**，可以是一个虚拟按钮，一个实体按键等等。\n\n**交互规则**就是隐式或显式指导交互发生作用的规则。\n\n**响应反馈**是指通过某种用户能理解的方式告知交互的规则和结果。\n\n**循环模式**就是一种或多种交互组合、循环以最终达成交互目标而形成的操作模式。\n\n## 交互体现的是细节\n\n交互体现的是人与产品的互动，人和产品的互动往往又来自于各种各样的细节。\n\n细节就是在有限的条件下，利用有限的空间、时间、规则来帮助用户完成和产品的互动，好的细节就是让用户高效、愉悦得完成互动。\n\n也就是一个个细节的组合和积累整体完成了产品使用体验的表达，进而可以得出**优秀的产品使用体验，必然包含无数个优秀的细节设计**，细节就是本质，是评价产品使用优劣的标准。\n\n## 设计触发器的基本原则\n\n任何交互的开始都始于一个**触发器**，用户要使用一个触发器必然是为了达成某种目的，因此交互设计也自然开始于对用户需求的理解：用户想要做什么、什么时候想做，有多么频繁，达成目的之后用户又要去做什么，以此往复。\n\n对用户需求的洞察就是对用户使用交互场景的洞察，场景又决定了触发器在什么时候、什么地方以什么样的形式出现，那么触发器的在场景中的辨识是交互设计首先要解决的问题。\n\n触发器设计的第一个原则：**必须让用户在使用场景下能认出来**。\n\n我多年的职业生涯中，经常能听到用户对使用某个产品的吐槽：这谁能看出来是个按钮。类似的吐槽反映出来就是触发器设计的辨识度是有问题的。\n\n触发器设计的第二个原则：**保证相同的触发器每次都触发相同的动作**。\n\n这一原则保证了用户在使用的过程中能对触发器的反馈逐渐形成准确的心智模型，如果违反了这一原则，用户可能会疑惑甚至被迫区分不同的场景才能准确完成交互的目的，难以形成习惯。\n\n触发器设计的第三个原则：**提前展示触发器交互的关键数据**。\n\n在触发器被启动之前应该让用户知道其包含的关键信息，提醒用户是否有必要启动触发器，因而触发器需要提前预判用户可能关注有价值信息是什么，比如打开邮件的按钮会提醒用户有多少新邮件，让用户决定是否有必要打开。对于前端设计来说，一般触发器常常会有多种状态可以用来展示关键信息：\n\n**默认状态**\n\n表示不活动的状态\n\n**活动状态**\n\n后台有活动，比如后台下载或更新\n\n**悬停状态**\n\n鼠标或手势放上去之后给出对应提示，比如图片元素的 alt 提示\n\n**鼠标单击进行中**\n\n在启动触发器的时候展示信息\n\n触发器设计的第四个原则：**不要破坏视觉使用情景**。\n\n这个原则是指触发器的设计应符合用户期待，如果一个触发器被设计成按钮，就应该具有按钮的形态和特征，能符合用户对按钮的基本认知。\n\n触发器设计的第五个原则：**用得越多的触发器越要引人注目**。\n\n多数人经常要使用的，应该最引人注目；少数人有时会用的，应该容易注意到；极少数人常用的，应该通过搜索找到。\n\n## 设计交互规则的最佳实践\n\n**交互过程要保持概念统一**\n\n如果一个名字或动词多次出现在交互过程中，要始终保持它们含义的一致性，如果有相近的词出现，要把它们进行合并统一。\n\n**如果可能，不要让用户从零开始**\n\n如果技术手段不受限制，不要让用户从零开始进行操作，让用户从其结束的重新开始，充分利用收集到用户数据来辅助用户完成操作。\n\n**如果一个事情非常复杂，帮助用户尽可能把复杂的事情都做了，或者把绝对的控制权交给用户**\n\n斯勒复杂性守恒定律：所有活动都有内在的复杂性，超过了某个临界点，简化是不可能的。既然如此，唯一的问题就是如何对待复杂性。要么让系统来处理，不让用户介入；要么让用户来处理，把更多的决定权（包括控制权）交给用户。\n\n**如果可能，尽量提供有限的选项，如果不能，提供聪明的默认的选项**\n\n好的交互始终让用户尽量少做选择，如果难以避免，尽量替用户考虑，能够提供多种聪明的默认选项，此时默认选项要能够满足大部分人的需求。\n\n**预防错误，或者错误发生之后可以引导用户去解决**\n\n好的交互应该可以防止用户犯错，或者出错时可以事先预料到，并且能提供引导来帮助用户消除犯错的焦虑。","src/content/posts/talk-about-design.mdx","eaeaae825c56610d","talk-about-design.mdx","talk-about-test",{"id":1334,"data":1336,"body":1341,"filePath":1342,"digest":1343,"legacyId":1344,"deferredRender":22},{"title":1337,"summary":1338,"date":1339,"tags":1340,"group":78,"featured":38},"聊聊测试：入门和实践","在我个人职业生涯的前两年，我几乎没有写过几个正规的测试用例，大部分时候都是赶进度用人工测试，当然所在的团队规模也不是特别大，所有的测试都是 developer 自己完成。那个时候我对测试虽然稍有存疑，但还是抱着想试试的态度，当时摆在我面前的问题是：测什么和如何测。",["Date","2017-10-14T00:00:00.000Z"],[],"在我个人职业生涯的前两年，我几乎没有写过几个正规的测试用例，大部分时候都是赶进度用人工测试，当然所在的团队规模也不是特别大，所有的测试都是 developer 自己完成。那个时候我对测试虽然稍有存疑，但还是抱着想试试的态度，当时摆在我面前的问题是：测什么和如何测。\n\n随着日后经历的团队规模不断变大，开发的软件服务的复杂度和用户量的不断变高，对测试的理解也从不知如何想入手到持续推进自动化和 CI 在团队中不断普及和应用，甚至强行将测试覆盖率和测试质量纳为开发人员的考核指标，在此我们一起好好聊聊软件生命质量的保证：测试。\n\n# 为什么很多 developer 不写测试，甚至厌恶写测试\n\n不想测试的 developer 常常由自己的一套理由或者借口。\n\n## 观点一：我的代码跑得很好，为什么要测试\n\n对这样的观点最有力的回应是，你怎么知道你的代码跑得好好的，你测试过么，除非你现在测试一下你的代码证明它跑得很正确。但事实上自动化测试带来的好处绝对是显而易见的：\n\n- 可重复执行，有利于代码反复修改和迭代\n- 可随时发布，让你的代码第一时间接触用户\n- 节省时间\n......\n\nwecatch 开源的 app-turbo 在上线到生产环境第一个版本之后（彼时测试覆盖率不足20%），每迭代一个小版本大概需要一周时间，当测试覆盖率达到 30% 已经可以 3 天发一个小版本，现在 50% 的覆盖率如果不是大功能变动，一天发可以一个版本。\n\n{/* more */}\n\n## 观点二：测试会让开发周期变长\n\n测试就像是练习长跑，一开始身体肯定会非常不适应，但跑步这件事从更长远的时间来看对健康是有益的。同样，测试在软件开发的早期会花费不短的时间，但如果你能坚持并不断地改进它，让它最终变成软件的一部分，它能让你的软件得到持续的改进，质量不断提高，还能帮助你节省很多时间。\n\n大部分 developer 不愿意测试，都是觉得测试让开发周期变长，这个周期他们一般都指创作软件时花费的时间，而事实上占用整个软件生命周期最长的部分是**维护**，把测试放到这个尺度上来衡量它占用的时间其实是很可观的。\n\n## 观点三：不知道测试什么\n\n万事开头难，如果真的准备要测试你写的代码，下面这些意见值得参考。\n\n1. 从你的一个函数开始，最好这个函数不依赖任何外部系统，包括数据库、网络等，这样的测试就是单元测试\n2. 测试你的软件最复杂的部分，然后持续改进这部分代码，你会马上从自动化测试中受益。\n3. 任何时候如果你发现了一个 bug，在修复之前写一个测试用来来覆盖它，来验证你确实修复了这个问题\n4. 当你觉得写新的代码毫无头绪时，去写一个测试用例吧，既能让你暂时摆脱眼前的思考，还能打发时间\n\n# 没有任何测试经验，如何实践\n\n对于一个来到测试世界的新人来说，确实很难知道从哪里开始测试，对于刚接触测试，推荐了解和实践 ：\n\n- Unit testing 单元测试\n- Integration testing 集成测试\n- Regression testing 回归测试\n\n\n## Unit testing\n\n如何定义 unit testing？如果你要做的测试：\n\n- 与数据库产生交互\n- 与网络产生交互\n- 使用了文件系统\n- 不能和其他单元测试一起执行\n- 需要特殊的运行环境保障测试的执行\n\n这些测试都不能算是 unit testing，unit testing 要保证自身可以在**不依赖任何第三方系统**的情况下完成测试，尤其针对提供单一功能的函数或类。\n\nUnit testing 是最基础最简单的测试单元，输入输出都非常容易，几乎没有依赖，不需要搭建复杂的外部系统就可以实践和验收。\n\n为了让 unit testing 编写容易、测试准确，测试对象一定要具备良好的可测试性，衡量可测性最常见的标准有：\n- 函数职责单一\n- 单一的输入，必然产生单一的输出，不具有二义性\n可见测试反过来可作用于代码的设计和组织，逼迫 developer 输出更优质的代码。\n\n入门实践 unit testing 可从现有代码中不与外部依赖的单一的 function 和 class 开始，逐步改进和增强。\n\n## Integration testing\n\n集成测试是面向体系的测试，要求必须要有准确的外部环境依赖来保证数据的正确输入和交互，集成测试要求 developer 能对代码的工作流程了如指掌，并且能正确模拟各个模块的输入和输出以达到**合并和组织单元模块让以验证它们一起工作是否表现良好**的目的。\n\n\n集成测试需要更多的数据准备和输入，而且要求数据之间的逻辑关系定义明确，所以开始集成测试前一定要：\n- 准备你的测试环境，比如硬件资源、数据库依赖等\n- 准备你的测试数据，明确数据间的关系定义，并且能够重复输入，比如 SQL 语句、某些表的数据\n- 组合代码的工作流程，让其可以满足验证不同的逻辑分支\n\n\n## Regression testing \n\n回归测试是在单元测试和集成测试的基础上，对已有测试的重复验证，其目的是为了保证新的修改不会对旧功能造成破坏。\n\n回归测需要注意的重要的一点是一定要界定回归的范围，把握和控制不同的修改造成的影响以及是否需要回归。\n\n>这些介绍已经足够入门和实践了，首先为你的代码最复杂的部分写测试，越是复杂的部分越是能从自动化测试中受益，即使只是使用最简单的测试工具完成你的工作。\n\n\n# 完整测试的生命周期\n\n很多主流语言都自带了测试框架或工具用来完成测试有关的繁重工作，一般来讲对于一个应用来说，按照代码作用域划分都会有几种不同范围的测试。\n\n- package test | module test\n- function test\n- class test\n- API test\n\n按照这几种维度，测试框架一般会提供不同阶段的 hook 用来完成测试所需要数据和环境的准备与销毁工作：\n\n```\n# setup\nsetupModule | setupPackage\nsetupClass\nsetupFunction\nsetupMethod\n\n# teardown\n\nteardownModule | teardownPackage\nteardownClass\nteardownFunction\nteardownMethod\n\n```\n\n而测试的所有工作就是围绕这些控制生命周期的各种 hook 展开的，所以学习和使用他们是开展测试的第一步工作。\n\n# 推荐阅读\n\n- http://pythontesting.net/books/pytest\n- Test-Driven Development with Python\n- Lessons Learned in Software Testing: A Context-Driven Approach\n- Beautiful Testing: Leading Professionals Reveal How They Improve Software\n- Testing Computer Software\n- Agile Testing: A Practical Guide for Testers and Agile Teams\n- [10 个良好的测试习惯](https://mp.weixin.qq.com/s/8no-xuY_ZxHLDbnFDPEA_A)\n\n\n# 参考资料\n\n- http://www.softwaretestinghelp.com/types-of-software-testing/\n- https://github.com/zhyq0826/zhyq0826.github.io/issues/75\n- https://hackernoon.com/common-excuses-why-developers-dont-test-their-software-908a465e122c","src/content/posts/talk-about-test.mdx","a752fb424bb1abc7","talk-about-test.mdx","target-process-result",{"id":1345,"data":1347,"body":1352,"filePath":1353,"digest":1354,"legacyId":1355,"deferredRender":22},{"title":1348,"summary":1349,"date":1350,"tags":1351,"group":884,"featured":38},"目标 过程 结果","# 目标",["Date","2017-11-20T00:00:00.000Z"],[],"# 目标\n\n## 什么是目标\n\n目标是一个方向，用来指导实际行动朝着一个对结果有正向作用的方向前进的，也就是目标应该是一个指向未发生的结果的箭头，用来时刻提醒行动的路线是不是准确的，从这点来说目标指向的结果是一个中长期之后才能发生事情。\n\n目标需要有个 why，用来说明目标背后突出的核心理念是为什么要做一件事，为什么要这个结果，所以定了目标之前一定要先写下 why 。\n\n目标反应出来的 why 是做事的基本理念和指导原则。\n\n目标提现出来的是问题模型结构中的why。\n\n## 目标的特点\n\n- 时间跨度长\n- 有一定的难度\n- 结果带有一定的不确定性\n- 具有方向性\n- 有反应问题核心的 why\n\n## 目标的意义\n\n目标是做事的目的，没有目的行动是不存在的，哪怕是看一场电影或者吃一顿饭都是以娱乐精神和填饱肚子为目的，因而凡做事目的必须放在首位，因而指定一个清晰而且具体的目标对指导行动和最终的结果指向具有重大意义\n\n## 如何制定目标\n\n制定目标之前首先要明确什么才是好目标，即好目标的标准是什么\n\n## 什么才是好目标\n\n**1.specific 具体的**\n目标一定是具体可见的\n\n**2.measureable 可测的**\n好目标指向的结果必须是可以度量的，不能是抽象的\n\n**3.Achiveable 可实现的**\n目标一定是可以实现的，不可以实现的是梦想\n\n**4.realistic 有现实意义**\n目标必须会产生具体影响的，不能是虚无的\n\n**5.timeline 有明确期限**\n目标不能占用无穷尽的时间，必须是有时间限制的\n\n**6.challenge 有挑战**\n目标不是为了按部就班的完成任务，而是为了超越现在，所以目标一定是带有挑战性的，只有通过客服具有挑战性的目标，个人能力才能得到超越\n\n## 如何制定好目标\n\n知道了好目标的标准，对制定目标就有对应的衡量标准和指导原则，那目标制定之后可以对照着这些标准进行调整直到目标符合一个好目标的标准\n\n### 1.提出一个想法\n\n想法是一个假设，假设就是对还未发生的事情进行一个结果预测，这个结果是根据我们已知的知识和经验推导出来的，假设是否准确，也就是我们推导出的结果是否就是准确的，需要执行一系列的行动来帮助我们完成这个假设验证。\n\n有时候有些假设的结果是非常显而易见的，也就是我们基于过去对结果的预测肯定是准确的，此时说明的我们过去的经验对于预测和判定未来这件事是适合的。\n\n有时候我们的假设带着很大的不确定性，说明基于过去的经验和认知对这种假设的预测是不够用的，此时需要我们搜集更多的信息来验证我们的假设，假设一旦有一定程度上的验证，此时假设，也就是这个想法可以转换成一个具体可以执行的目标。\n\n### 2.想法转换成目标\n\n有了想法并且得到一定程度的验证之后，我们可以把这个想法转换成一个目标，比如我有一个赚钱的想法是通过写公众号，不断逼迫自己输出的同时达到逼迫自己不断输入，在此过程中如果能积累一定量的粉丝，打造出一定的影响力，就可以开展相应的课程培训，把输出转换成金钱。\n\n这个想法已经有很多人得到了验证，所以通过**写公众号赚钱的假设**是成立的。\n\n如何把这个假设转换成目标，需要对这个假设进行拆分，也就是我们需要完成这个假设需要哪些步骤。\n\n- 有输入\n- 有输出\n- 能够吸引对输出感兴趣的人\n- 不但能够要吸引对输出感兴趣的人还能积累到一定的量\n- 有可以让人付费的输出\n- 有人付费\n\n到最后一步，有人付费是我们最终想要的一个结果，也就是说我们要达到的目标。\n\n假设转换成目标：通过有价值的内容输出积累一定量的粉丝之后，做付费内容输出得到经济回报\n\n### 3.目标的拆解\n\n有了目标之后，我就需要通过这个目标反推我们需要做什么能够达到目标，也就实现目标的过程是什么。\n\n而任务计划实质上是一个短期的可达到的一个目标\n\n\n\n# 过程\n\n## 什么是任务\n\n任务是对目标的拆解，任务反映的是一个更小的目标，这种小反映在：\n- 时间跨度更小\n- 工作量更小\n- 能够及时得到反馈\n- 更容易控制和调整，灵活性好\n\n## 为什么要有任务\n\n人的精力是有限的，能力是有限的，比如如何把 一个大象吃掉，答案就是一口一口的吃。只有在个人能力以及精力可控范围之内，人才能把事情做好，从这点上也就是在承认人的弱势就是不擅长管理一个超出某个量级的事务，无论量级是体现在数量上还是复杂性上。\n\n因而必须要对大目标进行拆解形成可实践的任务，以实现目标的真正落地。\n\n目标和任务是要严格区分的，什么样的事情应该划为目标，什么的样是事情应该划为目标是严格遵守任务和目标的定义。\n\n## 如何拆解目标为任务\n\n**1.明确定义目标**\n只有一个清晰的明确的目标才能进行拆解\n\n**2.通过目标结果逆推实现的步骤**\n目标定义之后，就有了一个宏大的结果在未来等着，可以对照这个未来的目标结果进行实现的假设和推导。\n\n**3.记下推导的步骤**\n推导出的步骤一定要记下来。\n\n**4.对每个步骤也进行逆推导并记录步骤**\n\n**5.重复4的过程，以达到对目标拆解到至少3层**\n- 第一层步骤（目标的直接推导拆解）\n- 第二层步骤（目标拆解步骤的拆解）\n- 第三层步骤（目标拆解步骤的步骤的拆解）\n\n**6.停止拆解时已经可以看到具体可执行的动作了，此时我们称之为一个任务**","src/content/posts/target-process-result.mdx","aed4cd3fdcfac07b","target-process-result.mdx","tcp-timewait",{"id":1356,"data":1358,"body":1363,"filePath":1364,"digest":1365,"legacyId":1366,"deferredRender":22},{"title":1359,"summary":1360,"date":1361,"tags":1362,"group":1163,"featured":38},"从一次 TIME_WAIT 调优说起","## keep-alive 连接",["Date","2018-03-02T00:00:00.000Z"],[],"## keep-alive 连接\n\n在 http 1.0 中，如果客户端在发起请求时加入 `Connection:keep-alive` 首部，服务端在响应的时候也加入 `Connection:keep-alive` 首部，则此次 http 请求将使用持久连接，即请求结束之后 TCP 连接不会关闭以供后续请求继续使用。不难看出，持久连接必须是客户端和服务器都同时支持才可能会发生，因为 TCP 协议是双向通信。\n\n实现持久连接的 http 请求必须要保证报文可以正确判断起始和结束，这在 http 中是通过 content-length 首部以及 chunk 传输来保证的，具体可以参见《http 权威指南》“连接管理”章节，文章 [HTTP协议头部与Keep-Alive模式详解](https://www.byvoid.com/zhs/blog/http-keep-alive-header) 也对 keep-alive 作用和意义有详细介绍。\n\n\n总得来说利用 keep-alive 可有效利用 TCP 连接来提高 web 请求的性能。\n\n\n## 一般 web 服务的架构\n\n\n以简单的 Python web 服务为例，其架构组织如下：\n\n![](https://static.git-star.com/d36251e.jpg)\n\n其中 Python app 大多数是 web framework + gunicorn 的组合，gunicorn 是一个 web server。\n\n一个来自 user 的请求会经过如下处理用户最终才能获得响应：\n\n![](https://static.git-star.com/WX20180302-165435.png)\n\n其中 user 连接 nginx 的 TCP 和 nginx 连接 app 的 TCP 是不同的连接，也就是说要完成一个完整的请求 nginx 必须维系着自身与 user 和 app 两端的连接，nginx 作为代理会负责对 user 的请求进行中转处理然后发起与 app 的新的 TCP 连接，这就是 nginx 的角色。\n\n\n## 从线上后端 app 服务大量的 TIME_WAIT 说起\n\n默认情况下的，大多数现代浏览器以及其他 web 终端与 nginx 的连接默认都会开启 keep-alive，但是 nginx 与后端 app 则不一定。\n\n以我遇到的场景为例，在后端 app 服务所在的服务器，通过查看其和 nginx 端的连接通过 netstat 查看能够看到\n\n```\nnetstat -n | grep 10.10.93.110   | grep TIME_WAIT | wc -l\n```\n\n处于 TIME_WAIT 的 TCP 是 1000 多个，但处于 ESTABLISHED 是 20 多个，按照 TCP 协议的描述，具体见 [Transmission Control Protocol](https://en.wikipedia.org/wiki/Transmission_Control_Protocol)，处于 TIME_WAIT 的 TCP 连接在等待 2MSL 时间之后才会真正关闭，但是关闭之前其所占用端口和内存资源都不会释放，也就是说 TIME_WAIT 的变多说明服务器的处理能力会受到影响，甚至在极端情况下不响应。\n\nlinux 内核 MSL 是 60s，2MSL 就是 120s，每秒有 20 TCP 连接，假设响应时间很短，断开之后等待 2MSL，则 120s 之后差不多会有 1000 多个 TIME_WAIT，基本符合 TCP 的状态变迁。\n\n为什么后端 app 和 nginx 的连接会有如此多的 TIME_WAIT？\n\n\n## nginx 和 gunicorn 的默认配置\n\n默认 nginx 和后端 APP 的连接是短连接，即请求结束之后就会关闭，无论是 nginx 主动关闭还是后端 APP 主动关闭都会产生大量的 TIME_WAIT。\n\nGunicorn 作为一个 web server 已经很早就开始支持 keep-alive 了，在本文开始说过要保持持久连接，连接的两端都必须支持 keep-alive，所以这里我们主要修改 nginx 和上游 upstream 的连接来支持 keep-alive。\n\n\n## 修改 nginx 让 upstream  keep-alive\n\n在未修改 nginx 之前可以很明显看到\n\n```\nnetstat -n | grep 10.10.18.126 | grep ESTABLISHED | sort \n```\n后端 app 和 nginx 的连接中端口 nginx server 的端口一直在改变，修改 nginx 支持 upstream 的 keep-alive 之后，端口改变的频率降低，甚至一段时间内都不在变化，说明请求复用了连接。\n\nnginx 的 keep-alive 的支持需要在 upstream 配置 `keepalive 300;` 指令，并且在 location 中配置\n```\n    location /  {\n        proxy_http_version 1.1;\n        proxy_set_header Connection \"\";\n    }\n```\n告诉后端 app 请求支持 keep-alive。\n\n具体 keepalive 指令的理解详见[支持keep alive长连接\n](https://skyao.gitbooks.io/learning-nginx/content/documentation/keep_alive.html) ，尤其是需要注意对 keepalive 指令数量的控制，需要对 keepalive 有非常详细的了解。\n\n## 内核参数对 TIME_WAIT 的影响\n\n有很多内核参数决定了服务器 TIME_WAIT 在单位时间内产生的数量，比如\n- tcp_tw_recycle\n- tcp_tw_reuse\n- tcp_max_tw_buckets\n- net.ipv4.tcp_fin_timeout\n\n在配置服务器需要对不同内核参数进行特定场景的优化，为此就需要理解当前服务器的服务在整个 TCP 链接的角色和位置，比如是作为 client 还是 server。举例来说 nginx 对于下游用户来说是个 server，但是对于后端 app 来说是一个 client，nginx 扮演的角色的不同对其配置差异也很大。\n\n优化内核参数需要认真研读理论部分，仔细就行测验，在结合他人的实践经验针对自己的业务调整。详见\n\n- [服务器TIME_WAIT和CLOSE_WAIT详解和解决办法](https://www.cnblogs.com/sunxucool/p/3449068.html)\n- [再叙TIME_WAIT](https://huoding.com/2013/12/31/316)\n- [tcp_tw_recycle和tcp_timestamps导致connect失败问题](http://blog.sina.com.cn/s/blog_781b0c850100znjd.html)\n- [Android之网络丢包事件](http://www.litrin.net/2013/03/01/android%E4%B9%8B%E7%BD%91%E7%BB%9C%E4%B8%A2%E5%8C%85%E4%BA%8B%E4%BB%B6/)\n- [理解 Linux backlog/somaxconn 内核参数](http://jaminzhang.github.io/linux/understand-Linux-backlog-and-somaxconn-kernel-arguments/)\n- [TCP timestamp](http://perthcharles.github.io/2015/08/27/timestamp-intro/)","src/content/posts/tcp-timewait.mdx","9be3213516f56eba","tcp-timewait.mdx","technical-transformation-road-01",{"id":1367,"data":1369,"body":1374,"filePath":1375,"digest":1376,"legacyId":1377,"deferredRender":22},{"title":1370,"summary":1371,"date":1372,"tags":1373,"group":129,"featured":38},"现役司的技术转型之路","# 一、现状和治理思路",["Date","2018-04-25T00:00:00.000Z"],[],"# 一、现状和治理思路\n\n\n自从接手后端技术团队之后，面临的就是一个烂摊子，大小事故不断，新老人几乎没有衔接，导致大量业务代码逻辑无人知晓，架构设计没有办法追本溯源，比较长一段时间内都是急于救火，完全无暇顾及技术和管理，人员也是基本放任状态。\n\n在突击解决了几次线上面临的大事故之后，暂时摁住了故障频发的势头，让技术团队可以稍缓一口气，做一些早该进行的工作。\n\n## 现状描述\n\n整个后端技术团队支撑的是一组日活达百万的产品，包括各个公众平台，还包括一部分线下订单业务，涉及支付。现在面临的**外部状况**是：\n\n- 服务突发故障导致线下交易受阻，用户投诉\n- 业务需求压力过大，开发人员缺少，业务需求难以快速消化\n\n**内部状况**是：\n\n- 数百台服务资源利用和管理不善，忙的忙死，闲的闲死\n- 架构设计几乎是透明，导致新人无从摸索，出故障不能快速定位和解决\n- cache 服务、proxy 服务、nginx 服务、rpc 服务、注册和发现服务、异步任务服务、数据库服务彼此耦合严重，调用依赖非常混乱，变更困难，升级困难\n- 服务监控使用了多种监控手段，包括 glance、zabbix、munich \n- 异步任务存在多种技术选型，rq、beanstalkd、celery\n- 缓存集群使用多种技术选型，twproxy、codis、sentinel\n- 数据统计和存储使用多种技术选型，MySQL、MongoDB、hadoop、influxdb\n- 部署环境存在多种技术选型，walle、fabric、ansible\n- 服务以单体应用存在，无降级措施，无限流措施，一损俱损\n- 数十个 worker 单台机器部署，CPU 经常超负载\n- 几百个 crontab 任务\n- 同一业务代码散落的多个代码仓库改动升级困难\n- 等.....\n\n## 治理思路\n\n思维决定了行动，无思不行，行辅助思，从行中总结提升思维的高度和境界，思维反过来指导行为实践\n\n### 治理方式 from top to down\n\n公司业务使用的是云服务器，购买、新建、管理相对来说都非常方便，云厂商提供了类似业务**分组、标签、名称**等管理手段来管理服务器。为了让业务服务部署清晰，划分明了，首先从机器名称功能分组开始梳理，**保证机器的具有单一职责，方便动态扩容和管理**。\n\n功能和名称划分清晰之后保证业务开发人员能以**上帝视角审视所有服务以及它们之间的联系**。\n\n### 开放权限，人人参与\n\n为了让每一个开发者都能透彻了解它们开发、部署的服务以及运行状态，放开所有监控工具权限，放开云厂商的机器管理权限，让每一个人都能快速了解到部署的机器，也可以通过云厂商提供的监控及时了解机器的状态。\n\n开发者要能做运维，会做运维，运维必须要有开发者参与，此举才能保证 devops 理念的实践和落地\n\n### 定位问题，各个击破\n\n整理和梳理技术团队现在面临的每一个问题，按照优先级排序，逐个投入资源彻底解决，与其不断救火，不如集中力量完全消灭一处火源，逐步降低故障率。\n\n### 系统化所有日常工作\n\n[用系统来工作](http://www.duokan.com/book/62892) 这本书的作者详细阐述了如何自己从救火队长变成了每天只需工作一两个小时的高效能人士，作者的基本理念就是**把你所有的工作都系统化，让它们自己运转**，也就是把自动化上升到了一个新的高度，**系统化**。\n\n为了能最大效率的提升技术团队的效率和产出，在找到每一个问题并击破之后，就要想办法如何让每一个问题都演变成可以自己工作的小系统，小系统彼此联合形成一个更大的系统。\n\n\n# 二、机器的群组划分\n\n## 机器分组和命名\n\n上百台机器的规模在管理上如果没有合理的划分和规划，时间一长非常容易陷入混乱，比如\n\n- **难以评估现有业务规模和资源利用率**\n\n- **难以进行容量规划和动态扩容需要**\n\n- ...\n\n公司业务使用的 ucloud 云，ucloud 提供了**业务组（tag）和主机名称（name）**来表示机器，由此可以遵循 **from bottom to top** 的思路进行划分，即所有机器按照提供的基础功能进行划分，tag 表示其所提供的基础功能，name 表示具体的业务或者实现：\n\n![](https://static.git-star.com/WX20180426-120729.png)\n\n由此可以把所有机器按照这个思路划分为：\n\n- cache\n- nginx\n- MySQL\n- api\n- worker\n- devops\n- crontab\n- consul\n\n等不同的业务组（tag），每个业务组下面又根据具体的业务逻辑或实现进行命名，以 cache 为例，可以分为\n\n- codis-server\n- codis-proxy\n- redis\n- sentinel\n- twproxy\n- ssdb\n\n以后不论是机器扩容还是缩容都可以根据这些 tag 和 name 自动进行，然后再根据这些 tag 和 name 自动获取 ip，动态地在配置服务中心进行增减。\n\n## 动态生成各业务服务的快捷入口\n\n借助云提供的 API 可以非常方便的在跳板机生成所有服务器的快捷入口，动态的在跳板机实现对所有机器的快捷访问，生成类似快捷方式：\n\n```shell\nalias s_cache_redis_cache_20.235='ssh 10.10.20.235'\nalias s_cache_redis_cache_64.207='ssh 10.10.64.207'\nalias s_cache_redis_cache_29.166='ssh 10.10.29.166'\nalias s_cache_redis_cache_44.213='ssh 10.10.44.213'\nalias s_cache_redis_cache_95.237='ssh 10.10.95.237'\nalias s_cache_redis_cache_86.173='ssh 10.10.86.173'\n```\n\n# 三、资源隔离之域名拆分\n\n## 为什么执行域名拆分\n\n现在的团队支撑的所有业务都是通过同一个域名服务的，根据 URL PATH 的不同最终路由到不同的后端 APP\n\n| URL             | 业务                     | 备注          |\n| --------------- | ---------------------- | ----------- |\n| api.host.com/v1 | business logic 1 第一个版本 | 涉及支付，核心链路   |\n| api.host.com/v2 | business logic 1 第二个版本 | 涉及支付，核心链路   |\n| api.host.com/v3 | business logic 2 第一个版本 | 不涉及支付，非核心链路 |\n\n从以上表格不难看出，现有的域名设计方案，核心业务和非核心业务都是用同样的域名，也就是他们都是用的是**同一网关做出入口**，这样会导致的问题是：\n\n**由于非核心业务引起的流量突发会波及核心业务链路**\n\n非核心业务在一些热点事件或推送的影响下流量会在短时间激增，是平时业务 5 倍甚至更高，因此之前的团队为了应付这种情况做了动态的调整带宽包，每隔一分钟检测出口带宽的使用率，以避免因为出口带宽打满而引起业务不可用，但是这个解决方案仍然有几个问题：\n\n1. **带宽检测的有延迟，并不能在带宽打满的第一时间做出调整**\n2. **动态调整带宽包依赖与云厂商的相关服务，此前因为云厂商带宽调整服务不可用导致带宽调整失败**\n\n为了能够保证核心业务始终高可用，采取如下几个措施：\n\n第一，需要把各个业务**从域名开始彻底拆分，部署不同的网关**，由于核心业务带宽稳定，可以使用较高的基础带宽来保证业务的高可用，辅助以动态调整带宽预防突发情况。\n\n第二，非核心业务依然采用动态调整的带宽的方式，观测和预估流量的走向，在业务高峰发生之前提前调整，比如在推送发生时触发流量调整事件，在业务高峰的早 9 点和晚 9 点前后提前调整流量。\n\n## 划分域名的原则\n\n**域名拆分的原则是把具有相同功能 API 划分到同一域名之下，区分核心业务（支付、交易等）和非核心业务（资讯、用户消息、评论等），始终保证核心域名的网关可用。**\n\n为了保证域名拆分可以顺利推动和落地实践，需要 API 的使用方和制作方严格遵守同一套规范，即**对应功能要部署在对应的域名之下，对应的 API 的调用要使用对应的域名**。\n\n注意，同类型服务（比如服务于同一个客户端 APP）不要引入过多域名，过多域名不利于维护，根据自己的业务场景酌情划分。\n\n命名规则可以参考类似 consul 的域名命名规则：NAME.TAG.host.com，name 表示业务功能，tag 表示具体的应用，例如 order.app.host.com 和 news.app.host.com 。\n\n# 四、资源隔离之应用拆分\n\n>  域名拆分解决的是流量激增引起的主链路不可用的问题，而应用拆分是为了**杜绝故障引起的雪崩效应**\n\n## 单体应用的雪崩效应\n\n现在团队的服务是个独立的单体应用，无论消费方是内部应用还是外部 APP 最终都是路由到同一个后端服务，也就是所有的消费方**共享后端机器资源**，包括进程资源，这样的架构组织方式带来的问题是显而易见的：**由于单一应用引起的服务故障会波及所有服务消费方**。举例来说，由于设计不当，某些极端情况下，客户端 APP 会对服务器做重试请求，这些请求由于后端的处理不当演变成了**流量攻击**直接打垮所有后端服务，**由于进程未做隔离，后端服务打垮之后，其支撑的所有业务基本处于瘫痪状态，发生雪崩效应**。\n\n## 应用拆分部署\n\n之所以所有的服务都依赖共同的机器资源，很大程度上是因为原来的代码是**一个庞大的、各个模块耦合紧密的单体应用**，鉴于业务的复杂程度要把所有业务代码全部拆分短时间很难达成，但是可以把**各个业务分开部署，根据业务功能划分的不同的域名或 URL 路由到不同的后端 APP 以达到业务拆分的目的**。\n\n改造之前的 nginx 配置:\n\n```shell\nupstream rest_frontends {\n    # ip_hash;\n    keepalive 1200;\n    server ip1:19600 max_fails=1 fail_timeout=10s;\n    server ip2:19600 max_fails=1 fail_timeout=10s;\n    server ip3:19600 max_fails=1 fail_timeout=10s;\n    server ip4:19600 max_fails=1 fail_timeout=10s;\n\n    server ip5:19600 max_fails=1 fail_timeout=10s;\n    server ip6:19600 max_fails=1 fail_timeout=10s;\n    server ip7:19600 max_fails=1 fail_timeout=10s;\n    server ip8:19600 max_fails=1 fail_timeout=10s;\n    server ip9:19600 max_fails=1 fail_timeout=10s;\n}\n\n\nserver {\n    listen 80;\n    server_name api.host.com;\n\n    client_max_body_size 50M;\n    access_log  /data/log/nginx/rest.log api_access;\n    error_log  /data/log/nginx/rest_error.log;\n\n    location /volvo {\n        include /etc/nginx/martin_allow.conf;\n        deny all;\n        proxy_pass_header User-Agent;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Scheme $scheme;\n        proxy_next_upstream error timeout invalid_header http_502;\n        proxy_pass http://rest_frontends;\n    }\n\n\n    location /lotus {\n        proxy_pass_header User-Agent;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Scheme $scheme;\n        proxy_pass http://rest_frontends;\n    }\n\n}\n\n\n```\n\n\n\n改造之后的 nginx 配置：\n\n```shell\nupstream rest_frontends_volvo {\n    # ip_hash;\n    keepalive 1200;\n    server ip1:19600 max_fails=1 fail_timeout=10s;\n    server ip2:19600 max_fails=1 fail_timeout=10s;\n    server ip3:19600 max_fails=1 fail_timeout=10s;\n    server ip4:19600 max_fails=1 fail_timeout=10s;\n}\n\nupstream rest_frontends_lotus {\n    keepalive 1200;\n    server ip5:19600 max_fails=1 fail_timeout=10s;\n    server ip6:19600 max_fails=1 fail_timeout=10s;\n    server ip7:19600 max_fails=1 fail_timeout=10s;\n    server ip8:19600 max_fails=1 fail_timeout=10s;\n    server ip9:19600 max_fails=1 fail_timeout=10s;\n}\n\nserver {\n    listen 80;\n    server_name api.host.com;\n\n    client_max_body_size 50M;\n    access_log  /data/log/nginx/rest.log api_access;\n    error_log  /data/log/nginx/rest_error.log;\n\n    location /volvo {\n        include /etc/nginx/martin_allow.conf;\n        deny all;\n        proxy_pass_header User-Agent;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Scheme $scheme;\n        proxy_next_upstream error timeout invalid_header http_502;\n        proxy_pass http://rest_frontends_volvo;\n    }\n\n\n    location /lotus {\n        proxy_pass_header User-Agent;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Scheme $scheme;\n        proxy_pass http://rest_frontends_lotus;\n    }\n\n}\n\n```\n\n拆分之后，相当于各个业务功能的后端都是**相互隔离**的，即使某一业务导致后端服务故障，并不会波及其他业务。\n\n# 五、标准化\n\n> 标准化就是引入约束和规范，把各种流程借助对应的制度、工具等进规范化和自动化，尽量减少人为因素造成的故障或错误。\n\n## Git 仓库的标准化\n\n**收缩权限，统一各个项目的 owner**\n\n杜绝以私人身份建立仓库并上线，所有线上项目必须交由各自统一的 owner 进行建立、权限分配、部署和销毁。\n\n**统一分支开发模型**\n\n根据团队的实际情况采用合适的分支开发模型，强制所有成员必须严格按照分支模型进行仓库的管理，降低多人协作造成的混乱。\n\n**统一开发流程**\n\n核心项目全部采用 fork and pull request 开发流程，严格进行代码审核和测试、上线和回滚。\n\n## 环境的标准化\n\n为解决本地开发环境依赖服务过多的问题，搭建专有的 VPN 服务，使得可以在本地连接任意线上测试环境服务,并且统一线上环境、测试环境、本地环境的配置，能够非常轻松对本地任何项目进行开发和调试。\n\n## 部署流程的标准化\n\n简单项目采用 walle 等第三方部署工具部署，复杂项目使用 fabric 完成，为每一个 APP 统一部署流程：\n\n- SQL 检查\n- 表更新\n- 创建 release tag\n- 更新代码\n- 更新依赖\n- 执行 build\n- 重启服务 \n- 服务检测\n\n\n## 团队知识标准化\n\n建立团队知识体系，并且以工具形势进行落地，建立团队内部使用的 wiki 、技术业务文档等，方便新人快速熟悉业务和快速查找。\n\n\n## 故障定位标准化\n\n建立故障 checklist，方便任何不熟悉整套服务体系的人快速定位故障和解决问题","src/content/posts/technical-transformation-road-01.mdx","5a76581d8e893a37","technical-transformation-road-01.mdx","tornado-async-style",{"id":1378,"data":1380,"body":1386,"filePath":1387,"digest":1388,"legacyId":1389,"deferredRender":22},{"title":1381,"summary":1382,"date":1383,"tags":1384,"group":1385,"featured":38},"tornado 中的异步调用模式","## fundamental concepts",["Date","2017-02-08T00:00:00.000Z"],[],"tornado","## fundamental concepts\n\n### 同步\n调用者等待调用结果的返回\n\n### 异步\n调用者不等待调用结果的返回，而是通过间隔轮询、通知等方式得知结果\n\n### 阻塞\n调用方式影响后续指令的执行\n\n### 非阻塞\n调用方式不影响后续指令的执行\n\n---\n\n一般来说，阻塞是绝对的，非阻塞则是相对的，因为任何指令或调用的执行都要占用 CPU 周期，或网络，或 IO。非阻塞只是说调用或者资源消耗不影响后续逻辑执行，他们经得起等待。非阻塞往往和异步一起出现。\n\n[tornado](https://github.com/tornadoweb/tornado) 是一个异步非阻塞 httpserver，同时也是一个 web framework。\n\n> [Tornado](http://www.tornadoweb.org/) is a Python web framework and asynchronous networking library, originally developed at [FriendFeed](http://friendfeed.com/). By using non-blocking network I/O, Tornado can scale to tens of thousands of open connections, making it ideal for [long polling](http://en.wikipedia.org/wiki/Push_technology#Long_polling), [WebSockets](http://en.wikipedia.org/wiki/WebSocket), and other applications that require a long-lived connection to each user。\n\n在 tornado 中异步和非阻塞是通过 ioloop 和 Future 实现的，Future 是借助 python 的协程来实现非阻塞调用。tornado 提供了不同的异步调用形式来适配不同的调用场景，本文的目的就是为了说明不同形式是如何使用的以及它们的差别。\n\n为了演示方便，这里使用了一个公共模块 util.py 来提供 ioloop 的启动和销毁，下文不做特殊说明皆是如此。\n\n{/* more */}\n\n\n```python\n# util.py \nimport tornado.ioloop\n\nCOUNTER = 0\n\ndef stop_loop(times):\n    global COUNTER\n    COUNTER += 1\n    if COUNTER == times:\n        tornado.ioloop.IOLoop.instance().stop()\n        print('====> ioloop end')\n\n\ndef start_loop():\n    print('====> ioloop start')\n    ioloop = tornado.ioloop.IOLoop.current()\n    ioloop.start()\n```\n\n## 最常用的调用方式\n\n在 tornado 中最普遍的使用方式是把函数的调用结果封装成 Future，利用 ioloop 执行并异步获得结果。\n\n```python\n# -*- coding:utf-8 -*-\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado.concurrent import Future\nfrom tornado import gen\n\nfrom util import stop_loop, start_loop\n\n\n# fetch 返回的是 future\ndef asyn_fetch_future(url):\n    http_client = AsyncHTTPClient()\n    return http_client.fetch(url)\n\n\ndef asyn_fetch_future_callback(future):\n    result = future.result()\n    print('future_callback')\n    print(result.request.url, result.code, result.reason, result.request_time)\n    stop_loop(1)\n\n\nif __name__ == '__main__':\n    result_future = asyn_fetch_future('http://www.apple.com/cn/')  #1\n    result_future.add_done_callback(asyn_fetch_future_callback)\n    start_loop()\n```\n在 `#1` 处通过tornado 提供的异步 httpclient 获得一个 Future，为 Future 添加执行结果回调函数获得执行结果，Future 的执行结果也是一个 Future。\n\n输出结果如下\n\n```\n====> ioloop start\nfuture_callback\n('http://www.apple.com/cn/', 200, 'OK', 0.5546278953552246)\n====> ioloop end\n        0.71 real         0.06 user         0.06 sys\n```\n\n这种调用方式必须手动启动 ioloop 并在调用结束之后手动销毁 ioloop，想要获得调用结果必须为 Future 添加回调。\n\n## 只关心调用，不在乎结果\n\n有时候我们并不在乎函数的调用结果，只要函数正确执行即可，ioloop 提供了 spawn_callback 来执行这样的操作：\n\n```python\n# -*- coding:utf-8 -*-\nimport tornado.gen\nimport tornado.ioloop\n\nfrom util import start_loop, stop_loop\n\n\n@tornado.gen.coroutine\ndef divide(x, y):\n    return x / y\n\n\nif __name__ == '__main__':\n    # The IOLoop will catch the exception and print a stack trace in\n    # the logs. Note that this doesn't look like a normal call, since\n    # we pass the function object to be called by the IOLoop.\n    tornado.ioloop.IOLoop.current().spawn_callback(divide, 1, 0)\n    tornado.ioloop.IOLoop.current().add_timeout(\n        tornado.ioloop.time.time() + 1, stop_loop, 1)\n    start_loop()\n```\n\n借助 spawn_callback 可以直接执行函数调用，但是依然需要手动处理 ioloop 的开闭。\n\n## 一次性执行\n\nrun_sync 可以自动开启 ioloop 并在函数执行结束之后关闭 ioloop，此种调用在执行一次性操作时非常有用，比如要对数据库进行一次性修改：\n\n```python\n@tornado.gen.coroutine\ndef init_tag():\n    tb_tag = Tag() #1\n    for i in range(10):\n        result = yield tb_tag.insert({'name': random.choice('abcdefghjklpoiuytrewq')})\n        print(result)\n\n\nif __name__ == '__main__':\n    tornado.ioloop.IOLoop.current().run_sync(lambda: init_tag())\n```\n\n`#1` 是一个 [motor](http://motor.readthedocs.io/en/stable/) Mongodb collection，借助 run_sync 可以非常方便对数据库执行操作，由于run_sync 只接受一个参数，如果函数调用需要传参，可以把函数封装成 lambda。\n\n## 使用 callback*\n\n如果调用需要与 callback 函数进行交互，可以利用 gen.task\n\n```python\n# -*- coding:utf-8 -*-\nimport tornado.gen\nimport tornado.ioloop\n\nfrom util import start_loop, stop_loop\n\n\n@tornado.gen.coroutine\ndef call_task():\n    result = yield tornado.gen.Task(some_function, 1, 2)\n    raise tornado.gen.Return(result)\n\n\ndef fetch_coroutine_callback(future):\n    print('coroutine callback ==> ', future.result())\n    stop_loop(1)\n\n\ndef some_function(x, y, callback=None):\n    print('some_function called')\n    callback(x * y)\n\n\nif __name__ == '__main__':\n    future = call_task()\n    future.add_done_callback(fetch_coroutine_callback)\n    start_loop()\n```\n\n使用 gen.task 可以直接返回一个 Future ，被调用的函数会自动增加一个 callback 函数，用来在函数执行结束之后把结果进行回调通知。\n\n## 通过 threadPool 来调用阻塞操作\n\n```python\n#-*- coding:utf-8 -*-\nfrom tornado.concurrent import Future\nfrom tornado import gen\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom util import start_loop, stop_loop\n\n\nEXECUTOR = ThreadPoolExecutor(max_workers=4)\n\n\ndef fetch_coroutine_callback(future):\n    print('coroutine callback')\n    print(future.result())\n    stop_loop(2)\n\n\ndef sleep_func(t):\n    print('sleep_func call')\n    time.sleep(t)\n    return 'blocking func result'\n\n\n@gen.coroutine\ndef blocking():\n    result = yield EXECUTOR.submit(sleep_func, *(4, ))\n    raise gen.Return(result)\n\n\n@gen.coroutine\ndef not_blocking():\n    future = Future()\n    future.set_result('not blocking func result')\n    result = yield future\n    raise gen.Return(result)\n\n\nif __name__ == '__main__':\n    \"\"\"\n    用多线程的方式借助协程实现异步调用\n    \"\"\"\n    blocking().add_done_callback(fetch_coroutine_callback)\n    not_blocking().add_done_callback(fetch_coroutine_callback)\n    start_loop()\n\n```\n\n如果代码中有阻塞操作，可以借助 ThreadPoolExecutor 来完成异步的调用，这样把耗时的操作交给别的线程，可以使当前的线程继续执行后续的操作。这里的阻塞操作一般是 IO 或者其他系统调用。\n\n## 并行执行\n\ntornado 的 Future 是支持并行执行的，可以对多个 future 进行 yield 操作并返回多个结果。\n\n```python\n# -*- coding:utf-8 -*-\nfrom tornado.httpclient import AsyncHTTPClient\nfrom tornado.concurrent import Future\nfrom tornado import gen\n\nfrom util import stop_loop, start_loop\n\n\n@gen.coroutine\ndef fetch_many_coroutine(urls):\n    http_client = AsyncHTTPClient()\n    response1, response2 = yield [http_client.fetch(urls[0]), http_client.fetch(urls[1])]\n    raise gen.Return([response1, response2])\n\n@gen.coroutine\ndef fetch_coroutine(urls):\n    http_client = AsyncHTTPClient()\n    responses = yield [http_client.fetch(url) for url in urls]\n    raise gen.Return(responses)\n\n\ndef fetch_coroutine_callback(future):\n    print('coroutine callback')\n    for result in future.result():\n        print(\n            result.request.url,\n            result.code, result.reason, result.request_time)\n    stop_loop(2)\n\n\nif __name__ == '__main__':\n    \"\"\"\n    使用gen.coroutine 可以很方便让包含 yield 的函数返回future\n    \"\"\"\n    result_future = fetch_coroutine(['https://baidu.com', 'https://baidu.com'])\n    result_future.add_done_callback(fetch_coroutine_callback)\n    result_future = fetch_many_coroutine(['https://baidu.com', 'https://baidu.com'])\n    result_future.add_done_callback(fetch_coroutine_callback)\n    start_loop()\n\n\n```\n\n文中所有代码见 [tornado-asyn](https://github.com/zhyq0826/tornado-asyn)，欢迎指正。","src/content/posts/tornado-async-style.mdx","ec091034b41a160b","tornado-async-style.mdx","ticket-server",{"id":1390,"data":1392,"body":1398,"filePath":1399,"digest":1400,"legacyId":1401,"deferredRender":22},{"title":1393,"summary":1394,"date":1395,"tags":1396,"group":78,"featured":38},"发号器设计漫谈","本质上发号器解决的问题就是分布式环境之下 ID 的唯一性，但是由于不同的业务场景差异悬殊，发号器的设计也有很大的不同，而且由于很多互联网公司的业务数据都是用的关系数据库，因而需要 ID 是自增的数字以满足数据库索引的要求，比如数字对 MySQL 的索引 B+ 就很友好，本文就常见...",["Date","2019-03-11T00:00:00.000Z"],[1397,1390],"发号器","本质上发号器解决的问题就是分布式环境之下 ID 的唯一性，但是由于不同的业务场景差异悬殊，发号器的设计也有很大的不同，而且由于很多互联网公司的业务数据都是用的关系数据库，因而需要 ID 是自增的数字以满足数据库索引的要求，比如数字对 MySQL 的索引 B+ 就很友好，本文就常见发号器设计进行了详细的阐述和对比，希望对你有所帮助。\n\n\n## MySQL 发号器\n\nFlickr 在技术博客 [Ticket Servers: Distributed Unique Primary Keys on the Cheap](http://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-the-cheap/) 中透露了他们是如何设计发号器的，主要是利用了 MySQL 的自增技术。\n\n**如何用 MySQL 的自增来设计发号器？**要弄清楚这些问题，我们需要一点一点从 MySQL 的自增主键开始讲起。\n\n### last_insert_id() 函数\n\n我们先在 MySQL 中创建一个带自增列的表，基于Innodb 引擎：\n\n```sql\nCREATE TABLE `test_auto_increment` (\n  `id` bigint(11) unsigned NOT NULL AUTO_INCREMENT,\n  PRIMARY KEY (`id`)\n)\n```\n\n然后再插入几条数据：\n\n```sql\ninsert into `test_auto_increment` (id) values (0);\ninsert into `test_auto_increment` (id) values (0);\n```\n\n执行这条语句：\n\n```sql\nselect LAST_INSERT_ID();\n```\n\n在我的机器上这条语句返回的是 2，也就是插入两条数据之后 auto_increment 列的值。last_insert_id() 这个函数在不带参数的情况下，返回的是一个 64 位无符号整数，**表示在 MySQL 中最近的一次执行 Insert 语句时 auto_increment 列产生的值**，注意是**最近**，也就是说如果我们再创建一个表，插入数据之后再执行这个函数，结果就会发生变化，如果没有执行过任何 insert 语句，那么多次执行这个函数结果是一样的。\n\n**需要注意的是当前执行的 insert 语句不会对 last_insert_id() 函数产生影响**，比如说通过在 insert 语句中引用 last_insert_id 函数，last_insert_id 的返回值也是**这条 insert 语句上次的 insert** 产生的递增的值。\n\n```sql\ninsert into test_auto_increment select LAST_INSERT_ID();\n```\n\n**在 MySQL 中，last_insert_id() 产生的值实际上是 MySQL server 维护在每个 connection 上的 ，这就意味着不同的 client 的看到返回值是不同的，他们看到的都是最近通过他们自身的 session 执行的 insert 语句产生的自增值，对其他的 client 没有影响**。\n\n### 获取最新的一个自增值\n\n我们的目的是设计发号器，由于只有 insert 语句才会产生一个自增值，也就是我们想要获得一个自增的值必须先要插入一条数据，然后想办法获得该值。上面我们已经创建了一个带自增列的表，于是想要获得一个自增的主键我们可以在同一个 session 中执行下面的操作：\n\n```sql\ninsert into `test_auto_increment` (id) values (0);\nselect LAST_INSERT_ID();\n```\n\n到现在为止，设计一个全局唯一的发号器好像已经完成了。Anybody and any question？😁 这位优秀的同学有话要说：虽然全局唯一的发号器的目标已经达到了，但是无形之中 insert 语句会产生很多无用的数据，比如像 flick 一秒钟要上传 60 张图片，还不包括其他元数据，一天也要产生 500 万的数据量，一个月就要 1.5 亿数据，很快这个发号器的表就会变得很大。这个问题提的很好，我们来一起思考一下如何解决发号器表数据量过快增长的问题。\n\n### 防止自增表数据过大\n\n由于 insert 语句会不断产生数据，那有没有一种办法既可以让自增键不断得增长，还能让数据量不至于过大呢？有几种办法。\n\n1. 由于我们只关心自增的值，表中已经产生的数据是没有意义的，可以定时进行清除。\n2. 由于我们只关心自增的值，获得自增的数据之后，原来的值就可以顺手删除了，实时清除无意义数据。\n3. **利用 MySQL 提供的 REPLACE 语句**\n\n方法 1 和 2 本质上是一样的，都是需要开发者自己去处理，但是 3 利用了 MySQL 的特性 [replace](https://dev.mysql.com/doc/refman/8.0/en/replace.html)，更便捷。要想利用 replace 语句需要我们对之前的表结构做一下变更，新增一个具有唯一性索引的字段：\n\n```sql\nalter table test_auto_increment add column stub int unique key;\ndelete * from test_auto_increment; //清楚之前产生的数据\n```\n\n**这里的唯一性的索引是必须的，因为 replace 的原理是先删除具有相同主键或唯一性索引的行，然后再插入新的行**。改变之后再执行下面的语句，表的数据不再增长：\n\n```sql\nreplace into `test_auto_increment` (stub) values (2019);\nSELECT LAST_INSERT_ID();\n```\n\n### 高可用的发号器\n\n我们已经通过 MySQL 的自增设计了可以满足需求的发号器，但是我们的发号器是单点的，只能用一个 MySQL 实例来发号，一旦 MySQL 故障就发号器就不可用了。我们需要一个高可用的发号器架构来消除单点的问题。\n\n幸运的是 MySQL 提供了 [auto_increment_increment](https://dev.mysql.com/doc/refman/8.0/en/replication-options-master.html#sysvar_auto_increment_increment) 和 [auto_increment_offset](https://dev.mysql.com/doc/refman/8.0/en/replication-options-master.html#sysvar_auto_increment_offset) 。原本 auto_increment_increment 和 auto_increment_offset 为解决 MySQL master-master 架构中 auto_increment 冲突的问题，这两个变量在 MySQL 中既可以在全局中设置，也可以在具体的一个 session 中更改，他们具体的值是 1~65535，接下来我们详细阐述他们对 auto_increment 的影响。\n\n**auto_increment_increment** 这个变量控制的是自增列的 interval，查看 MySQL 的默认设置：\n\n```shell\nmysql> show variables like 'auto_inc%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 1     |\n| auto_increment_offset    | 1     |\n+--------------------------+-------+\n2 rows in set (0.00 sec)\n\nmysql>\n```\n\n然后我们把这个值改为 10：\n\n```mysql\nmysql> SET @@auto_increment_increment=10;\nQuery OK, 0 rows affected (0.05 sec)\n\nmysql> show variables like 'auto_inc%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 10    |\n| auto_increment_offset    | 1     |\n+--------------------------+-------+\n2 rows in set (0.00 sec)\n\nmysql>\n```\n\n然后我们创建一个表进行测试并且插入一些数据：\n\n```mysql\nmysql> CREATE TABLE `test_auto_increment2` (\n    ->   `id` bigint(11) unsigned NOT NULL AUTO_INCREMENT,\n    ->   PRIMARY KEY (`id`)\n    -> );\nQuery OK, 0 rows affected (0.31 sec)\n\nmysql> INSERT INTO test_auto_increment2 VALUES (0), (0), (0), (0);\nQuery OK, 4 rows affected (0.14 sec)\nRecords: 4  Duplicates: 0  Warnings: 0\nmysql> select * from test_auto_increment2;\n+----+\n| id |\n+----+\n|  1 |\n| 11 |\n| 21 |\n| 31 |\n+----+\n4 rows in set (0.00 sec)\n\nmysql>\n```\n\n可以看到自增列的值间隔是 10。\n\n**auto_increment_offset** 这个变量决定了自增列的起始值，接着在刚才我们打开的 session 中设置这个值：\n\n```mysql\nmysql> SET @@auto_increment_offset=5;\nQuery OK, 0 rows affected (0.02 sec)\nmysql> show variables like 'auto_inc%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 10    |\n| auto_increment_offset    | 5     |\n+--------------------------+-------+\n2 rows in set (0.00 sec)\n```\n\n然后插入一些数据查看变化：\n\n```mysql\nmysql> INSERT INTO test_auto_increment2 VALUES (0), (0), (0), (0);\nQuery OK, 4 rows affected (0.29 sec)\nRecords: 4  Duplicates: 0  Warnings: 0\n\nmysql> select * from test_auto_increment2;\n+----+\n| id |\n+----+\n|  1 |\n| 11 |\n| 21 |\n| 31 |\n| 45 |\n| 55 |\n| 65 |\n| 75 |\n+----+\n8 rows in set (0.00 sec)\n\nmysql>\n```\n\n可以看到自增列接下来的值变成 45、55、65、75，实际上 MySQL 是根据下面的公式计算自增列的值：\n\n```python\nauto_increment_offset + N × auto_increment_increment\n```\n\nN 是 正整数，新行插入产生的自增值都会比已经存在的自增值要大，则根据上面的规则应该是 5 + N * 10 = [10, 15, 25, 35, 45,...]，根据上面的计算规则 MySQL 的官方给出的答案是 35，但是实际上 5.7.6 版本中则是从 45 开始的，具体原因我猜测因为 auto_increment_increment 规定了 interval 必须要是 10，而如果是从 35 的话，35 和 31 的 interval 就不是 10 了 ：）。\n\n既然可以通过 auto_increment_increment 和 auto_increment_offset 控制步长和起始值，那么我们就可以利用这个特性来水平扩展我们的发号器。\n\n![](https://static.git-star.com/mysql-ticket-server.jpg)\n\n如图所示，发号器从一台扩展到 2 台，再扩展到 4 台，每次扩展我们都需要重新改变 offset ，调到一个比之前已经生成的 id 更大的值，并且调整 increment 为扩展的发号器数量，这样才能保证新扩展之后的发号器不冲突。\n\n不难看出基于 MySQL 的发号器有一个很大的问题：**扩展麻烦，每次扩展都需要调整步长和初始值，而且为了达到性能要求只能水平加 MySQL 机器**。\n\n## Twitter Snowflake \n\nTwitter 在 2010 年开源了一个全局 ID 生成器的算法叫 Snowflake，如图所示：\n\n![](https://static.git-star.com/snowflake.jpeg)\n\n该算法用一个 64 位整数来表示唯一性 ID，64 按照不同的段位进行划分：\n\n1. 首位 1 bit 不用，固定是 0 ，由于计算机中正数的最高位是 0，ID 是正数\n2. 41 位表示时间戳，精确到毫秒，这 41 位可以表示的数字范围是 0 ~ 2^41-1，这里只需要无符号数，也就是说如果从某个时间戳开始算起，这 41 位能够容纳的最长时间是 (2^41-1) / 1000*3600\\*24\\*365 ≈ 69 年\n3. 10 位工作机器 id，可以根据业务需要把这 10 位用作机器节点 id 或者数据中心 id，比如有 3 个数据中心就可以留 2 位出来，剩下的作为机器节点 id。\n4. 12 位序列号，可以表示 2^12-1 = 4095 个整数，表示同一时间戳能产生的所有序号。\n\nsnowflake 算法理论上每秒可以产生 4095*1000 个 id，能够满足很大的业务量需求，相比使用 MySQL 的自增进行发号，这个**算法容易实现，水平扩展方便，只要保证扩展之后的 10 位工作机器 id 是唯一即可**，需要注意的是由于算法依赖机器的时间戳，如果机器的时间戳发生过回拨，也就是回退到之前的某个时间可能会导致 id 重发。\n\nsnowflake 算法的具体实现可以参考如下文章：\n\n- https://juejin.im/post/5a7f9176f265da4e721c73a8\n- https://segmentfault.com/a/1190000011282426\n\n## 美团点评的 Leaf 方案\n\n前段时间美团开源了自家的分布式 ID 生成方案 Leaf https://github.com/Meituan-Dianping/Leaf ，其在博客文章 https://tech.meituan.com/2017/04/21/mt-leaf.html  谈过其设计思路，大致如下。\n\nLeaf 是基于 MySQL 的分布式 ID 生成方案，但是不同于使用 MySQL 自增的方式，Leaf 做了改良：\n\n1. 由于 MySQL 自增方案中每做一次发号就要写一次数据库，在并发量大的情况下，MySQL 压力太大，**Leaf 每做一次发号不是发一个号，而是发一个号段，比如 1 ~ 1000 这个号段，这样可以大大减少 MySQL 写的压力**\n2. 通过调整步长和初始值来进行水平扩展非常复杂，难以精确控制，**Leaf 为不同业务（通过 tag 区分）定义了不同的号段长和初始值，每个业务获取 ID 都相互隔离，互不影响**\n3. Leaf 不是直接从 MySQL 中获取 ID，而是通过 proxy，**proxy 会把从 MySQL 获取的号段做缓存，有了 proxy 之后如果需要对发号器进行扩展，直接扩展 proxy 并且多分配一些号段即可，不需要变更 MySQL**\n\n整个 Leaf 的架构如下：\n\n![](https://static.git-star.com/meituan-leaf.jpg)\n\n其中 MySQL 的表定义了：\n\n| Filed       | type         | comment |\n| ----------- | ------------ | ------- |\n| biz_tag     | varchar(128) | 业务 tag  |\n| max_id      | bigint       | 已发号的最大值 |\n| step        | int(11)      | 号段长     |\n| desc        | varchar(256) |         |\n| update_time | timestamp    |         |\n\n具体业务实现以上图 `test_tag` 为例，比如 proxy-2 节点上没有 test_tag 的号段，然后需要从 DB 更新号段，更新号段就是把 test_tag 对应的 max_id 增加一个步长：\n```mysql\nBegin\nUPDATE table SET max_id=max_id+step WHERE biz_tag=test_tag\nSELECT tag, max_id, step FROM table WHERE biz_tag=test_tag\nCommit\n\n```\n\n变更之后 test_tag 的 max_id = 4000，之后每个 proxy 如果号段消耗完成就又以这种方式获取。\n\n除此之外 Leaf 还针做了如下优化：\n\n第一，如果 proxy 特别多，有可能会有多个 proxy 会在同时获取同一个 tag 的号段，这会导致 DB 有短时间的卡顿 proxy 更新号段线程发生阻塞从而影响发号。因而 Leaf 在 proxy 做了预更新机制，也就是在号段消耗约 10% 左右就开始更新下一批号段，并且 Leaf 中号段的长度是峰值 QPS 的百倍之多，这样能让 DB 即使出现短暂故障也不会影响发号。\n\n第二，Leaf 的 DB 采用一主多从的方式部署，同时分机房，并且 DB 的主从切换采用 https://github.com/Meituan-Dianping/DBProxy 保证了 Leaf 服务的高可用\n\n**Leaf 这种架构能够做到**：\n\n- Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。\n- ID号码是趋势递增的 8 byte的64位数字，满足主流关系型数据库存储的主键要求。\n- 容灾性高：Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。\n- 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来\n\n由于 Leaf 是通过递增号段的方式发号，很容易让竞品根据号段猜出一些商业数据，Leaf 根据 snowflake 做了改进设计了 Leaf-snowflake， 并且使用 zookeeper 同步 Leaf-snowflake 服务的时间戳以及 worker id 来解决由于机器时钟回拨和节点变更的问题，详细可以见 https://tech.meituan.com/2017/04/21/mt-leaf.html \n\n## MongoDB ObjectID \n\nMongoDB 的 ObjectID 也是一个可以在分布式环境之下使用的唯一性 ID，并且他是根据它的生成规则可以轻松在 client 端生成，这样 ID 的开销就转移到了 client 端。\n\nObjectID 总共有 12字节分别是：\n\n- a 4-byte value representing the seconds since the Unix epoch 时间戳\n- a 5-byte random value  随机值\n- a 3-byte counter, starting with a random value 计数器\n\nMongoDB 的 ID 带有时间戳信息，可以推断出生成 ID 的时间，而且这个 ID 也是趋势递增的，在客户端生成速度快是他的优势。MongoDB 的 ObjectID 结合 MongoDB 的环境使用最高效，有些场景可以替换 UUID 来用。\n\n## UUID\n\nUUID(Universally Unique Identifier) 标准型式包含 32 个 16 进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符，示例：`550e8400-e29b-41d4-a716-446655440000`，到目前为止业界一共有5种方式生成UUID，详情见IETF发布的UUID规范 http://www.ietf.org/rfc/rfc4122.txt 。\n\nUUID 比 MongoDB 的 ObjectID 还要长，占用 16 字节，不易于在类似 MySQL 这样的系统中存储检索，由于在客户端生成，效率很高，但是依赖于客户端的 MAC 地址，有暴露 MAC 地址的风险，\n\n## 小结\n\n行文至此，我们一起来分析总结一下几种发号方案的优缺点。\n\n#### 方案一，MySQL 自增\n\n**优势**：实现简单，能够应付大部分场景，易于存储索引\n\n**缺点**：水平扩展复杂，数据库在并发场景高的场景下压力大\n\n#### 方案二，snowflake 算法\n\n**优势**：实现不算复杂，水平扩展容易，并发量大，能够应付绝大数业务场景，趋势递增，易于存储索引\n\n**缺点**：依赖于时间戳，机器时间回拨会导致 ID 重复发送\n\n#### 方案三，MongoDB ObjectID\n\n**优势**：client 端生成，速度快，效率高，配合 MongoDB 在分布式环境中使用，自带时间戳，一些场景可以替换 UUID\n\n**缺点**：不利于 MySQL 这样的关系型数据库存储索引\n\n#### 方案四，UUID\n\n**优势**：client  端生成，效率高\n\n**缺点**：太长，不易关系型数据库存储索引，有一定的安全风险\n\n## 开源实现\n\n以上方案的部分开源实现：\n\n- https://github.com/Meituan-Dianping/Leaf\n- https://github.com/baidu/uid-generator\n- https://github.com/edwingeng/wuid \n- https://github.com/bwmarrin/snowflake","src/content/posts/ticket-server.mdx","2b45651af511c2de","ticket-server.mdx","turbo-motor",{"id":1402,"data":1404,"body":1410,"filePath":1411,"digest":1412,"legacyId":1413,"deferredRender":22},{"title":1405,"summary":1406,"date":1407,"tags":1408,"group":1409,"featured":38},"让 turbo 支持异步调用 MongoDB","turbo-motor 是为了支持 turbo 异步调用 MongoDB而实现的，完全兼容 turbo ORM 层的 API，并且封装了 motor 这一支持在 tornado 中异步调用 MongoDB 的库。",["Date","2018-04-11T00:00:00.000Z"],[],"turbo","[turbo-motor](https://github.com/wecatch/turbo-motor) 是为了支持 turbo 异步调用 MongoDB而实现的，完全兼容 turbo ORM 层的 API，并且封装了 [motor](https://motor.readthedocs.io/en/stable/tutorial-tornado.html) 这一支持在 tornado 中异步调用 MongoDB 的库。\n\n由于 motor 是异步执行，这就需要在 turbo 的 handler 中，其实也就是 tornado 的 web.RequestHandler 中要进行异步，像这样：\n\n```python\nclass AsynHandler(BaseHandler):\n\n    @tornado.gen.coroutine\n    def get(self):\n        result = yield user_model.Tag().find_many(limit=10)\n        self.render('tag.html', result=result)\n```\n\n异步的装饰器 `@tornado.gen.coroutine` 必不可少，在这里 Tag 这个 model 是一个使用 turbo_motor 提供的封装了 motor 调用的 model，实现它也很简单：\n\n```python\nclass Tag(MotorModel):\n\n    \"\"\"\n    name: tag name\n    atime: added time\n    \"\"\"\n    name = 'tag'\n\n    field = {\n        'name': (str, ''),\n        'atime': (datetime, None),\n    }\n```\n\n其中 MotorModel 是 [turbo_motor.model.BaseModel](https://github.com/wecatch/turbo-motor/blob/master/turbo_motor/model.py#L14) 的子类，它实现了异步调用 MongoDB 所有的 API。\n\n如上所述，想在 turbo 的应用中使用 motor，只要引入 turbo_motor 这个插件即可，然后应用的 handler 处理方法写成异步的。\n\n完整示例参考 turbo 提供的 demo 中的 [AsynHandler](https://github.com/wecatch/app-turbo/blob/master/demos/app-server/apps/app/app.py#L22)","src/content/posts/turbo-motor.mdx","e9c60cbbb7f1416c","turbo-motor.mdx","understand-architecture",{"id":1414,"data":1416,"body":1421,"filePath":1422,"digest":1423,"legacyId":1424,"deferredRender":22},{"title":1417,"summary":1418,"date":1419,"tags":1420,"group":78,"featured":38},"理解架构这件事","在软件的开发演进过程中，都会涉及软件的架构，那软件架构究竟是指什么？在软件的整个生命周期中又都包含什么样形式的软件架构？它们的作用又是什么？什么样的角色和团队要为这些架构负责？带着这些问题我们一起聊聊软件架构这些事。",["Date","2021-11-21T00:00:00.000Z"],[161],"在软件的开发演进过程中，都会涉及软件的架构，那软件架构究竟是指什么？在软件的整个生命周期中又都包含什么样形式的软件架构？它们的作用又是什么？什么样的角色和团队要为这些架构负责？带着这些问题我们一起聊聊软件架构这些事。\n\n## 什么是架构\n\n架构的本意是指结构以及结构之间的关系，而作为动词的架构就是指根据需求、目标、问题场景等所做出的一些列符合要求的设计决策，换句话说**架构就是做设计决策**，但是软件开发本身就是一个不断设计的过程，所以才有开发一个软件其实就是在做 software design 的说法，那是不是就可以说软件设计就是软件架构？这样的说法并不正确。\n\n要解决一个问题，可能会设计出101种解决方案，但并不是设计所有这些解决方案时都可以称之为架构，因为最终你会根据多种因素比如时间、金钱、团队技术水平等只选择其中的一种方案，而你**做出这种潜在选择的设计决策就是架构**。\n\n不难理解，所有的架构的都是设计，但是并非所有的设计都是架构，架构反映的是让一个系统成型的重要设计决策，决策的重要性是通过改变的成本来衡量的。架构的这种定义决定了架构几乎存在于软件开发的方方方面面，比如网络架构、数据架构、解决方案架构、安全架构等等。\n\n## 架构的种类\n\n架构和决策有关，因而架构的种类划分会根据决策的问题场景不同而不同，按照软件开发的生命周期可以分为：业务需求架构、产品功能架构、应用系统架构、应用程序架构。\n\n### 业务需求架构\n\n业务需求架构发生在业务需求提出的阶段，这个阶段的处于软件开发的最早期，此时开发者对于要解决的问题可能根本还不了解，甚至提出需求的人也未必真的能把问题讲清楚，说明白。因此这一阶段最重要的就是梳理业务需求和业务流程，为产品提供明确可被解决一个个业务问题。\n\n**业务需求架构**就是在软件开发的初期，罗列业务需求，提取业务问题，梳理业务流程，明确业务价值以做出合理的业务规划。\n\n### 产品功能架构\n\n明确了业务需求，就需要设计解决业务问题的产品，产品有什么的样的功能，各个功能之间的关系是什么，业务流程是如何通过产品提供的的功能完成的，这些都是产品功能架构要解决的问题。\n\n**产品功能架构**就是设计产品所具有的所有功能模块以及各个模块之间的关系，将它们按照合理的层级、关系进行梳理组织，形成具有完整性的产品结构。\n\n### 应用系统架构\n\n一般来说，应用系统架构是更大规模的应用程序的集成与架构，系统架构会横跨多个应用程序，并且应用程序之间有明显的边界和职责划分，甚至还包括硬件，系统架构关注的是应用程序之间如何集成、关联、调用，在系统架构中，不会特别关注单个应用程序的技术细节，除非这些技术细节影响了系统之间的集成。系统架构中经常会涉及非功能性需求，比如审计要求、系统的构建和发布形式、系统的可伸缩性、可用性要求、安全性要求等等。\n\n**应用系统架构**就是具有不同能力和职责的应用程序之间的结构、层次、关系的划分和集成，系统架构要求在更高层次上描绘应用程序之间的关系，并且需要考虑很多非功能性需求。\n\n### 应用程序架构\n\n应用程序架构是大多开发者所熟知的设计应用程序所涉及到的技术架构，因为其本身就是关于编程语言选择、代码模块划分、API 设计、框架选择、命名规范、函数设计、错误处理、设计模式、单元测试等一系列技术细节的选择、约束、规范。\n\n**应用程序架构**就是应用程序的技术架构，这将是软件开发和软件生命周期中最细粒度的架构，应用程序的架构好坏直接决定了软件代码的质量、可维护性和可扩展性，应用程序架构几乎涉及到的技术开发的所有细节。\n\n## 谁该为架构负责\n\n现在，我们知道了架构就是设计决策，软件开发又包含：业务需求架构、产品功能架构、应用系统架构、应用程序架构，那谁该为这些架构做出正确的设计决策？可能大多数读者的第一反应是该架构师上场了，是的，此时需要架构师来干活了。但是什么样的角色适合做这些架构，技术、产品、提出需求的人还是项目经理 ？\n\n绝大多数**业务需求架构**设计都免不了会受到技术成本、市场因素等客观条件的约束，要能设计出满足诉求人合理业务需求的架构，需要决策者对能对各种综合性因素做出考量，包括但不限于技术、市场、金钱、团队构成等，这就要求决策者必须是能理解需求、了解市场、熟悉技术、知道团队构成，这就是业务需求架构的人选要求。\n\n有了业务需求架构的输入，设计**产品功能架构**可以说软件开始进入落地阶段了，以笔者的理解，这就是大多数产品经理角色的能力范围。\n\n应用系统架构和应用程序架构很显然是属于技术的范畴了，这也是我们通常意义上所说的架构师所负责的领域范围，负责技术架构的人一般被称之为**软件架构师**。\n\n## 架构师的角色应该如何扮演\n\n很明确的说，架构师是一种角色而不是一个职位或是某个人，因为担当角色的可能不只是某个人，也可能是一个团队，这个角色需要扮演以下职责才能发挥他的作用。\n\n### 理解需求，明确目标\n\n这个角色首先需要理解需求，理解最终产品是什么，以及产品所要达成的目标是什么，除此之外，对于软件所要满足的非功能性需求，比如性能、伸缩性、可靠性、安全性等也要保持关注。\n\n### 设计软件\n\n软件是设计出来的，软件的设计过程包含很多的技术细节，技术选型如何做？如何选择合适的框架和数据库？是否应该包含 ORM 框架？编码规则是什么？如何测试软件的正确性？代码质量如何保证？这些都是软件设计要关注的，但远远不止这些。\n\n### 预估风险\n\n设计成功的软件可能很难，但是想要它失败却很容易。软件的设计开发过程中隐含着种种风险，尤其是在交付日期逼近，很少有人会真正关注软件是否真的会以设想的方式工作，架构师这个角色必须要承担这种风险管理职责，确保软件的交付是正确的。\n\n在做技术决策时需要审慎评估和选择，例如如果你的业务非常复杂，对灵活性要求很高，这个时候选择一个大而全的ORM框架就要三思，越大越全，也意味着灵活性的缺失，最终会导致架构的僵化，难以扩展和变动。笔者曾亲见过，有团队把引入 Django 的 ORM作为团队的主要 ORM 框架，从而最终导致公司在上市审计时候做出变动非常困难，如果系统对稳定性要求很高，引入一个未经考验的组件可能就是个风险点，笔者所在的团队就曾经历过采用 Istio 这个网关新星而失败。\n\n### 架构演化\n\n没有一成不变的软件，软件生命周期的绝大部分时间都在维护和改动，同理也不应该有一劳永逸的架构，没有架构会在设计之初一下子就把将来所有的可能性都覆盖，**软件架构是在软件开发的维护过程中随着需求的变化而不断演化的**，问题需求决定了架构的设计，反过来架构设计又决定了软件的开发效率和质量，架构发生演化的另一个因素就是**开发团队的反馈**，架构师因而要根据软件需求的变化和团队的反馈应时调整，**应时**的含义是说**不应该过早也不应该过晚**进行调整。\n\n### 参与开发\n\n笔者见过很多架构师从来不写代码，这和厨师从来不吃自己做的饭没有任何区别，架构师不参与开发就不能亲身检验自己的设计是否合理，完全交由开发团队很难保证最终的架构设计可以被成功塑造，架构师有义务通过主动参与开发来引导开发团队落地架构实践。\n\n既可以参与实际编码，又能够做出重要的设计决策，要求架构师能够做到在底层技术细节和架构大局之间灵活切换，做架构师真的好难，既要又要，因而不是人人都能成为架构师。\n\n### 质量保证\n\n好的架构不一定会让软件最终成功交付，但是差的软件质量一定会让软件交付失败，因此架构师保证软件的质量至关重要。质量保证不仅仅是代码评审，架构师需要在架构实践中引入合适的设计原则、编码标准、测试基线等来保证架构的质量。\n\n## 如何成为一个合格的架构师\n\n知道了架构师应该扮演的角色，那该如何成为可以成功扮演这些角色的架构师。毕竟有种说法是“人人都是架构师”，其背后的含义好像是说不成为一个架构师都不能称之为人了，因而成为架构师对“作为一个人真”的是至关重要。\n\n### 平衡技术深度和广度\n\n毋庸置疑，架构师需要掌握很多的技术知识，且需横跨多个领域，这是对架构师技术能力的硬性要求。广则不深，专则难以广，架构师需要在广度和深度之间适度权衡，有的放矢，听上上是正确的废话，但是真的很管用。没有广度，很难预知架构面临的风险，风险可能来自任何地方；没有深度，无法保证在架构演化过程中可以及时做出影响全局的重要技术决策，细节往往决定成败。\n\n### 学习领导力，建立影响力\n\n领导力和影响力是架构师需要必须要具备的重要品质，而影响力的建立是一个非常长期的结果，这通常和架构师自身的技术能力过硬有关，更和架构师善于倾听他人的想法，并做出合理回应有关。架构师不仅仅是要善于处理一堆技术问题，更是一个团队的润滑剂和教练，他需要为团队创建一个共同的目标，并且积极带领团队为之付出努力。软件架构不仅关乎技术，还关乎人，有团队的地方就有情绪、政治、利益，架构师就是需要在满足大多数人利益的情况下，还能让团队成员保持着积极面对问题的热情，这就是领导力。\n\n### 学会控制和放权\n\n架构需要约束，约束就是需要控制，控制什么，什么时候控制，都是架构师要掌握的，可能架构师没有人事豁免的权力，但是技术决策上应该有决定权。控制总会让人不爽，控制是为了保证架构正确落地和质量，但是控制一定程度上也会导致开发效率降低。如果控制的范围过大，控制的数量过多，常常会适得其反，让开发团队产生抵触情绪，控制的范围太小，可能起不到促进架构演化的作用。如何决定？**保留架构师的技术裁决权，适当放权给团队**，划定可一定时间内执行落地的范围，和团队达成一致，比如约束命名规范，和团队协商对命名约束达并成一致，借助 IDE 工具快速让命名规则在已有代码库中保持统一，并保证可以持续在后续的编码中落地。**快速让已经存在的命名保持统不仅践行了架构实践，也让团队认识到这种约束的真正意义，协商一致可以你让团队成员都遵守共同的承诺**。\n\n技术的裁决权为什么重要？在很多关键时刻，**独裁可能才是解决问题的最佳形式**，并不是所有人都有勇气打破常规做出一些正确但是当时团队又无法理解的技术决策。\n\n### 做好抽象，关注细节\n\n架构师需要知道在什么时候关注抽象，什么时候关注细节，过度的抽象可会导致细节藏的太深，架构无法揭示软件实际的面貌，细节太多也会让软件缺乏架构的指导，让架构失去作用。关注抽象需要有大局观，关注细节需认识抽象的局限。更多的抽象的，意为更多的理解成本，更多的细节意味着又会导致难以扩展和维护。架构师需要在二者之间做出平衡。\n\n\n\n---\n\n\n\n成为架构师的途径看似有点虚无缥缈，还充斥着正确无比的大道理，就好像听了很多道理依然过不好生活一样，实践才是检验大道理的唯一标准，你需要在团队中做一次架构来开始架构师之路。","src/content/posts/understand-architecture.mdx","eb9dc44b9a21d097","understand-architecture.mdx","understand-react-2",{"id":1425,"data":1427,"body":1432,"filePath":1433,"digest":1434,"legacyId":1435,"deferredRender":22},{"title":1428,"summary":1429,"date":1430,"tags":1431,"group":18,"featured":38},"深入理解 react 的渲染","## 什么是 React",["Date","2024-09-03T00:00:00.000Z"],[18],"## 什么是 React\n\nReact 是一个 UI Library，也就是用来构建用户界面的库。React 通过Javascript 完成了对 HTML DOM 的所有表达来实现UI的翻译和构建。\n\n## React 的渲染过程\n\nReact 的渲染过程就是把组件翻译出来的 DOM append 到 DOM tree 并绑定对应事件的过程。当 React 的 props 或者 state 发生变化之后，React 会对 props 和 state 进行 diff 比较，然后重新进行渲染，于是Render 过程会重新走一遍。\n\n## React 是如何保证 props 和 state 的变化始终能和UI保持一致的\n\n在 function component 中，props、state、以及 component 内部出现的任何函数和变量都是以**快照**的形式出现，一旦 props 或 state 发生变化之后，所有函数内部的状态都会被重新刷新一遍形成新的快照，渲染的过程就是把快照还原到UI的过程，每个渲染过程都有自己的快照，不同快照之间相互不影响，因此不论component渲染多少次，都能保证UI和状态的一致性。[通过延迟函数来理解快照](https://codesandbox.io/s/elastic-maria-h1i87w?file=/src/App.js:113-121)\n```jsx\n\nimport \"./styles.css\";\nimport React, {useState} from 'react';\n\n\nexport default function App() {\n  const [count, setCount] = useState(0);\n\n  function handleAlertClick() {\n    setTimeout(() => {\n      alert('You clicked on: ' + count);\n    }, 3000);\n  }\n\n  return (\n    \u003Cdiv>\n      \u003Cp>You clicked {count} times\u003C/p>\n      \u003Cbutton onClick={() => setCount(count + 1)}>\n        Click me\n      \u003C/button>\n      \u003Cbutton onClick={handleAlertClick}>\n        Show alert\n      \u003C/button>\n    \u003C/div>\n  );\n}\n```\n![img](https://static.git-star.com/20240903231910.jpg)\n上面的代码中声明了 count 这个 state，当点击 Show Alert Button 之后再点击 Click Me 对 count 进行变更，会观察到 alert 显示的值和实际的值是不一样的。\n\n**为什么会是这种违反直觉的结果？**\n\n我们继续尝试剖析 **React Component 本质上是一个数据状态的快照**这句话的含义。所谓快照就是某一个时刻所有数据的状态，而在 React 中 UI 就是数据状态呈现的载体，数据状态有多少种变化，快照就会有多少个，UI 也对应呈现多少种变化，但是任意一个时刻 UI 只呈现一种数据状态。在上面的示例中，我们通过延迟函数捕获了数据变化过程中某一时刻的状态，把这一时刻的状态延迟到未来(timeout 函数中的延迟时间)呈现，可以看到虽然在 alter 出现的这一刻 B，Component 的数据状态是 B-state 但是 alert 呈现出来的数据状态却是 A-state，这个 A-state 就是 Component 在 A 的那一刻其数据状态被延迟函数捕获了，捕获之后的快照就是 A-state-snapshot。React 通过这种【捕获状态->生成快照->渲染快照】的机制保证了 UI 数据的一致性，也就是任意时刻 UI 呈现的状态和当时的数据状态始终一致。\n\n**Component 中的状态都包含哪些？**\n\n任何声明在 Component 内部顶层的变量，包含函数、state、变量、props 都是 Component 的状态，任何时候这些状态发生了变化都会触发 React 重新渲染 Component。当函数内依赖 props 或者 state 做逻辑处理时，函数会捕获对应 props 或者 state 的最新状态。[通过多次改变state来理解快照](https://codesandbox.io/s/984x0t?file=/App.js&utm_medium=sandpack)理解了 Component 的状态是什么，我们一起继续看看这个例。\n```jsx\n\nimport { useState } from 'react';\n\nexport default function Counter() {\n  const [number, setNumber] = useState(0);\n\n  return (\n    \u003C>\n      \u003Ch1>{number}\u003C/h1>\n      \u003Cbutton onClick={() => {\n        setNumber(number + 1);\n        setNumber(number + 1);\n        setNumber(number + 1);\n      }}>+3\u003C/button>\n    \u003C/>\n  )\n}\n\n```\n![img](https://static.git-star.com/20240903232054.jpg)\n在 button 的 onClick 事件中，number 这个状态在三个 setNumber 调用中都指向的是相同的状态，它们都是某一时刻 nunber 的快照。因此原代码想要 number 自增 3 次是无法实现的，最终效果是调用三次 setNumber 和调用一次的效果是一样的。官方详细介绍 https://beta.reactjs.org/learn/state-as-a-snapshot\n\n## React 如何管理组件和状态的关系\n\nReact 管理的状态是由组件在UI DOM 树中的位置来决定的，UI Tree 就是组件组成的树\n\n![img](https://static.git-star.com/1725354902137-0fdaa377-65b9-4f42-b4a1-2938507db2ee.png)\n\n[**两个 Counter 分别在不同的位置，它们独享各自的状态互不影响**](https://codesandbox.io/s/3f7gzd?file=%2FApp.js&utm_medium=sandpack)\n\n![img](https://static.git-star.com/1725354901903-49ee2feb-69ef-4ee9-8c7b-c3a3af453bf9.png)\n\n[**相同类型的组件在同一个位置，共享彼此的状态**](https://codesandbox.io/s/q77znv?file=%2FApp.js&utm_medium=sandpack)\n\n![img](https://static.git-star.com/1725354902261-53c1b5cf-c6d4-47dd-b66c-a9e44b65ac2a.png)\n\n[**相同位置不同类型组件，状态各自独立**](https://codesandbox.io/s/ti7i1q?file=%2FApp.js&utm_medium=sandpack)\n\n![img](https://static.git-star.com/1725354902024-cd99a79f-4f9a-45c4-af61-e390c52e97fb.png)\n\n[**相同位置的同类型的组件通过 key 实现状态重置**](https://codesandbox.io/s/huufo3?file=%2FApp.js&utm_medium=sandpackkey)，key的作用就是告诉 react 这是两个不同的组件，需要不同的各自独立的状态管理 **使用 hook 和 reducer 来管理状态**React hook 很多，最常用的就是 useState、useEffect、useCallback、useRef、useContext、useReducer，当业务变复杂时，需要管理的状态将非常多，这段代码来自琅琊阁，一个页面的状态多达 42 个\n\n![img](https://static.git-star.com/1725354905888-d7f5e580-93b1-435f-8360-c32340b3ecb0.png)\n\n状态多带来了两个显著的问题：组件渲染性能受到影响状态之间的依赖关系复杂不明，容易制造bug复杂难以调试，开发效率降低因而又继续引申出新的疑问：需要这么多状态么？如果无法减少状态的数目，如何有效管理状态的依赖？\n\n## React 提供了 useEffect 和 reducer 来管理状态\n\n使用 useEffect 管理状态的依赖关系。useEffect 有三种依赖管理形式：完全不依赖，每次 render 都会执行空的依赖列表，只在第一次 render 执行依赖某个具体的state或props，只在 props 或 state 发生变更之后才执行为了让 state 之间的关系能够尽量明确化，一定要避免在 useEffect 中隐式依赖 state或props上面的代码中依赖了 a 这个state，但是当 a 发生变化时，并不会执行，因而为了避免发生这种情况，我们建议useEffect 中的函数就在 useEffect 中完成定义和使用，这样能保证后续逻辑变动时，相关的代码总是在一起的。handleThis 重构成一个 useCallback 函数**使用reducer实现状态管理的高内聚**在琅琊阁的迭代管理中对一个状态的增删改查出现了在代码的多处，而且随着事件的变多这样重复的逻辑依然会继续出现\n\n![img](https://static.git-star.com/1725354905700-96a48cdb-f3ce-4639-bc67-1d7b99356492.png)\n\n![img](https://static.git-star.com/1725354906244-1218a106-75ed-4d56-b973-83c1c62f74ba.png)\n\n![img](https://static.git-star.com/1725354906576-795b8ab3-efea-43f2-8a6e-1414cb93ffaf.png)\n\n使用 reducer 重构之后，所有对状态的修改都集中在一起，代码的内聚性变强\n\n![img](https://static.git-star.com/1725354908000-2426ad14-bf05-498d-a871-1f92c932985f.png)\n\nreduce的使用非常简单：定义一个 reduce 函数，第一个参数是state，第二个参数是 action把所有对state的修改放到reduce函数中在component中使用reduce**组件的通信**大部分情况下，我们通过props来完成组件之间的通信（props支持传递组件、函数、state等），但是可能会遇到一个参数需要传递到很多个组件中或者一个参数被传递的层次特别深\n\n![img](https://static.git-star.com/1725354908254-f507d9ce-3c6b-40fd-a896-a5801e341cfa.png)\n\n最常见的就是用户信息，可能很多个组件都需要；如果网站有主题是动态的，主题相关的属性可能会传递的非常深。React 提供了 context 来实现多个组件之间的信息共享。Context 的使用也非常简单：定义 context\n\n```jsx\nimport { SprintModel } from '@/domainModel/sprint';\n\nimport React, { createContext } from 'react';\n\nimport { UserRole } from '@/domainModel/user';\n\nexport const SprintContext = createContext\u003C{\n\n    currentSprint?: SprintModel;\n\n    userRole?: UserRole;\n\n    setCurrentSprint: React.Dispatch\u003CReact.SetStateAction\u003CSprintModel>>;\n\n    setIndustryId: React.Dispatch\u003CReact.SetStateAction\u003Cstring>>;\n\n}>({\n\n    setCurrentSprint: () => { },\n\n    setIndustryId: () => { },\n\n});\n```\n\n使用 context\n\n```jsx\nconst { currentSprint, setCurrentSprint,\nuserRole, setIndustryId } = useContext(SprintContext);\n```\n\n为 context 提供值\n\n```jsx\n\u003C SprintContext.Providervalue={{ currentSprint, setCurrentSprint, userRole, setIndustryId } }>\n    \u003Cdiv className={styles['sprint-operation']}>\n\n        \u003CSprintHeader demandLoading={loading} title=\"排期结果\" type=\"sprintResults\"/>\n\n        \u003CSprintAlert alertStyle={{ margin: '15px 20px -10px 20px' }}/>\n\n        \u003CSpin spinning={loading}>\n\n        \u003Cdiv className={styles.resultsLayout}>\n\n            \u003CRightMain setLoading={setLoading}/>\n        \u003C/div>\n    \u003C/div >\n\u003C/SprintContext.Provider >\n```\n\n使用context时，component从距离组件最近的context获取到对应的值，如果有多个context共存，距离component近的context会覆盖较远的context。","src/content/posts/understand-react-2.mdx","2c7a90e66b942fe9","understand-react-2.mdx","understand-react",{"id":1436,"data":1438,"body":1443,"filePath":1444,"digest":1445,"legacyId":1446,"deferredRender":22},{"title":1439,"summary":1440,"date":1441,"tags":1442,"group":18,"featured":38},"理解和学习 react","2013 年 react 刚出来的时候，由于自己并不是前端，看着这个家伙新奇，但是并没有投入太多目光，但是工作中或多或少会用到前端，断断续续也接触了一下，直到今年实在也是迈不过去了，索性花点时间研究一下，以下就是我在写 react 的过程中的一点心得。",["Date","2022-08-21T00:00:00.000Z"],[18],"2013 年 react 刚出来的时候，由于自己并不是前端，看着这个家伙新奇，但是并没有投入太多目光，但是工作中或多或少会用到前端，断断续续也接触了一下，直到今年实在也是迈不过去了，索性花点时间研究一下，以下就是我在写 react 的过程中的一点心得。\n\n## React 究竟是什么\n\n我是从 jQuery 时代过来的人，用过 Backbone、YahooUi 和 Dojo，也用 jQuery 自己造轮子替代了生产环境中的 Backbone 应用，而且跑的很好，日活百万的安卓壁纸一直跑着我造的轮子，直到原生 APP 上线很久以后才慢慢开始下线，在手机性能非常拉垮的 2011～2015，jQuery 非常够用，据说 slack 也是 jQuery 写的。\n\n在 2015 年之后，vuejs、angular、react 如火如荼，我却选择了 emberjs 作为公司前端的技术选型，很重要一个原因还是因为 jQuery 有足够大的生态，而这些新起之秀都需要从头造轮子，团队甚至连专业前端都没有，哪来精力和新框架硬杠，倒是不复杂的场景都用 react 和 vuejs 试了试水，终究没有大规模使用，直到我离开创业公司，我也没有写过一行 react 代码。\n\n今年开始断断续续写了写 react（主要后端可能写着更无聊🐶），写着写着我愈发想知道 react 到底是什么，因为这货和 emberjs 截然不同，直到看了 [React as a UI Runtime](https://overreacted.io/react-as-a-ui-runtime/) 我才有点明白这货和我当年用 jQuery 造的轮子思路还有点像。当时为了解决前端模板渲染效率和维护性问题，通过 JS 的简单对象动态创建出静态字符串模板，然后在根据模板在页面中的位置，通过 DOM 对象动态的替换，每个页面都是有一个或几个这样的对象组成，这个 JS 对象包含了:\n\n![](https://static.git-star.com/WX20220821-221415@2x.png)\n\n- 静态模板 - template\n\n- 数据加载和组装 - load\n\n- 渲染 - render\n\n1. 静态模板包含原始的HTML和条件判断，实现了根据条件渲染不同的HTML片段\n\n2. 数据加载和组装类似 react 中的 `useEffect` 处理非 UI 逻辑以及加工 state\n\n3. 渲染类似 react 中 ListRender 和 Render，静态模板和渲染过程中都会有事件进行绑定\n\n每个这样的 JS 对象都自包含着数据加载、事件处理、模板渲染等等，实现了高内聚，不同的 JS 对象通信是依靠全局的 JS 对象完成的，类似 react 中的 AppContext。\n\n闲篇扯完，回到正题，react 究竟是什么？React 从诞生之初就说自己是：\n\n> A JavaScript library for building user interfaces。\n\n而 Dan Abramov 做了进一步解释：React is a ui runtime。Runtime 很准确的说明了 react 扮演的角色，也就是说 react 扮演了一个实时维持 UI 状态的运行时，这样才能在 UI 状态变化时做到高效渲染。这个运行时，react 称之为 Host Instance，也就是包含 Dom Nodes Tree 的一个环境，这个环境本身其实也是一个 Dom Node，特殊的地方在于它是 react 维护的。这个环境包含 react 维持组件运行状态的各种属性以及和宿主环境交互的各种 API，在 web browner 中就是 DOM API：appendChild、removeChild等，在 macOS React Native 中可能就是 Mac 自身的 UIKit API。在 react 中，一个 `ReactElement` 就是一个 Host Instance，也是 react 构建 UI 的最小单元。\n\n## React 如何渲染组件\n\n```jsx\nReactDOM.render(\n  \u003Cbutton className=\"blue\" />,\n  document.getElementById('container')\n);\n```\n\n一个组件 `\u003Cbutton className=\"blue\" />` 在 react 中会表达成一个 JS 表达式：\n```js\n{\n    type: 'button',\n    props: { className: 'blue' }\n}\n```\n\n这个表达式通过 DOM 的形式描述了一个组件以及组件的状态，渲染组件的过程就是把这个表达式翻译成 DOM 加入到渲染容器的过程:\n\n```js\nconst domContainer = document.getElementById('container')\nlet domNode = document.createElement('button');\ndomNode.className = 'blue';\ndomContainer.appendChild(domNode)\n```\n\n当组件的状态出现变化的时候，react 会对组件的各个属性进行比较，以此来决定是否需要重新渲染:\n\n```jsx\n// className blue->red\nReactDOM.render(\n  \u003Cbutton className=\"red\" />,\n  document.getElementById('container')\n);\n\n\n// node type button->p\nReactDOM.render(\n  \u003Cp>Hello world\u003C/p>,\n  document.getElementById('container')\n);\n```\n\n如果比较中发现，组件前后是同类型的组件只是组件属性发生了变化，react 会直接复用之前渲染的 Host Instance，如果是不一样的组件，则重新渲染，react 这一处理过程叫 Reconciliation。\n\nReact 的渲染机制大致如此，具体到条件渲染、循环渲染的具体处理逻辑可以详看 https://overreacted.io/react-as-a-ui-runtime/#lists 。\n\n## 重绘给 UI Runtime 带来的改变是什么\n\n讨论这个问题，我们限定在 react 的 Function Component 中。React 作为一个 UI runtime 维护了 UI 渲染时需要的状态，而通过改变 state 和 props 会触发 react 重新渲染组件，为了保证 UI 的正确渲染以及高性能，react 需要决定什么是需要重新渲染的，什么不需要，默认情况下如果我们不做任何处理，react 会重新渲染 Function Component 中所有的内容，包括函数。也就是说只要触发了 component 重新渲染，component 内部一切都是新的。\n\n```jsx\nimport { useState } from \"react\";\n\nfunction Hello(props){\n  return \u003C>{props.name}\u003C/>\n}\n\nexport default function App(props){\n  const [name, setName] = useState('hello world');\n\n  const someFunc = ()=>{\n    console.log(\"some func render\")\n  }\n\n  someFunc()\n\n  return (\n    \u003Cdiv className=\"App\" onClick={()=> setName(new Date().toTimeString())} >\n      \u003CHello name={name} >\u003C/Hello>\n    \u003C/div>\n  );\n}\n\n```\n\n上述代码在 name 发生改变时会触发组件重新渲染，可以看到 `someFunc` 也会重新执行，由于 JS 重没有办法获取变量的 ID，如果能这里看到是每次渲染都会是一个新的 ID，即便 someFunc 并没有参与UI的改变。\n\nReact 的这种机制让 UI 的改变变得简单和灵活，而且开发者心智负担更轻，不像 ember 中必须要告诉 template 这是个 tracked 属性，也不像 vuejs 什么都放到 model 中，亦或者通过 compute 以及 watch 来决定什么时候要触发 UI 的改变。React 中只要 props 或者 state 发生了改变都会让组件以及子组件重新渲染，这种渲染机制让开发变得简单了，但可能会带来性能问题，而性能是 react 自身要操的心了，大部分时候一般的 App 不会涉及到。\n\n再来看看重绘制时 react 如何管理 UI 的状态。\n\n```jsx\nimport { useEffect, useState } from \"react\";\n\nfunction Hello(props) {\n  return \u003C>{props.name}\u003C/>\n}\n\nexport default function App(props) {\n  const [name, setName] = useState(new Date().toTimeString());\n\n  useEffect(() => {\n    setTimeout(() => {\n      console.log(name)\n    }, 3000);\n  })\n\n  return (\n    \u003Cdiv className=\"App\" onClick={() => setName(new Date().toTimeString())} >\n      \u003CHello name={name} >\u003C/Hello>\n    \u003C/div>\n  );\n}\n```\n\n来看结果\n\n![](https://static.git-star.com/WX20220904-230229@2x.png)\n\n当 UI 的时间已经改变时，控制台输出的时间仍然是个旧值，react 始终保证每次渲染都是渲染时的状态，react 中称这种行为为 `state capture`。React 会在渲染组件时捕获 UI 状态，也就是渲染实际上当时 UI 的快照。这样保证了状态不论改变多少次，UI 的变化总是会和状态保持着一致性。当然如果 state 频繁改变，react 还会通过 batch update 以及多次渲染合并称一次来满足 UI 渲染的性能要求，个中细节参考 [React as a UI Runtime](https://overreacted.io/react-as-a-ui-runtime/) 、[A Complete Guide to useEffect](https://overreacted.io/a-complete-guide-to-useeffect/) 。\n\n\n\n## React 的灵活性让开发过程愉悦\n\n相比其他框架，React 的有一个很大特征就是**灵活**，由于 react 的最小 UI 单元其实就是一个 React Element ，而且几乎没有实现成本，这就导致了可以基于 UI Element 完成任意的组合实现各种不同的 UI 单元，而且基于 props 和 state 的 UI 状态管理，让 react 的 UI 的交互模式变得非常纯粹，不需要再掌握更复杂的模式了，这些能完成 95% 的工作，心智非常简单，开发高效。\n\n灵活也带来另一个问题，就是如何才能做好组合的设计和抽象，以实现组件的维护成本更低，复用程度更高。因而不同水平的开发人员使用 react 实现相同的功能可能差异还是很大的。\n\n## 学习 React 从哪里开始\n\n1. 和其他大部分开源技术一样，官网总是有最好的教程 https://reactjs.org/ ，用 [Create React App](https://create-react-app.dev/) 写个小项目熟悉一下 JSX 的语法，大部分从来没接触过 JSX 的人都需要花点时间适应 JSX 语法\n2. 接着拨云见雾了解 React 的本质是什么 [React as a UI Runtime](https://overreacted.io/react-as-a-ui-runtime/)\n3. 学习使用 [Hooks](https://reactjs.org/docs/hooks-intro.html)\n4. Hooks 使用一段时间之后，了解一下 hooks 的来龙去脉以及 hook 的本质 [A Complete Guide to useEffect](https://overreacted.io/a-complete-guide-to-useeffect/)\n\n熟悉了解了这些大部分 React 的开发都能进行了，一边学习一边多看看官网的文档，包括历年新特性的发布介绍，慢慢会对 React 有更深入的理解。","src/content/posts/understand-react.mdx","e706e6025eee5200","understand-react.mdx","understand-semantic-ui-grid",{"id":1447,"data":1449,"body":1456,"filePath":1457,"digest":1458,"legacyId":1459,"deferredRender":22},{"title":1450,"summary":1451,"date":1452,"tags":1453,"group":64,"featured":38},"理解 semantic-ui grid 的使用","semantic-ui 是一套类似于 bootstrap 的 ui framework，相比 bootstrap 有如下优点： - 组件采用语义化的组织方式，容易理解，容易记忆 - 组件库非常丰富，几乎不需要引入第三方的组件，统一性强 - 由于采用语义化的方式命名，所有组件都有自...",["Date","2017-02-05T00:00:00.000Z"],[1454,1455],"grid","布局","[semantic-ui](http://semantic-ui.com) 是一套类似于 bootstrap 的 ui framework，相比 bootstrap 有如下优点：\n- 组件采用语义化的组织方式，容易理解，容易记忆\n- 组件库非常丰富，几乎不需要引入第三方的组件，统一性强\n- 由于采用语义化的方式命名，所有组件都有自己的命名空间，相互不受干扰，侵入性弱，对自定义 css 干扰小，bootstrap 则改写了很多元素的默认样式，复写困难\n- 自定义容易，semantic ui 的源码中各个组件相互独立，依赖清晰，自定义方便\n\n## fundamental concepts\n\n- **container**\nA fixed width container 具有固定宽度的容器\n- **grid**\n网格\n- **column**\n网格的列\n- **row**\n网格的行\n\n\n## 固定宽度居中布局\n\nsemantic ui 提供容器 container 来快速实现固定宽度居中，使用 `container` 不需要任何 `grid`\n\n```html\n\u003Cdiv class=\"ui container\">\n    \u003Cdiv class=\"c\">\n        content\n    \u003C/div>\n\u003C/div>\n\n```\n\n如果需要对一段文本进行固定居中，semantic ui 提供了 `text container`\n\n{/* more */}\n\n```html\n\u003Cdiv class=\"ui text container\">\n    Sometimes you just need to put a single column of centered text on a page. A text container is a special type of container optimized for a single flowing column of text, like this instructions on this page.\n\u003C/div>\n\n```\n\n\n## grid 布局\n\n\n### 自动换行\n\ngrid 布局可以非常容易地实现任意行列组合的布局。如果 `column` 直接作为 `grid` 的 child，即没有 `row`，当前行占满之后会自动 flow 到下一行。\n\n```html\n\u003Cdiv class=\"ui grid\">\n    \u003Cdiv class=\"four wide column\">\n        content\n    \u003C/div>\n    \u003Cdiv class=\"four wide column\">\n        content\n    \u003C/div>\n    \u003Cdiv class=\"four wide column\">\n        content\n    \u003C/div>\n    \u003Cdiv class=\"four wide column\">\n        content\n    \u003C/div>\n    \u003C!-- 换行 -->\n    \u003Cdiv class=\"four wide column\">\n        content\n    \u003C/div>\n    \u003Cdiv class=\"four wide column\">\n        content\n    \u003C/div>\n    \u003Cdiv class=\"four wide column\">\n        content\n    \u003C/div>\n    \u003Cdiv class=\"four wide column\">\n        content\n    \u003C/div>\n\u003C/div>\n\n```\n\n`column` 不指定宽度时，默认用的是 1 个单位的宽。\n\n### 手动换行\n\n使用 `row` 可以强迫当前行即使内容没有占满就自动换行\n\n\n```html\n\u003Cdiv class=\"ui three column grid\">\n    \u003Cdiv class=\"column\">\n        \n    \u003C/div>\n    \u003C!-- 换行 -->\n    \u003Cdiv class=\"row\">\n        \u003Cdiv class=\"column\">\n            content\n        \u003C/div>\n        \u003Cdiv class=\"column\">\n            content\n        \u003C/div>\n        \u003Cdiv class=\"column\">\n            content\n        \u003C/div>\n    \u003C/div>\n\u003C/div>\n```\n\n### 指定 grid 的 column count\n\n\n可以在 `grid` 上指定单个 `column` 的 count，当每行的 column count 达到指定数目后就自动换行，不管有没有指定 `row`\n\n```html\n\u003Cdiv class=\"ui three column grid\">\n    \u003Cdiv class=\"column\">\u003C/div>\n    \u003Cdiv class=\"column\">\u003C/div>\n    \u003Cdiv class=\"column\">\u003C/div>\n    \u003C!-- 换行 -->\n    \u003Cdiv class=\"column\">\u003C/div>\n    \u003Cdiv class=\"column\">\u003C/div>\n    \u003Cdiv class=\"column\">\u003C/div>\n    \u003Cdiv class=\"row\">\n        \u003Cdiv class=\"column\">content\u003C/div>\n        \u003Cdiv class=\"column\">content\u003C/div>\n        \u003Cdiv class=\"column\">content\u003C/div>\n        \u003C!-- 称满一行 -->\n    \u003C/div>\n\u003C/div>\n\n```\n\n\n### row 内的 column 默认没有高度\n\n```html\n\n\u003Cdiv class=\"ui three column grid\">\n    \u003Cdiv class=\"row\">\n        \u003C!-- height 0 -->\n        \u003Cdiv class=\"column\">\n        \u003C/div>\n        \u003Cdiv class=\"column\">\n        \u003C/div>\n        \u003Cdiv class=\"column\">\n        \u003C/div>\n    \u003C/div>\n\u003C/div>\n```\n\n### 指定 column 的宽度\n\n```html\n\u003Cdiv class=\"ui grid\">\n    \u003Cdiv class=\"four wide column\">\u003C/div>\n    \u003Cdiv class=\"column\">\u003C/div>\n    \u003Cdiv class=\"column\">\u003C/div>\n\u003C/div>\n```\n\n\n### 特定 grid 必须要有 row\n\n`celled grid`、`internally celled grid`、`divided grid`、`vertially divide grid` 都需要指定 row\n\n\n```html\n\u003Cdiv class=\"ui celled grid\">\n    \u003Cdiv class=\"row\" >\n        \u003Cdiv class=\"column\">content\u003C/div>\n        \u003Cdiv class=\"column\">content\u003C/div>\n        \u003Cdiv class=\"column\">content\u003C/div>\n    \u003C/div>\n\u003C/div>\n\n```\n\n### 居中 column\n\n如果 column 没有占满一行，可以使用 `centered grid`, `centered row`, or `centered column` 来使列居中\n\n```html\n\u003Cdiv class=\"ui two column centered grid\">\n    \u003Cdiv class=\"column\">\u003C/div>\n    \u003Cdiv class=\"four column centered row\">\n      \u003Cdiv class=\"column\">content\u003C/div>\n      \u003Cdiv class=\"column\">content\u003C/div>\n    \u003C/div>\n\u003C/div>\n```\n\n`row` 中指定的 column count 能够覆盖 grid 的 column count\n\n### 浮动 column\n\nleft floated item should come first, and a right floated item last in its row\n\n```html\n\u003Cdiv class=\"ui grid\">\n    \u003Cdiv class=\"left floated six wide column\">\n      \u003Cdiv class=\"ui segment\">\n        Left floated\n      \u003C/div>\n    \u003C/div>\n    \u003Cdiv class=\"right floated six wide column\">\n      \u003Cdiv class=\"ui segment\">\n        Right floated\n      \u003C/div>\n    \u003C/div>\n\u003C/div>\n\n```\n\n### 可以在任意级别 grid, row, column 指定文本的对齐方式\n\n\n```html\n\u003Cdiv class=\"ui grid\">\n    \u003Cdiv class=\"right aligned eight wide column\">\n      right aligned column\n    \u003C/div>\n    \u003Cdiv class=\"left aligned eight wide column\">\n      left aligned column\n    \u003C/div>\n    \u003Cdiv class=\"center aligned two column row\">\n      \u003Cdiv class=\"column\">\n        center aligned row\n      \u003C/div>\n      \u003Cdiv class=\"column\">\n        center aligned row\n      \u003C/div>\n    \u003C/div>\n    \u003Cdiv class=\"sixteen wide right aligned column\">\n      right aligned column\n    \u003C/div>\n\u003C/div>\n```\n\n**垂直居中对齐**\n\n```html\n\u003Cdiv class=\"ui middle aligned four column centered grid\">\n    \u003Cdiv class=\"row\">\n      \u003Cdiv class=\"column\">\n        \u003Cimg class=\"ui wireframe image\" src=\"assets/images/wireframe/image.png\">\n      \u003C/div>\n      \u003Cdiv class=\"column\">\n        \u003Cimg class=\"ui wireframe image\" src=\"assets/images/wireframe/image.png\">\n        \u003Cimg class=\"ui wireframe image\" src=\"assets/images/wireframe/image.png\">\n      \u003C/div>\n      \u003Cdiv class=\"column\">\n        \u003Cimg class=\"ui wireframe image\" src=\"assets/images/wireframe/image.png\">\n      \u003C/div>\n    \u003C/div>\n\u003C/div>\n```\n\n\n### 均分 column width\n\n`grid` 指定 equal width 可以使 `row` 中的任意列宽度相同\n\n```\n\u003Cdiv class=\"ui equal width grid\">\n    \u003Cdiv class=\"row\">\n      \u003Cdiv class=\"column\">column\u003C/div>\n      \u003Cdiv class=\"column\">column\u003C/div>\n      \u003Cdiv class=\"column\">column\u003C/div>\n      \u003Cdiv class=\"column\">column\u003C/div>\n    \u003C/div>\n    \u003Cdiv class=\"row\">\n      \u003Cdiv class=\"column\">column\u003C/div>\n      \u003Cdiv class=\"column\">column\u003C/div>\n      \u003Cdiv class=\"column\">column\u003C/div>\n    \u003C/div>\n\u003C/div>\n```\n\n**codepen sample**\n\n\u003Cp data-height=\"265\" data-theme-id=\"0\" data-slug-hash=\"oByPyE\" data-default-tab=\"result\" data-user=\"zhyq0826\" data-embed-version=\"2\" data-pen-title=\"oByPyE\" class=\"codepen\">See the Pen \u003Ca href=\"http://codepen.io/zhyq0826/pen/oByPyE/\">oByPyE\u003C/a> by 三月沙 (\u003Ca href=\"http://codepen.io/zhyq0826\">@zhyq0826\u003C/a>) on \u003Ca href=\"http://codepen.io\">CodePen\u003C/a>.\u003C/p>\n\u003Cscript async src=\"https://production-assets.codepen.io/assets/embed/ei.js\">\u003C/script>\n\n\n## 注意事项\n\n\n1. 2.3.2 中，column 的子元素不能直接是 row，如果要在 column 下使用 row 必须嵌套在 grid 中\n\n```html\n  \u003Cdiv class=\"fourteen wide column\">\n      \u003Cdiv class=\"ui grid\">\n        \u003C!-- 必须要嵌套在 新的 grid 中 -->\n          \u003Cdiv class=\"row\" > \n\n          \u003C/div>\n      \u003C/div>\n  \u003C/div>\n\n```","src/content/posts/understand-semantic-ui-grid.mdx","72353ab26a1da42c","understand-semantic-ui-grid.mdx","unix-domain-socket",{"id":1460,"data":1462,"body":1467,"filePath":1468,"digest":1469,"legacyId":1470,"deferredRender":22},{"title":1463,"summary":975,"date":1464,"tags":1465,"group":1163,"featured":38},"Unix domain socket 实现和使用",["Date","2018-03-31T00:00:00.000Z"],[1466],"socket","## 问题描述\n\n现在的我司有个推送的业务 Python 实现，每次要对几百万用户进行**特定**推送（具体业务实现也比较复杂，有很多过滤条件），并且要实时**统计**推送用户中 Android 和 IPhone 各占比多少，推送的用户是根据特定的条件过滤出来的，这些用户过滤出来之后只以用户 id 的形式存在，并不知道他们所属的设备是什么，而且这批用户中还包含大量的非注册用户，因此如果要知道用户所属设备必须再次从数据库获取。\n\n在这个推送的早期，用户量其实很少，程序员每次都是从数据库中全量获取所有数据，当时内存占用不到 1 G。随着业务规模的扩大，每次推送的用户越来越多，导致程序占用的内存到了 10 个G，对问题进行分析之后发现，最耗内存的包含两部分：**一是**筛选用户每次几百万数据全部加载内存，然后依次进行筛选过滤；**二是**对推送用户进行统计是实时统计的，每次也是几百万用户数据全部加载，然后再过滤筛选。\n\n## 目标\n\n1. 降低内存的占用量\n2. 保证推送在百万级别下依然客观\n\n## 解决方案\n\n1. 避免全量用户进行计算\n\n   对满足条件的用户一次筛选一批，然后进行计算，然后再筛选下一批，而不是一次全部加载再计算，避免内存过早被占用过大\n\n2. 实时统计部分进行分离\n\n   对需要统计的百万用户进行分离统计\n\n1 和 2 设计原则都是基于**生产者消费者模式**，1 可以借助 gevent 或 thread 进行多 worker 协同过滤筛选，既保证速度又避免内存过多占用；由于是在本机进行，统计分离可以借助外部存储实现，比如推送过程中把推送数据写入外部存储，再进行统计，为了达到实时的目的，在此**实现了一个 UNIX domain server 作为 consumer**。\n\n## Unix domain socket\n\nUnix domain socket 必须是同主机间进程才能使用，而且 API 完全兼容 TCP socket，使用简单，但是不同于 TCP socket 它没有 TCP **网络协议栈的约束，不需要打包拆包、计算校验和、维护序号和应答等**，只是将应用层数据从一个进程拷贝到另一个进程。这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的。Unix Domain Socket也提供面向流和面向数据包两种API接口，类似于TCP和UDP，但是面向消息的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱。\n\n## 使用 unix domain socket\n\n创建 unix domain socket server 的过程和创建普通 TCP socket 没有太大差异\n\n```python\ndef socket_server():\n    dirname = os.path.dirname(os.path.abspath(__file__))\n    # 指定 socket 是 unix domain socket\n    server = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n    sockname = os.path.join(dirname, os.path.basename(__file__) + '.sock')\n    if os.path.exists(sockname):\n        os.remove(sockname)\n    server.bind(sockname)\n    server.listen(2046)\n    while 1:\n    \tconn, addr = server.accept()\n```\n\n客户端与 TCP 的区别就是不是通过 IP 和 PORT 来识别 server 而是通过 pathname\n\n```python\ndirname = os.path.dirname(os.path.abspath(__file__))\nclient = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\nclient.connect(os.path.join(DIRNAME, 'push_count_server.py.sock'))\n```\n\n## 注意\n\n1. 不同于 TCP socket server，如果 backlog 满了，client 再去尝试连接 domain socket server 会直接被拒绝，报 connection refused，无法再继续重试。\n2. 每次启动 server 都需要检查使用的 pathname 是否已经存在，如果存在需要删除 unlink(sockname) 然后再 bind。\n\n## 参考资料\n\n- https://troydhanson.github.io/network/Unix_domain_sockets.html\n- https://www.ibm.com/support/knowledgecenter/en/SSB23S_1.1.0.14/gtpc1/unixsock.html","src/content/posts/unix-domain-socket.mdx","59beb65556d9fb23","unix-domain-socket.mdx","use-makrdown-to-format-wxmp",{"id":1471,"data":1473,"body":1479,"filePath":1480,"digest":1481,"legacyId":1482,"deferredRender":22},{"title":1474,"summary":1475,"date":1476,"tags":1477,"group":129,"featured":38},"用 markdown 自定义排版公众号文章","可能吧的阿禅的之前写了一篇文章介绍了他是如何排版公众号文章的：思路就是用 markdown 写作，然后使用专门的工具导出为 html 文件，最后把自定义的样式应用到导出的文件，复制粘贴最终的内容到微信公众号。",["Date","2016-11-18T00:00:00.000Z"],[1478],"微信公众号","可能吧的阿禅的之前写了一篇文章介绍了他是如何排版公众号文章的：思路就是用 markdown 写作，然后使用专门的工具导出为 html 文件，最后把自定义的样式应用到导出的文件，复制粘贴最终的内容到微信公众号。\n\n在这篇文章中，我将一步步说明如何把阿禅的思路应用到时间中。\n\n## 选择一款舒适的 markdown 写作工具\n\nmarkdown 的写作工具有很多，这里我只介绍两款 mac 下的软件，非常好用，而且免费开源\n\n- [Typora](http://www.typora.io/) \n- [macdown](https://github.com/MacDownApp/macdown) \n\n{/* more */}\n\n这两款 markdown 编辑器都支持所见即所得写作方式，支持多种主题、支持导出各种格式的文件。\n\n## 学习 markdown 语法\n\nmarkdown 的语法非常简单，对于一般性的写作，只需要记住一些常用的标记即可，markdown 的教程很多，在此推荐 **http://wowubuntu.com/markdown/**。\n\n\n## 导出不带样式的 html 文件\n\n借助写作工具，markdown 可以非常容易地导出 html 文件，为了可以自定义样式和排版，一定要选择**无样式**的导出。\n\n## 自定义导出 html 文件的样式\n\n为了可以完全掌控排版的效果和样式，你需要编写完整的 css 来应用到导出的文件，对此你可以选择学习编写完整的 css，或者请教你身边的程序员朋友帮你完成这一步。\n\n## 应用样式到 html 文件\n\n想要自定义样式完全发挥作用，这些自定义样式最终应该是以**内联**的方式出现在导出的 html 文件中，这也是微信公众号提供的这类富文本编辑器的功能所在，为了把你在上一步编写的外部 css 变成 html 的内联样式，你需要像阿禅在文章中说的那样：写一个 replace 的函数脚本，挨个替换。为了简化这一步的操作，我编写了一个小工具 **markdown-css** 来完成 css 样式从外部到内联的转换。\n\nmarkdown-css 的使用很简单，文末会附有相应的地址告诉你该如何安装和使用，类似于这样：\n\n```\nmarkdown-css post.html --style=mystyle.css --out=public\n```\n\nmarkdown-css 会把上一步导出的 html 文件与你编写的样式进行处理，然后输出带有内联样式的 html 文件，默认在当前目录的 **public** 下。双击打开输出的 html 文件，然后复制粘贴到微信公众号。\n\n至此，你的自定义排版就大功告成了。\n\n------\n\n如果你在实践的过程中遇到什么问题，可以反馈给我，也许可以帮助到你。\n\n> [可能吧的文章是如何排版的？](http://mp.weixin.qq.com/s?__biz=MjM5ODQwMjA4MA==&mid=2649293603&idx=1&sn=57f38200555dcba76d6358594416c089&mpshare=1&scene=1&srcid=1106ssUPcBWLZUq7D9vqXEkj#rd)\n>\n> [markdown](http://wowubuntu.com/markdown/)\n>\n> [markdown-css](http://wecatch.me/markdown-css/)","src/content/posts/use-makrdown-to-format-wxmp.mdx","4984f068d270663b","use-makrdown-to-format-wxmp.mdx","valueable-or-not-valueable",{"id":1483,"data":1485,"body":1491,"filePath":1492,"digest":1493,"legacyId":1494,"deferredRender":22},{"title":1486,"summary":1487,"date":1488,"tags":1489,"group":884,"featured":38},"有价值的，没价值的","最近公司组织去中欧商学院听了一堂 EMBA 的课程，课程时间很短，近 3 个多小时，然而就在这三小时中，忽然又想明白了之前好像已经想明白的一个道理：价值究竟是什么。",["Date","2018-06-15T00:00:00.000Z"],[1490],"价值","最近公司组织去中欧商学院听了一堂 EMBA 的课程，课程时间很短，近 3 个多小时，然而就在这三小时中，忽然又想明白了之前好像已经想明白的一个道理：价值究竟是什么。\n\n## 价值\n\n> 维基百科对价值定义：价值，泛指客体对于主体表现出来的积极意义和有用性。可视为是能够公正且适当反映商品、服务或金钱等值的总额。根据新古典主义经济学，物体的价值就是该物体在一个开放和竞争的交易市场中的价格，因此价值主要决定于对于该物体的需求，而不是供给。\n\n如果我们换个角度简单把价值换算成利益再回过来看价值，对价值的理解会慢慢清晰起来。相比价值，利益更具体，相比金钱，利益更抽象，而且利益也有一定的相对性。至此，我们常常说的**做有价值的事情**，就可以翻译为**做有利益的事情**。\n\n## 对自己有价值\n\n套一下公式：对自己有价值 = 对自己有利益，对个体的利益简单分个类：\n- 身体需要，食色性也，几乎所有的物质享受都直接与金钱挂钩\n- 精神需要，爱与被爱，认同与被认同等等，也就是人在职场、社会、家庭中体现出来的复杂关系\n\n明确了个体的利益是什么，剩下要做的事情就是如何让个体的利益得到最大化。这几乎也是我们现在大多数人之所以还没有被生活所打垮最直接的动力了：**赚更多的钱和得到更多的爱**。\n\n那如何让个体利益得到最大化，也就是如何可以让个体赚更多的钱以及在社会、家庭、职场中得到更多的支持和认同呢？抛开各种各样的技巧、经验、能力这些表面现象，这个问题的最后的答案其实很简单：**投资自己**。\n\n那应该对自己投资什么？答案其实也很简单：**保持健康和坚持学习**。这个朴素的道理是我在经历计算机这个行业快速的变迁以及生活的种种压力之后才慢慢琢磨明白的。\n\n保持健康的重要性不言而喻，这是我们能正常活着的大前提，注意我说的是活着本身。坚持学习对个体有益的地方在于能够不断提高个体的竞争力，保证个体不论在什么时候都能有比较大的价值输出，而这个价值输出直接决定了对别人的价值。\n\n由于本篇不设计具体的操作，具体如何保持持健康可以参考其他资料，如何学习可以参考我之前的一篇文章[我的学习方法论](/blog/my-learning)\n\n## 对别人有价值\n\n接着套公式：对别人有价值 = 对别人有利益，利益交换利益，意味着：\n- 可能会带来更多的金钱财富来满足身体需要\n- 可能会带来更多的爱与被爱来满足精神需要\n\n如何提高对别人的利益？简单点描述就意味着要让个体变得更有用，更有价值，答案在这里其实很明了了，**还是投资自己**。\n\n## 投资自己的原则\n\n在当今的社会组织中，由于信息的严重不对称和能力的悬殊对比，其实这个世界的运转基本是掌握在少数人手中的，大多数人是被牵着走的。更直接一点来说就是制定规则的人决定了游戏是如何玩的，也就是决定了游戏中利益的是如何分配的。这样的游戏规则在互联网时代信息的分发中显得更是如此，随便举几个例子，PC 时代的百度，移动互联网的今日头条系等等。在完全由巨头制定的信息分发游戏规则中如何玩？答案就是**投资自己的第一原则：做时间的主人**。\n\n虽然李笑来就随随便便用一个白皮书就募资上亿以及和他带来的台湾胖子撕逼这些事让我对李笑来这个人的人品逐渐开始深深怀疑，但是从客观角度讲，李笑来讲的很多道理还是非常到位的，正如李笑来说的，时间是没有办法延长或缩短，你只能利用它，所以他把七年当成一辈子来过，利用这个七年的一辈子投资自己，让自己发生翻天覆地的变化。为什么是七年，因为七年一般都可以恰好干成一件事，比如学一门外语，学会谈吉他等等。推荐李笑来的书《七年就是一辈子》，免费的。\n\n**投资自己的第二原则：有目标**。目标的重要含义我之前也写过一篇文章[目标 过程 结果](/blog/target-process-result)，这里不赘述了。\n\n**投资自己的第三原则：学会学习如何学习**。虽然我上面提供了一篇参考文章如何学，但是适用每个人的方法论都是有差异，所以需要在实践中不断摸索总结自己的方法论。\n\n**投资自己的第四原则：学会休息**。经历过高考的人都非常清楚，为了高考所有人都拼命的刻苦学习，但是不是每个人都会休息，人和人的差异就这样体现出来了，而现在随着在线娱乐平台兴起之后，直播、短视频等娱乐信息是如此发达，综艺秀场不断，工作忙碌之后的娱乐大家都很在行，追剧，刷抖音，围观微博等等，但是不是任何人都会懂得休息。究竟如何休息，打开 Google 搜索一下就能得到答案。\n\n有这四个原则已经够了：\n- 做时间的主人\n- 有目标\n- 学会学习如何学习\n- 学会休息\n\n## 技术人的价值如何实现\n\n这个话题太大了，足够一篇文章的篇幅，我相信我有机会把这个话题写出来，梳理成文供大家参考。\n\n## 这个时代信息的价值\n\n不夸张的说，这真的是信息爆炸的时代，但是大部分信息都毫无价值，有价值的信息要么我们普通人根本看不见，要么看见了\n也识别不出其中的价值，但是有些信息我敢说一定没有太大价值，典型如今日头条的新闻，娱乐八卦的内容，抖音快手的视频，这些信息除了娱乐几乎没有任何价值了。所以如果没有能力挖掘出有价值的信息，至少能做到不被毫无价值的信息所淹没，避免生命被浪费。","src/content/posts/valueable-or-not-valueable.mdx","ea4f8fbc2b5fd025","valueable-or-not-valueable.mdx","wechat-pay-bugs",{"id":1495,"data":1497,"body":1502,"filePath":1503,"digest":1504,"legacyId":1505,"deferredRender":22},{"title":1498,"summary":1499,"date":1500,"tags":1501,"group":196,"featured":38},"Python 中如何修复微信支付漏洞","微信支付爆出安全漏洞，详见 http://www.techweb.com.cn/digitallife/2018-07-04/2682206.shtml，具体原理是微信支付的回调是 xml，这个漏洞的就是利用 xml 可以自定义文档结构来调用外部实体的能力来注入不安全信息，漏洞全...",["Date","2018-07-04T00:00:00.000Z"],[],"微信支付爆出安全漏洞，详见 http://www.techweb.com.cn/digitallife/2018-07-04/2682206.shtml，具体原理是微信支付的回调是 xml，这个漏洞的就是利用 xml 可以自定义文档结构来调用外部实体的能力来注入不安全信息，漏洞全称是 XML External Entity Injection ，简称 XXE，微信官方已经在给出漏洞修复的具体实践，参见  https://pay.weixin.qq.com/wiki/doc/api/jsapi.php?chapter=23_5 。\n\nPython 中的 xml 解析一般使用 xml 这个标准库，Python 官方对标准库的安全使用有具体建议，参见 https://docs.python.org/2/library/xml.html#xml-vulnerabilities   :\n\n![](https://static.git-star.com/WX20180704-120452.png)\n\n上述表格详细列举了各个标准模块的安全性，请仔细检查相关支付回调业务中 xml 的使用情况。\n\n除此之外，Python 有一个非常著名的库 xmltodict ( https://github.com/martinblech/xmltodict) 用以解析 xml，这个库的最新版本修复了 XXE 见 https://github.com/martinblech/xmltodict/issues/174 ，xmltodict 依赖于 https://pypi.org/project/defusedexpat/ 这个包，默认情况下需要手动安装，所以需要在你的应用程序依赖中显式写入：\n\n```\ndefusedexpat==0.4.0\nxmltodict==0.11.0\n```\n\n**一切工作做好之后，请仔细进行测试你的代码，确保它们对 xml 的解析是安全的**。","src/content/posts/wechat-pay-bugs.mdx","2ddd78779687c58b","wechat-pay-bugs.mdx","wechat-product-opinion",{"id":1506,"data":1508,"body":1514,"filePath":1515,"digest":1516,"legacyId":1517,"deferredRender":22},{"title":1509,"summary":1510,"date":1511,"tags":1512,"group":129,"featured":38},"我的产品记第一记","**写在开头的话**",["Date","2015-04-25T00:00:00.000Z"],[1513],"微信","**写在开头的话**\n\n虽然我很热衷于创造有意思的东西，本质上还是个程序员，偶尔会文艺一下，喜欢新技术，爱折腾东西。自嘲还算懂点产品，但对产品经理这个职业称呼似乎天生没有好感。现在要做一些只有产品才做的事情，但是如果有人称呼我为产品经理或产品狗，估计我会当即反击回去：你**才是产品狗。\n\n{/* more */}\n\n我是程序员，希望写出有价值的产品，曾经是，以后还是。\n\n## 微信背后的产品观\n\n在我准备调整一下适应做产品和写程序这样的双重角色的时候，BOSS发来一链接，点开一看是几年前一篇关于张小龙分享微信背后产品观的文章。最早看到的有关这篇文章是由和菜头整理发布的，后来又看了一个口述的版本。不过都是旧文了。\n\n由于微信的巨大成功，有关微信的一切好像自然都成了被膜拜和被模仿的。而微信的成功与腾讯庞大的生态又是不无关系的，比如导入 qq 熟人关系，代替 qq 接受消息等等。认识到这一点，再去看这背后的产品观可能会更客观一点。\n\n以下是从此文中摘录的几个观点\n\n\n- **保持简单**\n- **满足人性的需要**\n- **有明确的定位**\n- **如果你不知道自己是对还是错，快速尝试**\n- **没有唯一的答案**\n\n\n保持简单实在是件难得的事情，保持专注更难得。人性是复杂的，但满足人性真的还是要根据产品的定位来区分。快速尝试一定要有一个优秀的团队支撑。任何一个产品背后要么有一个正确的逻辑，要么有一个正确的直觉，如果什么都没有，一定有问题。","src/content/posts/wechat-product-opinion.mdx","06559adc7fc72693","wechat-product-opinion.mdx","weekly-0001",{"id":1518,"data":1520,"body":1528,"filePath":1529,"digest":1530,"legacyId":1531,"deferredRender":22},{"title":1521,"summary":1522,"date":1523,"tags":1524,"group":1527,"featured":38},"本周值得读第1期","## Go",["Date","2018-05-25T00:00:00.000Z"],[1525,1271,825,1526],"go","大牛","技术周刊","## Go\n\nGo 中有很重要的两个概念几乎所有 gopher 在初学 Go 时都会感到困惑，一个是 interface，一个是 function type，为了揭示这两个概念隐藏的魔力，本周推荐以下三篇文章：\n\n**How to use interfaces in Go**\n\nhttp://jordanorelli.tumblr.com/post/32665860244/how-to-use-interfaces-in-go\n\n**Function Types in Go (golang)**\n\nhttp://jordanorelli.com/post/42369331748/function-types-in-go-golang\n\n**Understanding Golang's Func Type**\n\nhttps://www.integralist.co.uk/posts/understanding-golangs-func-type/\n\n> 推荐理由：1. 解决了初学者对 interface 使用时的困惑  2. 结合实践解释了 function type 的实际应用和强大特性\n\n\n## SQLAlchemy\n\nPython 的生态系统中有一个非常优秀的 database framework：SQLAlchemy，它提供了：\n\n- ORM\n- 丰富的数据库支持\n- 成熟高性能的可扩展架构\n- 函数式的查询语句\n- 纯 SQL 语句支持\n- ...\n\n可以说无论你面临的业务是简单还是复杂，合理使用 SQLAlchemy ，它都能让你的应用程序在数据库的管理和使用上如虎添翼，即使在非 Python 的生态，能和 SQLAlchemy 匹敌的也没有几个，本周推荐 SQLAlchemy 背后精妙的架构实现：\n\n**The architecture of SQLAlchemy**\n\nhttp://aosabook.org/en/sqlalchemy.html\n\n> 推荐理由：优秀的开源软件架构实现\n\n## PyMongo\n\nPyMongo 是 MongoDB 官方的 Python 驱动，伴随着 MongoDB 的成长，PyMongo 也经历了从一开始问题不断到现在逐步稳定成熟，而且接口非常易于使用，其在处理 MongoDB 连接的机制非常优秀，而且可以结合 gevent 使用，本周推荐 PyMongo 官方 FAQ 中对于其 connection pool 工作机制的介绍：\n\n**How does connection pooling work in PyMongo**\n\nhttp://api.mongodb.com/python/current/faq.html#how-does-connection-pooling-work-in-pymongo\n\n> 推荐理由：优秀的开源软件架构实现\n\n## 大牛推荐\n\n本周推荐大牛是阿里巴巴数据库内核研发负责人：何登成\n\n**Blog**\n\nhttp://hedengcheng.com/\n\n**Github**\n\nhttps://github.com/hedengcheng\n\n**weibo**\n\nhttps://weibo.com/u/2216172320\n\n\n> 推荐理由：每周都会有一个大牛推荐，让读者可以近距离了解大牛的思想动态，一起向大牛学习，模仿大牛，有一天我们都有可能成为大牛","src/content/posts/weekly-0001.mdx","f10a2d9a7acabd70","weekly-0001.mdx","weekly-0003",{"id":1532,"data":1534,"body":1541,"filePath":1542,"digest":1543,"legacyId":1544,"deferredRender":22},{"title":1535,"summary":1522,"date":1536,"tags":1537,"group":1527,"featured":38},"本周值得读第3期",["Date","2018-06-10T00:00:00.000Z"],[1538,1539,1540],"多线程","web","framework","## Go\n\n任何流行的语言其 web framework 都是百花齐放，比如 nodejs，Python，ruby，Go 也不例外，于是如何选择自己业务合适的 web framework 一定要做很多对比的和权衡，本周推荐对 Go 流行 web framework 的各种测评比较：\n\n**top-6-web-frameworks-for-go-as-of-2017**\n\nhttps://blog.usejournal.com/top-6-web-frameworks-for-go-as-of-2017-23270e059c4b\n\n> 推荐理由，流行 Go web framework 对比评测\n\n## Python \n\nPython 的多线程比 Java 简单，而且在 Python 的各种使用场景中使用的也非常多，同步机制是 Python 多线程非常重要的一个话题，本周推荐博客，对 Python 的同步机制进行深入浅出的讲解，对理解 Python 多线程机制很有帮助：\n\n**Python threads synchronization: Locks, RLocks, Semaphores, Conditions, Events and Queues**\n\nhttp://www.laurentluce.com/posts/python-threads-synchronization-locks-rlocks-semaphores-conditions-events-and-queues/\n\n> 推荐理由，覆盖全面，深入实现机制，高阶程序员必备\n\nEpoll 网络模型广泛用在各种 web server 中，包括 nginx、gunicorn、tornado 等非常著名的开源软件，Python 中如何编写 epoll 的应用程序，本周推荐为你揭晓：\n\n**How To Use Linux epoll with Python**\n\nhttp://scotdoyle.com/python-epoll-howto.html\n\n> 推荐理由，网络编程绕不开的 epoll\n\n## 本周大牛推荐\n\nJoel Spolsky，stackoverflow 的 CEO ，有着十几年的软件开发经验，同样还经营着最具影响力的程序问答网站，作者经常在博客中介绍自己对软件开发领域的思考以及经营公司的种种理念，值得细究，值得思考：\n\n**博客**\n\n https://www.joelonsoftware.com/\n\n> 推荐理由，Stack Overflow","src/content/posts/weekly-0003.mdx","5a654b07b48248e9","weekly-0003.mdx","weekly-0002",{"id":1545,"data":1547,"body":1551,"filePath":1552,"digest":1553,"legacyId":1554,"deferredRender":22},{"title":1548,"summary":1522,"date":1549,"tags":1550,"group":1527,"featured":38},"本周值得读第2期",["Date","2018-06-01T00:00:00.000Z"],[1525,196,1526],"## Go\n\n本周推荐 Go 的标准库解读系列，此系列来自 medium，虽然是英文的但是深入浅出，内容涵盖 IO、同步机制、interface、编码、goroutine 等，是读 Go 标准库常用库的比较完整的介绍了：\n\n**Go Spec 系列**\n\nhttps://medium.com/golangspec\n\n> 推荐理由，优秀的 Go 标准库介绍\n\n## Python \n\n了解一门语言的标准库，对日常可以熟练使用语言帮助非常大，Python 和 Go 一样都有非常优秀的官方文档，除此之外还有一些第三方作者写的关于 Python 标准库的使用，比官方例子更多，细节描述更到位，本周推荐 Python How To 系列：\n\n**Python Module of the Week**\n\n- https://pymotw.com/2/\n- https://pymotw.com/3/\n\n> 推荐理由，优秀的 Python 标准库介绍\n\n## 本周大牛推荐\n\n本周推荐 Python 著名的 web framework flask 的作者 Armin Ronacher ，作为后端程序员能有如此高产是相当了不起了，除了 flask，作者还创建了 sphinx，jinja2，click 等一系列非常著名的 Python 项目：\n\n**博客**\n\nhttp://lucumr.pocoo.org/\n\n**开源项目**\n\nhttp://lucumr.pocoo.org/projects/\n\n> 推荐理由，此大牛不但高产，而且项目几乎都开源，大牛的博客也几乎都是计算机领域相关的思考和讨论，对于计算机行业深入了解非常有意义。","src/content/posts/weekly-0002.mdx","a421c4f0de041edb","weekly-0002.mdx","weekly-0004",{"id":1555,"data":1557,"body":1562,"filePath":1563,"digest":1564,"legacyId":1565,"deferredRender":22},{"title":1558,"summary":1559,"date":1560,"tags":1561,"group":1527,"featured":38},"本周值得读第4期","## 分布式",["Date","2018-06-22T00:00:00.000Z"],[],"## 分布式\n\n本周推荐分布式系统领域中一个非常知名的开源软件 Consul，由 hashicorp 开发，这家公司也是 vagrant 的背后的公司，主营云计算领域中的基础设施服务。\n\n**Consul**\n\nConsul 是由 Go 编写，使用部署都很简单，而且提供的功能非常强大包括：\n\n- 服务注册和发现\n- KV 存储\n- 多数据中心支持\n\nConsul 设计和实现非常值得学习，官方的文档写的逻辑调理而且深入浅出，是最好的 Consul 学习材料，如果想深入学习和实践分布式理论 Consul 值得参考：\n\n- https://www.consul.io/\n\n> 推荐理由，学习分布式的典型案例，包括一致性协议、分布式选举等\n\n## Go\n\nGo 标准库中实现了和各路数据库交互的标准，虽然说官方文档已经把这些标准库讲的很详细了，但是这些文档中并没有讲解如何使用这些接口和数据库交互，下面推荐的这个教程写的非常好，可以说是入门和了解 Go 和 database 交互最佳的教程\n\n\n**http://go-database-sql.org/overview.html**\n\n> 推荐理由，Go 数据库入门最佳教程","src/content/posts/weekly-0004.mdx","afecbea37f857cce","weekly-0004.mdx","weekly-0006",{"id":1566,"data":1568,"body":1574,"filePath":1575,"digest":1576,"legacyId":1577,"deferredRender":22},{"title":1569,"summary":1570,"date":1571,"tags":1572,"group":1527,"featured":38},"本周值得读第6期","## websocket",["Date","2018-08-18T00:00:00.000Z"],[1573],"websocket","## websocket \n\nwebsocket 是在 HTTP 协议之上利用 HTTP 的 TCP 连接实现的长连接协议，\n在需要和浏览器保持长连接以及需要双向通信的场景下经常使用，本周重点介绍有关 websocket ，包括介绍以及和 HTTP2 的对比等。\n\n**介绍**\n\n[An Introduction to WebSockets\n](http://blog.teamtreehouse.com/an-introduction-to-websockets)\n\n**Websocket 和 HTTP2 的对比**\n\n[How JavaScript works: Deep dive into WebSockets and HTTP/2 with SSE + how to pick the right path](https://blog.sessionstack.com/how-javascript-works-deep-dive-into-websockets-and-http-2-with-sse-how-to-pick-the-right-path-584e6b8e3bf7)\n\n## 大牛推荐\n\n本周推荐一名 Go 程序员，博客文章经常刊登有关 Go 的主题，也是悉尼 Go group 的组织者：\n\n博客地址 https://dave.cheney.net","src/content/posts/weekly-0006.mdx","db0b208df089ba53","weekly-0006.mdx","weekly-0005",{"id":1578,"data":1580,"body":1584,"filePath":1585,"digest":1586,"legacyId":1587,"deferredRender":22},{"title":1581,"summary":1522,"date":1582,"tags":1583,"group":1527,"featured":38},"本周值得读第5期",["Date","2018-07-01T00:00:00.000Z"],[1525],"## Go\n\n本周 Go 推荐官方博客的相关主题，Go 的官方博客对一些特定主题的解释非常值得反复阅读，对理解 Go 相关特性帮助很大，再此摘取：\n\n**Go 官方博客**\n\n- https://blog.golang.org/h2push\n- https://blog.golang.org/errors-are-values\n- https://blog.golang.org/package-names\n- https://blog.golang.org/constants\n- https://blog.golang.org/pipelines\n- https://blog.golang.org/strings\n- https://blog.golang.org/slices\n- https://blog.golang.org/advanced-go-concurrency-patterns\n- https://blog.golang.org/concurrency-is-not-parallelism\n- https://blog.golang.org/json-and-go\n- https://blog.golang.org/go-slices-usage-and-internals\n- https://blog.golang.org/error-handling-and-go\n- https://blog.golang.org/laws-of-reflection\n- https://blog.golang.org/organizing-go-code\n- https://blog.golang.org/race-detector\n- https://blog.golang.org/context\n- https://blog.golang.org/examples\n- https://blog.golang.org/http-tracing","src/content/posts/weekly-0005.mdx","7f9efd4fa64a1fe3","weekly-0005.mdx","what-about-consul",{"id":1588,"data":1590,"body":1595,"filePath":1596,"digest":1597,"legacyId":1598,"deferredRender":22},{"title":1591,"summary":1592,"date":1593,"tags":1594,"group":224,"featured":38},"Consul 安装和基本使用","## 什么是 consul",["Date","2017-11-15T00:00:00.000Z"],[224],"## 什么是 consul \n\n[Consul](https://www.consul.io/) 是一个服务配置和发现工具，它包含的主要特性有：\n\n### 服务发现\n\n通过 DNS 或 HTTP 对依赖的服务的进行发现。\n\n### 健康检查\n\nConsul clients 能够提供很多种表示服务健康状态的指标，包括服务请求状态，节点内存使用情况等，\n路由会依赖这些信息进行服务选择。\n\n### KV 存储\n\nConsul 支持 KV Store，application 可以利用其用来做动态配置、特性标识存储、节点选举、协调等，Consul 的 KV \n通过 HTTP API 调用，非常方便使用。\n\n### 多数据中心\n\nConsul 支持多数据中心，夸机房。\n\n\n## Consul 的基本概念\n\n### Agent\n\nConsul 是一个分布式，高可用的系统，组成 Consul 服务的每个节点都是一个 agent，agent 可以 server 或 client 的模式启动\n\n### Client\n\n负责转发所有的 RPC 到 server 节点，本身无状态且轻量级，因此可以部署大量的 client 节点\n\n### Server\n\n负责的数据存储和数据的复制集，一般 Consul server 由 3-5 个结点组成来达到高可用，server 之间能够进行相互选举。一个 datacenter 推荐至少有一个 Consul server 的集群。\n\n![](https://static.git-star.com/20160827175251975.png)\n\n## Agent 的生命周期\n\n当 agent 第一次创建，它并不知道 cluster 中的任何节点，为了发现其它节点，它必须加入到 cluster 中，这是通过 **join** 命令根据 agent 启动时的配置信息自动进行的。一旦节点加入，节点信息会被广播到整个 cluster，最终所有节点都会感知到对方。**如果 agent 是一个 server，其它 server 就会开始向它复制数据**。\n\n假如发生了网络故障，某些节点可能不可达。在这种情况下，不可达的节点被标记为 failed，由于没有办法区分究竟是网络故障还是 agent 自身发生了 crash，二者不区分对待。**一旦节点信息被标记为 failed，它的信息被记录到 service catalog 中**。\n\n当节点因为某种原因离开了 cluster，cluster 标记节点为 having left，**所有和节点相关的服务会立即注销**，如果 agent 是 server，replication 会停止。\n\n## 安装和启动\n\nConsul 使用 Go 编写，用 binary package 发布，可以非常容易安装和使用，在此页面 \nhttps://www.consul.io/downloads.html 下载所需平台的包，下载对应的 binary 包解压并且配置 consul binary 包对应的 Path 即可使用。\n\n- [linux path 配置](https://stackoverflow.com/questions/14637979/how-to-permanently-set-path-on-linux)\n- [windows path 配置](https://stackoverflow.com/questions/1618280/where-can-i-set-path-to-make-exe-on-windows)\n\n设置完 path 即可进行测试:\n\n```shell\nconsul\nUsage: consul [--version] [--help] \u003Ccommand> [\u003Cargs>]\n\nAvailable commands are:\n    agent          Runs a Consul agent\n    catalog        Interact with the catalog\n    event          Fire a new event\n    exec           Executes a command on Consul nodes\n    force-leave    Forces a member of the cluster to enter the \"left\" state\n    info           Provides debugging information for operators.\n    join           Tell Consul agent to join cluster\n    keygen         Generates a new encryption key\n    keyring        Manages gossip layer encryption keys\n    kv             Interact with the key-value store\n    leave          Gracefully leaves the Consul cluster and shuts down\n    lock           Execute a command holding a lock\n    maint          Controls node or service maintenance mode\n    members        Lists the members of a Consul cluster\n    monitor        Stream logs from a Consul agent\n    operator       Provides cluster-level tools for Consul operators\n    reload         Triggers the agent to reload configuration files\n    rtt            Estimates network round trip time between nodes\n    snapshot       Saves, restores and inspects snapshots of Consul server state\n    validate       Validate config files/directories\n    version        Prints the Consul version\n    watch          Watch for changes in Consul\n```\n\n### 启动 Consul agent\n\nConsul agent 启动之后 Consul 的服务才算是真正的建立了，agent 可以以 client 或 server 的形式启动，在一个 datacenter 中至少有一个 server，通常情况下推荐配置 3-5 个 server。\n\nServer 启动完毕之后，就可以把其他 agent 以 client 的形式启动。**Client 负责注册服务，健康检查，转发请求**。\n\n为了测试方便，我们以 dev 的模式启动 agent。\n```shell\nconsul agent -dev -node=zhaoyongqiang\n==> Starting Consul agent...\n==> Consul agent running!\n           Version: 'v1.0.0'\n           Node ID: '99fa5591-60cb-cd6f-2b82-046d63b50cbe'\n         Node name: 'zhaoyongqiangdeiMac.local'\n        Datacenter: 'dc1' (Segment: '\u003Call>')\n            Server: true (Bootstrap: false)\n       Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, DNS: 8600)\n      Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)\n           Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false\n\n==> Log data will now stream in as it occurs:\n\n    2017/11/15 18:37:06 [DEBUG] Using random ID \"99fa5591-60cb-cd6f-2b82-046d63b50cbe\" as node ID\n    2017/11/15 18:37:06 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:99fa5591-60cb-cd6f-2b82-046d63b50cbe Address:127.0.0.1:8300}]\n    2017/11/15 18:37:06 [INFO] raft: Node at 127.0.0.1:8300 [Follower] entering Follower state (Leader: \"\")\n    2017/11/15 18:37:06 [INFO] serf: EventMemberJoin: zhaoyongqiangdeiMac.local.dc1 127.0.0.1\n    2017/11/15 18:37:06 [INFO] serf: EventMemberJoin: zhaoyongqiangdeiMac.local 127.0.0.1\n    2017/11/15 18:37:06 [INFO] consul: Handled member-join event for server \"zhaoyongqiangdeiMac.local.dc1\" in area \"wan\"\n    2017/11/15 18:37:06 [INFO] consul: Adding LAN server zhaoyongqiangdeiMac.local (Addr: tcp/127.0.0.1:8300) (DC: dc1)\n    2017/11/15 18:37:06 [INFO] agent: Started DNS server 127.0.0.1:8600 (tcp)\n    2017/11/15 18:37:06 [INFO] agent: Started DNS server 127.0.0.1:8600 (udp)\n    2017/11/15 18:37:06 [INFO] agent: Started HTTP server on 127.0.0.1:8500 (tcp)\n    2017/11/15 18:37:06 [WARN] raft: Heartbeat timeout from \"\" reached, starting election\n    2017/11/15 18:37:06 [INFO] raft: Node at 127.0.0.1:8300 [Candidate] entering Candidate state in term 2\n    2017/11/15 18:37:06 [DEBUG] raft: Votes needed: 1\n    2017/11/15 18:37:06 [DEBUG] raft: Vote granted from 99fa5591-60cb-cd6f-2b82-046d63b50cbe in term 2. Tally: 1\n    2017/11/15 18:37:06 [INFO] raft: Election won. Tally: 1\n    2017/11/15 18:37:06 [INFO] raft: Node at 127.0.0.1:8300 [Leader] entering Leader state\n    2017/11/15 18:37:06 [INFO] consul: cluster leadership acquired\n    2017/11/15 18:37:06 [INFO] consul: New leader elected: zhaoyongqiangdeiMac.local\n    2017/11/15 18:37:06 [DEBUG] consul: Skipping self join check for \"zhaoyongqiangdeiMac.local\" since the cluster is too small\n    2017/11/15 18:37:06 [INFO] consul: member 'zhaoyongqiangdeiMac.local' joined, marking health alive\n    2017/11/15 18:37:07 [INFO] agent: Synced node info\n    2017/11/15 18:38:06 [DEBUG] consul: Skipping self join check for \"zhaoyongqiangdeiMac.local\" since the cluster is too small\n    2017/11/15 18:38:07 [DEBUG] agent: Node info in sync\n    2017/11/15 18:39:06 [DEBUG] manager: Rebalanced 1 servers, next active server is zhaoyongqiangdeiMac.local.dc1 (Addr: tcp/127.0.0.1:8300) (DC: dc1)\n    2017/11/15 18:39:06 [DEBUG] consul: Skipping self join check for \"zhaoyongqiangdeiMac.local\" since the cluster is too small\n    2017/11/15 18:39:47 [DEBUG] agent: Node info in sync\n```\n\n**注意 OS X 用户：Consul 使用 hostname 做 node name，如果 node name 包含句点，会导致 DNS 无法工作，所以需要显式设置 node name 用 -node flag**\n\nagent 启动之后输出的主要信息包括：\n\n- Node name - 唯一的节点名称，可以通过 -node 更改\n- Datacenter - 数据中心名称，可以通过 -datacenter 更改\n- Server 表明 - Agent 是否以 server 的形式启用\n- Client Addr - Client 使用的地址和端口\n- Cluster Addr - 在 Cluster 各个 agent 通信使用的地址和端口\n\n### Consul 集群成员\n\n使用 `consul members` 命令可以查看 cluster 中所有 node 的信息，执行此命令你可以看到已经在集群中的成员，输出包含：\n\n- Node 节点名称\n- Address 启动的地址\n- Status 节点健康状态\n- Type 节点类型\n\n```shell\nNode           Address         Status  Type    Build  Protocol  DC   Segment\nzhaoyongqiang  127.0.0.1:8301  alive   server  1.0.0  2         dc1  \u003Call>\n```\n\n可以使用 `-detailed` flag 获取更详细的信息。\n\nmembers 命令是基于 [gossip protocol](https://www.consul.io/docs/internals/gossip.html)，该协议属于最终一致性。这意味着，在任何时间通过从当前 agent 获取的信息并不一定是当前 server 的状态，为了获取节点的最新信息，可以 HTTP API 。\n\n```shell\ncurl localhost:8500/v1/catalog/nodes\n[\n    {\n        \"ID\": \"fc63fe61-00b4-92fe-9625-e88b804c23ea\",\n        \"Node\": \"zhaoyongqiang\",\n        \"Address\": \"127.0.0.1\",\n        \"Datacenter\": \"dc1\",\n        \"TaggedAddresses\": {\n            \"lan\": \"127.0.0.1\",\n            \"wan\": \"127.0.0.1\"\n        },\n        \"Meta\": {\n            \"consul-network-segment\": \"\"\n        },\n        \"CreateIndex\": 5,\n        \"ModifyIndex\": 6\n    }\n]\n```\n\n除此以外还可以使用 DNS Interface 查询，注意查询 DNS 时必须要指定到当前 agent 的 DNS server，默认是启动在 8600 端口的。\n\n```shell\ndig @127.0.0.1 -p 8600 zhaoyongqiang.node.consul\n; \u003C\u003C>> DiG 9.8.3-P1 \u003C\u003C>> @127.0.0.1 -p 8600 zhaoyongqiang.node.consul\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER\u003C\u003C- opcode: QUERY, status: NOERROR, id: 49030\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0\n;; WARNING: recursion requested but not available\n\n;; QUESTION SECTION:\n;zhaoyongqiang.node.consul. IN  A\n\n;; ANSWER SECTION:\nzhaoyongqiang.node.consul. 0    IN  A   127.0.0.1\n\n;; Query time: 0 msec\n;; SERVER: 127.0.0.1#8600(127.0.0.1)\n;; WHEN: Wed Nov 15 18:51:20 2017\n;; MSG SIZE  rcvd: 59\n```\n\n### 停止 agent\n\n使用 Ctrl-C 停止启动的 agent，一旦 agent 终止，这个 node 将会从 cluster 中移除。\n\n如果 agent 的退出是 gracefully 的，Consule 会通知 cluster 中的其它成员该节点离线了。 如果强制停止 agent，其它 agent 会自动检测失联的 agent 并且从 cluster 中移除，如果一个 member 失联出故障了，健康状态会标志位变成 critical，但是其并不会从 catalog 移除。Consul 会在该成员下次上线之后重新连接，这种机制能保证能从特定的网络故障中恢复。\n\n如果 agent 是 server 模式启动的，graceful 移除可以避免潜在的存储问题。如何安全的添加和移除节点见 [guides section](https://www.consul.io/docs/guides/index.html)。\n\n## **参考资料**\n\n- https://www.consul.io/intro/getting-started/agent.html","src/content/posts/what-about-consul.mdx","3c843e937f4fd1cc","what-about-consul.mdx","why-did-i-make-turbo",{"id":1599,"data":1601,"body":1608,"filePath":1609,"digest":1610,"legacyId":1611,"deferredRender":22},{"title":1602,"summary":1603,"date":1604,"tags":1605,"group":1409,"featured":38},"python 轮子 turbo 的诞生记","> turbo 与其说是一个 framework ，不如说是一个后端的解决方案。",["Date","2016-07-23T00:00:00.000Z"],[1409,1606,1607],"backend","wheel","> [turbo](https://github.com/wecatch/app-turbo) 与其说是一个 framework ，不如说是一个后端的解决方案。\n\n## turbo 是如何诞生的?\n\ntornado 是异步非阻塞的 web 服务器，同时也是一个 web framework，功能简单但完全够用。\n\n原东家的技术栈是：tornado、mongodb、redis、openresty，最大的服务每天服务的独立用户有上百万。早期大部分项目完全使用 tornado 最原始的方式构建，一个 main 文件包含几百个路由，所有的 handler 分布在十几个大大小小的文件夹下面，项目基本的文件结构包含：\n\n- 一个抽象的 dal 层(数据抽象)\n- 数据库连接(db)\n- 配置(conf)\n- 工具(utils)\n- 缓存(cache)\n- 第三方库(lib)\n\n随着项目的代码越来越多，多个特性开发常常同时进行，开发人员经常要非常小心地应对代码的更改，即使如此，冲突依然时常发生，代码的可维护性和健壮性日益变差。\n\n创业公司由于业务面临飞速增长，多条业务线齐头并进，开发团队往往要同时维护很多个项目，有的项目生命周期很短，一次活动就结束了，有的项目要对外合作，随合作的结束而结束，有的项目服务新的产品，需要快速构建。不同的项目由不同的开发人员创建，创建项目的方式基本是 copy 旧项目，比较原始，容易出错。项目结构在不同的项目之间的差异随着业务的不同，差别渐渐凸显，重复的功能性代码和工具性代码也逐渐变多。\n\n\n{/* more */}\n\n\n在这样的背景之下，影响后端开发效率和开发质量主要问题可归纳为：\n\n- 大项目路由多，不易管理，不易变更\n- 项目目录分层不够，协同开发困难\n- 构建没有标准，混乱不堪，可维护性差\n- 重复性代码可共享性差，不易插拔\n- tornado 天生原始，没有 Session、数据库连接、配套的 mongodb ORM、缓存管理、RESTFul等丰富特性辅以提高开发效率。\n\nturbo 就是为解决这些问题而创建的，因而 turbo 更像是一个解决方案。\n\n\n## turbo 具有什么特性？\n\n- 项目构建工具，一键生成项目目录和 app 结构\n- Session，提供灵活的接口，可以自定义存储方式\n- 简单的 mongodb ORM，和 mongoose 相比，非常简单甚至粗糙，但足够用了\n- 丰富且高度统一的目录划分，项目再大也不怕\n- 代码可插拔，易移植，易维护\n- 可以方便实现 RESTFul 风格的 api\n- 灵活的路由组织结构，非常方便重构和查找\n\n### 一键构建\n\n目录结构一键生成，不再是从旧项目拷贝，结构一致，高度统一，可维护性变强。\n\n```bash\n% turbo-admin -h                                                                                                                                                        \nturbo init project, server or app.\n    Usage:\n      turbo-admin (-h | --help)\n      turbo-admin startproject  \u003Cproject>\n      turbo-admin startserver   \u003Cserver>\n      turbo-admin startapp      \u003Capp>\n      turbo-admin index         \u003Cmodel_name>\n\n    Options:\n      -h,  --help        Show help document\n\n% turbo-admin startproject hello-turbo\n% cd hello-turbo\n% tree -L 2\n├── app-server\n│   ├── apps\n│   ├── main.py\n│   ├── setting.py\n│   ├── static\n│   └── templates\n├── config\n│   └── __init__.py\n├── db\n│   ├── __init__.py\n│   ├── conn.py\n│   └── setting.py\n├── helpers\n│   ├── __init__.py\n│   ├── settings.py\n│   └── user\n├── lib\n│   ├── __init__.py\n│   └── session.py\n├── models\n│   ├── __init__.py\n│   ├── base.py\n│   ├── settings.py\n│   └── user\n├── service\n│   └── __init__.py\n├── store\n│   ├── __init__.py\n│   ├── actions.py\n│   ├── modules\n│   └── mutation_types.py\n└── utils\n    └── __init__.py\n```\n\n### Session\n\n自带 Session，存储方式可以自由变更，灵活性强。\n\n```python\n\nfrom turbo.session import HeaderObject, CookieObject\nfrom turbo.session import Store, RedisStore, DiskStore\n\n```\n\n### 简单的 mongodb ORM \n\nORM 提供最基本的 collection 结构到代码的映射，表结构清晰明了，增删改均可灵活定义数据一致性检查。\n\n```python\n\nimport turbo.model\n\nclass Category(turbo.model.BaseModel):\n\n    \"\"\"分类\n\n    field:\n        name: 名称\n        ename: 英文名\n        desc: 描述\n        tag: 标签列表\n        sn: 序号\n        nvideo: 视频数量\n        cover: 封面\n        uid: 创建用户\n        atime: 时间\n    \"\"\"\n\n    name = 'category'\n    field = {\n        'name':             (basestring, ''),\n        'ename':            (basestring, ''),\n        'desc':             (basestring, ''),\n        'tag':              (list, []),\n\n        'sn':               (int, 0),\n        'nvideo':           (int, 0),\n\n        'cover':            (ObjectId, None),\n        'uid':              (ObjectId, None),\n\n        'atime':            (datetime, None),\n    }\n\n\n```\n\n### 丰富的目录结构划分\n\n严格定义了各个目录的结构的作用以及层次，提供了一般大型项目所需的各种目录划分\n\n```bash\n├── README.md\n├── app-server # 业务 server\n├── config # 全局配置\n├── db # db 连接\n├── helpers # 全局业务逻辑\n├── lib # 第三方依赖库\n├── models # 表结构\n├── script # 一次性脚本\n├── service # 业务性工具\n├── store # 全局状态管理\n├── task # 异步任务\n├── utils # 非业务性工具\n\n```\n\n### 代码可插拔, 易移植\n\n```bash\napps\n├── __init__.py\n├── app\n│   ├── __init__.py\n│   ├── app.py\n│   ├── base.py\n│   ├── setting.py\n├── base.py\n├── settings.py\n\n```\n\n每个业务 app 都具有一样的结构，配置和业务代码随着业务所需分布在各个不同的层次，抽象程度越高的代码，所在层次越高，比如全局合法性检查可以放置在 `apps/base.py` 中，越具体的业务所在的层次越低，比如具体的注册登录逻辑可以放置在 `apps/app/app.py` 中。如果业务发生变更，业务目录 `app` 可完整移植。\n\n所有业务 `app` 都必须在 `apps/settings.py` 下注册才能生效，上下线 so easy.\n\n### RESTFul api\n\nhttp 协议所支持的方法都可以在 turbo 中以大小写的方式区分来实现普通页面 render 和接口 api\n\n\n```python\n# render \ndef get(self):\n    pass\n    \n# api  \ndef GET(self):\n    self._data = {'username': 'zhyq0826'}\n\n```\n\n### 灵活的路由\n\n路由紧随业务代码，turbo 提供了\n\n- register_group_urls\n- register_url\n\n两种方式来实现路由的注册\n\n```python\n\nregister.register_group_urls('', [\n    ('/', app.HomeHandler),\n    ('/index', app.HomeHandler, 'index'),\n    ('/hello', app.HomeHandler, 'home'),\n])\n\nregister.register_url('/v1/hello', app.ApiHandler)\n\n```\n\n可以十分方便的更改路由规则。\n\n### 集成很多实用的功能特性\n\n在使用mongodb 和 tornado 的实际开发中遇到了各式各样的问题，因而 turbo 自身在发展过程中集成了很多小功能，非常实用。\n\n\n1.可以使用命令行一键生成所有 collection 的索引\n\n```bash\nturbo-admin index \u003Cmodel_name>\n```\n\n2.类似 flux 的状态和事件分发机制，可以非常方便管理和更改全局变量状态，此特性可以用以请求统计，函数调用统计等方面\n\n```python\n#user.py\n\nfrom turbo.flux import Mutation, register, State\n\nmutation = Mutation(__file__)\nstate = State(__file__)\n\n@register(mutation)\ndef increase_rank(rank):\n    return rank+1\n\n\n@register(mutation)\ndef dec_rank(rank):\n    return rank-1\n    \n#actions.py\n\nfrom turbo.flux import Mutation, register, dispatch, register_dispatch\n\nimport mutation_types\n\n@register_dispatch('user', mutation_types.INCREASE)\ndef increase(rank):\n    pass\n\n\ndef decrease(rank):\n    return dispatch('user', mutation_types.DECREASE, rank)\n\n\n@register_dispatch('metric', 'inc_qps')\ndef inc_qps():\n    pass\n\n```\n\n3.mongodb 读写调用 hook，利用该 hook ，可以统计 mongodb 读写调用状况\n\n```python\n\nclass Model(turbo.model.BaseModel):\n\n    def write_action_call(self, name, *args, **kwargs):\n        \"\"\"\n        execute when write action occurs, note: in this method write action must be called asynchronously\n        \"\"\"\n        pass\n\n    def read_action_call(self, name, *args, **kwargs):\n        \"\"\"\n        execute when read action occurs, note: in this method read action must be called asynchronously\n        \"\"\"\n        pass\n\n```\n\n4.日志可以根据文件所在路径生成 logger 名称，也可以自定义 logger 路径、级别、名称等\n```python\n\nfrom turbo.util import getLogger\n\nlogger = getLogger(__file__)\n\nlogger = getLogger('feed', log_level=logging.DEBUG, log_path='/var/log/feed.log')\n\n```\n\n5.字符串化 mongodb 数据\n\n```python\n\nfrom turbo.util import to_str, to_list_str, to_dict_str, json_encode\n\ndata  = json_encode(to_str(db.collection.find()))\n\n```\n6.参数快捷提取和转换\n\n```python\n\n    _get_params = {\n        'need': [\n            ('skip', int),\n            ('limit', int),\n        ],\n        'option': [\n            ('did', basestring, None)\n        ]\n    }\n\n\n```\n\n可调用 self.parameters 完成参数提取工作，必须的参数不存在或转换错误时，值为 `None`，可选的参数可以指定默认值。\n\n```python\nassert self.parameters['skip'] == 0\nassert self.parameters['did'] == None\n```\n\n> 除上面列举的之外，turbo 还具有很多实用的特性，仓库地址：https://github.com/wecatch/app-turbo\n\n## 适时而建的轮子 turbo \n\nturbo 在生产环境中应用了近一年，最大的项目日独立用户过百万，还有十多个大大小小的项目的后端使用了 turbo，已经经过了最初的考验。\n\n后端的轮子相比前端来说，远不如后者的来的快、来的猛，后端需要更长久的磨练和雕琢，一点一滴都需要经过业务的锤炼和数据的洗礼，才能渐成佳品，成为解决特定问题的利器。而轮子的创造更要把握时机，顺势而发，过早，轮子不够健全，解决问题不够彻底，很难推广使用，甚至有可能成了绊脚石，过晚，很多问题已经导致代码积劳成疾，想要完全治愈，必然代价不菲。\n\nturbo 正是为了解决 tornado 和 mongodb 类应用在面对代码规模庞大、多人协同所遭遇的种种问题而创造的，它的立足点非常实际，没有炫技，不浮夸，切中要害，直面问题。\n\nturbo 的实用就是它的华丽所在。\n\n\n- [Github](https://github.com/wecatch/app-turbo) \n- QQ群交流: 387199856","src/content/posts/why-did-i-make-turbo.mdx","2a898c3e1403aca4","why-did-i-make-turbo.mdx","why-emberjs-is-best-for-cms",{"id":1612,"data":1614,"body":1620,"filePath":1621,"digest":1622,"legacyId":1623,"deferredRender":22},{"title":1615,"summary":1616,"date":1617,"tags":1618,"group":310,"featured":38},"为什么选择 emberjs 开发 dashboard 和 CMS 类系统","在开始之前，先看一组 github 数据",["Date","2016-06-04T00:00:00.000Z"],[1619],"emberjs","在开始之前，先看一组 github 数据\n\n**ember.js**\n\n- star 16291\n- contributors 586\n- releases  181\n- issues 167 open, 4397 closed\n\nhttps://github.com/emberjs/ember.js\n\n**angular.js**\n\n- star 49643\n- contributors 1476\n- releases 169\n- issues 817 open, 6992 closed\n\nhttps://github.com/angular/angular.js\n\n**vue.js**\n\n- star 19883\n- contributors 69\n- releases 137\n- issues 27 open, 2252 closed\n\nhttps://github.com/vuejs/vue\n\n\n**react.js**\n\n- star 43026\n- contributors 713\n- releases 46\n- issues 480 open, 2843 closed\n\nhttps://github.com/facebook/react\n\n\n**riot.js**\n\n- star 9565\n- contributors 138\n- releases 137\n- issues 96 open, 1089 closed\n\n\nhttps://github.com/riot/riot\n\n> 注: 统计时间为本文编写之时\n\nemberjs 和其他同类框架一样，至少在 github 的 表现足以证明其流行度是不低的，但各个框架的诞生的场景以及解决的问题又不尽相同。\n\nemberjs 是基于 jquery 的一个全栈式前端框架，它提供了从路由层-> view 层->数据和网络交互层的全部解决方案，只用 emberjs 就足以解决前端单页应用遇到的所有复杂问题，而且兼具有不俗的开发效率和开发质量。\n\n{/* more */}\n\n## emberjs 的特性\n\n### 全栈式解决方案\n\nemberjs 是一个大而全的框架，它几乎囊括了单页应用开发所需要的方方面面: component，model，service，route，temlate\n，ember-data。借助 emberjs 几乎可以完成任何规模的复杂应用，而不用担心它没有提供足够丰富的特性或者需要求助其他第三方库(不一定可以很好的和框架本身集成)。\n\n\n### 基于 jquery \n\nemberjs 是完全基于 jquery 的，意味着任何基于 jquery 的第三方库都可以和 ember app 集成，而这些年构建于  jquery 之上的框架和插件不计其数，在没有必要重复造轮子的地方，完全可以用丰富的第三方轮子替代，比如 bootstrap，semantic-ui 这种大而全的 UI framework，jQuery-File-Upload 这种可以兼容各种主流浏览器的文件上传组件。利用这一优势，大量现成的 jquery 插件能很快集在 ember app 中，借助 ember component 又可以很轻松达到复用的目的。\n\n### 良好的兼容性\n\n最低能够兼容到 IE 8，新版本也在逐步淘汰低版本IE的兼容。\n\n### 约定优于配置\n\n开发、管理和维护复杂的单页应用，是一件非常考验组织架构的事情，组件的复用、网络的交互、全局状态的管理、复杂的表单数据、路由等都需要经过精心设计和严格的代码规范才能最大限度的保证在多人协同开发之下，代码仍具有良好的维护成本和高效高质的产出。emberjs 秉承约定由于配置的理念，已经在框架层面把应用的最基本结构确定了，开发者只需要顺势而为，即可保证代码的可维护性和可协作性。\n\n\n### 数据的双向绑定\n\n不同于在 react 中，数据只能单向流动，emberjs 中的数据默认是双向的，这意味着数据的变更完全交由框架处理，虽然双向数据绑定在复杂应用中易于导致数据的状态变更不易跟踪和维护，但是对于频繁且复杂的表单处理，双向绑定可以极大的提高开发效率，通过一定的约束和规范，让双向绑定在可控的范围内发生，并不会对维护造成太大的影响。\n\n\n### 传统的字符串模板\n\n对于习惯了传统模板的很多后端程序员来说，字符串模板非常易于接受和理解，几乎没有学习成本，而且能很好的反应 html 结构和视图，这点相对于 react 的 jsx 语法就有很大的不同。这点也足以构成像我这样的后端程序员偏爱 emberjs 的一个理由。\n\n\n### 完备的构建工具和构建流程\n\n\nemberjs 社区提供了完备的构建工具和构建流程来保证 ember app 的开发和发布效率，基上能完成在多种环境之下的一键开发和部署，非常方便。\n\n\n### 渐进式的向下兼容\n\n前端的发展日新月异，新技术层出不穷，要想一直惠于新技术和新方案的发展，需要不断的升级优化。这也带来了不小的升级维护开销。如果一个框架完全不考虑遗留系统，升级代价巨大，对于人力紧缺，时间宝贵的小团队来说，这样的代价负担不起。emberjs 很好的做到了这一点，基本每个版本都可以做出很平滑的过渡，而不是大规模的修改。在这一点上，angular 就显得非常激进。\n\n\n## emberjs 究竟适合什么样的场景\n\n- 全栈式解决方案\n- 基于 jquery \n- 约定优于配置\n- 数据的双向绑定\n- 传统的字符串模板\n- 完备的构建工具和构建流程\n\n基于这些特点，emberjs 非诚适合于\n\n- 需要一体化解决方案(懒)\n- 不会特别在乎体积，不会特别在乎性能(用的人不是很多，没有时间优化)\n- 需要一个大而全的 css framework，类似bootstrap，semantic-ui，foundation(还是懒)\n- 表单处理复杂(频繁创建和修改，查询)\n- 尽量利用第三方高质量的库来解决现成问题(缺乏足够的时间和精力造轮子)\n- 非专业前端程序员开发和维护(后端程序员开发和发布)\n- 不能花太多时间进行组织架构和代码规范(业务变更频繁，多人交叉开发，缺乏足够的经验和时间进行架构设计，缺前端)\n\n具有以上特点的各种复杂的 dashboard 和 内容管理应用。这类应用基本具备性能要求不高，但是需求变更频繁，表单处理复杂，由于频繁变更后端逻辑和数据结构，页面的组织结构和交互需要频繁修改。高频变更之下，要保证代码具有很强的一致性和可维护性，ember 约定优于配置的理念恰如其分得契合这样的需求。\n\n## emberjs 的问题\n\n1.体积庞大\n\nemberjs 的体积非常庞大\n\n\n| Framework              | Version    | Minified Size (gzip) |\n|------------------------|------------|----------------------|\n| Ember                                          | 2.5.0      | 117.26kb             |\n| Polymer + Web Components Polyfill Lite         | 1.4.0      | 54.48kb              |\n| Angular                                        | 1.5.0      | 53.17kb              |\n| React                                          | 15.0.2     | 43.62kb              |\n| Web Components Polyfill                        | 0.7.22     | 33.66kb              |\n| Vue                                            | 1.0.21     | 25.98kb              |\n| Riot                                           | 2.4.1      | 9.23kb               |\n\n\n单从体积上看，emberjs 显得过于雍正，但是在很多场景之下，体积根本不是需要考虑的因素。\n\n\n2.性能\n\n由于 emberjs 提供了单页应用开发所需要的几乎全部解决方案，相比于像 vuejs、reactjs、riot等这些专注于 UI 层的框架的的性能就有了一定的差距，再加上字符串模板天生特性和 emberjs 实现双向绑定的机制，性能不是很好是 emberjs 的一个问题，但是并不代表 emberjs 没有优化的空间。[discourse](http://www.discourse.org/) 就是很好的案例。点击查看 discourse 团队对 emberjs 的优化 [eviltrout](https://eviltrout.com/)。\n\n3.灵活性差\n\n大而全框架天生的缺陷\n\n4.学习曲线陡峭\n\n\nemberjs 特性众多，开发环境相对复杂，需要较长的时间入门和实践，尤其是对刚接触全栈式前端框架的初学者来说，要很好掌握component 交互、单双数据绑定使用场景、插件开发等需要花一定时间学习。\n\nemberjs 的开发一旦掌握，开发效率会出奇得快。\n\n\n## 选择合适的才是最好的\n\n我们的团队在生产环境中使用了 reactjs、emberjs、vuejs、riot，还有部分 angular 遗留项目。\n\nangular 是最初使用 js framework 时候的一个尝试，生产环境没有做过大规模得实践，现在基本放弃。\n\nriot 是个优秀框架，体积小，性能优越，灵活性极强，也正是这点，在代码量达到一定规模之后，如果架构设计跟不上代码量和复杂性的增长，可维护性会越来越差。riot 的轮子也很少。\n\nreact 的出现带来了前端跨越式地发展，也带来了全新的思维方式来构建前端 UI 层，几乎是一个全新生态，正因为如此， react 使用的所有轮子都需要重新打造才能完全发挥 react 带来的优势。还有一点是，JSX 的语法也完全不符合代码即视图的设计理念，需要时间适应。\n\nvue 同样是个十分优秀的框架，接口表现力强，学习成本低，能够很快入门，同样 vue 保留了 html 结构即视图的模板概念，使用起来非常顺手，结合 vue-router 和 vuex，一样可以构建非常复杂的应用。vue 的生态也缺乏足够多的轮子。\n\n对于面向大规模用户、性能要求卓越、灵活性强的、轮子不得不造、多人协作的场景，react 和 vue 是更合适的选择。但是面对类似 dashboard 和 CMS 这种表单处理众多、需求复杂的、变更频繁的业务场景，emberjs 可能是更好的选择。\n\n\n- 国内第一个 emberjs 讨论区 [emberjs-china](http://emberjs-china.org/)\n- 基于 semant-ui 的 ember addon [ember-semantic-ui](https://github.com/wecatch/ember-semantic-ui)\n- 比 ember-data 简单很多的 ORM [ember-easy-orm](https://github.com/wecatch/ember-easy-orm)","src/content/posts/why-emberjs-is-best-for-cms.mdx","0531ec4411188df8","why-emberjs-is-best-for-cms.mdx","why-pack-unpack",{"id":1624,"data":1626,"body":1631,"filePath":1632,"digest":1633,"legacyId":1634,"deferredRender":22},{"title":1627,"summary":1628,"date":1629,"tags":1630,"group":196,"featured":38},"Python 中的 pack 和 unpack","## 为什么要进行 pack 操作和 unpack 操作",["Date","2018-03-10T00:00:00.000Z"],[1163],"## 为什么要进行 pack 操作和 unpack 操作\n\n不同类型的语言支持不同的数据类型，比如 Go 有 int32、int64、uint32、uint64 等不同的数据类型，这些类型占用的字节大小不同，而同样的数据类型在其他语言中比如 Python 中，又是完全不同的处理方式，比如 Python 的 int 既可以是有符号的，也可以是无符号的，这样一来 Python 和 Go 在处理同样大小的数字时存储方式就有了差异。\n\n除了语言之间的差别，不同的计算机硬件存储数据的方式也有很大的差异，有的 32 bit 是一个 word，有的 64 bit 是一个 word，而且他们存储数据的方式或多或少都有些差异。\n\n当这些不同的语言以及不同的机器之间进行数据交换，比如通过 network 进行数据交换，他们需要对彼此发送和接受的字节流数据进行 pack 和 unpack 操作，以便数据可以正确的解析和存储。\n\n也就是说 pack 和 unpack 是用来在计算机之间以及不同语言之间进行网络交流时的对数据数据格式翻译和转换操作的。\n\n## 计算机如何存储整型\n\n可以把计算机的内存看做是一个很大的字节数组，一个字节包含 8 bit 信息可以表示 0-255 的无符号整型，以及 -128--127 的有符号整型。当存储一个大于 8 bit 的值到内存时，这个值常常会被切分成多个 8 bit 的 segment 存储在一个连续的内存空间，一个 segment 一个字节。有些处理器会把高位存储在内存这个字节数组的头部，把低位存储在尾部，这种处理方式叫 **big-endian**，有些处理器则相反，低位存储在头部，高位存储在尾部，称之为 **little-endian**。\n\n假设一个寄存器想要存储 0x12345678 到内存中，big-endian 和 little-endian 分别存储到内存 1000 的地址表示如下\n\n| address | big-endian | little-endian |\n| ------- | ---------- | ------------- |\n| 1000    | 0x12       | 0x78          |\n| 1001    | 0x34       | 0x56          |\n| 1002    | 0x56       | 0x34          |\n| 1003    | 0x78       | 0x12          |\n\nPython 中字节在机器中存储的字节顺序用字母表示如下：\n\n| Character | Byte order             | Size     | Alignment |\n| --------- | ---------------------- | -------- | --------- |\n| `@`       | native                 | native   | native    |\n| `=`       | native                 | standard | none      |\n| `\u003C`       | little-endian          | standard | none      |\n| `>`       | big-endian             | standard | none      |\n| `!`       | network (= big-endian) | standard | none      |\n\n\n## 计算机如何存储 character\n\n和存储 number 的方式类似，character 通过一定的编码格式进行编码比如 unicode，然后以字节的方式存储。\n\n## Python 中的 struct 模块\n\nPython 提供了三个与 pack 和 unpack 相关的函数\n\n```python\nstruct.pack(fmt, v1, v2, ...)\nstruct.unpack(fmt, string)\nstruct.calcsize(fmt)\n```\n\n第一个函数 `pack` 负责将不同的变量打包在一起，成为一个字节字符串。\n\n第二个函数 `unpack` 将字节字符串解包成为变量。\n\n第三个函数 `calsize` 计算按照格式 fmt 打包的结果有多少个字节。\n\n## pack 操作\n\nPack 操作必须接受一个 template string 以及需要进行 pack 一组数据，这就意味着 pack 处理操作**定长**的数据\n\n```python\nimport struct\n\na = struct.pack(\"2I3sI\", 12, 34, \"abc\", 56)\nb = struct.unpack(\"2I3sI\", a)\n\nprint b\n```\n\n上面的代码将两个整数 12 和 34，一个字符串 “abc” 和一个整数 56 一起打包成为一个字节字符流，然后再解包。其中打包格式中明确指出了打包的长度：`\"2I\"` 表明起始是两个`unsigned int`，`\"3s\"` 表明长度为 4 的字符串，最后一个 `\"I\"` 表示最后紧跟一个 `unsigned int`，所以上面的打印 b 输出结果是：(12, 34, ‘abc’, 56)，完整的 Python pack 操作支持的数据类型见下表。\n\n| Format | C Type               | Python type        | Standard size | Notes    |\n| ------ | -------------------- | ------------------ | ------------- | -------- |\n| `x`    | pad byte             | no value           |               |          |\n| `c`    | `char`               | string of length 1 | 1             |          |\n| `b`    | `signed char`        | integer            | 1             | (3)      |\n| `B`    | `unsigned char`      | integer            | 1             | (3)      |\n| `?`    | `_Bool`              | bool               | 1             | (1)      |\n| `h`    | `short`              | integer            | 2             | (3)      |\n| `H`    | `unsigned short`     | integer            | 2             | (3)      |\n| `i`    | `int`                | integer            | 4             | (3)      |\n| `I`    | `unsigned int`       | integer            | 4             | (3)      |\n| `l`    | `long`               | integer            | 4             | (3)      |\n| `L`    | `unsigned long`      | integer            | 4             | (3)      |\n| `q`    | `long long`          | integer            | 8             | (2), (3) |\n| `Q`    | `unsigned long long` | integer            | 8             | (2), (3) |\n| `f`    | `float`              | float              | 4             | (4)      |\n| `d`    | `double`             | float              | 8             | (4)      |\n| `s`    | `char[]`             | string             |               |          |\n| `p`    | `char[]`             | string             |               |          |\n| `P`    | `void *`             | integer            |               | (5), (3) |\n\n## 计算字节大小\n\n可以利用 calcsize 来计算模式 \"2I3sI\" 占用的字节数\n\n```python\nprint struct.calcsize(\"2I3sI\") # 16\n```\n\n可以看到上面的三个整型加一个 3 字符的字符串一共占用了 16 个字节。为什么会是 16 个字节呢？不应该是 15 个字节吗？1 个 int 4 字节，3 个字符 3 字节。但是在 `struct` 的打包过程中，根据特定类型的要求，必须进行字节对齐（关于字节对齐详见 https://en.wikipedia.org/wiki/Data_structure_alignment） 。由于默认 `unsigned int` 型占用四个字节，因此要在字符串的位置进行4字节对齐，因此即使是 3 个字符的字符串也要占用 4 个字节。\n\n再看一下不需要字节对齐的模式\n\n```python\nprint struct.calcsize(\"2Is\") # 9\n```\n\n由于单字符出现在两个整型之后，不需要进行字节对齐，所以输出结果是 9。\n\n## unpack 操作\n\n对于 `unpack` 而言，只要 `fmt` 对应的字节数和字节字符串 `string` 的字节数一致，就可以成功的进行解析，否则 `unpack` 函数将抛出异常。例如我们也可以使用如下的 `fmt` 解析出 `a`：\n\n```python\nc = struct.unpack(\"2I2sI\", a)\nprint struct.calcsize(\"2I2sI\")\nprint c   # 16 (12, 34, 'ab', 56)\n```\n\n## 不定长数据 pack\n\n如果打包的数据长度未知该如何打包，这样的打包在网络传输中非常常见。处理这种不定长的内容的主要思路是把长度和内容一起打包，解包时首先解析内容的长度，然后再读取正文。\n\n### 打包变长字符串\n\n对于变长字符在处理的时候可以把字符的长度当成数据的内容一起打包。\n\n```python\ns = bytes(s)\ndata = struct.pack(\"I%ds\" % (len(s),), len(s), s)\n```\n\n上面代码把字符 s 的长度打包成内容，可以在进行内容读取的时候直接读取。\n\n### 解包变长字符串\n\n```python\nint_size = struct.calcsize(\"I\")\n(i,), data = struct.unpack(\"I\", data[:int_size]), data[int_size:]\n```\n\n解包变长字符时首先解包内容的长度，在根据内容的长度解包数据\n\n## 参考资料\n\n- http://www.perlmonks.org/?node_id=224666\n- https://docs.python.org/2/library/struct.html\n- http://kaiyuan.me/2015/12/25/python-struct/","src/content/posts/why-pack-unpack.mdx","8ca0e3df6e0fda86","why-pack-unpack.mdx","projects",["Map",1637,1638],"personal-site",{"id":1637,"data":1639,"body":1650,"filePath":1651,"digest":1652,"legacyId":1653,"deferredRender":22},{"title":1640,"summary":1641,"date":1642,"tags":1643,"link":1647,"repo":1648,"status":1649},"个人站点（Astro + React）","Markdown/MDX 驱动的内容体系，时间线与评论集成的个人品牌站点。",["Date","2024-11-20T00:00:00.000Z"],[1644,1645,1646],"astro","mdx","branding","https://example.com","https://github.com/yourname/personal-site","released","特性：\n\n- Astro + React，静态优先\n- content collections 规范化 frontmatter\n- 时间线/分组视图，Utterances 评论","src/content/projects/personal-site.mdx","48e09ba013e3b873","personal-site.mdx","insights",["Map",1656,1657],"ai-frontend-radar",{"id":1656,"data":1658,"body":1666,"filePath":1667,"digest":1668,"legacyId":1669,"deferredRender":22},{"title":1659,"summary":1660,"date":1661,"tags":1662,"group":1664,"featured":38,"source":1665},"AI x 前端趋势速览","前端与 AI 的结合点：生成式 UI、设计落地、代码辅助与智能运维。",["Date","2024-10-28T00:00:00.000Z"],[1663,35],"ai","前沿资讯","https://example.com/ai-frontend","- 设计到代码：Figma/Sketch 插件直接生成可用组件\n- 自适应 UI：根据用户上下文动态调整布局与密度\n- 研发效率：代码补全 + 测试生成 + 提交前智能审查\n- 运行时：智能压测、错误聚类、回归影响面分析","src/content/insights/ai-frontend-radar.mdx","77c40209e708aa99","ai-frontend-radar.mdx","tools",["Map",1672,1673],"devlog-cli",{"id":1672,"data":1674,"body":1685,"filePath":1686,"digest":1687,"legacyId":1688,"deferredRender":22},{"title":1672,"summary":1675,"date":1676,"version":1677,"link":1678,"download":1679,"tags":1680,"changelog":1682},"命令行速记工具，把每日开发笔记直接写入 Markdown 并推送到仓库。",["Date","2024-09-15T00:00:00.000Z"],"0.3.0","https://example.com/devlog","https://example.com/devlog/download",[272,1681],"productivity",[1683,1684],"支持模版插入与标签","新增本地搜索与归档","用法：\n\n```bash\ndevlog init\ndevlog add \"支持站点时间线\" --tag timeline\ndevlog sync\n```","src/content/tools/devlog-cli.mdx","c6899d414b80f70b","devlog-cli.mdx"]